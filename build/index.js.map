{"version":3,"sources":["webpack://collection-storage/webpack/universalModuleDefinition","webpack://collection-storage/webpack/bootstrap","webpack://collection-storage/./src/interfaces/BaseCollection.ts","webpack://collection-storage/external \"crypto\"","webpack://collection-storage/./src/helpers/retry.ts","webpack://collection-storage/external \"mongodb\"","webpack://collection-storage/external \"zlib\"","webpack://collection-storage/external \"util\"","webpack://collection-storage/external \"url\"","webpack://collection-storage/external \"https\"","webpack://collection-storage/external \"http\"","webpack://collection-storage/./src/mongo/MongoCollection.ts","webpack://collection-storage/external \"ioredis\"","webpack://collection-storage/external \"pg\"","webpack://collection-storage/./src/helpers/serialiser.ts","webpack://collection-storage/./src/memory/MemoryCollection.ts","webpack://collection-storage/./src/interfaces/BaseDB.ts","webpack://collection-storage/./src/memory/MemoryDb.ts","webpack://collection-storage/./src/mongo/MongoDb.ts","webpack://collection-storage/./src/dynamodb/api/Results.ts","webpack://collection-storage/./src/dynamodb/api/AWSError.ts","webpack://collection-storage/./src/dynamodb/api/DDB.ts","webpack://collection-storage/./src/dynamodb/DynamoCollection.ts","webpack://collection-storage/./src/helpers/PromiseTracker.ts","webpack://collection-storage/./src/helpers/LruCache.ts","webpack://collection-storage/./src/dynamodb/api/AWS.ts","webpack://collection-storage/./src/dynamodb/DynamoDb.ts","webpack://collection-storage/./src/redis/helpers.ts","webpack://collection-storage/./src/redis/RedisCollection.ts","webpack://collection-storage/./src/redis/scripts.ts","webpack://collection-storage/./src/redis/RedisConnectionPool.ts","webpack://collection-storage/./src/redis/RedisDb.ts","webpack://collection-storage/./src/postgresql/hstore.ts","webpack://collection-storage/./src/postgresql/sql.ts","webpack://collection-storage/./src/postgresql/PostgresCollection.ts","webpack://collection-storage/./src/postgresql/PostgresDb.ts","webpack://collection-storage/./src/wrappers/WrappedCollection.ts","webpack://collection-storage/./src/wrappers/encryption/nodeEncryptionSync.ts","webpack://collection-storage/./src/wrappers/encrypted.ts","webpack://collection-storage/./src/wrappers/compressed.ts","webpack://collection-storage/./src/wrappers/migrated.ts","webpack://collection-storage/./src/index.ts","webpack://collection-storage/./src/CollectionStorage.ts"],"names":["root","factory","exports","module","define","amd","global","installedModules","__webpack_require__","moduleId","i","l","modules","call","m","c","d","name","getter","o","Object","defineProperty","enumerable","get","r","Symbol","toStringTag","value","t","mode","__esModule","ns","create","key","bind","n","object","property","prototype","hasOwnProperty","p","s","BaseCollection","constructor","keys","this","innerPreAct","preAct","entry","internalAdd","searchAttribute","searchValue","returnAttributes","isIndexed","Error","internalGet","internalGetAll","update","options","undefined","id","upsert","withoutId","internalUpsert","isIndexUnique","some","k","internalUpdate","internalRemove","wait","pending","addPending","Promise","resolve","reject","push","internalReady","async","e","forEach","f","attribute","keyOptions","Boolean","unique","require","sleep","millis","setTimeout","shouldRetry","timeoutMillis","initialDelayMillis","maxDelayMillis","delayGrowth","jitter","limit","Date","now","currentDelay","attempt","fn","delay","Math","min","random","message","DOT_REG","fieldNameToMongo","encodeURIComponent","replace","MONGO_ERROR_IDX","withUpsertRetry","retry","MongoError","code","exec","getErrorIndex","convertToMongo","converted","v","Buffer","MBinary","_bsontype","convertFromMongo","buffer","decodeURIComponent","makeMongoProjection","names","projection","fieldName","configureCollection","collection","existing","indexes","catch","idxToCreate","idxToDelete","Set","map","idx","delete","keyName","makeIndex","index","match","find","a","b","aKey","bKey","length","every","indicesMatch","createIndexes","size","all","idxName","dropIndex","MongoCollection","stateRef","closed","super","initAsync","insertOne","updateOne","$set","query","mongoUpdate","updateMany","findOne","cursor","result","raw","deleteMany","deletedCount","MARK_BINARY","charCodeAt","MARK_STRING","MARK_BINARY_BUFF","Uint8Array","of","serialiseValue","toString","JSON","stringify","deserialiseValue","type","data","substr","from","parse","includes","serialiseValueBin","concat","deserialiseValueBin","subarray","serialiseRecord","record","deserialiseRecord","MemoryCollection","simulatedLatency","Map","indices","serialised","internalCheckDuplicates","set","internalPopulateIndices","has","updates","internalGetSerialisedIds","sId","oldSerialised","oldValue","newValue","newSerialised","internalRemoveIndices","sIds","fields","field","applyFilter","sKey","serialisedValue","checkId","add","BaseDB","makeCollection","getCollection","cached","collectionCache","normKeys","sort","join","cachedNormKeys","cachedCol","created","close","syncClose","toAwait","values","allSettled","then","internalClose","globalDbs","initial","getGlobal","MemoryDb","url","parsedUrl","URL","hostname","params","searchParams","Number","db","MongoDb","client","escapeName","MongoClient","default","connect","useNewUrlParser","useUnifiedTopology","getDb","Paged","aws","pageLimit","POSITIVE_INFINITY","batched","consumer","do","lastKey","page","pageItems","nextKey","items","AWSError","status","isType","endsWith","isTransient","AWS_URL_FORMAT","ifNotEmpty","flatten","escapedExpressions","expressions","attrValues","attrNames","hasExpr","hasAnyValues","attributeExpression","joiner","attributes","parts","hasValues","Array","isArray","rawAttrNames","attr","attrName","attrValue","ExpressionAttributeValues","ExpressionAttributeNames","attrs","retryPolling","retryRemaining","INVALID_NAME_CHARS","hex","padStart","padEnd","createAttributeDefinitions","schemas","attributeName","attributeType","entries","AttributeName","AttributeType","createSecondaryIndex","IndexName","indexName","KeySchema","keySchema","keyType","KeyType","Projection","ProjectionType","projectionType","nonKeyAttributes","NonKeyAttributes","ProvisionedThroughput","throughput","DDB","host","consistentRead","region","getConsumedUnits","totalCapacityUnits","getTableNames","response","ExclusiveStartTableName","lastTableName","TableNames","LastEvaluatedTableName","upsertTable","tableName","pKeySchema","secondaryIndices","waitForReady","TableName","AttributeDefinitions","GlobalSecondaryIndexes","BillingMode","replaceIndices","waitForTable","describeTable","waitForIndices","desc","Table","TableStatus","IndexStatus","item","Item","ConditionExpression","ReturnConsumedCapacity","condition","Key","UpdateExpression","requestedAttrs","ProjectionExpression","ConsistentRead","getItem","keyAttrs","fullAttrs","slice","extracted","tableQuery","callBatched","RequestItems","Keys","batchKeys","Responses","UnprocessedKeys","batchPutItems","batchItems","PutRequest","UnprocessedItems","batchDeleteItems","DeleteRequest","getAllItems","ExclusiveStartKey","Items","LastEvaluatedKey","limitOne","colocatedAttrs","nonColocatedAttrs","KeyConditionExpression","Limit","pkItems","batchGetItems","filter","callDelete","deleteAndReturnItem","returnOld","ReturnValues","Attributes","toCreate","oldIndices","old","toDelete","GlobalSecondaryIndexUpdates","Delete","Create","batchLimit","remaining","queue","splice","retryItems","fnName","body","request","method","service","headers","json","ConsumedCapacity","capacity","reduce","CapacityUnits","wrapError","handleError","ignore","toDynamoValue","B","toDynamoItem","isDynamoBinary","fromDynamoItem","fromDynamoValue","toDynamoKey","INDEX_META_KEY","indexTable","toDDBThroughput","ReadCapacityUnits","max","ceil","read","WriteCapacityUnits","write","getCombinedThroughput","throughputFn","totalThroughput","hasThroughput","cur","configureTable","ddb","nonuniqueKeys","uniqueKeys","indexTableName","deleteTable","info","ix","newKeys","oldKeys","SS","indexItems","putItem","DynamoCollection","itemId","itemNoKey","updateItem","_","getItemsBySecondaryKey","ddbSearchValue","ddbItem","filteredReturn","assign","primaryItem","deleteItem","success","successes","successesOut","failures","runAll","atomicPutUniques","updatedUnique","changedAttrs","PromiseTracker","flightResolve","flight","inflight","finally","current","clear","LruCache","calc","storage","flush","remove","next","EMPTY_BUFFER","alloc","ISO_TIME_STRIP","ALGORITHM","withTransientErrorRetry","sha256","hash","createHash","digest","hmac","createHmac","AWS","keyID","secret","baseKey","date","parsedURL","search","binaryBody","canonicalTime","toISOString","canonicalDate","credentialScope","getKey","canonicalPath","encodeURI","decodeURI","pathname","allHeaders","Host","headerNames","header","toLowerCase","canonicalHeaders","signedHeaders","canonicalRequest","signature","Authorization","fetch","protocol","https","http","req","res","on","chunk","text","statusCode","__type","end","keyCache","kRegion","keyCacheRegion","keyCacheDate","DynamoDb","tableNamePrefix","parsed","username","password","process","env","AWS_ACCESS_KEY_ID","AWS_SECRET_ACCESS_KEY","split","parseInt","getDDB","minifyLuaScript","lines","argNames","combined","ln","trim","RegExp","notUndefined","makeIndexKeys","partialSerialisedValue","prefix","parseItem","itemHasContent","unwatchAll","unwatch","mapAwaitSync","RedisCollection","pool","keyPrefix","keyPrefixes","keyInfo","nonUniqueKeys","withConnection","runAdd","patchSerialised","retryWithConnection","patch","getUpdatePatch","runUpdates","insertValue","getAndWatchBySerialisedKey","patches","getByKeysKeepWatches","makeKey","cut","indexedKeys","rawByKeyKeepWatches","pipeline","multi","serialisedId","checkWatch","keyCount","flat","watch","argsList","makeUpdateArgs","results","updateArgs","checkUpdate","chain","updateWithoutCheck","diff","patchUniqueKeys","patchNonUniqueKeys","oldUniqueKeys","oldNonUniqueKeys","serialisedIds","commands","multiExec","exists","hmget","hgetall","keyAddress","smembers","SCRIPT_ADD","FRAG_CHECK_UPDATE","FRAG_UPDATE","SCRIPT_CHECK_UPDATE","SCRIPT_UPDATE_WITHOUT_CHECK","SCRIPT_UPDATE","SCRIPT_REMOVE","withRetry","RedisConnectionPool","RedisStatic","maxConnections","teardown","getConnection","returnConnection","inUse","doClose","closingFn","connections","disconnect","pop","defineCommand","lua","defineAllScripts","q","shift","RedisDb","lazyConnect","getConnectionPool","quoteHValue","DQUOTE_REG","SQUOTE_REG","quoteValue","msg","ID_REG","withIdentifiers","base","identifiers","STATEMENTS","CREATE_TABLE","GET_INDEX_NAMES","CREATE_INDEX","CREATE_UNIQUE_INDEX","DROP_INDEX","INSERT","UPDATE","UPDATE_ID","UPSERT_ID","SELECT_ONE","SELECT_ALL","SELECT_ALL_BY","SELECT_ID","DELETE","DELETE_ID","toHStore","encodeHStore","fromHStore","rawMap","hstore","currentKey","quote","decodeHStore","PostgresCollection","T","rowMode","oldIndexNames","rows","startsWith","keyEntries","I","indicesToDelete","release","rest","runTableQuery","rowCount","queryName","cachedQueries","PostgresDb","Pool","connectionString","hasAnyField","WrappedCollection","baseCollection","wrapper","wrapAll","unwrapAll","getAll","extra","preRemove","processed","preWrap","allFields","wrap","preUnwrap","unwrap","ALG","ALG_BUF","nodeEncryptionSync","encrypt","iv","crypto","randomBytes","cipher","createCipheriv","part","final","decrypt","equals","encrypted","decipher","createDecipheriv","generateKey","createSecretKey","serialiseKey","export","deserialiseKey","makeEncrypter","encryptByKey","encryption","allowRaw","encryptByRecord","keyCollection","cacheSize","cache","loadKey","generateIfNeeded","cachedAsync","removeKey","encryptByRecordWithMasterKey","sMasterKey","opts","keyEnc","gzipCompress","promisify","zlib","gzip","gzipDecompress","gunzip","MARK_UNCOMPRESSED","compress","compressionThresholdBytes","gzipped","compressValue","allowRawBuffer","decompressValue","MigratedCollection","migrations","extraFetchFields","extendAttributes","applyMigration","migration","migrate","CollectionStorage","dbClass"],"mappings":"CAAA,SAA2CA,EAAMC,GAC1B,iBAAZC,SAA0C,iBAAXC,OACxCA,OAAOD,QAAUD,IACQ,mBAAXG,QAAyBA,OAAOC,IAC9CD,OAAO,qBAAsB,GAAIH,GACP,iBAAZC,QACdA,QAAQ,sBAAwBD,IAEhCD,EAAK,sBAAwBC,IAR/B,CASGK,QAAQ,WACX,O,YCTE,IAAIC,EAAmB,GAGvB,SAASC,EAAoBC,GAG5B,GAAGF,EAAiBE,GACnB,OAAOF,EAAiBE,GAAUP,QAGnC,IAAIC,EAASI,EAAiBE,GAAY,CACzCC,EAAGD,EACHE,GAAG,EACHT,QAAS,IAUV,OANAU,EAAQH,GAAUI,KAAKV,EAAOD,QAASC,EAAQA,EAAOD,QAASM,GAG/DL,EAAOQ,GAAI,EAGJR,EAAOD,QA0Df,OArDAM,EAAoBM,EAAIF,EAGxBJ,EAAoBO,EAAIR,EAGxBC,EAAoBQ,EAAI,SAASd,EAASe,EAAMC,GAC3CV,EAAoBW,EAAEjB,EAASe,IAClCG,OAAOC,eAAenB,EAASe,EAAM,CAAEK,YAAY,EAAMC,IAAKL,KAKhEV,EAAoBgB,EAAI,SAAStB,GACX,oBAAXuB,QAA0BA,OAAOC,aAC1CN,OAAOC,eAAenB,EAASuB,OAAOC,YAAa,CAAEC,MAAO,WAE7DP,OAAOC,eAAenB,EAAS,aAAc,CAAEyB,OAAO,KAQvDnB,EAAoBoB,EAAI,SAASD,EAAOE,GAEvC,GADU,EAAPA,IAAUF,EAAQnB,EAAoBmB,IAC/B,EAAPE,EAAU,OAAOF,EACpB,GAAW,EAAPE,GAA8B,iBAAVF,GAAsBA,GAASA,EAAMG,WAAY,OAAOH,EAChF,IAAII,EAAKX,OAAOY,OAAO,MAGvB,GAFAxB,EAAoBgB,EAAEO,GACtBX,OAAOC,eAAeU,EAAI,UAAW,CAAET,YAAY,EAAMK,MAAOA,IACtD,EAAPE,GAA4B,iBAATF,EAAmB,IAAI,IAAIM,KAAON,EAAOnB,EAAoBQ,EAAEe,EAAIE,EAAK,SAASA,GAAO,OAAON,EAAMM,IAAQC,KAAK,KAAMD,IAC9I,OAAOF,GAIRvB,EAAoB2B,EAAI,SAAShC,GAChC,IAAIe,EAASf,GAAUA,EAAO2B,WAC7B,WAAwB,OAAO3B,EAAgB,SAC/C,WAA8B,OAAOA,GAEtC,OADAK,EAAoBQ,EAAEE,EAAQ,IAAKA,GAC5BA,GAIRV,EAAoBW,EAAI,SAASiB,EAAQC,GAAY,OAAOjB,OAAOkB,UAAUC,eAAe1B,KAAKuB,EAAQC,IAGzG7B,EAAoBgC,EAAI,GAIjBhC,EAAoBA,EAAoBiC,EAAI,G,uZC9EtC,MAAeC,EAMlBC,YACWC,GACnB,KADmBA,OACnB,4DACAC,KAAKC,YAAcD,KAAKE,OAAOb,KAAKW,MAGtC,UAAiBG,GAEf,aADMH,KAAKC,cACJD,KAAKI,YAAYD,GAG1B,UAIEE,EACAC,EACAC,GAEA,IAAKP,KAAKQ,UAAUH,GAClB,MAAM,IAAII,MAAO,gBAAeJ,GAGlC,aADML,KAAKC,cACJD,KAAKU,YAAYL,EAAiBC,EAAaC,GAGxD,aAIEF,EACAC,EACAC,GAEA,GAAIF,IAAoBL,KAAKQ,UAAUH,GACrC,MAAM,IAAII,MAAO,gBAAeJ,GAGlC,aADML,KAAKC,cACJD,KAAKW,eAAeN,EAAiBC,EAAaC,GAG3D,aACEF,EACAC,EACAM,EACAC,EAAyB,IAEzB,GAAwB,OAApBR,QAA0CS,IAAdF,EAAOG,IAAoBH,EAAOG,KAAOT,EACvE,MAAM,IAAIG,MAAM,oBAElB,GAAII,EAAQG,OAAQ,CAClB,GAAwB,OAApBX,EACF,MAAM,IAAII,MAAO,8BAA6BJ,GAEhD,IAAIY,EAAYL,EAMhB,OALIrC,OAAOkB,UAAUC,eAAe1B,KAAK4C,EAAQ,QAC/CK,E,+VAAY,CAAH,GAAQL,UACVK,EAAUF,UAEbf,KAAKC,cACJD,KAAKkB,eAAeZ,EAAwBW,EAAWJ,GAEhE,IAAKb,KAAKQ,UAAUH,GAClB,MAAM,IAAII,MAAO,gBAAeJ,GAElC,IACGL,KAAKmB,cAAcd,IACpB9B,OAAOwB,KAAKa,GAAQQ,KAAMC,GAAMrB,KAAKmB,cAAcE,IAEnD,MAAM,IAAIZ,MAAM,aAIlB,aADMT,KAAKC,cACJD,KAAKsB,eAAejB,EAAiBC,EAAaM,EAAQC,GAGnE,aACER,EACAC,GAEA,IAAKN,KAAKQ,UAAUH,GAClB,MAAM,IAAII,MAAO,gBAAeJ,GAGlC,aADML,KAAKC,cACJD,KAAKuB,eAAelB,EAAiBC,GAO9C,gBAA0BkB,GACxB,MAAMC,EAA8C,GAC9CC,EAAa,IAAqB,IAAIC,QAAQ,CAACC,EAASC,KAC5DJ,EAAQK,KAAK,CAACF,EAASC,MAEzB7B,KAAK+B,cAAgBL,EACrB1B,KAAKC,YAAc+B,gBACXN,IACC1B,KAAKE,UAEd,UACQsB,EACN,MAAOS,GAIP,OAHAjC,KAAK+B,cAAgB,IAAqBJ,QAAQE,OAAOI,GACzDjC,KAAKC,YAAc,KAAc,MAAMgC,QACvCR,EAAQS,QAASC,GAAMA,EAAE,GAAGF,IAG9BjC,KAAK+B,mBAAgBjB,EACrBd,KAAKC,YAAcD,KAAKE,OAAOb,KAAKW,MACpCyB,EAAQS,QAASC,GAAMA,EAAE,MAGjB3B,UAAU4B,GAClB,MACgB,OAAdA,QAC4CtB,IAA5Cd,KAAKD,KAAKqC,GAIJjB,cAAciB,GACtB,MAAMC,EAAarC,KAAKD,KAAKqC,GAC7B,MACgB,OAAdA,GACAE,QAAQD,GAAcA,EAAWE,QAK3BrC,UAEV,kBAIEG,EACAC,EACAC,GAC0C,MAE1C,wBADkBP,KAAKW,eAAeN,EAAiBC,EAAaC,IACzD,UAAX,QAAiB,KAGTW,eACRH,EACAH,EACAC,GAEA,OAAOb,KAAKsB,eAAe,KAAMP,EAAIH,EAAQC,M,cC/JjDvD,EAAOD,QAAUmF,QAAQ,W,6BCAzB,SAASC,EAAMC,GACb,OAAO,IAAIf,QAASC,GAAiBe,WAAWf,EAASc,IAG5C,KAACE,GACdC,gBAAgB,IAChBC,qBAAqB,GACrBC,iBAAiB,IACjBC,cAAc,EACdC,UAAS,GACP,KAAOjB,UACT,MAAMkB,EAAQC,KAAKC,MAAQP,EAC3B,IAAIQ,EAAeP,EACnB,IAAK,IAAIQ,EAAU,GAAKA,GAAW,EACjC,IAEE,aAAaC,IACb,MAAOtB,GACP,IAAKW,EAAYX,GACf,MAAMA,EAGR,MAAMuB,EACJC,KAAKC,IAAIL,EAAcN,IACtBE,EAASQ,KAAKE,SAAW,GAI5B,GAFAN,GAAgBL,EAEZG,KAAKC,MAAQI,EAAQN,EAEvB,MADAjB,EAAE2B,SAAY,mBAAkBN,cAC1BrB,QAIFQ,EAAMe,M,cClClBlG,EAAOD,QAAUmF,QAAQ,Y,cCAzBlF,EAAOD,QAAUmF,QAAQ,S,cCAzBlF,EAAOD,QAAUmF,QAAQ,S,cCAzBlF,EAAOD,QAAUmF,QAAQ,Q,cCAzBlF,EAAOD,QAAUmF,QAAQ,U,cCAzBlF,EAAOD,QAAUmF,QAAQ,S,8DCAzB,wEAaA,MAGMqB,EAAU,MAChB,SAASC,EAAiB1F,GACxB,MAJS,OAILA,EALW,MAQR2F,mBAAmB3F,GAAM4F,QAAQH,EAAS,OAUnD,MAAMI,EAAkB,kCAKxB,MAAMC,EAAkBC,YAAOlC,GAC7BA,aAAamC,cACF,OAAXnC,EAAEoC,MACmB,SAPvB,SAAuBpC,GAAuB,MAC5C,OAAO,UAAAgC,EAAgBK,KAAKrC,EAAE2B,gBAAvB,eAAkC,KAAM,GAM/CW,CAActC,IAGhB,SAASuC,EACP1F,GAEA,MAAM2F,EAAqC,GAW3C,OAVAlG,OAAOwB,KAAKjB,GAAOoD,QAASb,IAC1B,IAAIqD,EAAK5F,EAAcuC,GACvB,GAAIqD,aAAaC,OACfD,EAAI,IAAIE,SAAQF,QAEX,GAAiB,iBAANA,GAAkBA,EAAEG,UACpC,MAAM,IAAIpE,MAAM,0CAElBgE,EAAUX,EAAiBzC,IAAMqD,IAE5BD,EAGT,SAASK,EACPhG,GAEA,IAAKA,EACH,OAAO,KAET,MAAM2F,EAAe,GASrB,OARAlG,OAAOwB,KAAKjB,GAAOoD,QAASb,IAC1B,IAAIqD,EAAK5F,EAAcuC,GA3C3B,IAA4BjD,EA6CP,iBAANsG,GAAkC,WAAhBA,EAAEG,YAC7BH,EAAIA,EAAEK,QAEPN,GAhDuBrG,EAgDciD,EA3DzB,QAYXjD,EAXK,KAcF4G,mBAAmB5G,KA4CoBsG,IAEvCD,EAGT,SAASQ,EACPC,GAEA,MAAMC,EAAsC,GAO5C,OANID,IACFC,EAAU,KAAa,EACvBD,EAAMhD,QAASkD,IACbD,EAAWrB,EAAiBsB,KAAc,KAGvCD,EA+BTnD,eAAeqD,EACbC,EACAvF,EAAoB,IAEpB,MAAMwF,QAA+BD,EAAWE,UAAUC,MAAM,IAAM,IAChEC,EAAoC,GACpCC,EAAc,IAAIC,IAAIL,EAASM,IAAKC,GAAQA,EAAI1H,OACtDuH,EAAYI,OAAO,QAEnBxH,OAAOwB,KAAKA,GACT8F,IAAKG,GAhCV,SAAmBA,EAAiBnF,EAAsB,IACxD,MAAM0B,EAASD,QAAQzB,EAAQ0B,QAE/B,MAAO,CACLnD,IAAK,CAAE,CAFQ0E,EAAiBkC,IAEbzD,EAAS,EAAI,UAChCA,UA2BkB0D,CAAUD,EAASjG,EAAKiG,KACzC9D,QAASgE,IACR,MAAMC,EAAQZ,EAASa,KAAMN,GAzBnC,SAAsBO,EAAuBC,GAC3C,GAAIhE,QAAQ+D,EAAE9D,UAAYD,QAAQgE,EAAE/D,QAClC,OAAO,EAET,MAAMgE,EAAOF,EAAEjH,IACToH,EAAOF,EAAElH,IACTW,EAAOxB,OAAOwB,KAAKwG,GACzB,OAAIhI,OAAOwB,KAAKyG,GAAMC,SAAW1G,EAAK0G,QAG/B1G,EAAK2G,MAAOrF,GAAOkF,EAAKlF,KAAOmF,EAAKnF,IAeFsF,CAAab,EAAKI,IACnDC,EACFR,EAAYI,OAAOI,EAAM/H,MAEzBsH,EAAY5D,KAAKoE,KAGnBR,EAAYe,cACRnB,EAAWsB,cAAclB,GAE7BC,EAAYkB,YACRlF,QAAQmF,IAAI,IAAInB,GAAaE,IAAKkB,GAAYzB,EAAW0B,UAAUD,KAI9D,MAAME,UAA0CpH,IACtDC,YACYwF,EACjBvF,EAAkB,GACDmH,EAAqB,CAAEC,QAAQ,IAEhDC,MAAMrH,GADN,KAHiBuF,aAGjB,KADiB4B,WAGjBlH,KAAKqH,UAAUhC,EAAoBC,EAAYvF,IAGvCG,SACR,GAAIF,KAAKkH,SAASC,OAChB,MAAM,IAAI1G,MAAM,qBAIpB,kBAA4B3B,SACpBkB,KAAKsF,WAAWgC,UAAU9C,EAAe1F,IAGjD,qBACEiC,EACAH,SAEMsD,EAAgB,IAAMlE,KAAKsF,WAAWiC,UAC1C/C,EAAe,CAAEzD,OACjB,CAAEyG,KAAMhD,EAAe5D,IACvB,CAAEI,QAAQ,KAId,qBACEX,EACAC,EACAM,GAEA,MAAM6G,EAAQjD,EAAe,CAAE,CAACnE,GAAkBC,IAC5CoH,EAAc,CAAEF,KAAMhD,EAAe5D,IACvCZ,KAAKmB,cAAcd,SACfL,KAAKsF,WAAWiC,UAAUE,EAAOC,SAEjC1H,KAAKsF,WAAWqC,WAAWF,EAAOC,GAI5C,kBAIErH,EACAC,EACAC,GAMA,OAAOuE,QAJW9E,KAAKsF,WAAWsC,QAChCpD,EAAe,CAAE,CAACnE,GAAkBC,IACpC,CAAE6E,WAAYF,EAAoB1E,MAKtC,qBAIEF,EACAC,EACAC,GAEA,MAAMsH,EAAS7H,KAAKsF,WAAWc,KAC7B/F,EAAkBmE,EAAe,CAAE,CAACnE,GAAkBC,IAAiB,GACvE,CAAE6E,WAAYF,EAAoB1E,KAG9BuH,EAA2B,GAGjC,aAFMD,EAAO3F,QAAS6F,GAAQD,EAAOhG,KAAKgD,EAAoBiD,KAEvDD,EAGT,qBACEzH,EACAC,GAKA,aAHqBN,KAAKsF,WAAW0C,WACnCxD,EAAe,CAAE,CAACnE,GAAkBC,MAExB2H,cAAgB,K,cCvOlC3K,EAAOD,QAAUmF,QAAQ,Y,cCAzBlF,EAAOD,QAAUmF,QAAQ,O,ijBCQzB,MACM0F,EAAc,IAAIC,WAAW,GAC7BC,EAAc,IAAID,WAAW,GAE7BE,EAAmBC,WAAWC,GAAGL,GAehC,SAASM,EAAe1J,GAC7B,OAAIA,aAAiB6F,OACX,IAAG7F,EAAM2J,SAAS,UAEP,iBAAV3J,EACD,IAAGA,EAEQ,kBAAVA,EACFA,EAAQ,IAAM,IAET,OAAVA,EACK,IAED,IAAG4J,KAAKC,UAAU7J,GAGrB,SAAS8J,EAAiB9J,GAC/B,MAAM+J,EAAO/J,EAAM,GACbgK,EAAOhK,EAAMiK,OAAO,GAC1B,OAAQF,GACN,IAAK,IAAK,OAAOlE,OAAOqE,KAAKF,EAAM,UACnC,IAAK,IAAK,OAAOA,EACjB,IAAK,IAAK,OAAO,EACjB,IAAK,IAAK,OAAO,EACjB,IAAK,IAAK,OAAO,KACjB,IAAK,IAAK,OAAOJ,KAAKO,MAAMH,GAC5B,QACE,GA9CkB,iBA8CEI,SAASL,GAC3B,OAAOH,KAAKO,MAAMnK,GAEpB,MAAM,IAAI2B,MAAO,qBAAoBoI,IAIpC,SAASM,EAAkBrK,GAChC,OAAIA,aAAiB6F,OACZA,OAAOyE,OAAO,CAACf,EAAkBvJ,IAEnC6F,OAAOqE,KAAKR,EAAe1J,GAAQ,QAGrC,SAASuK,EAAoBvK,GAClC,GAAqB,iBAAVA,EACT,OAAO8J,EAAiB9J,GAG1B,MAAM+J,EAAO/J,EAAM,GACnB,OAAI+J,IAASX,EACJpJ,EAAMwK,SAAS,GAEpBT,IAAST,EACJtJ,EAAMwK,SAAS,GAAGb,SAAS,QAE7BG,EAAiB9J,EAAM2J,SAAS,SAGlC,SAASc,EACdC,GAEA,MAAM1B,EAAiC,GAIvC,OAHAvJ,OAAOwB,KAAKyJ,GAAQtH,QAASb,IAC3ByG,EAAOzG,GAAKmH,EAAgBgB,EAAenI,MAEtCyG,EAGF,SAAS2B,EACdD,GAEA,MAAM1B,EAA8B,GAOpC,OANAvJ,OAAOwB,KAAKyJ,GAAQtH,QAASb,IAC3B,MAAMqD,EAAI8E,EAAOnI,GACbqD,IACFoD,EAAOzG,GAAKuH,EAAiBlE,MAG1BoD,E,urBCtEM,MAAM4B,UAA2C7J,IAKvDC,YACLC,EAAkB,GACD4J,EAAmB,EACnBzC,EAAqB,CAAEC,QAAQ,IAEhDC,MAAMrH,GADN,KAFiB4J,mBAEjB,KADiBzC,WACjB,uCAN6E,IAS7ElH,KAAK8I,KAAO,IAAIc,IAEhBrL,OAAOwB,KAAKA,GAAMmC,QAASb,IACzBrB,KAAK6J,QAAQxI,GAAgB,IAAIuI,MAI3B1J,SACR,GAAIF,KAAKkH,SAASC,OAChB,MAAM,IAAI1G,MAAM,qBAElB,OA9CJ,SAAeiC,GACb,GAAKA,EAKL,OAAO,IAAIf,QAASC,GAAiBe,WAAWf,EAASc,IAwChDD,CAAMzC,KAAK2J,kBAGpB,kBAA4B7K,GAC1B,MAAMgL,EAAaP,EAAgBzK,GACnCkB,KAAK+J,wBAAwBD,GAAY,GACzC9J,KAAK8I,KAAKkB,IAAIF,EAAW/I,GAAI+I,GAC7B9J,KAAKiK,wBAAwBH,GAG/B,qBACE/I,EACAH,GAEIZ,KAAK8I,KAAKoB,IAAI1B,EAAezH,UACzBf,KAAKsB,eAAe,KAAMP,EAAIH,SAE9BZ,KAAKI,YAAL,GAAmBW,MAAOH,IAIpC,qBACEP,EACAC,EACAM,GAEA,MAEMuJ,EAFOnK,KAAKoK,yBAAyB/J,EAAiBC,GAEvCuF,IAAKwE,IACxB,MAAMC,EAAgBtK,KAAK8I,KAAKpK,IAAI2L,GAC9BE,EAAWd,EAAkBa,GAC7BE,EAAW,EAAH,KAAQD,GAAa3J,GACnC,GAAI4J,EAASzJ,KAAOwJ,EAASxJ,GAC3B,MAAM,IAAIN,MAAM,oBAGlB,MAAO,CAAE6J,gBAAeG,cADFlB,EAAgBiB,MAIxCL,EAAQjI,QAAQ,EAAGoI,mBAAoBtK,KAAK0K,sBAAsBJ,IAClE,IACEH,EAAQjI,QAAQ,EAAGuI,mBAAoBzK,KAAK+J,wBAAwBU,GAAe,IACnF,MAAOxI,GAEP,MADAkI,EAAQjI,QAAQ,EAAGoI,mBAAoBtK,KAAKiK,wBAAwBK,IAC9DrI,EAERkI,EAAQjI,QAAQ,EAAGuI,oBACjBzK,KAAK8I,KAAKkB,IAAIS,EAAc1J,GAAI0J,GAChCzK,KAAKiK,wBAAwBQ,KAIjC,qBAIEpK,EACAC,EACAC,GAEA,IAAIoK,EAMJ,OAJEA,EADEtK,EACKL,KAAKoK,yBAAyB/J,EAAiBC,GAE/C,IAAIN,KAAK8I,KAAK/I,QAEhB4K,EAAK9E,IAAKwE,GAvGrB,SACEvB,EACA8B,GAEA,IAAKA,EACH,OAAO9B,EAET,MAAMhB,EAAyB,GAI/B,OAHA8C,EAAO1I,QAAS2I,IACd/C,EAAO+C,GAAS/B,EAAK+B,KAEhB/C,EA4FoBgD,CACvBrB,EAAkBzJ,KAAK8I,KAAKpK,IAAI2L,IAChC9J,IAIJ,qBACEF,EACAC,GAEA,MAAMqK,EAAO3K,KAAKoK,yBAAyB/J,EAAiBC,GAO5D,OANAqK,EAAKzI,QAASmI,IACZ,MAAMC,EAAgBtK,KAAK8I,KAAKpK,IAAI2L,GACpCrK,KAAK0K,sBAAsBJ,GAC3BtK,KAAK8I,KAAK/C,OAAOsE,KAGZM,EAAKlE,OAGN2D,yBACN/J,EACAC,GAEA,MAAMyK,EAAOvC,EAAelI,GAC5B,GAAwB,OAApBD,EACF,OAAOL,KAAK8I,KAAKoB,IAAIa,GAAQ,CAACA,GAAQ,GAExC,MAAM7E,EAAQlG,KAAK6J,QAAQxJ,GAC3B,IAAK6F,EACH,MAAM,IAAIzF,MAAO,iBAAgBJ,iBAEnC,MAAMsK,EAAOzE,EAAMxH,IAAIqM,GACvB,OAAOJ,EAAO,IAAIA,GAAQ,GAGpBZ,wBACNiB,EACAC,GAEA,GAAIA,GAAWjL,KAAK8I,KAAKoB,IAAIc,EAAgBjK,IAC3C,MAAM,IAAIN,MAAM,aAElBlC,OAAOwB,KAAKC,KAAKD,MAAMmC,QAAS9C,IAC9B,MAAM8G,EAAQlG,KAAK6J,QAAQzK,GAC3B,GAAIY,KAAKmB,cAAc/B,IAAQ8G,EAAMgE,IAAIc,EAAgB5L,IACvD,MAAM,IAAIqB,MAAM,eAKdwJ,wBACNe,GAEAzM,OAAOwB,KAAKC,KAAKD,MAAMmC,QAAS9C,IAC9B,MAAM8G,EAAQlG,KAAK6J,QAAQzK,GACrBsF,EAAIsG,EAAgB5L,GAC1B,IAAId,EAAI4H,EAAMxH,IAAIgG,GACbpG,IACHA,EAAI,IAAIsH,IACRM,EAAM8D,IAAItF,EAAGpG,IAEfA,EAAE4M,IAAIF,EAAgBjK,MAIlB2J,sBACNM,GAEAzM,OAAOwB,KAAKC,KAAKD,MAAMmC,QAAS9C,IAC9B,MAAM8G,EAAQlG,KAAK6J,QAAQzK,GACrBsF,EAAIsG,EAAgB5L,GACpBd,EAAI4H,EAAMxH,IAAIgG,GACpBpG,EAAEyH,OAAOiF,EAAgBjK,IACpBzC,EAAEuI,MACLX,EAAMH,OAAOrB,M,wHCxLN,MAAeyG,EAK5BrL,YACmBsL,GAIjB,KAJiBA,iBAIjB,kBATsC,CAAEjE,QAAQ,IAShD,yBAPiC,IAAIyC,KAShCyB,cAAgCjN,EAAc2B,GACnD,MAAMuL,EAAStL,KAAKuL,gBAAgB7M,IAAIN,GAClCoN,GFboBlN,EEaKyB,GFHzB,IAJQxB,OAAOwB,KAAKzB,GACzBmN,OACA5F,IAAKxE,GAAO,GAAEqH,KAAKC,UAAUtH,MAAMqH,KAAKC,UAAUrK,EAAE+C,OACpDqK,KAAK,QAPC,OAFJ,IAAuBpN,EEc1B,GAAIgN,EAAQ,CACV,MAAOK,EAAgBC,GAAaN,EACpC,GAAIE,IAAaG,EACf,MAAM,IAAIlL,MAAO,+BAA8BrC,0BAEjD,OAAOwN,EAET,MAAMC,EAAU7L,KAAKoL,eAAehN,EAAM2B,GAE1C,OADAC,KAAKuL,gBAAgBvB,IAAI5L,EAAM,CAACoN,EAAUK,IACnCA,EAGTC,QACE,GAAI9L,KAAKkH,SAASC,OAChB,OAEFnH,KAAK+L,YACL,MAAMC,EAAU,IAAIhM,KAAKuL,gBAAgBU,UACtCpG,IAAI,EAAE,CAAE3H,MAAJ,0BAAY,EAAAA,GAA8B6D,qBAA1C,aAAW,YAClB,OAAOJ,QAAQuK,WAAWF,GAASG,KAAK,IAAMnM,KAAKoM,iBAG3CL,YACR/L,KAAKkH,SAASC,QAAS,EAIfiF,kBCvCZ,MAAMC,EAVN,SAAsBjO,EAAckO,GAClC,MAAM/G,EAAY9H,OAAeW,GACjC,OAAImH,IAIH9H,OAAeW,GAAQkO,EACjBA,GAGSC,CAChB,4BACA,IAAI3C,KAGS,MAAM4C,UAAiBrB,EAC7BrL,aAAY,iBAAE6J,EAAmB,GAAM,IAC5CvC,MAAM,CAAChJ,EAAM2B,IAAS,IAAI2J,EAAiB3J,EAAM4J,EAAkB3J,KAAKkH,WAG1E,eAAsBuF,GACpB,MAAMC,EAAY,IAAIC,MAAIF,GACpBrO,EAAOsO,EAAUE,SACvB,GAAIxO,GAAQiO,EAAUnC,IAAI9L,GACxB,OAAOiO,EAAU3N,IAAIN,GAEvB,MAAMyO,EAASH,EAAUI,aACnBnD,EAAmBoD,OAAOF,EAAOnO,IAAI,qBACrCsO,EAAK,IAAIR,EAAS,CAAE7C,qBAI1B,OAHIvL,GACFiO,EAAUrC,IAAI5L,EAAM4O,GAEfA,EAGF3B,cAAgCjN,EAAc2B,GACnD,OAAOqH,MAAMiE,cAAcjN,EAAM2B,GAG5B+L,QACL9L,KAAK+L,aCpCM,MAAMkB,UAAgB9B,EAC3BrL,YACWoN,EACjBjG,GAEAG,MAAM,CAAChJ,EAAM2B,IAAS,IAAIkH,EACxBjH,KAAKkN,OAAOF,KAAK1H,WAVvB,SAAoBlH,GAClB,OAAO2F,mBAAmB3F,GASM+O,CAAW/O,IACvC2B,EACAC,KAAKkH,WAJP,KAFiBgG,SAUnB,qBAA4BT,GAC1B,MAAM,YAAEW,SAAsB,QAAN,qBAAa,KAEnCC,QAASpG,SACD,QAAN,qBAAwC,KACtCiG,QAAeE,EAAYE,QAAQb,EAAK,CAC5Cc,iBAAiB,EACjBC,oBAAoB,IAEtB,OAAO,IAAIP,EAAQC,EAAQjG,GAGtBoE,cAAgCjN,EAAc2B,GACnD,OAAOqH,MAAMiE,cAAcjN,EAAM2B,GAG5B0N,QACL,OAAOzN,KAAKkN,OAAOF,KAGXZ,gBACR,OAAOpM,KAAKkN,OAAOpB,SCnChB,MAAM4B,EACX5N,YACmB6N,EACApK,EACAqK,EAAYb,OAAOc,mBACpC,KAHiBF,MAGjB,KAFiBpK,KAEjB,KADiBqK,YAGnBE,QAAQC,GACN,OAAO/N,KAAK2N,IAAIK,GAAGhM,UACjB,IAAIiM,EAEJ,IAAK,IAAIC,EAAO,EAAGA,EAAOlO,KAAK4N,UAAWM,GAAQ,EAAG,CACnD,MAAOC,EAAWC,SAA2BpO,KAAKuD,GAAG0K,GAGrD,SAFMF,EAASI,GACfF,EAAUG,GACLH,EACH,OAIJ,MAAM,IAAIxN,MAAM,oBAIpB,YACE,MAAM4N,EAAa,GAInB,aAHMrO,KAAK8N,QAASjQ,IAClBwQ,EAAMvM,QAAQjE,KAETwQ,GCnCI,MAAMC,UAAiB7N,MACpCX,YACmByO,EACA1F,EACjBjF,GAEAwD,MAAO,aAAYmH,YAAiB1F,eAAkBjF,KADtD,KAHiB2K,SAGjB,KAFiB1F,OAMnB,cAAc5G,EAAY4G,GACxB,OACG5G,aAAaqM,GAAYrM,EAAEuM,OAAO3F,IAClC5G,aAAaxB,OAASwB,EAAE2B,UAAYiF,EAIzC2F,OAAO3F,GACL,OAAO7I,KAAK6I,KAAK4F,SAAU,IAAG5F,IAAW7I,KAAK6I,OAASA,EAGzD6F,cACE,OACE1O,KAAKuO,QAAU,KACfvO,KAAK6I,KAAK4F,SAAS,4BACnBzO,KAAK6I,KAAK4F,SAAS,4CACnBzO,KAAK6I,KAAK4F,SAAS,0BACnBzO,KAAK6I,KAAK4F,SAAS,yB,ksBC6FzB,MAAME,EAAiB,yDAIvB,SAASC,EAAqC9Q,GAC5C,OAAOA,EAAE2I,OAAS3I,OAAIgD,EAGxB,SAAS+N,EAAQ/P,EAAgBiB,GAC/B,OAAOA,EAAK8F,IAAKzG,GAAQsJ,KAAKC,UAAU7J,EAAMM,KAAOsM,OASvD,SAASoD,EACPC,GAEA,IAAIlR,EAAI,EACR,MAAMmR,EAAsB,GACtBC,EAAoC,GAC1C,IAAIC,GAAU,EACVC,GAAe,EACnB,MAAMrH,EAAkC,GA2BxC,OAzBAvJ,OAAOwB,KAAKgP,GAAa7M,QAAS9C,IAChC,MAAM,oBAAEgQ,EAAF,OAAuBC,EAAvB,WAA+BC,GAAeP,EAAY3P,GAE1DmQ,EAAkB,GAClBC,GAAaC,MAAMC,QAAQJ,GAC3BK,EAAeF,MAAMC,QAAQJ,GAAcA,EAAa/Q,OAAOwB,KAAKuP,GACrEK,EAAalJ,SAIlBkJ,EAAazN,QAAS0N,IACpB,MAAMC,EAAY,IAAGhS,EACfiS,EAAa,IAAGjS,EACtB0R,EAAMzN,KAAKsN,EAAoBS,EAAUC,IACzCb,EAAUY,GAAYD,EAClBJ,IACFR,EAAWc,GAAcR,EAAuBM,IAElD/R,GAAK,IAEPiK,EAAO1I,GAAyB,iBAAXiQ,EAAsBE,EAAM7D,KAAK2D,GAAUA,EAAOE,GACvEJ,EAAeA,GAAgBK,EAC/BN,GAAU,KAGPA,EAIL,OACKpH,GADL,IAEEiI,0BAA2BZ,EAAeH,OAAalO,EACvDkP,yBAA0Bf,IANnB,GAUX,MAAM9J,EAAc8K,IAAD,CACjBb,oBAAsBQ,GAAiBA,EACvCP,OAAQ,IACRC,WAAYW,GAAS,KAGjBC,EAAe/L,YAClBlC,GAAOqM,EAASE,OAAOvM,EArEQ,8BAqEuC,YAAdA,EAAE2B,QAC3D,CAAEf,cAAe,IAAOE,eAAgB,IAAME,QAAQ,IAElDkN,EAAiBhM,YACpBlC,GAAqB,gCAAdA,EAAE2B,SAGNwM,EAAqB,mBAEpB,SAASjD,EAAW/O,GAIzB,OAAOA,EAAK4F,QAAQoM,EAAqBlS,IACvC,MACMmS,EADOnS,EAAEiK,WAAW,GACTM,SAAS,IAC1B,OAAI4H,EAAI5J,QAAU,EACR,KAAI4J,EAAIC,SAAS,EAAG,KAEtB,KAAID,EAAIC,SAAS,EAAG,OAC3BC,OAAO,EAAG,KAOf,SAASC,EAA2BC,GAClC,MAAMR,EAAQ,IAAIrG,IAQlB,OAPA6G,EAAQvO,QAASnC,GAASA,EAAKmC,QAAQ,EAAGwO,gBAAeC,oBACvD,GAAKV,EAAM/F,IAAIwG,IAER,GAAIT,EAAMvR,IAAIgS,KAAmBC,EACtC,MAAM,IAAIlQ,MAAO,mCAAkCiQ,QAFnDT,EAAMjG,IAAI0G,EAAeC,MAKtB,IAAIV,EAAMW,WAAW/K,IAAI,EAAE6K,EAAeC,MAAjB,CAC9BE,cAAeH,EACfI,cAAeH,KAInB,SAASI,EAAqBlT,GAC5B,MAAO,CACLmT,UAAWnT,EAAEoT,UACbC,UAAWrT,EAAEsT,UAAUtL,IAAI,EAAG6K,gBAAeU,cAAlB,CACzBP,cAAeH,EACfW,QAASD,KAEXE,WAAY,CACVC,eAAgB1T,EAAE2T,iBAAmB3T,EAAE4T,iBAAmB,UAAY,aACtEC,iBAAkB7T,EAAE4T,kBAEtBE,sBAAuB9T,EAAE+T,YAI7B,SAASjL,EAAaN,EAAmCC,GACvD,OAAID,EAAE8K,UAAU1K,SAAWH,EAAE4K,UAAUzK,QAGhCJ,EAAE8K,UAAUzK,MAAM,CAACrF,EAAGxD,IAC3BwD,EAAEqP,gBAAkBpK,EAAE4K,UAAUrT,GAAGgT,eACnCxP,EAAE+P,UAAY9K,EAAE4K,UAAUrT,GAAGwT,SAI1B,MAAMQ,EAOX/R,YACmB6N,EACAmE,GACjB,eAAEC,GAAiB,GAAsB,IACzC,KAHiBpE,MAGjB,KAFiBmE,OAEjB,oFAN2B,GAO3B,MAAMvC,EAAQZ,EAAerK,KAAKwN,GAC9BvC,GACF,CAAGvP,KAAKgS,QAAUzC,EAElBvP,KAAKgS,OAAS,YAEhBhS,KAAK+R,eAAiBA,EAGxBE,mBACE,OAAOjS,KAAKkS,mBAGdC,gBAEE,OAAO,IAAIzE,EAAM1N,KAAK2N,IAAK3L,UACzB,MAAMoQ,QAAwCpS,KAAKhC,KAAK,aAAc,CACpEqU,wBAAyBC,IAE3B,MAAO,CAACF,EAASG,WAAYH,EAASI,yBACrC,IAGLC,YACEC,EACAC,EACAC,EAAqD,GACrDC,EACAjB,GAGA,OAAO5R,KAAK2N,IAAIK,GAAGhM,UACjB,IAAI6J,GAAU,EACd,UACQ7L,KAAKhC,KAAK,cAAe,CAC7B8U,UAAWJ,EACXK,qBAAsBvC,EAA2B,CAC/CmC,KACGC,EAAiB/M,IAAI,EAAGsL,eAAgBA,KAE7CD,UAAWyB,EAAW9M,IAAI,EAAG6K,gBAAeU,cAAlB,CACxBP,cAAeH,EACfW,QAASD,KAEX4B,uBAAwBpE,EAAWgE,EAAiB/M,IACjDhI,GAAMkT,EAAqBlT,KAE9BoV,YAAarB,EAAa,cAAgB,kBAC1CD,sBAAuBC,IAEzB/F,GAAU,EACV,MAAO5J,GACP,IAAIqM,EAASE,OAAOvM,EAzMG,0BA4MrB,MAAMA,QAFAjC,KAAKkT,eAAeR,EAAWE,GAUzC,OAJIC,SACI7S,KAAKmT,aAAaT,GAAW,GAG9B7G,IAIXuH,cAAcV,GAEZ,OAAO1S,KAAKhC,KAAK,gBAAiB,CAAE8U,UAAWJ,IAGjDS,aAAaT,EAAmBW,GAC9B,OAAOnD,EAAalO,UAClB,MAAMsR,QAAatT,KAAKoT,cAAcV,GACtC,GAA+B,WAA3BY,EAAKC,MAAMC,YACb,MAAM,IAAI/S,MAAM,WAElB,MAAMoJ,EAAUyJ,EAAKC,MAAMP,uBAC3B,GAAIK,GAAkBxJ,GAAWA,EAAQzI,KAAMvD,GAAyB,WAAlBA,EAAE4V,aACtD,MAAM,IAAIhT,MAAM,aAKtB,kBAAkBiS,SAEV1S,KAAKhC,KAAK,cAAe,CAAE8U,UAAWJ,IAG9C,cAAcA,EAAmBgB,EAAenR,SAExCvC,KAAKhC,KAAK,UAAV,KACJ8U,UAAWJ,EACXiB,KAAMD,GACH5E,EAAmB,CACpB8E,oBAAqB,CACnBxE,oBAAsBQ,GAAkB,wBAAuBA,KAC/DP,OAAQ,QACRC,WAAY/M,EAAS,CAACA,GAAU,OAPhC,IAUJsR,uBAAwB,WAI5B,iBACEnB,EACAtT,EACAwB,EACAkT,SAGM9T,KAAKhC,KAAK,aAAV,KACJ8U,UAAWJ,EACXqB,IAAK3U,GACF0P,EAAmB,CACpBkF,iBAAkB,CAChB5E,oBAAqB,CAACQ,EAAM9Q,IAAmB,GAAE8Q,KAAQ9Q,IACzDuQ,OAASvR,GAAe,OAAMA,EAAE4N,KAAK,KACrC4D,WAAY1O,GAEdgT,oBAAqB,CACnBxE,oBAAqB,CAACQ,EAAM9Q,IAAmB,GAAE8Q,KAAQ9Q,IACzDuQ,OAAQ,QACRC,WAAYwE,GAAa,OAZzB,IAeJD,uBAAwB,WAI5B,cACEnB,EACAtT,EACA6U,GAGA,MAAMnL,QAA6B9I,KAAKhC,KAAK,UAAV,KACjC8U,UAAWJ,EACXqB,IAAK3U,GACF0P,EAAmB,CAAEoF,qBAAsB/O,EAAW8O,MAHxB,IAIjCE,eAAgBnU,KAAK+R,eACrB8B,uBAAwB,WAI1B,OAAK/K,EAAK6K,MAASpV,OAAOwB,KAAK+I,EAAK6K,MAAMlN,OAGnCqC,EAAK6K,KAFH,KAKX,oBACEjB,EACA3S,EACAkU,GAGA,IAAKlU,EAAK0G,OACR,MAAO,GAET,GAAoB,IAAhB1G,EAAK0G,OACP,MAAO,OAAOzG,KAAKoU,QAAQ1B,EAAW3S,EAAK,GAAIkU,IAGjD,MAAMI,EAAW9V,OAAOwB,KAAKA,EAAK,IAC5BuU,EAAYL,aAAH,EAAGA,EAAgBM,QAC9BD,GACFD,EAASnS,QAASb,IACXiT,EAAUpL,SAAS7H,IACtBiT,EAAUxS,KAAKT,KAKrB,MAAMwI,EAAU,IAAID,IACpB7J,EAAKmC,QAAQ,CAAC9C,EAAKvB,IAAMgM,EAAQG,IAAI6E,EAAQzP,EAAKiV,GAAWxW,IAE7D,MAAM2W,EAAgCzU,EAAK8F,IAAI,IAAM,MAC/C4O,EAAa,OACd3F,EAAmB,CAAEoF,qBAAsB/O,EAAWmP,MAD3C,IAEdH,eAAgBnU,KAAK+R,iBAsBvB,aAnBM/R,KAAK0U,YAAY3U,EAAM,IAAKiC,UAAqB,MACrD,MAAM8G,QAAkC9I,KAAKhC,KAAK,eAAgB,CAChE2W,aAAc,CACZ,CAACjC,GAAD,OACK+B,GADL,IAEEG,KAAMC,KAGVhB,uBAAwB,UAQ1B,OANA/K,EAAKgM,UAAUpC,GAAWxQ,QAASwR,IACjC,MAAMxN,EAAQ2D,EAAQnL,IAAImQ,EAAQ6E,EAAMW,SAC1BvT,IAAVoF,IACFsO,EAAUtO,GAASwN,MAGhB,UAAA5K,EAAKiM,gBAAgBrC,UAArB,eAAiCkC,OAAQ,KAG3CJ,EAGTQ,cAActC,EAAmBrE,GAE/B,OAAOrO,KAAK0U,YAAYrG,EAAO,GAAIrM,iBACShC,KAAKhC,KAAK,iBAAkB,CACpE2W,aAAc,CACZ,CAACjC,GAAYuC,EAAWpP,IAAK6N,IAAD,CAAawB,WAAY,CAAEvB,KAAMD,OAE/DG,uBAAwB,WAEbsB,iBAAiBzC,IAAc,IAAI7M,IAAKhI,GAAMA,EAAEqX,WAAYvB,OAI7EyB,iBAAiB1C,EAAmB3S,GAElC,OAAOC,KAAK0U,YAAY3U,EAAM,GAAIiC,iBACUhC,KAAKhC,KAAK,iBAAkB,CACpE2W,aAAc,CACZ,CAACjC,GAAYmC,EAAUhP,IAAKzG,IAAD,CAAYiW,cAAe,CAAEtB,IAAK3U,OAE/DyU,uBAAwB,WAEbsB,iBAAiBzC,IAAc,IAAI7M,IAAKhI,GAAMA,EAAEwX,cAAetB,MAIhFuB,YAAY5C,EAAmBuB,GAE7B,MAAMxM,EAAQ,KACZqL,UAAWJ,GACR5D,EAAmB,CAAEoF,qBAAsB/O,EAAW8O,MAFhD,IAGTE,eAAgBnU,KAAK+R,eACrB8B,uBAAwB,UAE1B,OAAO,IAAInG,EAAM1N,KAAK2N,IAAK3L,UACzB,MAAMoQ,QAAkCpS,KAAKhC,KAAK,OAAV,OACnCyJ,GADmC,IAEtC8N,kBAAmBtH,KAErB,MAAO,CAACmE,EAASoD,MAAOpD,EAASqD,oBAIrC,6BACE/C,EACAzB,EACA7R,EACA6U,EACAyB,GAGA,MAAMC,EAAiB,CAAC,MAClBC,EAA8B,IACnC3B,GAAkB,IAAI/R,QAAS0N,IACjB,OAATA,IACErR,OAAOmB,eAAe1B,KAAKoB,EAAKwQ,GAClC+F,EAAe7T,KAAK8N,GAEpBgG,EAAkB9T,KAAK8N,MAI7B,MAAMnI,EAAQ,KACZqL,UAAWJ,EACX1B,UAAWC,GACRnC,EAAmB,CACpB+G,uBAAwB,CACtBzG,oBAAqB,CAACQ,EAAM9Q,IAAmB,GAAE8Q,KAAQ9Q,IACzDuQ,OAAQ,QACRC,WAAYlQ,GAEd8U,qBAAsB/O,EAAWwQ,MAT1B,IAWTxB,gBAAgB,EAChBN,uBAAwB,UAE1B,IAAIxF,EACJ,GAAIqH,EAAU,CAKZrH,SAJwCrO,KAAKhC,KAAK,QAAV,OACnCyJ,GADmC,IAEtCqO,MAAO,MAEQN,WAEjBnH,QAAc,IAAIX,EAAM1N,KAAK2N,IAAK3L,UAChC,MAAMoQ,QAAkCpS,KAAKhC,KAAK,QAAV,OACnCyJ,GADmC,IAEtC8N,kBAAmBtH,KAErB,MAAO,CAACmE,EAASoD,MAAOpD,EAASqD,oBAChC3O,MAGL,IAAKuH,EAAM5H,QAAWwN,IAAmB2B,EAAkBnP,OACzD,OAAO4H,EAGT,MAAM0H,QAAgB/V,KAAKgW,cACzBtD,EACArE,EAAMxI,IAAI,EAAG9E,SAAH,CAAeA,QACzB6N,EAAWgH,IAEb,OAAOvH,EACJxI,IAAI,CAAC6N,EAAM7V,IAAOkY,EAAQlY,GAAR,OAAmB6V,GAASqC,EAAQlY,IAAQ,MAC9DoY,OAAQvC,GAASA,GAGtB,iBAAiBhB,EAAmBtT,SAC5BY,KAAKkW,WAAWxD,EAAWtT,GAAK,GAGxC+W,oBAAoBzD,EAAmBtT,GACrC,OAAOY,KAAKkW,WAAWxD,EAAWtT,GAAK,GAGzC,iBAAyBsT,EAAmBtT,EAAcgX,GAexD,aAbwCpW,KAAKhC,KAAK,aAAV,KACtC8U,UAAWJ,EACXqB,IAAK3U,GACF0P,EAAmB,CACpB8E,oBAAqB,CACnBxE,oBAAsBQ,GAAkB,oBAAmBA,KAC3DP,OAAQ,QACRC,WAAY,CAAC/Q,OAAOwB,KAAKX,GAAK,QAPI,IAUtCyU,uBAAwB,QACxBwC,aAAcD,EAAY,eAAYtV,MAExBwV,WAGlB,qBACE5D,EACAE,EAAqD,IAGrD,MAAMrN,QAAiBvF,KAAKoT,cAAcV,GACpC7I,EAAU,IAAID,IACd2M,EAA6C,GAC7CC,EAAajR,EAASgO,MAAMP,wBAA0B,GAC5D,IAAK,IAAInV,EAAI,EAAGA,EAAI2Y,EAAW/P,OAAQ5I,GAAK,EAAG,CAC7C,MAAMiI,EAAM0Q,EAAW3Y,GACvBgM,EAAQG,IAAIlE,EAAIkL,UAAWlL,GAE7B,IAAK,IAAIjI,EAAI,EAAGA,EAAI+U,EAAiBnM,OAAQ5I,GAAK,EAAG,CACnD,MAAMiI,EAAM8M,EAAiB/U,GACvB4Y,EAAM5M,EAAQnL,IAAIoH,EAAImL,WAC5B,GAAIwF,EAAK,CACP,IAAK9P,EAAab,EAAK2Q,GACrB,MAAM,IAAIhW,MAAO,2CAA0CqF,EAAImL,WAEjEpH,EAAQ9D,OAAOD,EAAImL,gBAEnBsF,EAASzU,KAAKgE,GAGlB,MAAM4Q,EAAW,IAAI7M,EAAQ9J,QAE7B,IAAK,IAAIlC,EAAI,EAAGA,EAAI6Y,EAASjQ,OAAQ5I,GAAK,QAClCmC,KAAKhC,KAAK,cAAe,CAC7B8U,UAAWJ,EACXiE,4BAA6B,CAAC,CAC5BC,OAAQ,CAAE5F,UAAW0F,EAAS7Y,cAI5BmC,KAAKmT,aAAaT,GAAW,GAErC,IAAK,IAAI7U,EAAI,EAAGA,EAAI0Y,EAAS9P,OAAQ5I,GAAK,QAClCmC,KAAKhC,KAAK,cAAe,CAC7B8U,UAAWJ,EACXK,qBAAsBvC,EAA2B,CAAC+F,EAAS1Y,GAAGsT,YAC9DwF,4BAA6B,CAAC,CAAEE,OAAQ9F,EAAqBwF,EAAS1Y,cAGlEmC,KAAKmT,aAAaT,GAAW,GAK/BgC,YACNrG,EACAyI,EACAvT,GAEA,MAAMwT,EAAY1I,EAAMkG,QACxB,OAAOvU,KAAK2N,IAAIK,GAAG,IAAMmC,EAAenO,UACtC,MAAMgV,EAAQD,EAAUxC,QAExB,IADAwC,EAAUtQ,OAAS,EACZuQ,EAAMvQ,QAAQ,CACnB,MAAMwO,EAAa+B,EAAMC,OAAO,EAAGH,GAG7BI,QAAmB3T,EAAG0R,GAC5B8B,EAAUjV,QAAQoV,GAEpB,GAAIH,EAAUtQ,OACZ,MAAM,IAAIhG,MAAM,kCAKtB,WACE0W,EACAC,GAEA,MAeMtO,SAfiB9I,KAAK2N,IAAI0J,QAAQ,CACtCC,OAAQ,OACR7K,IAAKzM,KAAK8R,KACVE,OAAQhS,KAAKgS,OACbuF,QAAS,WACTC,QAAS,CACP,eAAgB,6BAChB,eAAiB,qBAAoBL,GAEvCC,UAMoBK,KACtB,GAAI3O,EAAK4O,iBAAkB,CACzB,IAAIC,EAEFA,EADElI,MAAMC,QAAQ5G,EAAK4O,kBACV5O,EAAK4O,iBAAiBE,OAAO,CAAC7Y,EAAGb,IAAOa,EAAIgO,OAAO7O,EAAE2Z,eAAiB,GAEtE9K,OAAOjE,EAAK4O,iBAAiBG,eAE1C7X,KAAKkS,oBAAsByF,EAE7B,OAAO7O,G,2iCCzqBX,SAASgP,EAAUjP,EAAcjF,GAC/B,OAAQ3B,IACN,MAAMqM,EAASE,OAAOvM,EAAG4G,GAAQ,IAAIpI,MAAMmD,GAAW3B,GAI1D,SAAS8V,EACPlP,EACAtF,GAEA,OAAQtB,IACN,GAAIqM,EAASE,OAAOvM,EAAG4G,GACrB,OAAOtF,IAET,MAAMtB,GAIV,MAAM+V,EAAS,OAEf,SAASC,EAAcnZ,GAKrB,MAAO,CAAEoZ,EADG/O,EAAkBrK,GACd2J,SAAS,WAG3B,SAAS0P,EAAarZ,GACpB,MAAMgJ,EAAkB,GAIxB,OAHAvJ,OAAOwB,KAAKjB,GAAOoD,QAAS9C,IAC1B0I,EAAO1I,GAAO6Y,EAAcnZ,EAAMM,MAE7B0I,EAGT,SAASsQ,EAAetZ,GACtB,OAAOP,OAAOmB,eAAe1B,KAAKc,EAAO,KAiB3C,SAASuZ,EAA4CvZ,GACnD,IAAKA,EACH,OAAO,KAET,MAAMgJ,EAAkC,GAIxC,OAHAvJ,OAAOwB,KAAKjB,GAAOoD,QAAS9C,IAC1B0I,EAAO1I,GAhBX,SAAyBN,GACvB,GAAIsZ,EAAetZ,GACjB,OAAOuK,EAAoB1E,OAAOqE,KAAKlK,EAAMoZ,EAAG,WAElD,MAAM,IAAIzX,MAAM,kCAYA6X,CAAgBxZ,EAAMM,MAE/B0I,EAGT,SAASyQ,EAAY3I,EAAc9Q,GACjC,IAAKsZ,EAAetZ,GAClB,MAAM,IAAI2B,MAAM,kCAElB,MAAO,CACLyX,EAAGvT,OAAOyE,OAAO,CACfzE,OAAOqE,KAAQ4G,EAAF,IAAW,QACxBjL,OAAOqE,KAAKlK,EAAMoZ,EAAG,YACpBzP,SAAS,WAIhB,MAAM+P,GAAiB,CAAEN,EAAGvT,OAAOqE,KAAK,KAAKP,SAAS,WAEhDgQ,GAAc/F,GAAiCA,EAAF,IASnD,SAASgG,GACP9G,GAEA,GAAKA,EAGL,MAAO,CACL+G,kBAAmBlV,KAAKmV,IAAI,EAAGnV,KAAKoV,KAAKjH,EAAWkH,OACpDC,mBAAoBtV,KAAKmV,IAAI,EAAGnV,KAAKoV,KAAKjH,EAAWoH,SAIzD,SAASC,GACPlZ,EACAmZ,GAEA,MAAMC,EAAkB,CAAEL,KAAM,EAAGE,MAAO,GAC1C,IAAII,GAAgB,EASpB,OARArZ,EAAKmC,QAAS0N,IACZ,MAAMyJ,EAAMH,aAAH,EAAGA,EAAetJ,GACvByJ,IACFD,GAAgB,EAChBD,EAAgBL,MAAQO,EAAIP,KAC5BK,EAAgBH,OAASK,EAAIL,SAG1BI,EAAgBD,EAAkB,KAG3CnX,eAAesX,GACbC,EACA7G,EACA8G,EACAC,EACAP,GAEA,MAAMQ,EAAiBjB,GAAW/F,IAE3B7G,SAAiBlK,QAAQmF,IAAsB,CACpDyS,EAAI9G,YACFC,EACA,CAAC,CAAEhC,cAAe,KAAMC,cAAe,IAAKS,QAAS,SACrDoI,EAAc3T,IAAK+J,IAAD,CAChBqB,UAAW9D,EAAWyC,GACtBuB,UAAW,CAAC,CAAET,cAAed,EAAMe,cAAe,IAAKS,QAAS,SAChEQ,WAAY8G,GAAgBQ,aAAD,EAACA,EAAetJ,QAE7C,EACA8I,GAAgBQ,aAAD,EAACA,EAAe,QAEjCO,EAAWhT,OAAS8S,EAAI9G,YACtBiH,EACA,CAAC,CAAEhJ,cAAe,KAAMC,cAAe,IAAKS,QAAS,SACrD,IACA,EACAsH,GAAgBO,GAAsBQ,EAAYP,KAChDK,EAAII,YAAYD,GAAgBjU,MAAMuS,KAG5C,GAAInM,IAAY4N,EAAWhT,OACzB,OAIF,MAAMmT,QAAaL,EAAInF,QAAQsF,EAAgB,CAAEG,GAAIrB,IAAkB,CAAC,WAClEsB,EAAU,IAAIlU,IAAI6T,GAClBM,EAAoB,GAlH5B,IAA2Bjb,EAsHzB,GAHI8a,IAnHqB9a,EAmHK8a,EAAKrX,OAlH5BhE,OAAOmB,eAAe1B,KAAKc,EAAO,QAmHvCib,EAAQjY,QAAQ8X,EAAKrX,OAAOyX,GAAG/D,OAAQvC,IAAUoG,EAAQ/T,OAAO2N,KAE9DoG,EAAQjT,KAAM,CAEhB,MAAMoJ,EAAQ,IAAI6J,SACZP,EAAIjE,YAAY5C,EAAW,CAAC,QAASzC,IAAQnC,QAAQ9L,UACzD,MAAMiY,EAAwB,GAI9B,OAHA5L,EAAMnM,QAASwR,GAASzD,EAAM/N,QAAS0N,IACrCqK,EAAWnY,KAAK,CAAE+X,GAAItB,EAAY3I,EAAM8D,EAAK9D,IAAQ7O,GAAI2S,EAAK3S,QAEzDwY,EAAIvE,cAAc0E,EAAgBO,UAEtC,IAAKF,EAAQtT,OAClB,aAMI8S,EAAIW,QAAQR,EAAgB,CAAEG,GAAIrB,GAAgBjW,OAAQ,CAAEyX,GAAIP,KAGzD,MAAMU,WAA2Cta,IAGvDC,YACYyZ,EACA7G,EACjB3S,EAAkB,GAClBmZ,GAEA9R,MAAMrH,GADN,KAJiBwZ,MAIjB,KAHiB7G,YAGjB,oBAPkD,IAUlD,MAAM8G,EAAsC,GAC5Cjb,OAAOqS,QAAQ7Q,GAAMmC,QAAQ,EAAE9C,EAAKyB,OAC9BA,aAAJ,EAAIA,EAAS0B,QACXvC,KAAKyZ,WAAW3X,KAAK1C,GAErBoa,EAAc1X,KAAK1C,KAIvBY,KAAKqH,UAAUiS,GACbC,EACA7G,EACA8G,EACAxZ,KAAKyZ,WACLP,IAIJ,wBACE,OAAOlZ,KAAK0S,UAGd,6BACE,OAAO+F,GAAWzY,KAAK0S,WAGftS,YAAYtB,GACpB,OAAOkB,KAAKka,QAAQ/B,EAAarZ,IAGzBoC,eACRH,EACAH,GAEA,MAAM8S,EAAOyE,EAAa,GAAEpX,MAAOH,KAC3BG,GAAIqZ,GAAyB1G,EAAd2G,EAAvB,EAAqC3G,EAArC,QACMtU,EAAM,CAAE2B,GAAIqZ,GAGlB,OAAOpa,KAAKsa,WAAWlb,EAAKib,EAAWjb,GAAKqG,MAAMsS,EArPd,kCAyPlC,IAAM/X,KAAKka,QAAQxG,GAAMjO,MAAMsS,EAC7B,eAIA,IAAM/X,KAAKsa,WAAWlb,EAAKib,EAAWjb,GAAKqG,MAAMqS,EA9PjB,kCAkQ9B,8BAMR,qBACEzX,EACAC,EAFF,GAIiB,IADbS,GAAIwZ,GACS,EADH3Z,EACG,YACf,GAAwB,OAApBP,QACIL,KAAKsa,WACTnC,EAAa,CAAEpX,GAAIT,IACnB6X,EAAavX,IACb6E,MAAMsS,EAjR0B,kCAiRmBC,QAChD,CACL,MAAM3J,QAAcrO,KAAKW,eAAeN,EAAiBC,EAAa,CAAC,aACjEqB,QAAQmF,IAAIuH,EAAMxI,IAAI,EAAG9E,QAASf,KAAKsa,WAC3CnC,EAAa,CAAEpX,OACfoX,EAAavX,GACbuX,EAAa,CAAE,CAAC9X,GAAkBC,KAClCmF,MAAMsS,EAxR0B,kCAwRmBC,OAIzD,kBAIE3X,EACAC,EACAC,GAEA,GAAwB,OAApBF,EACF,OAAOgY,QAAqCrY,KAAKuZ,IAAInF,QACnDpU,KAAK0S,UACLyF,EAAa,CAAEpX,GAAIT,IACnBC,IAIJ,IAAKP,KAAKmB,cAAcd,GAAkB,CAQxC,OAAOgY,SAPgBrY,KAAKuZ,IAAIiB,uBAC9Bxa,KAAK0S,UACLvF,EAAW9M,GACX8X,EAAa,CAAE,CAAC9X,GAAkBC,IAClCC,GACA,IAE6C,IAGjD,MAAMka,EAAiBxC,EAAc3X,GAC/BlB,QAAYY,KAAKuZ,IAAInF,QACzBqE,GAAWzY,KAAK0S,WAChB,CAAEmH,GAAItB,EAAYlY,EAAiBoa,IACnC,CAAC,OAEH,IAAKrb,EACH,OAAO,KAET,IAAKmB,EACH,OAAO8X,QAAqCrY,KAAKuZ,IAAInF,QAAQpU,KAAK0S,UAAWtT,IAE/E,MAAMsb,EAAmB,GACnBC,EAAiB,IAAI/U,IAAIrF,GAO/B,GANIoa,EAAe5U,OAAO,OACxBxH,OAAOqc,OAAOF,EAAStb,GAErBub,EAAe5U,OAAO1F,KACxBqa,EAAQra,GAAmBoa,GAEzBE,EAAe9T,KAAM,CACvB,MAAMgU,QAAoB7a,KAAKuZ,IAAInF,QAAQpU,KAAK0S,UAAWtT,EAAK,IAAIub,IACpE,IAAKE,EAGH,OAAO,KAETtc,OAAOqc,OAAOF,EAASG,GAEzB,OAAOxC,EAA+BqC,GAGxC,qBAIEra,EACAC,EACAC,GAEA,IAAKF,EAAiB,CAEpB,aADoBL,KAAKuZ,IAAIjE,YAAYtV,KAAK0S,UAAWnS,GAAkBuG,OAC9DjB,IAAIwS,GAEnB,GAAIrY,KAAKmB,cAAcd,GAAkB,CACvC,MAAMqT,QAAa1T,KAAKU,YAAYL,EAAiBC,EAAcC,GACnE,OAAOmT,EAAO,CAACA,GAAQ,GASzB,aAPoB1T,KAAKuZ,IAAIiB,uBAC3Bxa,KAAK0S,UACLvF,EAAW9M,GACX8X,EAAa,CAAE,CAAC9X,GAAkBC,IAClCC,GACA,IAEWsF,IAAIwS,GAGnB,qBACEhY,EACAC,GAEA,GAAwB,OAApBD,EAA0B,CAE5B,aADsBL,KAAK8a,WAAW3C,EAAa,CAAEpX,GAAIT,KACxC,EAAI,EAEvB,MAAM+N,QAAcrO,KAAKW,eAAeN,EAAiBC,EAAa,CAAC,OAIvE,aAHwBqB,QAAQmF,IAAIuH,EAAMxI,IAAI,EAAG9E,QAASf,KAAK8a,WAC7D3C,EAAa,CAAEpX,WAEAkV,OAAQ8E,GAAYA,GAAStU,OAGhD,uBACE1F,EACA2S,EACA+F,EACAlW,GAEA,IAAKkW,EAAWhT,OAEd,kBADMlD,IAIR,MAAMmW,EAAiBjB,GAAWzY,KAAK0S,WACjCsI,EAAsB,GAC5B,UA3YJhZ,eACEiK,EACAgP,EACA1X,GAEA,MAIM2X,SAJgBvZ,QAAQuK,WAAWD,EAAOpG,IAAI7D,gBAC5CuB,EAAGzE,GACTmc,EAAanZ,KAAKhD,OAEKmX,OAAQrW,GAAmB,aAAbA,EAAE2O,QACzC,GAAI2M,EAASzU,OACX,MAAMyU,EAAS,GAiYPC,CAAO1B,EAAYuB,EAAYpL,GAAS5P,KAAKuZ,IAAIW,QACrDR,EACA,CAAEG,GAAItB,EAAY3I,EAAM8D,EAAK9D,IAAQ7O,MACrC,MACA0E,MAAMqS,EAlZ0B,kCAkZkB,aAAYlI,WAC1DrM,IACN,MAAOtB,GAKP,YAJMjC,KAAKuZ,IAAInE,iBACbsE,EACAsB,EAAUnV,IAAK+J,IAAD,CAAaiK,GAAItB,EAAY3I,EAAM8D,EAAK9D,QACtDnK,MAAMuS,GACF/V,GAIV,cAAsByR,GACpB,OAAO1T,KAAKob,iBACV1H,EAAK3S,GACL2S,EACA1T,KAAKyZ,WACL,IAAMzZ,KAAKuZ,IAAIW,QACbla,KAAK0S,UACLgB,EACA,MACAjO,MAAMqS,EAta0B,kCAsaiB,kBAIvD,iBAAyB1Y,EAAcwB,EAAiBkT,GACtD,MAAMuH,EAAgBrb,KAAKyZ,WAAWxD,OAAQ5P,GAAM9H,OAAOmB,eAAe1B,KAAK4C,EAAQyF,IACvF,IAAKgV,EAAc5U,OAEjB,kBADMzG,KAAKuZ,IAAIe,WAAWta,KAAK0S,UAAWtT,EAAKwB,EAAQkT,GAGzD,MAAM2C,QAAYzW,KAAKuZ,IAAInF,QAAQpU,KAAK0S,UAAWtT,EAAKic,GACxD,IAAK5E,EACH,MAAM,IAAInI,EAAS,IAlbe,kCAkbuB,iCAE3D,MAAMgN,EAAeD,EAAcpF,OAAQ5P,GAAOoQ,EAAIpQ,GAAW6R,IAAOtX,EAAOyF,GAAW6R,SACpFlY,KAAKob,iBACThc,EAAI2B,GACJH,EACA0a,EACA,IAAMtb,KAAKuZ,IAAIe,WAAWta,KAAK0S,UAAWtT,EAAKwB,EAAzC,OAAsD6V,GAAQ3C,WAEhE9T,KAAKuZ,IAAInE,iBACbqD,GAAWzY,KAAK0S,WAChB4I,EAAazV,IAAK+J,IAAD,CAAaiK,GAAItB,EAAY3I,EAAM6G,EAAI7G,QAI5D,iBAAyBxQ,GACvB,IACE,GAAKY,KAAKyZ,WAAWhT,OAEd,CACL,MAAMiN,QAAa1T,KAAKuZ,IAAIpD,oBAAoBnW,KAAK0S,UAAWtT,SAC1DY,KAAKuZ,IAAInE,iBACbqD,GAAWzY,KAAK0S,WAChB1S,KAAKyZ,WAAW5T,IAAK+J,IAAD,CAAaiK,GAAItB,EAAY3I,EAAM8D,EAAK9D,mBALxD5P,KAAKuZ,IAAIuB,WAAW9a,KAAK0S,UAAWtT,GAQ5C,OAAO,EACP,MAAO6C,GACP,GAAIqM,EAASE,OAAOvM,EA9cc,mCA+chC,OAAO,EAET,MAAMA,I,6DC9dG,MAAMsZ,GAAe,c,YAAA,K,EAAA,W,EACN,IAAI3V,I,6FAEhCoI,GAAMzK,GACJ,IAAIiY,EAAgB,OACpB,MAAMC,EAAS,IAAI9Z,QAASC,IAC1B4Z,EAAgB5Z,IACfuK,KAAK,KACNnM,KAAK0b,SAAS3V,OAAO0V,KAGvB,OADAzb,KAAK0b,SAASxQ,IAAIuQ,GACXlY,IAAKoY,QAAQH,GAGtB,aACE,MAAMI,EAAU,IAAI5b,KAAK0b,UACzB1b,KAAK0b,SAASG,cACRla,QAAQuK,WAAW0P,ICjBd,MAAME,GAGZhc,YACY6X,G,UACjB,KADiBA,W,EACjB,K,EAAA,U,EAJyB,IAAI/N,I,6FAMxB0B,OAAOlM,EAAQ2c,GACpB,MAAMjd,EAAQkB,KAAKgc,QAAQtd,IAAIU,GAC/B,GAAIY,KAAKgc,QAAQjW,OAAO3G,GAEtB,OADAY,KAAKgc,QAAQhS,IAAI5K,EAAKN,GACfA,EAET,MAAM+M,EAAUkQ,EAAK3c,GAGrB,OAFAY,KAAKgc,QAAQhS,IAAI5K,EAAKyM,GACtB7L,KAAKic,QACEpQ,EAGT,kBAAyBzM,EAAQ2c,GAC/B,MAAMjd,EAAQkB,KAAKgc,QAAQtd,IAAIU,GAC/B,GAAIY,KAAKgc,QAAQjW,OAAO3G,GAEtB,OADAY,KAAKgc,QAAQhS,IAAI5K,EAAKN,GACfA,EAET,MAAM+M,QAAgBkQ,EAAK3c,GAG3B,OAFAY,KAAKgc,QAAQhS,IAAI5K,EAAKyM,GACtB7L,KAAKic,QACEpQ,EAGFqQ,OAAO9c,GACZY,KAAKgc,QAAQjW,OAAO3G,GAGd6c,QACN,KAAOjc,KAAKgc,QAAQnV,KAAO7G,KAAK2X,UAC9B3X,KAAKgc,QAAQjW,OAAO/F,KAAKgc,QAAQjc,OAAOoc,OAAOrd,Q,6rBC3BrD,MAAMsd,GAAezX,OAAO0X,MAAM,GAC5BC,GAAiB,kBACjBC,GAAY,mBAEZC,GAA0BrY,YAAOlC,KAASA,aAAaqM,IAAarM,EAAEyM,eAE5E,SAAS+N,GAAO/X,GACd,MAAMgY,EAAOC,sBAAW,UAExB,OADAD,EAAK9b,OAAO8D,GACLgY,EAAKE,OAAO,OAGrB,SAASC,GAAKzd,EAAa0J,GACzB,MAAM4T,EAAOI,sBAAW,SAAU1d,GAElC,OADAsd,EAAK9b,OAAOkI,EAAM,QACX4T,EAAKE,SAuBC,MAAMG,GAanBjd,YAA6Bkd,EAAeC,GAAgB,KAA/BD,QAA+B,iDAV5B,IAAIlB,GAAyB,IAUD,yBAR1B,IAAIA,GAAyB,IAQH,mBANhC,IAAIA,GAAyB,KAMG,mBAJhC,IAAIP,IAI4B,kBAF3C,GAGfvb,KAAKkd,QAAUvY,OAAOqE,KAAM,OAAMiU,EAAU,QAG9CjP,GAAMzK,GACJ,OAAOvD,KAAK0b,SAAS1N,GAAGzK,GAG1B8T,SAAQ,OACNC,EADM,IAEN7K,EAFM,OAGNuF,EAHM,QAINuF,EAJM,QAKNC,EAAU,GALJ,KAMNJ,EAAOgF,GAND,KAONe,EAAO,IAAIha,OAIX,MAAMia,EAAa3Q,aAAeE,IAAOF,EAAM,IAAIE,IAAIF,GACvD,GAAI2Q,EAAUC,OACZ,MAAM,IAAI5c,MAAM,iDAElB,GAAIT,KAAKmH,OACP,MAAM,IAAI1G,MAAM,qBAGlB,IAAI6c,EAEFA,EADElG,aAAgBzS,OACLyS,EACY,iBAATA,EACHzS,OAAOqE,KAAKoO,EAAM,QAElBzS,OAAOqE,KAAKN,KAAKC,UAAUyO,GAAO,QAGjD,MAAMmG,EAAgBJ,EAAKK,cAAcxZ,QAAQsY,GAAgB,IAC3DmB,EAAgBF,EAAcxU,OAAO,EAAG,GACxC2U,EAAmB,GAAED,KAAiBzL,KAAUuF,iBAChDnY,EAAMY,KAAK2d,OAAOF,EAAezL,EAAQuF,GAGzCqG,EAAgBC,UAAUA,UAAUC,UAAUV,EAAUW,aAAe,IAGvEC,EAAqC,SACtCxG,GADmC,IAEtCyG,KAAMb,EAAUtL,KAChB,aAAcyL,IAKVW,EAAc3f,OAAOwB,KAAKie,GAC7BnY,IAAKsY,GAAWA,EAAOC,eACvB3S,OAEG4S,EAAmBH,EACtBrY,IAAKsY,GAAY,GAAEA,KAAUH,EAAWG,QACxCzS,KAAK,IACF4S,EAAgBJ,EAAYxS,KAAK,KAEjC6S,EAAmB,CACvBjH,EACAsG,EArB2B,GAuB3BS,EACAC,EACA7B,GAAOa,IACP5R,KAAK,MASD8S,EAAY3B,GAAKzd,EAPF,CACnBmd,GACAgB,EACAG,EACAjB,GAAO9X,OAAOqE,KAAKuV,EAAkB,UACrC7S,KAAK,OAEmCjD,SAAS,OAUnD,OARAuV,EAAWS,cAAgB,CACxB,GAAElC,iBAAwBvc,KAAKgd,SAASU,IACxC,iBAAgBY,EAChB,aAAYE,GACb9S,KAAK,aAEAsS,EAAWC,KAEXje,KAAK0e,MAAMtB,EAAWE,EAAY,CACvChG,SACAE,QAASwG,IAIb,cACMhe,KAAKmH,eAGHnH,KAAK0b,SAASla,OACpBxB,KAAKmH,QAAS,GAGRuX,MACNjS,EACA2K,EACAvW,GAEA,GAAIb,KAAKmH,OACP,MAAM,IAAI1G,MAAM,qBAGlB,MAAMke,EAA6B,UAAjBlS,EAAIkS,SAAwBC,KAAQC,KACtD,OAAO7e,KAAK0b,SAAS1N,GAAG,IAAMwO,GAAwB,IAAM,IAAI7a,QAAQ,CAACC,EAASC,KAChF,MAAMid,EAAMH,EAAStH,QAAQ5K,EAAK5L,EAAUke,IAC1C,MAAMxP,EAAkB,GACxBwP,EAAIC,GAAG,OAASC,GAAU1P,EAAMzN,KAAKmd,IACrCF,EAAIC,GAAG,MAAO,KACZ,IACE,MAAME,EAAOva,OAAOyE,OAAOmG,GAAO9G,SAAS,QAC3C8G,EAAM9I,OAAS,EACf,MAAMgR,EAAO/O,KAAKO,MAAMiW,IACnBH,EAAII,YAAcJ,EAAII,YAAc,IAEvCtd,EAAO,IAAIyM,EAASyQ,EAAII,YAAc,EAAG1H,EAAK2H,OAAQ3H,EAAK7T,UAE3DhC,EAAQ,CAAE2M,OAAQwQ,EAAII,WAAY1H,SAEpC,MAAOxV,GACPJ,EAAOI,QAIb6c,EAAIE,GAAG,QAASnd,GAChBid,EAAI9F,MAAM5B,GACV0H,EAAIO,UAIA1B,OACNF,EACAzL,EACAuF,GAEA,OAAOvX,KAAKsf,SAAShU,OAAQ,GAAEmS,KAAiBzL,KAAUuF,IAAW,KACnE,MAAMgI,EAAUvf,KAAKwf,eAAelU,OAAQ,GAAEmS,KAAiBzL,IAAU,IAAM6K,GAC7E7c,KAAKyf,aAAanU,OAAOmS,EAAe,IAAMZ,GAAK7c,KAAKkd,QAASO,IACjEzL,IAEF,OAAO6K,GAAKA,GAAK0C,EAAShI,GAAU,mBCtK3B,MAAMmI,WAAiBvU,EAC5BrL,YACW6N,EACA4L,EACjBoG,EACAzG,GAEA9R,MAAM,CAAChJ,EAAM2B,IAAS,IAAIoa,GACxBna,KAAKuZ,IACLoG,EAAkBxS,EAAW/O,GAC7B2B,EACAmZ,aAJoB,EAIpBA,EAAc7Z,KAAK,KAAMjB,KAL3B,KAJiBuP,MAIjB,KAHiB4L,MAYnB,eAAsB9M,EAAayM,GACjC,MAAM0G,EAAS,IAAIjT,IAAIF,GACvB,IAAIrN,EACA6d,EAQJ,GAPI2C,EAAOC,UACTzgB,EAAMwgB,EAAOC,SACb5C,EAAS2C,EAAOE,WAEhB1gB,EAAM2gB,QAAQC,IAAIC,kBAClBhD,EAAS8C,QAAQC,IAAIE,wBAElB9gB,IAAQ6d,EACX,MAAM,IAAIxc,MAAM,iCAElB,MAAMke,EAA+C,UAAnCiB,EAAO9S,aAAapO,IAAI,OAAsB,OAAS,QACnEqT,EAAgE,SAA9C6N,EAAO9S,aAAapO,IAAI,kBAC1CihB,EAAkBC,EAAO7B,SAAShV,OAAO,GAEzC4E,EAAM,IAAIoP,GAAI3d,EAAK6d,GACnB1D,EAAM,IAAI1H,EAAIlE,EAAM,GAAEgR,OAAciB,EAAO9N,OAAQ,CAAEC,mBAC3D,OAAO,IAAI2N,GACT/R,EACA4L,EACAoG,EACAzG,IAtEoBrM,EAsEa+S,EAAO9S,aAtEQ,CACpD4F,EACAzB,KAEA,IAAIW,EAA4B,KAchC,GAZEA,EADEX,EAEApE,EAAOnO,IAAK,aAAYgU,WAAmBzB,MAC3CpE,EAAOnO,IAAK,aAAYgU,YACxB7F,EAAOnO,IAAK,aAAYgU,IACxB7F,EAAOnO,IAAI,aAIXmO,EAAOnO,IAAK,aAAYgU,IACxB7F,EAAOnO,IAAI,cAGVkT,GAA6B,MAAfA,EACjB,OAAO,KAET,MAAMrC,EAAQqC,EAAWuO,MAAM,KAC/B,GAAqB,IAAjB5Q,EAAM9I,OACR,MAAM,IAAIhG,MAAO,sCAAqCiS,KAAazB,GAAa,OAAOW,oCAEzF,MAAO,CACLkH,KAAM/L,OAAOqT,SAAS7Q,EAAM,GAAI,IAChCyJ,MAAOjM,OAAOqT,SAAS7Q,EAAM,GAAI,QA3BX1C,MA0EjBxB,cAAgCjN,EAAc2B,GACnD,OAAOqH,MAAMiE,cAAcjN,EAAM2B,GAG5BsgB,SACL,OAAOrgB,KAAKuZ,IAGJnN,gBACR,OAAOpM,KAAK2N,IAAI7B,SChEb,SAASwU,GACdC,KACGC,GAEH,IAAIC,EAAWF,EAAM1a,IAAK6a,GAAOA,EAAGC,QAAQjV,KAAK,KAIjD,OAHA8U,EAASte,QAAQ,CAAC9D,EAAMP,KACtB4iB,EAAWA,EAASzc,QAAQ,IAAI4c,OAAQ,MAAKxiB,OAAW,KAAO,QAAOP,EAAI,QAErE4iB,E,kjCCfT,MAAMI,GAAmBnN,QAAkC5S,IAAT4S,EAElD,SAASoN,GACP/gB,EACAghB,GAEA,OAAOhhB,EACJkW,OAAO,EAAG7W,SAAU2hB,EAAuB3hB,IAC3CyG,IAAI,EAAGzG,MAAK4hB,YAAc,GAAEA,KAAUD,EAAuB3hB,MAGlE,SAAS6hB,GACPvN,EACA9I,GAEA,IAAKA,EACH,OAAO8I,EAET,MAAM5L,EAAwC,GAC9C,IAAK,IAAI3F,EAAI,EAAGA,EAAIyI,EAAOnE,OAAQtE,GAAK,EACtC2F,EAAO8C,EAAOzI,IAAOuR,EAAavR,GAEpC,OAAO2F,EAGT,SAASoZ,GAAexN,GACtB,OAAOnV,OAAO0N,OAAOyH,GAAMtS,KAAMsD,GAAa,OAANA,GAG1C1C,eAAemf,GAAWjU,SAClBA,EAAOkU,UAGfpf,eAAeqf,GACbpV,EACA1I,GAEA,MAAMuE,EAAc,GACpB,IAAK,IAAIjK,EAAI,EAAGA,EAAIoO,EAAOxF,OAAQ5I,GAAK,EAEtCiK,EAAOhG,WAAWyB,EAAG0I,EAAOpO,KAE9B,OAAOiK,EAGM,MAAMwZ,WAA0CzhB,IAOtDC,YACYyhB,EACAP,EACjBjhB,EAAkB,IAElBqH,MAAMrH,GADN,KAHiBwhB,OAGjB,KAFiBP,SAEjB,sBAV0D,IAU1D,qBARsC,IAQtC,wBANyC,IASzCziB,OAAOwB,KAAKA,GAAMmC,QAASb,IACzB,MAAMjC,EAAMiC,EACNmgB,EAAa,GAAER,KAAU5hB,IAC/BY,KAAKyhB,YAAYriB,GAAOoiB,EACxB,MAAME,EAAU,CAAEtiB,MAAK4hB,OAAQQ,GAC3BzhB,EAAKX,GAAMmD,OACbvC,KAAKyZ,WAAW3X,KAAK4f,GAErB1hB,KAAK2hB,cAAc7f,KAAK4f,KAKpBthB,YAAYtB,GACpB,MAAMgL,EAAaP,EAAgBzK,GACnC,OAAOkB,KAAKuhB,KAAKK,eAAe5f,UAE9B,UADoBhC,KAAK6hB,OAAO3U,EAAQpD,GAAY,GAElD,MAAM,IAAIrJ,MAAM,eAKZa,eACRjB,EACAC,EACAM,GACA,OAAEI,IAEF,MAAM8gB,EAAkBvY,EAAgB3I,GAClCmK,EAAOvC,EAAelI,GAE5B,MAAwB,OAApBD,EACKL,KAAKuhB,KAAKQ,oBAAoB/f,UACnC,MAAMggB,QAAchiB,KAAKiiB,eAAe/U,EAAQnC,EAAM+W,GACtD,GAAIE,QACIhiB,KAAKkiB,WAAWhV,EAAQ,CAAC8U,SAC1B,GAAIhhB,EAAQ,CACjB,MAAMmhB,EAAc,SAAKL,GAAR,IAAyB/gB,GAAIgK,IAC9C,UAAW/K,KAAK6hB,OAAO3U,EAAQiV,GAAa,GAC1C,MAAM,IAAI1hB,MAAM,eAGnB0gB,IAGEnhB,KAAKuhB,KAAKQ,oBAAoB/f,UACnC,MAAM2I,QAAa3K,KAAKoiB,2BAA2BlV,EAAQ7M,EAAiB0K,GACtEsX,SAAiBhB,GACrB1W,EACCN,GAAQrK,KAAKiiB,eAAe/U,EAAQ7C,EAAKyX,KACzC7L,OAAO4K,UACJ7gB,KAAKkiB,WAAWhV,EAAQmV,IAC7BlB,IAGKzgB,YAIRL,EACAC,EACAC,GAEA,MAAMwK,EAAOvC,EAAelI,GAC5B,OAAON,KAAKuhB,KAAKQ,oBAAoB/f,UAAkB,MACrD,MAAMqI,SAAarK,KAAKoiB,2BAA2BlV,EAAQ7M,EAAiB0K,IAAO,GACnF,QAAYjK,IAARuJ,EACF,OAAO,KAGT,wBADsBrK,KAAKsiB,qBAAqBpV,EAAQ,CAAC7C,GAAM9J,IAChD,UAAf,QAAqB,MACpB4gB,IAGKxgB,eAIRN,EACAC,EACAC,GAEA,OAAOP,KAAKuhB,KAAKQ,oBAAoB/f,UACnC,IAAI2I,EACJ,GAAItK,EAAiB,CACnB,MAAM0K,EAAOvC,EAAelI,GAC5BqK,QAAa3K,KAAKoiB,2BAA2BlV,EAAQ7M,EAAiB0K,OACjE,CACLJ,QAAauC,EAAOnN,KAAKC,KAAKuiB,QAAQ,MACtC,MAAMC,EAAMxiB,KAAKghB,OAAOva,OAAS,EACjCkE,EAAOA,EAAK9E,IAAKnB,GAAMA,EAAEqE,OAAOyZ,IAElC,OAAOxiB,KAAKsiB,qBAAqBpV,EAAQvC,EAAMpK,IAC9C4gB,IAGK5f,eACRlB,EACAC,GAEA,MAAMyK,EAAOvC,EAAelI,GACtBmiB,EAAclkB,OAAOwB,KAAKC,KAAKD,MAGrC,OAFA0iB,EAAY3gB,KAAK,MAEV9B,KAAKuhB,KAAKQ,oBAAoB/f,UACnC,MAAM2I,QAAa3K,KAAKoiB,2BAA2BlV,EAAQ7M,EAAiB0K,GACtEsD,SAAegT,GACnB1W,EACCN,GAAQrK,KAAK0iB,oBAAoBxV,EAAQ7C,EAAKoY,KAC9CxM,OAAO4K,IAEV,GAAqB,IAAjBxS,EAAM5H,OACR,OAAO,EAGT,MAAMkc,EAAWzV,EAAO0V,QAaxB,OAZAvU,EAAMnM,QAASwR,IACb,MAAM+F,EAAaqH,GAAc9gB,KAAKyZ,WAAY/F,GAC5CiO,EAAgBb,GAAc9gB,KAAK2hB,cAAejO,GACxDiP,EAASzG,OACP,EAAIzC,EAAWhT,OAASkb,EAAclb,OACtCzG,KAAKuiB,QAAQ7O,EAAK3S,OACf0Y,KACAkI,EACHjO,EAAK3S,YAGH4hB,EAASre,OACR+J,EAAM5H,QACZ0a,IAGGoB,QAAQM,GACd,MAAQ,GAAE7iB,KAAKghB,UAAU6B,IAG3B,aACE3V,EADF,EAGE4V,GACkB,IAFlB,GAAE/hB,GAEgB,EAFT+I,EAES,aAClB,MAAM2P,EAAaqH,GAAc9gB,KAAKyZ,WAAY3P,GAC5C6X,EAAgBb,GAAc9gB,KAAK2hB,cAAe7X,GAElDiZ,EAAW,EAAItJ,EAAWhT,OAASkb,EAAclb,OACjDoG,EAAS,CACb7M,KAAKuiB,QAAQxhB,MACV0Y,KACAkI,EACHlI,EAAWhT,OACX,KACA1F,KACGxC,OAAOqS,QAAQ9G,GAAYkZ,QAGhC,IAAKF,EACH,OAAOxgB,cAAc4K,EAAOhC,IAAI6X,KAAalW,IAG/C,MAAM/E,QAAeoF,EAClB0V,QACA1X,IAAI6X,KAAalW,GACjBvI,OACH,IAAKwD,EACH,MAAM,IAAIrH,MAAM,mBAElB,OAAO6B,QAAQwF,EAAO,GAAG,IAG3B,qBACEoF,EACA7C,EACAyX,SAEM5U,EAAO+V,MAAMjjB,KAAKuiB,QAAQlY,IAChC,MAAMC,QAAsBtK,KAAK0iB,oBAC/BxV,EACA7C,EACA9L,OAAOwB,KAAKC,KAAKD,MAAMkW,OAAQ5U,GAAMygB,EAAgBzgB,KAEvD,IAAKiJ,EACH,OAEF,MAAMG,EAAgB,MAAKqX,GAO3B,OANAvjB,OAAOwB,KAAK0K,GAAevI,QAASb,IAC9BiJ,EAAcjJ,KAAOoJ,EAAcpJ,YAC9BoJ,EAAcpJ,UACdiJ,EAAcjJ,MAGlB,CAAEgJ,MAAKI,gBAAeH,iBAG/B,iBACE4C,EACAmV,GAEA,MAAMa,EAAWb,EACdxc,IAAKmc,GAAUhiB,KAAKmjB,eAAenB,IACnC/L,OAAO4K,IAEV,IAAKqC,EAASzc,OACZ,OAGF,GAAwB,IAApByc,EAASzc,OAAc,CACzB,MAAM2c,QAAgBlW,EAAO0V,QAC1BhiB,OAAOsiB,EAAS,GAAG,GAAIA,EAAS,GAAG,IACnC5e,OAEH,IAAK8e,EACH,MAAM,IAAI3iB,MAAM,mBAElB,IAAK2iB,EAAQ,GAAG,GACd,MAAM,IAAI3iB,MAAM,aAElB,OAOF,UAJiC4gB,GAC/B6B,EACCG,GAAenW,EAAOoW,YAAYD,EAAW,GAAIA,EAAW,MAExCjiB,KAAMzC,IAAOA,GAClC,MAAM,IAAI8B,MAAM,aAGlB,IAAI8iB,EAAQrW,EAAO0V,QACnBM,EAAShhB,QAASmhB,IAChBE,EAAQA,EAAMC,mBAAmBH,EAAW,GAAIA,EAAW,MAI7D,UAFsBE,EAAMjf,OAG1B,MAAM,IAAI7D,MAAM,mBAIZ0iB,gBACN,IAAE9Y,EAAF,cAAOC,EAAP,cAAsBG,IAEtB,MAAMgZ,EAAOllB,OAAOqS,QAAQnG,GAAeuY,OAC3C,IAAKS,EAAKhd,OACR,OAEF,MAAMid,EAAkB5C,GAAc9gB,KAAKyZ,WAAYhP,GACjDkZ,EAAqB7C,GAAc9gB,KAAK2hB,cAAelX,GACvDmZ,EAAgB9C,GAAc9gB,KAAKyZ,WAAYnP,GAC/CuZ,EAAmB/C,GAAc9gB,KAAK2hB,cAAerX,GAC3D,GACEsZ,EAAcnd,SAAWid,EAAgBjd,QACzCod,EAAiBpd,SAAWkd,EAAmBld,OAE/C,MAAM,IAAIhG,MAAM,0CAclB,MAAO,CAZU,EAA2D,GAAtDijB,EAAgBjd,OAASkd,EAAmBld,QACnD,CACbzG,KAAKuiB,QAAQlY,MACVqZ,KACAC,KACAC,KACAC,EACHH,EAAgBjd,OAChBid,EAAgBjd,OAASkd,EAAmBld,OAC5C4D,KACGoZ,IAKP,2BACEvW,EACA4W,EACAlZ,GAEA,MAAMwY,QDlVHphB,eACLkL,EACA6W,GAEA,OAAKA,EAAStd,OAGPyG,EAAO0V,MAAMmB,GAAUzf,OAFrB,GC6Ue0f,CACpB9W,EACA4W,EACGje,IAAKwE,GAAQrK,KAAKuiB,QAAQlY,IAC1BxE,IAAKxE,GAAOuJ,EAAS,CAAC,QAASvJ,KAAMuJ,GAAU,CAAC,UAAWvJ,KAEhE,IAAK+hB,EACH,MAAM,IAAI3iB,MAAM,mBAElB,OAAO2iB,EACJvd,IAAI,EAAE,CAAE6N,KAA0BuN,GAAUvN,EAAM9I,IAClDqL,OAAOiL,IACPrb,IAAI4D,GAGT,0BACEyD,EACA2V,EACAjY,GAEA,MAAMxL,EAAMY,KAAKuiB,QAAQM,GACzB,IAAInP,EACJ,GAAI9I,EAAQ,CACV,IAAKA,EAAOnE,OAAQ,CAGlB,aADqByG,EAAO+W,OAAO7kB,GACnB,QAAK0B,EAEvB4S,QAAaxG,EAAOgX,MAAM9kB,KAAQwL,QAElC8I,QAAaxG,EAAOiX,QAAQ/kB,GAE9B,MAAMwgB,EAASqB,GAAUvN,EAAM9I,GAC/B,OAAOsW,GAAetB,GAAUA,OAAS9e,EAG3C,iCACEoM,EACAlH,EACAgF,GAEA,GAAgB,OAAZhF,EACF,MAAO,CAACgF,GAEV,MAAMwW,EAAYxhB,KAAKyhB,YAAYzb,GACnC,IAAKwb,EACH,MAAM,IAAI/gB,MAAO,iBAAgBuF,iBAEnC,MAAMoe,EAAc,GAAE5C,KAAaxW,IAEnC,aADMkC,EAAO+V,MAAMmB,GACZlX,EAAOmX,SAASD,IC3Y3B,MAAME,GAAahE,GAAgB,CACjC,0CACA,aACA,MACA,yCACA,4CACA,eACA,QACA,MACA,6CACA,mBACA,uCACA,MACA,YACC,kBAEGiE,GAAoB,CACxB,yCACA,4CACA,eACA,QACA,OAGIC,GAAc,CAClB,qCACA,6CACA,iBACA,oDACA,OAIIC,GAAsBnE,GAAgB,IACvCiE,GACH,YACC,iBAAkB,gBAAiB,MAGhCG,GAA8BpE,GAAgB,IAC/CkE,IACF,iBAAkB,gBAAiB,MAGhCG,GAAgBrE,GAAgB,IACjCiE,MACAC,GACH,YACC,iBAAkB,gBAAiB,MAGhCI,GAAgBtE,GAAgB,CACpC,4BACA,mBACA,mCACA,OACC,M,yHChEH,MAAMuE,GAAY1gB,YAAOlC,GACV,iBAANA,GACO,oBAAdA,EAAE2B,SAGW,MAAMkhB,GAWZhlB,YACYilB,EACAtY,EACA5L,EACAmkB,GACjB,KAJiBD,cAIjB,KAHiBtY,MAGjB,KAFiB5L,UAEjB,KADiBmkB,iBACjB,sBAfuC,IAevC,gBAbc,GAad,gBAX4C,IAW5C,8CAPe,GASjB,qBACEzhB,EACA0hB,GAEA,MAAM/mB,QAAU8B,KAAKklB,gBACrB,IACE,aAAa3hB,EAAGrF,GADlB,cAGQ+mB,aAAN,EAAMA,EAAW/mB,IACjB8B,KAAKmlB,iBAAiBjnB,IAI1B,0BACEqF,EACA0hB,GAEA,OAAOJ,GAAU,IAAM7kB,KAAK4hB,eAAere,EAAI0hB,IAG1CnZ,QACL,OAAI9L,KAAKmH,OACAxF,QAAQC,WAGjB5B,KAAKmH,QAAS,EACK,IAAfnH,KAAKolB,OACPplB,KAAKqlB,UACE1jB,QAAQC,WAGV,IAAID,QAASC,IAClB5B,KAAKslB,UAAY,KACftlB,KAAKqlB,UACLzjB,QAKEyjB,UACNrlB,KAAKulB,YAAYrjB,QAAShE,GAAMA,EAAEsnB,cAClCxlB,KAAKulB,YAAY9e,OAAS,EAG5B,sBACE,GAAIzG,KAAKmH,OACP,MAAM,IAAI1G,MAAM,qBAGlB,MAAM9B,EAAIqB,KAAKulB,YAAYE,MAC3B,GAAI9mB,EAEF,OADAqB,KAAKolB,OAAS,EACPzmB,EAET,GAAIqB,KAAKolB,MAAQplB,KAAKglB,eAAgB,CACpChlB,KAAKolB,OAAS,EACd,MAAMlY,EAAS,IAAIlN,KAAK+kB,YAAY/kB,KAAKyM,IAAKzM,KAAKa,SAEnD,aADMqM,EAAOI,UDdJ,SAA0BJ,GAOvC,OANAA,EAAOwY,cAAc,MAAO,CAAEC,IAAKrB,KACnCpX,EAAOwY,cAAc,SAAU,CAAEC,IAAKhB,KACtCzX,EAAOwY,cAAc,cAAe,CAAEC,IAAKlB,KAC3CvX,EAAOwY,cAAc,qBAAsB,CAAEC,IAAKjB,KAClDxX,EAAOwY,cAAc,SAAU,CAAEC,IAAKf,KAE/B1X,ECQI0Y,CAAiB1Y,GAE1B,OAAO,IAAIvL,QAASC,IAClB5B,KAAKgX,MAAMlV,KAAKF,KAIZujB,iBAAiBjnB,GACvB,MAAM2nB,EAAI7lB,KAAKgX,MAAM8O,QAMG,MALpBD,EACFA,EAAE3nB,IAEF8B,KAAKolB,OAAS,EACdplB,KAAKulB,YAAYzjB,KAAK5D,GACH,IAAf8B,KAAKolB,QACP,UAAAplB,KAAKslB,iBAAL,cAAAtlB,SChGO,MAAM+lB,WAAgB5a,EAC3BrL,YACWyhB,GAEjBna,MAAM,CAAChJ,EAAM2B,IAAS,IAAIuhB,GAAgBthB,KAAKuhB,KAAMnjB,EAAM2B,IAD3D,KADiBwhB,OAKnB,qBAA4B9U,GAC1B,MAAQY,QAAS0X,SAAsB,QAAN,qBAAa,KAE9C,OAAO,IAAIgB,GAAQ,IAAIjB,GACrBC,EACAtY,EACA,CAAEuZ,aAAa,GAJU,IAStB3a,cAAgCjN,EAAc2B,GACnD,OAAOqH,MAAMiE,cAAcjN,EAAM2B,GAG5BkmB,oBACL,OAAOjmB,KAAKuhB,KAGJnV,gBACR,OAAOpM,KAAKuhB,KAAKzV,SCjCd,SAASoa,GAAYxhB,GAC1B,MAAQ,IAAGA,EAAEV,QAAQ,WAAY,WCDnC,MAAMmiB,GAAa,KAKnB,MAAMC,GAAa,KACZ,SAASC,GAAWC,GAGzB,MAAQ,IAAGA,EAAItiB,QAAQoiB,GAAY,SAGrC,MAAMG,GAAS,WACR,SAASC,GACdC,EACAC,GAEA,OAAOD,EAAKziB,QACVuiB,GACC7hB,GAjBK,IAiBiBgiB,EAAYhiB,EAAEqE,OAAO,IAjB/B/E,QAAQmiB,GAAY,U,qXCOrC,MAAMQ,GAAa,CACjBC,aAAc,CACZ,kCACA,gCACA,uBACA,KACAlb,KAAK,IAEPmb,gBAAiB,sFAEjBC,aAAc,8DACdC,oBAAqB,0DACrBC,WAAY,0BAEZC,OAAQ,oDAERC,OAAQ,qEACRC,UAAW,kDAEXC,UAAW,4GAEXC,WAAY,oDACZC,WAAY,0BACZC,cAAe,4CACfC,UAAW,sCAEXC,OAAQ,mCACRC,UAAW,8BAiEb,SAASC,GAASne,GAChB,OFlGK,SAAsBA,GAC3B,MAAM1B,EAAmB,GAIzB,OAHAvJ,OAAOwB,KAAKyJ,GAAQtH,QAASb,IAC3ByG,EAAOhG,KAAM,GAAEokB,GAAY7kB,OAAO6kB,GAAY1c,EAAOnI,SAEhDyG,EAAO4D,KAAK,KE6FZkc,CAAare,EAAgBC,IAGtC,SAASqe,IACN9mB,EAAI+H,GACL8B,GAEA,MAAMkd,EFjGD,SAAsBC,GAC3B,MAAMjgB,EAAiC,GACvC,IAAI8T,EAAU,GACVoM,EAAa,GACbC,GAAQ,EACZ,IAAK,IAAItoB,EAAI,EAAGA,EAAIooB,EAAOthB,QAAS,CAClC,MAAMvI,EAAI6pB,EAAOpoB,GACjB,OAAQzB,GACN,IAAK,IACL,IAAK,KACL,IAAK,KACL,IAAK,KACC+pB,IACFrM,GAAW1d,GAEb,MACF,IAAK,KACH0d,GAAWmM,EAAOpoB,EAAI,GACtBA,GAAK,EACL,MACF,IAAK,IACHsoB,GAASA,EACT,MACF,IAAK,IACCA,EACFrM,GAAW1d,EACgB,MAAlB6pB,EAAOpoB,EAAI,KACpBqoB,EAAapM,EACbA,EAAU,GACVjc,GAAK,GAEP,MACF,IAAK,IACCsoB,EACFrM,GAAW1d,GAEX4J,EAAOkgB,GAAcpM,EACrBoM,EAAa,GACbpM,EAAU,IAEZ,MACF,QACEA,GAAW1d,EAGfyB,GAAK,EAKP,OAHIqoB,IACFlgB,EAAOkgB,GAAcpM,GAEhB9T,EE+CQogB,CAAapf,GAC5Bgf,EAAO/mB,GAAKA,EAEZ,MAAM+G,EAAkC,GAExC,OAAK8C,GAOLA,EAAO1I,QAASC,IACd2F,EAAO3F,GAAKyG,EAAiBkf,EAAO3lB,MAE/B2F,IATLvJ,OAAOqS,QAAQkX,GAAQ5lB,QAAQ,EAAEb,EAAGqD,MAClCoD,EAAOzG,GAAKuH,EAAiBlE,KAExBoD,GASI,MAAMqgB,WAA6CtoB,IAGzDC,YACYyhB,EACA7O,EACjB3S,EAAkB,GACDmH,EAAqB,CAAEC,QAAQ,I,UAEhDC,MAAMrH,GADN,KAJiBwhB,OAIjB,KAHiB7O,YAGjB,KADiBxL,W,EANgE,I,EAOjF,mB,EAAA,M,sFAGAlH,KAAKqH,UAnGTrF,eACEuf,EACA7O,EACA3S,EAAoB,IAEpB,MAAM7B,QAAUqjB,EAAKjU,UACrB,UAGQpP,EAAEuJ,MAAM+e,GAAgBG,GAAWC,aAAc,CACrDwB,EAAG1V,KAGL,MAAM7I,QAAgB3L,EAAEuJ,MAAM,CAC5B4gB,QAAS,QACTnJ,KAAMyH,GAAWE,gBACjB5a,OAAQ,CAACyG,KAEL4V,EAAgB,IAAI1iB,IACxBiE,EAAQ0e,KACL1iB,IAAKlH,GAAMA,EAAE,IACbsX,OAAQpY,GAAOA,EAAE2qB,WAAc9V,EAAF,OAAoB7U,EAAE2qB,WAAc9V,EAAF,QAK9D+V,EAAalqB,OAAOqS,QAAQ7Q,GAClC,IAAK,IAAIlC,EAAI,EAAGA,EAAI4qB,EAAWhiB,OAAQ5I,GAAK,EAAG,CAC7C,MAAOwD,EAAGqD,GAAK+jB,EAAW5qB,GAC1B,GAAI6G,GAAKA,EAAEnC,OAAQ,CACjB,MAAMnE,EAAQ,GAAEsU,MAAcrR,IACzBinB,EAAcviB,OAAO3H,UAClBF,EAAEuJ,MAAM+e,GAAgBG,GAAWI,oBAAqB,CAC5DqB,EAAG1V,EACHgW,EAAGtqB,IACF4F,QAAQ,OAAQqiB,GAAWhlB,SAE3B,CACL,MAAMjD,EAAQ,GAAEsU,MAAcrR,IACzBinB,EAAcviB,OAAO3H,UAClBF,EAAEuJ,MAAM+e,GAAgBG,GAAWG,aAAc,CACrDsB,EAAG1V,EACHgW,EAAGtqB,IACF4F,QAAQ,OAAQqiB,GAAWhlB,MAIpC,MAAMsnB,EAAkB,IAAIL,GAC5B,IAAK,IAAIzqB,EAAI,EAAGA,EAAI8qB,EAAgBliB,OAAQ5I,GAAK,EAAG,CAClD,MAAMiI,EAAM6iB,EAAgB9qB,SACtBK,EAAEuJ,MAAM+e,GAAgBG,GAAWK,WAAY,CACnDoB,EAAG1V,EACHgW,EAAG5iB,MA9CT,QAoDE5H,EAAE0qB,WAyCatP,CAAeiI,EAAM7O,EAAW3S,IAGjD,qBAA+D,IAAnC,GAAEgB,GAAiC,EAA1B8nB,EAA0B,mBACvD7oB,KAAK8oB,cAAc,SAAUtgB,EAAezH,GAAK4mB,GAASkB,IAGlE,qBACE9nB,EACAH,SAEMZ,KAAK8oB,cAAc,YAAatgB,EAAezH,GAAK4mB,GAAS/mB,IAGrE,qBACEP,EACAC,EAFF,GAIiB,IADf,GAAES,GACa,EADN8nB,EACM,aACf,MAAMxe,EAAM7B,EAAelI,GACrBynB,EAASJ,GAASkB,GAExB,GAAwB,OAApBxoB,QACIL,KAAK8oB,cAAc,YAAaf,EAAQ1d,OACzC,CACL,MAAM1L,QAAUqB,KAAK8oB,cAAc,SAAUf,EAAQ1nB,EAAiBgK,GACtE,QAAWvJ,IAAPC,GAAoBpC,EAAEoqB,SAAW,GAAKpqB,EAAE4pB,KAAK,GAAG,KAAOxnB,EACzD,MAAM,IAAIN,MAAM,qBAKtB,kBAIEJ,EACAC,EACAC,GAEA,IAAIwH,EAMJ,OAJEA,EADsB,OAApB1H,QACUL,KAAK8oB,cAAc,YAAatgB,EAAelI,UAE/CN,KAAK8oB,cAAc,aAAczoB,EAAiBmI,EAAelI,IAE1EyH,EAAIghB,SAGFlB,GAAc9f,EAAIwgB,KAAK,GAAIhoB,GAFzB,KAKX,qBAIEF,EACAC,EACAC,GAEA,IAAIwH,EAQJ,OAJEA,EAHG1H,EAE0B,OAApBA,QACGL,KAAK8oB,cAAc,YAAatgB,EAAelI,UAE/CN,KAAK8oB,cAAc,gBAAiBzoB,EAAiBmI,EAAelI,UAJpEN,KAAK8oB,cAAc,cAM1B/gB,EAAIwgB,KAAK1iB,IAAKnB,GAAMmjB,GAAcnjB,EAAGnE,IAG9C,qBACEF,EACAC,GAEA,IAAIyH,EAMJ,OAJEA,EADsB,OAApB1H,QACUL,KAAK8oB,cAAc,YAAatgB,EAAelI,UAE/CN,KAAK8oB,cAAc,SAAUzoB,EAAiBmI,EAAelI,IAEpEyH,EAAIghB,SAGLD,cACNE,KACG/c,GAEH,GAAIjM,KAAKkH,SAASC,OAChB,MAAM,IAAI1G,MAAM,qBAGlB,IAAI6K,EAAStL,KAAKipB,cAAcD,GAMhC,OALK1d,IACHA,EAASkb,GAAgBG,GAAWqC,GAAY,CAAEZ,EAAGpoB,KAAK0S,YAC1D1S,KAAKipB,cAAcD,GAAa1d,GAG3BtL,KAAKuhB,KAAK9Z,MAAM,CACrBrJ,KAAO,GAAE4B,KAAK0S,aAAasW,IAC3BX,QAAS,QACTnJ,KAAM5T,EACNW,YC1OS,MAAMid,WAAmB/d,EAC9BrL,YACWyhB,GAEjBna,MAAM,CAAChJ,EAAM2B,IAAS,IAAIooB,GAAmB5G,EAAMnjB,EAAM2B,EAAMC,KAAKkH,WADpE,KADiBqa,OAKnB,qBAA4B9U,GAC1B,MAAM,KAAE0c,SAAe,QAAN,qBAAa,KACxB5H,EAAO,IAAI4H,EAAK,CAAEC,iBAAkB3c,IAE1C,aADM8U,EAAK9Z,MAAM,yCACV,IAAIyhB,GAAW3H,GAGjBlW,cAAgCjN,EAAc2B,GACnD,OAAOqH,MAAMiE,cAAcjN,EAAM2B,GAG5BkmB,oBACL,OAAOjmB,KAAKuhB,KAGJnV,gBACR,OAAOpM,KAAKuhB,KAAKlC,O,6rBCIrB,SAASgK,GACPvqB,EACA8L,GAEA,OAAOA,EACJxJ,KAAMyJ,GAAUtM,OAAOkB,UAAUC,eAAe1B,KAAKc,EAAO+L,IAGlD,MAAMye,GAOZxpB,YACYypB,EACA3e,EACA4e,GACjB,KAHiBD,iBAGjB,KAFiB3e,SAEjB,KADiB4e,UAGnB,UAAiBrpB,GACf,OAAOH,KAAKupB,eAAere,UAAUlL,KAAKypB,QAAQtpB,IAGpD,UAIEf,EACAN,EACA8L,GAEA,GAAI5K,KAAK4K,OAAO1B,SAAS9J,GACvB,MAAM,IAAIqB,MAAM,+BAElB,MAAMsH,QAAY/H,KAAKupB,eAAe7qB,IAAIU,EAAKN,EAAO8L,GACtD,OAAO7C,EAAM/H,KAAK0pB,UAAU3hB,EAAK,CAAE,CAAC3I,GAAMN,IAAW,KAGvD,aAIEM,EACAN,EACA8L,GAEA,QAAY9J,IAAR1B,GAAqBY,KAAK4K,OAAO1B,SAAS9J,GAC5C,MAAM,IAAIqB,MAAM,+BAElB,MAAMsH,QAAY/H,KAAKupB,eAAeI,OAAOvqB,EAAMN,EAAQ8L,GACrDgf,OAAiB9oB,IAAR1B,EAAqB,CAAE,CAACA,GAAMN,QAAUgC,EACvD,OAAOa,QAAQmF,IAAIiB,EAAIlC,IAAKnB,GAAM1E,KAAK0pB,UAAUhlB,EAAGklB,KAGtD,aACExqB,EACAN,EACA8B,EACAC,GAEA,GAAIb,KAAK4K,OAAO1B,SAAS9J,GACvB,MAAM,IAAIqB,MAAM,kCAElB,MAAMgE,QAAkBzE,KAAKypB,QAAQ7oB,EAAQ,CAAE,CAACxB,GAAMN,IACtD,OAAOkB,KAAKupB,eAAe3oB,OAAOxB,EAAKN,EAAO2F,EAAW5D,GAG3D,aACEzB,EACAN,GAEA,GAAIkB,KAAK4K,OAAO1B,SAAS9J,GACvB,MAAM,IAAIqB,MAAM,kCAElB,IAAKT,KAAKwpB,QAAQK,UAChB,OAAO7pB,KAAKupB,eAAerN,OAAO9c,EAAKN,GAGzC,MAAMuP,QAAcrO,KAAKupB,eAAeI,OAAOvqB,EAAKN,EAAO,CAAC,OAK5D,aAJM6C,QAAQmF,IAAIuH,EAAMxI,IAAI7D,gBACpBhC,KAAKwpB,QAAQK,UAAWnW,SACxB1T,KAAKupB,eAAerN,OAAO,KAAMxI,EAAK3S,OAEvCsN,EAAM5H,OAaf,cACE/B,EACAklB,GAEA,IAAIE,EACJ,GAAI9pB,KAAKwpB,QAAQO,SAAWV,GAAY3kB,EAAG1E,KAAK4K,QAAS,CACvD,MAAMof,EAAYJ,EAAQ,SAAKA,GAAUllB,GAAMA,EAC/ColB,QAAkB9pB,KAAKwpB,QAAQO,QAAQC,GAEzC,MAAMvlB,EAAY,MAAKC,GAMvB,aALM/C,QAAQmF,IAAI9G,KAAK4K,OAAO/E,IAAI7D,UAC5BzD,OAAOkB,UAAUC,eAAe1B,KAAK0G,EAAGrD,KAC1CoD,EAAUpD,SAAWrB,KAAKwpB,QAAQS,KAAK5oB,EAAIqD,EAAUrD,GAAIyoB,OAGtDrlB,EAaT,gBACEC,EACAklB,GAEA,IAAIE,EACJ,GAAI9pB,KAAKwpB,QAAQU,WAAab,GAAY3kB,EAAG1E,KAAK4K,QAAS,CACzD,MAAMof,EAAYJ,EAAQ,SAAKA,GAAUllB,GAAMA,EAC/ColB,QAAkB9pB,KAAKwpB,QAAQU,UAAUF,GAE3C,MAAMvlB,EAAY,MAAKC,GAMvB,aALM/C,QAAQmF,IAAI9G,KAAK4K,OAAO/E,IAAI7D,UAC5BzD,OAAOkB,UAAUC,eAAe1B,KAAK0G,EAAGrD,KAC1CoD,EAAUpD,SAAWrB,KAAKwpB,QAAQW,OAAO9oB,EAAIqD,EAAUrD,GAAIyoB,OAGxDrlB,GC3KX,MAAM2lB,GAAM,cACNC,GAAU1lB,OAAOqE,KAAQohB,GAAF,IAAU,QAmCxBE,OAhC2C,CACxDC,QAAS,CAACnrB,EAAgBsF,KACxB,MAAM8lB,EAAKC,KAAOC,YAJP,IAKLC,EAASF,KAAOG,eAAeR,GAAKhrB,EAAKorB,GACzCK,EAAOF,EAAO/pB,OAAO8D,GACrBomB,EAAQH,EAAOG,QACrB,OAAOnmB,OAAOyE,OAAO,CAACihB,GAASG,EAAIK,EAAMC,KAG3CC,QAAS,CAAC3rB,EAAgBsF,KACxB,IAAKA,EAAE6P,MAAM,EAAG8V,GAAQ5jB,QAAQukB,OAAOX,IACrC,MAAM,IAAI5pB,MAAM,gCAGlB,MAAM+pB,EAAK9lB,EAAE6P,MAAM8V,GAAQ5jB,OAAQ4jB,GAAQ5jB,OAhBhC,IAiBLwkB,EAAYvmB,EAAE6P,MAAM8V,GAAQ5jB,OAjBvB,IAmBLykB,EAAWT,KAAOU,iBAAiBf,GAAKhrB,EAAKorB,GAC7CK,EAAOK,EAAStqB,OAAOqqB,GACvBH,EAAQI,EAASJ,QAEvB,OAAOnmB,OAAOyE,OAAO,CAACyhB,EAAMC,KAG9BM,YAAa,IAAiBX,KAC3BY,gBAAgBZ,KAAOC,YAAY,KAEtCY,aAAelsB,GAA2BA,EAAImsB,SAE9CC,eAAiB1iB,GAA4B2hB,KAAOY,gBAAgBviB,ICVtE,SAAS2iB,GACPjC,GAKA,MAAO,CAAC5e,EAAc2e,IAChB3e,GAAU2e,EAELC,EAAQ5e,EAAQ2e,GAElBC,EA4BX,SAASkC,GACP3gB,GACA,WACE4gB,EAAarB,GADf,SAEEsB,GAAW,GACgC,IAE7C,MAAMxsB,EAAMusB,EAAWH,eAAezgB,GAEtC,OAAO0gB,GAAc,CACnB7gB,EACA2e,IACG,IAAID,GAAuCC,EAAgB3e,EAAQ,CACtEqf,KAAM,CAAC5oB,EAAGqD,IAAgCinB,EAAWpB,QAAQnrB,EAAK+J,EAAkBzE,IACpFylB,OAAQnoB,MAAOX,EAAGqD,KAChB,KAAMA,aAAaC,QAAS,CAC1B,GAAIinB,EACF,OAAOlnB,EAET,MAAM,IAAIjE,MAAM,oBAElB,OAAO4I,QAA0BsiB,EAAWZ,QAAQ3rB,EAAKsF,QAe/D,SAASmnB,GACPC,GACA,WACEH,EAAarB,GADf,SAEEsB,GAAW,EAFb,UAGEG,EAAY,GACyD,IAEvE,MAAMC,EAAQ,IAAIlQ,GAAmBiQ,GAE/BE,EAAUjqB,MACdkqB,EACA1iB,KAEA,MAAM,GAAEzI,GAAOyI,EAEf,QAAW1I,IAAPC,EACF,MAAM,IAAIN,MAAM,kCAGlB,OAAOurB,EAAMG,YAAYprB,EAAIiB,UAC3B,MAAM0R,QAAaoY,EAAcptB,IAAI,KAAMqC,EAAI,CAAC,QAChD,GAAI2S,EACF,OAAOiY,EAAWH,eAAe9X,EAAKtU,KAExC,IAAK8sB,EACH,MAAM,IAAIzrB,MAAM,sCAElB,MAAMrB,QAAYusB,EAAWP,cAE7B,aADMU,EAAc5gB,IAAI,CAAEnK,KAAI3B,IAAKusB,EAAWL,aAAalsB,KACpDA,KAILgtB,EAAYpqB,OAASjB,eACnB+qB,EAAc5P,OAAO,KAAMnb,GACjCirB,EAAM9P,OAAOnb,IAIf,OAAO0qB,GAAkB,CACvB7gB,EACA2e,IACG,IAAID,GAAsCC,EAAgB3e,EAAQ,CACrEqf,KAAM,CAAC5oB,EAAGqD,EAAGtF,IAAkCusB,EAAWpB,QAAQnrB,EAAK+J,EAAkBzE,IACzFylB,OAAQnoB,MAAOX,EAAGqD,EAAGtF,KACnB,KAAMsF,aAAaC,QAAS,CAC1B,GAAIinB,EACF,OAAOlnB,EAET,MAAM,IAAIjE,MAAM,oBAElB,OAAO4I,QAA0BsiB,EAAWZ,QAAQ3rB,EAAKsF,KAE3DqlB,QAASkC,EAAQ5sB,KAAK,MAAM,GAC5B6qB,UAAW+B,EAAQ5sB,KAAK,MAAM,GAC9BwqB,UAAWuC,KAgBf,SAASC,GACPC,EACAR,EACAjrB,EAA6E,IAE7E,MAAM0rB,EAAO1rB,EAMb,OAAOgrB,GALQH,GAAaY,EAAYC,EACfC,GACvB,CAAC,OACDV,GAEuCS,G,+BCvK3C,MAAME,GAAeC,qBAA0BC,KAAKC,MAC9CC,GAAiBH,qBAA0BC,KAAKG,QAEhDC,GAAoBpoB,OAAO4D,GAAG,GAqC7B,SAASykB,GACdpiB,EACA2e,EACA1oB,EAA2B,IAE3B,OAAO,IAAIyoB,GAAuCC,EAAgB3e,EAAQ,CACxEqf,KAAM,CAAC5oB,EAAGqD,IAzCd1C,eAA6B0C,GAAY,0BACvCuoB,EAA4B,MAE5B,MAAMnjB,EAAaX,EAAkBzE,GACrC,GAAIoF,EAAWrD,QAAUwmB,EAA2B,CAClD,MAAMC,QAAgBT,GAAa3iB,GACnC,GAAIojB,EAAQzmB,OAASqD,EAAWrD,OAAS,EACvC,OAAOymB,EAGX,OAAOvoB,OAAOyE,OAAO,CAAC2jB,GAAmBjjB,IA+BNqjB,CAAczoB,EAAG7D,GAClDspB,OAAQ,CAAC9oB,EAAGqD,IA7BhB1C,eAA+B0C,GAAW,SACxCknB,GAAW,EAD6B,eAExCwB,GAAiB,IAEjB,KAAM1oB,aAAaC,QAAS,CAC1B,GAAIinB,EACF,OAAOlnB,EAET,MAAM,IAAIjE,MAAM,4BAElB,GAAa,KAATiE,EAAE,IAAwB,MAATA,EAAE,GACrB,OAAO2E,QAA0BwjB,GAAenoB,IAElD,GAAIA,EAAE,KAAOqoB,GAAkB,GAC7B,OAAO1jB,EAAoB3E,EAAE4E,SAAS,IAExC,GAAIsiB,GAAYwB,EACd,OAAO1oB,EAET,MAAM,IAAIjE,MAAM,4BAUkB4sB,CAAgB3oB,EAAG7D,K,wVCtDvD,MAAMysB,GAIGxtB,YACYypB,EACAgE,EACAC,GACjB,KAHiBjE,iBAGjB,KAFiBgE,aAEjB,KADiBC,mBAGnB,UAAiBrtB,GACf,OAAOH,KAAKupB,eAAere,IAAI/K,GAGjC,UAIEE,EACAC,EACAC,GAEA,MAAMwH,QAAY/H,KAAKupB,eAAe7qB,IACpC2B,EACAC,EACAN,KAAKytB,iBAAiBltB,IAExB,OAAOwH,EAAM/H,KAAK0tB,eAAe3lB,EAAKxH,GAAoB,KAG5D,aAIEF,EACAC,EACAC,GAOA,aALmBP,KAAKupB,eAAeI,OACrCtpB,EACAC,EACAN,KAAKytB,iBAAiBltB,KAEZsF,IAAKkC,GAAQ/H,KAAK0tB,eAAe3lB,EAAKxH,IAGpD,aACEF,EACAC,EACAM,EACAC,GAEA,OAAOb,KAAKupB,eAAe3oB,OAAOP,EAAiBC,EAAaM,EAAQC,GAG1E,aACER,EACAC,GAEA,OAAON,KAAKupB,eAAerN,OAAO7b,EAAiBC,GAG7CmtB,iBAENltB,GACA,OAAIA,GAAoBP,KAAKwtB,iBACpB,IAAIjtB,KAAqBP,KAAKwtB,kBAEhCjtB,EAGDmtB,eACN3lB,EACAxH,GAEA,GAAIA,IAAqBA,EAAiBa,KAAMwO,GAAS5P,KAAKutB,WAAW3d,IACvE,OAAO7H,EAET,MAAMD,E,kWAAyB,IAAKC,GASpC,OARcxH,GAAoBhC,OAAOwB,KAAKC,KAAKutB,aAC7CrrB,QAAS9C,IACb,MAAMwQ,EAAOxQ,EACPuuB,EAAY3tB,KAAKutB,WAAW3d,GAC9B+d,IACF7lB,EAAO8H,GAAQ+d,EAAU5lB,EAAI6H,GAAO7H,MAGjCD,GAuCI8lB,OArBf,SAIEJ,EACAD,EACAhE,GAEA,OAAIA,EACK,IAAI+D,GACT/D,EACAgE,EACAC,GAGG,IAAIF,GACTC,EACAC,IC3FWK,UClCA,MACb,qBAA4BphB,GAC1B,IAAIqhB,EACJ,GAAIrhB,EAAI+b,WAAW,UACjBsF,EAAUthB,OACL,GAAIC,EAAI+b,WAAW,WACxBsF,EAAU7gB,OACL,GAAIR,EAAI+b,WAAW,YACxBsF,EAAUpO,QACL,GAAIjT,EAAI+b,WAAW,SACxBsF,EAAU/H,OACL,KAAItZ,EAAI+b,WAAW,YAGxB,MAAM,IAAI/nB,MAAO,2CAA0CgM,GAF3DqhB,EAAU5E,GAKZ,IACE,aAAa4E,EAAQxgB,QAAQb,GAC7B,MAAOxK,GACP,MAAM,IAAIxB,MAAO,kCAAiCgM,OAASxK,EAAE2B","file":"index.js","sourcesContent":["(function webpackUniversalModuleDefinition(root, factory) {\n\tif(typeof exports === 'object' && typeof module === 'object')\n\t\tmodule.exports = factory();\n\telse if(typeof define === 'function' && define.amd)\n\t\tdefine(\"collection-storage\", [], factory);\n\telse if(typeof exports === 'object')\n\t\texports[\"collection-storage\"] = factory();\n\telse\n\t\troot[\"collection-storage\"] = factory();\n})(global, function() {\nreturn "," \t// The module cache\n \tvar installedModules = {};\n\n \t// The require function\n \tfunction __webpack_require__(moduleId) {\n\n \t\t// Check if module is in cache\n \t\tif(installedModules[moduleId]) {\n \t\t\treturn installedModules[moduleId].exports;\n \t\t}\n \t\t// Create a new module (and put it into the cache)\n \t\tvar module = installedModules[moduleId] = {\n \t\t\ti: moduleId,\n \t\t\tl: false,\n \t\t\texports: {}\n \t\t};\n\n \t\t// Execute the module function\n \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n \t\t// Flag the module as loaded\n \t\tmodule.l = true;\n\n \t\t// Return the exports of the module\n \t\treturn module.exports;\n \t}\n\n\n \t// expose the modules object (__webpack_modules__)\n \t__webpack_require__.m = modules;\n\n \t// expose the module cache\n \t__webpack_require__.c = installedModules;\n\n \t// define getter function for harmony exports\n \t__webpack_require__.d = function(exports, name, getter) {\n \t\tif(!__webpack_require__.o(exports, name)) {\n \t\t\tObject.defineProperty(exports, name, { enumerable: true, get: getter });\n \t\t}\n \t};\n\n \t// define __esModule on exports\n \t__webpack_require__.r = function(exports) {\n \t\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n \t\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n \t\t}\n \t\tObject.defineProperty(exports, '__esModule', { value: true });\n \t};\n\n \t// create a fake namespace object\n \t// mode & 1: value is a module id, require it\n \t// mode & 2: merge all properties of value into the ns\n \t// mode & 4: return value when already ns object\n \t// mode & 8|1: behave like require\n \t__webpack_require__.t = function(value, mode) {\n \t\tif(mode & 1) value = __webpack_require__(value);\n \t\tif(mode & 8) return value;\n \t\tif((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;\n \t\tvar ns = Object.create(null);\n \t\t__webpack_require__.r(ns);\n \t\tObject.defineProperty(ns, 'default', { enumerable: true, value: value });\n \t\tif(mode & 2 && typeof value != 'string') for(var key in value) __webpack_require__.d(ns, key, function(key) { return value[key]; }.bind(null, key));\n \t\treturn ns;\n \t};\n\n \t// getDefaultExport function for compatibility with non-harmony modules\n \t__webpack_require__.n = function(module) {\n \t\tvar getter = module && module.__esModule ?\n \t\t\tfunction getDefault() { return module['default']; } :\n \t\t\tfunction getModuleExports() { return module; };\n \t\t__webpack_require__.d(getter, 'a', getter);\n \t\treturn getter;\n \t};\n\n \t// Object.prototype.hasOwnProperty.call\n \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n\n \t// __webpack_public_path__\n \t__webpack_require__.p = \"\";\n\n\n \t// Load entry module and return exports\n \treturn __webpack_require__(__webpack_require__.s = 9);\n","import type { Collection, UpdateOptions } from './Collection';\nimport type { IDable } from './IDable';\nimport type { DBKeys } from './DB';\n\nexport default abstract class BaseCollection<T extends IDable> implements Collection<T> {\n  // actually read publicly by BaseDB but we don't want this to be a user-accessible property\n  protected internalReady?: () => Promise<void>;\n\n  private innerPreAct: () => Promise<void> | void;\n\n  protected constructor(\n    protected readonly keys: DBKeys<T>,\n  ) {\n    this.innerPreAct = this.preAct.bind(this);\n  }\n\n  public async add(entry: T): Promise<void> {\n    await this.innerPreAct();\n    return this.internalAdd(entry);\n  }\n\n  public async get<\n    K extends keyof T & string,\n    F extends readonly (keyof T & string)[]\n  >(\n    searchAttribute: K,\n    searchValue: T[K],\n    returnAttributes?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>> | null> {\n    if (!this.isIndexed(searchAttribute)) {\n      throw new Error(`No index for ${searchAttribute}`);\n    }\n    await this.innerPreAct();\n    return this.internalGet(searchAttribute, searchValue, returnAttributes);\n  }\n\n  public async getAll<\n    K extends keyof T & string,\n    F extends readonly (keyof T & string)[]\n  >(\n    searchAttribute?: K,\n    searchValue?: T[K],\n    returnAttributes?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>>[]> {\n    if (searchAttribute && !this.isIndexed(searchAttribute)) {\n      throw new Error(`No index for ${searchAttribute}`);\n    }\n    await this.innerPreAct();\n    return this.internalGetAll(searchAttribute, searchValue, returnAttributes);\n  }\n\n  public async update<K extends keyof T & string>(\n    searchAttribute: K,\n    searchValue: T[K],\n    update: Partial<T>,\n    options: UpdateOptions = {},\n  ): Promise<void> {\n    if (searchAttribute === 'id' && update.id !== undefined && update.id !== searchValue) {\n      throw new Error('Cannot update ID');\n    }\n    if (options.upsert) {\n      if (searchAttribute !== 'id') {\n        throw new Error(`Can only upsert by ID, not ${searchAttribute}`);\n      }\n      let withoutId = update;\n      if (Object.prototype.hasOwnProperty.call(update, 'id')) {\n        withoutId = { ...update };\n        delete withoutId.id;\n      }\n      await this.innerPreAct();\n      return this.internalUpsert(searchValue as T['id'], withoutId, options);\n    }\n    if (!this.isIndexed(searchAttribute)) {\n      throw new Error(`No index for ${searchAttribute}`);\n    }\n    if (\n      !this.isIndexUnique(searchAttribute) &&\n      Object.keys(update).some((k) => this.isIndexUnique(k))\n    ) {\n      throw new Error('duplicate');\n    }\n\n    await this.innerPreAct();\n    return this.internalUpdate(searchAttribute, searchValue, update, options);\n  }\n\n  public async remove<K extends keyof T & string>(\n    searchAttribute: K,\n    searchValue: T[K],\n  ): Promise<number> {\n    if (!this.isIndexed(searchAttribute)) {\n      throw new Error(`No index for ${searchAttribute}`);\n    }\n    await this.innerPreAct();\n    return this.internalRemove(searchAttribute, searchValue);\n  }\n\n  // Subclass constructors can call this with a promise that will resolve when\n  // they are ready to be used. BaseCollection will automatically ensure that\n  // other interactions are queued until this promise resolves.\n  // (this call will always succeed; you can safely ignore the promise returned)\n  protected async initAsync(wait: Promise<unknown>): Promise<void> {\n    const pending: [() => void, (e: Error) => void][] = [];\n    const addPending = (): Promise<void> => new Promise((resolve, reject) => {\n      pending.push([resolve, reject]);\n    });\n    this.internalReady = addPending;\n    this.innerPreAct = async (): Promise<void> => {\n      await addPending();\n      return this.preAct();\n    };\n    try {\n      await wait;\n    } catch (e) {\n      this.internalReady = (): Promise<void> => Promise.reject(e);\n      this.innerPreAct = (): void => { throw e; };\n      pending.forEach((f) => f[1](e));\n      return;\n    }\n    this.internalReady = undefined;\n    this.innerPreAct = this.preAct.bind(this);\n    pending.forEach((f) => f[0]());\n  }\n\n  protected isIndexed(attribute: string): boolean {\n    return (\n      attribute === 'id' ||\n      this.keys[attribute as keyof DBKeys<T>] !== undefined\n    );\n  }\n\n  protected isIndexUnique(attribute: string): boolean {\n    const keyOptions = this.keys[attribute as keyof DBKeys<T>];\n    return (\n      attribute === 'id' ||\n      Boolean(keyOptions && keyOptions.unique)\n    );\n  }\n\n  // eslint-disable-next-line class-methods-use-this\n  protected preAct(): Promise<void> | void {}\n\n  protected async internalGet<\n    K extends keyof T & string,\n    F extends readonly (keyof T & string)[]\n  >(\n    searchAttribute: K,\n    searchValue: T[K],\n    returnAttributes?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>> | null> {\n    const all = await this.internalGetAll(searchAttribute, searchValue, returnAttributes);\n    return all[0] ?? null;\n  }\n\n  protected internalUpsert(\n    id: T['id'],\n    update: Partial<T>,\n    options: UpdateOptions,\n  ): Promise<void> {\n    return this.internalUpdate('id', id, update, options);\n  }\n\n  protected abstract internalAdd(entry: T): Promise<void>;\n\n  protected abstract internalGetAll<\n    K extends keyof T & string,\n    F extends readonly (keyof T & string)[]\n  >(\n    searchAttribute?: K,\n    searchValue?: T[K],\n    fields?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>>[]>;\n\n  protected abstract internalUpdate<K extends keyof T & string>(\n    searchAttribute: K,\n    searchValue: T[K],\n    update: Partial<T>,\n    options: UpdateOptions,\n  ): Promise<void>;\n\n  protected abstract internalRemove<K extends keyof T & string>(\n    searchAttribute: K,\n    searchValue: T[K],\n  ): Promise<number>;\n}\n","module.exports = require(\"crypto\");","function sleep(millis: number): Promise<void> | null {\n  return new Promise((resolve): any => setTimeout(resolve, millis));\n}\n\nexport default (shouldRetry: (e: any) => boolean, {\n  timeoutMillis = 60000,\n  initialDelayMillis = 20,\n  maxDelayMillis = 5000,\n  delayGrowth = 2,\n  jitter = true,\n} = {}) => async <T>(fn: () => Promise<T> | T): Promise<T> => {\n  const limit = Date.now() + timeoutMillis;\n  let currentDelay = initialDelayMillis;\n  for (let attempt = 1; ; attempt += 1) {\n    try {\n      // eslint-disable-next-line no-await-in-loop\n      return await fn();\n    } catch (e) {\n      if (!shouldRetry(e)) {\n        throw e;\n      }\n\n      const delay = (\n        Math.min(currentDelay, maxDelayMillis) *\n        (jitter ? Math.random() : 1)\n      );\n      currentDelay *= delayGrowth;\n\n      if (Date.now() + delay > limit) {\n        e.message += ` (timeout after ${attempt} attempts)`;\n        throw e;\n      }\n\n      // eslint-disable-next-line no-await-in-loop\n      await sleep(delay);\n    }\n  }\n};\n","module.exports = require(\"mongodb\");","module.exports = require(\"zlib\");","module.exports = require(\"util\");","module.exports = require(\"url\");","module.exports = require(\"https\");","module.exports = require(\"http\");","import {\n  Collection as MCollection,\n  Binary as MBinary,\n  IndexSpecification,\n  MongoError,\n} from 'mongodb';\nimport type { IDable } from '../interfaces/IDable';\nimport BaseCollection from '../interfaces/BaseCollection';\nimport type { KeyOptions } from '../interfaces/Collection';\nimport type { DBKeys } from '../interfaces/DB';\nimport type { StateRef } from '../interfaces/BaseDB';\nimport retry from '../helpers/retry';\n\nconst MONGO_ID = '_id';\nconst ID = 'id';\n\nconst DOT_REG = /\\./g;\nfunction fieldNameToMongo(name: string): string {\n  if (name === ID) {\n    return MONGO_ID;\n  }\n  return encodeURIComponent(name).replace(DOT_REG, '%2E');\n}\n\nfunction fieldNameFromMongo(name: string): string {\n  if (name === MONGO_ID) {\n    return ID;\n  }\n  return decodeURIComponent(name);\n}\n\nconst MONGO_ERROR_IDX = /^.*? index: ([^ ]+) dup key:.*$/;\nfunction getErrorIndex(e: MongoError): string {\n  return MONGO_ERROR_IDX.exec(e.message)?.[1] || '';\n}\n\nconst withUpsertRetry = retry((e) => (\n  e instanceof MongoError &&\n  e.code === 11000 &&\n  getErrorIndex(e) === '_id_'\n));\n\nfunction convertToMongo<T extends Partial<IDable>>(\n  value: T,\n): Record<string, unknown> {\n  const converted: Record<string, unknown> = {};\n  Object.keys(value).forEach((k) => {\n    let v = (value as any)[k];\n    if (v instanceof Buffer) {\n      v = new MBinary(v);\n      // eslint-disable-next-line no-underscore-dangle\n    } else if (typeof v === 'object' && v._bsontype) {\n      throw new Error('Must use Buffer to provide binary data');\n    }\n    converted[fieldNameToMongo(k)] = v;\n  });\n  return converted;\n}\n\nfunction convertFromMongo<T extends Partial<IDable>>(\n  value: Record<string, unknown> | null,\n): T | null {\n  if (!value) {\n    return null;\n  }\n  const converted: T = {} as any;\n  Object.keys(value).forEach((k) => {\n    let v = (value as any)[k];\n    // eslint-disable-next-line no-underscore-dangle\n    if (typeof v === 'object' && v._bsontype === 'Binary') {\n      v = v.buffer;\n    }\n    (converted as any)[fieldNameFromMongo(k)] = v;\n  });\n  return converted;\n}\n\nfunction makeMongoProjection(\n  names?: readonly string[],\n): Record<string, boolean> {\n  const projection: Record<string, boolean> = {};\n  if (names) {\n    projection[MONGO_ID] = false;\n    names.forEach((fieldName) => {\n      projection[fieldNameToMongo(fieldName)] = true;\n    });\n  }\n  return projection;\n}\n\ninterface MongoIndex {\n  name: string;\n  key: Record<string, -1 | 0 | 1 | 'hashed'>;\n  unique?: boolean;\n}\n\nfunction makeIndex(keyName: string, options: KeyOptions = {}): IndexSpecification {\n  const unique = Boolean(options.unique);\n  const mongoKey = fieldNameToMongo(keyName);\n  return {\n    key: { [mongoKey]: unique ? 1 : 'hashed' },\n    unique,\n  };\n}\n\nfunction indicesMatch(a: IndexSpecification, b: IndexSpecification): boolean {\n  if (Boolean(a.unique) !== Boolean(b.unique)) {\n    return false;\n  }\n  const aKey = a.key as Record<string, unknown>;\n  const bKey = b.key as Record<string, unknown>;\n  const keys = Object.keys(aKey);\n  if (Object.keys(bKey).length !== keys.length) {\n    return false;\n  }\n  return keys.every((k) => (aKey[k] === bKey[k]));\n}\n\nasync function configureCollection(\n  collection: MCollection,\n  keys: DBKeys<any> = {},\n): Promise<void> {\n  const existing: MongoIndex[] = await collection.indexes().catch(() => []);\n  const idxToCreate: IndexSpecification[] = [];\n  const idxToDelete = new Set(existing.map((idx) => idx.name));\n  idxToDelete.delete('_id_'); // MongoDB implicit primary key\n\n  Object.keys(keys)\n    .map((keyName) => makeIndex(keyName, keys[keyName]))\n    .forEach((index) => {\n      const match = existing.find((idx) => indicesMatch(idx, index));\n      if (match) {\n        idxToDelete.delete(match.name);\n      } else {\n        idxToCreate.push(index);\n      }\n    });\n  if (idxToCreate.length) {\n    await collection.createIndexes(idxToCreate);\n  }\n  if (idxToDelete.size) {\n    await Promise.all([...idxToDelete].map((idxName) => collection.dropIndex(idxName)));\n  }\n}\n\nexport default class MongoCollection<T extends IDable> extends BaseCollection<T> {\n  public constructor(\n    private readonly collection: MCollection,\n    keys: DBKeys<T> = {},\n    private readonly stateRef: StateRef = { closed: false },\n  ) {\n    super(keys);\n    this.initAsync(configureCollection(collection, keys));\n  }\n\n  protected preAct(): void {\n    if (this.stateRef.closed) {\n      throw new Error('Connection closed');\n    }\n  }\n\n  protected async internalAdd(value: T): Promise<void> {\n    await this.collection.insertOne(convertToMongo(value));\n  }\n\n  protected async internalUpsert(\n    id: T['id'],\n    update: Partial<T>,\n  ): Promise<void> {\n    await withUpsertRetry(() => this.collection.updateOne(\n      convertToMongo({ id }),\n      { $set: convertToMongo(update) },\n      { upsert: true },\n    ));\n  }\n\n  protected async internalUpdate<K extends keyof T & string>(\n    searchAttribute: K,\n    searchValue: T[K],\n    update: Partial<T>,\n  ): Promise<void> {\n    const query = convertToMongo({ [searchAttribute]: searchValue });\n    const mongoUpdate = { $set: convertToMongo(update) };\n    if (this.isIndexUnique(searchAttribute)) {\n      await this.collection.updateOne(query, mongoUpdate);\n    } else {\n      await this.collection.updateMany(query, mongoUpdate);\n    }\n  }\n\n  protected async internalGet<\n    K extends keyof T & string,\n    F extends readonly (keyof T & string)[]\n  >(\n    searchAttribute: K,\n    searchValue: T[K],\n    returnAttributes?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>> | null> {\n    const raw = await this.collection.findOne(\n      convertToMongo({ [searchAttribute]: searchValue }),\n      { projection: makeMongoProjection(returnAttributes) },\n    );\n    return convertFromMongo<T>(raw);\n  }\n\n  protected async internalGetAll<\n    K extends keyof T & string,\n    F extends readonly (keyof T & string)[]\n  >(\n    searchAttribute?: K,\n    searchValue?: T[K],\n    returnAttributes?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>>[]> {\n    const cursor = this.collection.find(\n      searchAttribute ? convertToMongo({ [searchAttribute]: searchValue }) : {},\n      { projection: makeMongoProjection(returnAttributes) },\n    );\n\n    const result: Pick<T, F[-1]>[] = [];\n    await cursor.forEach((raw) => result.push(convertFromMongo<T>(raw)!));\n\n    return result;\n  }\n\n  protected async internalRemove<K extends keyof T & string>(\n    searchAttribute: K,\n    searchValue: T[K],\n  ): Promise<number> {\n    const result = await this.collection.deleteMany(\n      convertToMongo({ [searchAttribute]: searchValue }),\n    );\n    return result.deletedCount || 0;\n  }\n}\n","module.exports = require(\"ioredis\");","module.exports = require(\"pg\");","// B = base64 binary\n// b = raw binary (*Bin functions only)\n// s = raw utf8 string\n// t = true\n// f = false\n// n = null\n// J = JSON (also accepts any plain JSON value for compatibility)\n\nconst JSON_INIT_CHARS = '{[\"0123456789-'; // t/f/n are dedicated values\nconst MARK_BINARY = 'b'.charCodeAt(0);\nconst MARK_STRING = 's'.charCodeAt(0);\n\nconst MARK_BINARY_BUFF = Uint8Array.of(MARK_BINARY);\n\nexport function canonicalJSON(o: Record<string, unknown> | undefined): string {\n  if (!o) {\n    return 'null';\n  }\n  // string comparison is intended\n  /* eslint-disable-next-line @typescript-eslint/require-array-sort-compare */\n  const content = Object.keys(o)\n    .sort()\n    .map((k) => `${JSON.stringify(k)}:${JSON.stringify(o[k])}`)\n    .join(',');\n  return `{${content}}`;\n}\n\nexport function serialiseValue(value: unknown): string {\n  if (value instanceof Buffer) {\n    return `B${value.toString('base64')}`;\n  }\n  if (typeof value === 'string') {\n    return `s${value}`;\n  }\n  if (typeof value === 'boolean') {\n    return value ? 't' : 'f';\n  }\n  if (value === null) {\n    return 'n';\n  }\n  return `J${JSON.stringify(value)}`;\n}\n\nexport function deserialiseValue(value: string): unknown {\n  const type = value[0];\n  const data = value.substr(1);\n  switch (type) {\n    case 'B': return Buffer.from(data, 'base64');\n    case 's': return data;\n    case 't': return true;\n    case 'f': return false;\n    case 'n': return null;\n    case 'J': return JSON.parse(data);\n    default:\n      if (JSON_INIT_CHARS.includes(type)) {\n        return JSON.parse(value);\n      }\n      throw new Error(`Unknown data type ${type}`);\n  }\n}\n\nexport function serialiseValueBin(value: unknown): Buffer {\n  if (value instanceof Buffer) {\n    return Buffer.concat([MARK_BINARY_BUFF, value]);\n  }\n  return Buffer.from(serialiseValue(value), 'utf8');\n}\n\nexport function deserialiseValueBin(value: Buffer | string): unknown {\n  if (typeof value === 'string') {\n    return deserialiseValue(value);\n  }\n\n  const type = value[0];\n  if (type === MARK_BINARY) {\n    return value.subarray(1);\n  }\n  if (type === MARK_STRING) {\n    return value.subarray(1).toString('utf8');\n  }\n  return deserialiseValue(value.toString('utf8'));\n}\n\nexport function serialiseRecord<T>(\n  record: T,\n): Record<string, string> {\n  const result: Record<string, string> = {};\n  Object.keys(record).forEach((k) => {\n    result[k] = serialiseValue((record as any)[k]);\n  });\n  return result;\n}\n\nexport function deserialiseRecord(\n  record: Record<string, string | null>,\n): Record<string, unknown> {\n  const result: Record<string, any> = {};\n  Object.keys(record).forEach((k) => {\n    const v = record[k];\n    if (v) {\n      result[k] = deserialiseValue(v);\n    }\n  });\n  return result;\n}\n","import type { IDable } from '../interfaces/IDable';\nimport BaseCollection from '../interfaces/BaseCollection';\nimport type { DBKeys } from '../interfaces/DB';\nimport type { StateRef } from '../interfaces/BaseDB';\nimport {\n  serialiseValue,\n  serialiseRecord,\n  deserialiseRecord,\n} from '../helpers/serialiser';\n\nfunction sleep(millis: number): Promise<void> | void {\n  if (!millis) {\n    return undefined;\n  }\n\n  // Simulate data access delays to ensure non-flakey e2e tests, etc.\n  return new Promise((resolve): any => setTimeout(resolve, millis));\n}\n\nfunction applyFilter<T, F extends readonly (keyof T)[]>(\n  data: T,\n  fields?: F,\n): Pick<T, F[-1]> {\n  if (!fields) {\n    return data;\n  }\n  const result: Pick<T, F[-1]> = {} as any;\n  fields.forEach((field) => {\n    result[field] = data[field];\n  });\n  return result;\n}\n\nexport default class MemoryCollection<T extends IDable> extends BaseCollection<T> {\n  private readonly data: Map<string, Record<string, string>>;\n\n  private readonly indices: Partial<Record<keyof T, Map<string, Set<string>>>> = {};\n\n  public constructor(\n    keys: DBKeys<T> = {},\n    private readonly simulatedLatency = 0,\n    private readonly stateRef: StateRef = { closed: false },\n  ) {\n    super(keys);\n\n    this.data = new Map();\n\n    Object.keys(keys).forEach((k) => {\n      this.indices[k as keyof T] = new Map();\n    });\n  }\n\n  protected preAct(): Promise<void> | void {\n    if (this.stateRef.closed) {\n      throw new Error('Connection closed');\n    }\n    return sleep(this.simulatedLatency);\n  }\n\n  protected async internalAdd(value: T): Promise<void> {\n    const serialised = serialiseRecord(value);\n    this.internalCheckDuplicates(serialised, true);\n    this.data.set(serialised.id, serialised);\n    this.internalPopulateIndices(serialised);\n  }\n\n  protected async internalUpsert(\n    id: T['id'],\n    update: Partial<T>,\n  ): Promise<void> {\n    if (this.data.has(serialiseValue(id))) {\n      await this.internalUpdate('id', id, update);\n    } else {\n      await this.internalAdd({ id, ...update } as T);\n    }\n  }\n\n  protected async internalUpdate<K extends keyof T & string>(\n    searchAttribute: K,\n    searchValue: T[K],\n    update: Partial<T>,\n  ): Promise<void> {\n    const sIds = this.internalGetSerialisedIds(searchAttribute, searchValue);\n\n    const updates = sIds.map((sId) => {\n      const oldSerialised = this.data.get(sId)!;\n      const oldValue = deserialiseRecord(oldSerialised) as T;\n      const newValue = { ...oldValue, ...update };\n      if (newValue.id !== oldValue.id) {\n        throw new Error('Cannot update ID');\n      }\n      const newSerialised = serialiseRecord(newValue);\n      return { oldSerialised, newSerialised };\n    });\n\n    updates.forEach(({ oldSerialised }) => this.internalRemoveIndices(oldSerialised));\n    try {\n      updates.forEach(({ newSerialised }) => this.internalCheckDuplicates(newSerialised, false));\n    } catch (e) {\n      updates.forEach(({ oldSerialised }) => this.internalPopulateIndices(oldSerialised));\n      throw e;\n    }\n    updates.forEach(({ newSerialised }) => {\n      this.data.set(newSerialised.id, newSerialised);\n      this.internalPopulateIndices(newSerialised);\n    });\n  }\n\n  protected async internalGetAll<\n    K extends keyof T & string,\n    F extends readonly (keyof T & string)[]\n  >(\n    searchAttribute?: K,\n    searchValue?: T[K],\n    returnAttributes?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>>[]> {\n    let sIds: string[];\n    if (searchAttribute) {\n      sIds = this.internalGetSerialisedIds(searchAttribute, searchValue!);\n    } else {\n      sIds = [...this.data.keys()];\n    }\n    return sIds.map((sId) => applyFilter(\n      deserialiseRecord(this.data.get(sId)!) as T,\n      returnAttributes,\n    ));\n  }\n\n  protected async internalRemove<K extends keyof T & string>(\n    searchAttribute: K,\n    searchValue: T[K],\n  ): Promise<number> {\n    const sIds = this.internalGetSerialisedIds(searchAttribute, searchValue);\n    sIds.forEach((sId) => {\n      const oldSerialised = this.data.get(sId)!;\n      this.internalRemoveIndices(oldSerialised);\n      this.data.delete(sId);\n    });\n\n    return sIds.length;\n  }\n\n  private internalGetSerialisedIds<K extends keyof T>(\n    searchAttribute: K,\n    searchValue: T[K],\n  ): string[] {\n    const sKey = serialiseValue(searchValue);\n    if (searchAttribute === 'id') {\n      return this.data.has(sKey) ? [sKey] : [];\n    }\n    const index = this.indices[searchAttribute];\n    if (!index) {\n      throw new Error(`Requested key ${searchAttribute} not indexed`);\n    }\n    const sIds = index.get(sKey);\n    return sIds ? [...sIds] : []; // convert set to array\n  }\n\n  private internalCheckDuplicates(\n    serialisedValue: Record<string, string>,\n    checkId: boolean,\n  ): void {\n    if (checkId && this.data.has(serialisedValue.id)) {\n      throw new Error('duplicate');\n    }\n    Object.keys(this.keys).forEach((key) => {\n      const index = this.indices[key as keyof T]!;\n      if (this.isIndexUnique(key) && index.has(serialisedValue[key])) {\n        throw new Error('duplicate');\n      }\n    });\n  }\n\n  private internalPopulateIndices(\n    serialisedValue: Record<string, string>,\n  ): void {\n    Object.keys(this.keys).forEach((key) => {\n      const index = this.indices[key as keyof T]!;\n      const v = serialisedValue[key];\n      let o = index.get(v);\n      if (!o) {\n        o = new Set<string>();\n        index.set(v, o);\n      }\n      o.add(serialisedValue.id);\n    });\n  }\n\n  private internalRemoveIndices(\n    serialisedValue: Record<string, string>,\n  ): void {\n    Object.keys(this.keys).forEach((key) => {\n      const index = this.indices[key as keyof T]!;\n      const v = serialisedValue[key];\n      const o = index.get(v)!;\n      o.delete(serialisedValue.id);\n      if (!o.size) {\n        index.delete(v);\n      }\n    });\n  }\n}\n","import type { Collection } from './Collection';\nimport type { IDable } from './IDable';\nimport type { DB, DBKeys } from './DB';\nimport { canonicalJSON } from '../helpers/serialiser';\n\nexport interface StateRef {\n  closed: boolean;\n}\n\ninterface AsyncCollection<T extends IDable> extends Collection<T> {\n  internalReady?: () => Promise<void>;\n}\n\nexport default abstract class BaseDB implements DB {\n  protected readonly stateRef: StateRef = { closed: false };\n\n  private readonly collectionCache = new Map<string, [string, Collection<any>]>();\n\n  constructor(\n    private readonly makeCollection: <T extends IDable>(\n      name: string,\n      keys?: DBKeys<T>,\n    ) => Collection<T>,\n  ) {}\n\n  public getCollection<T extends IDable>(name: string, keys?: DBKeys<T>): Collection<T> {\n    const cached = this.collectionCache.get(name);\n    const normKeys = canonicalJSON(keys);\n    if (cached) {\n      const [cachedNormKeys, cachedCol] = cached;\n      if (normKeys !== cachedNormKeys) {\n        throw new Error(`Cannot requuest collection '${name}' with different keys`);\n      }\n      return cachedCol;\n    }\n    const created = this.makeCollection(name, keys) as AsyncCollection<T>;\n    this.collectionCache.set(name, [normKeys, created]);\n    return created;\n  }\n\n  close(): Promise<void> | void {\n    if (this.stateRef.closed) {\n      return undefined;\n    }\n    this.syncClose();\n    const toAwait = [...this.collectionCache.values()]\n      .map(([, c]) => (c as AsyncCollection<IDable>).internalReady?.());\n    return Promise.allSettled(toAwait).then(() => this.internalClose());\n  }\n\n  protected syncClose(): void {\n    this.stateRef.closed = true;\n  }\n\n  // eslint-disable-next-line class-methods-use-this\n  protected internalClose(): Promise<void> | void {}\n}\n","import { URL } from 'url';\nimport MemoryCollection from './MemoryCollection';\nimport type { DBKeys } from '../interfaces/DB';\nimport type { IDable } from '../interfaces/IDable';\nimport BaseDB from '../interfaces/BaseDB';\n\nfunction getGlobal<T>(name: string, initial: T): T {\n  const existing = (global as any)[name];\n  if (existing) {\n    return existing;\n  }\n\n  (global as any)[name] = initial;\n  return initial;\n}\n\nconst globalDbs = getGlobal(\n  'collectionStorageInMemory',\n  new Map<string, MemoryDb>(),\n);\n\nexport default class MemoryDb extends BaseDB {\n  public constructor({ simulatedLatency = 0 } = {}) {\n    super((name, keys) => new MemoryCollection(keys, simulatedLatency, this.stateRef));\n  }\n\n  public static connect(url: string): MemoryDb {\n    const parsedUrl = new URL(url);\n    const name = parsedUrl.hostname;\n    if (name && globalDbs.has(name)) {\n      return globalDbs.get(name)!;\n    }\n    const params = parsedUrl.searchParams;\n    const simulatedLatency = Number(params.get('simulatedLatency'));\n    const db = new MemoryDb({ simulatedLatency });\n    if (name) {\n      globalDbs.set(name, db);\n    }\n    return db;\n  }\n\n  public getCollection<T extends IDable>(name: string, keys?: DBKeys<T>): MemoryCollection<T> {\n    return super.getCollection(name, keys) as MemoryCollection<T>;\n  }\n\n  public close(): void {\n    this.syncClose();\n  }\n}\n","import type { Db as MongoDbT, MongoClient as MongoClientT } from 'mongodb';\nimport type { DBKeys } from '../interfaces/DB';\nimport BaseDB from '../interfaces/BaseDB';\nimport type { IDable } from '../interfaces/IDable';\nimport type MongoCollectionT from './MongoCollection';\n\nfunction escapeName(name: string): string {\n  return encodeURIComponent(name);\n}\n\nexport default class MongoDb extends BaseDB {\n  private constructor(\n    private readonly client: MongoClientT,\n    MongoCollection: typeof MongoCollectionT,\n  ) {\n    super((name, keys) => new MongoCollection(\n      this.client.db().collection(escapeName(name)),\n      keys,\n      this.stateRef,\n    ));\n  }\n\n  public static async connect(url: string): Promise<MongoDb> {\n    const { MongoClient } = await import('mongodb');\n    const {\n      default: MongoCollection,\n    } = await import(/* webpackMode: \"eager\" */ './MongoCollection');\n    const client = await MongoClient.connect(url, {\n      useNewUrlParser: true,\n      useUnifiedTopology: true,\n    });\n    return new MongoDb(client, MongoCollection);\n  }\n\n  public getCollection<T extends IDable>(name: string, keys?: DBKeys<T>): MongoCollectionT<T> {\n    return super.getCollection(name, keys) as MongoCollectionT<T>;\n  }\n\n  public getDb(): MongoDbT {\n    return this.client.db();\n  }\n\n  protected internalClose(): Promise<void> {\n    return this.client.close();\n  }\n}\n","import type AWS from './AWS';\n\nexport interface Results<I> {\n  batched(consumer: (items: Readonly<I[]>) => (Promise<void> | void)): Promise<void> | void;\n\n  all(): Promise<Readonly<I[]>> | Readonly<I[]>;\n}\n\nexport class Paged<K, I> implements Results<I> {\n  constructor(\n    private readonly aws: AWS,\n    private readonly fn: (start: K | undefined) => Promise<[I[], K]>,\n    private readonly pageLimit = Number.POSITIVE_INFINITY,\n  ) {}\n\n  batched(consumer: (items: I[]) => (Promise<void> | void)): Promise<void> {\n    return this.aws.do(async () => {\n      let lastKey: K | undefined;\n      /* eslint-disable no-await-in-loop */ // pagination must be serial\n      for (let page = 0; page < this.pageLimit; page += 1) {\n        const [pageItems, nextKey]: [I[], K] = await this.fn(lastKey);\n        await consumer(pageItems);\n        lastKey = nextKey;\n        if (!lastKey) {\n          return;\n        }\n      }\n      /* eslint-enable no-await-in-loop */\n      throw new Error('Too many items');\n    });\n  }\n\n  async all(): Promise<I[]> {\n    const items: I[] = [];\n    await this.batched((i) => {\n      items.push(...i);\n    });\n    return items;\n  }\n}\n","// https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Programming.Errors.html\n\nexport default class AWSError extends Error {\n  constructor(\n    private readonly status: number,\n    private readonly type: string,\n    message: string,\n  ) {\n    super(`AWS error ${status}; type: ${type}; message: ${message}`);\n  }\n\n  static isType(e: unknown, type: string): boolean {\n    return (\n      (e instanceof AWSError && e.isType(type)) ||\n      (e instanceof Error && e.message === type)\n    );\n  }\n\n  isType(type: string): boolean {\n    return this.type.endsWith(`#${type}`) || this.type === type;\n  }\n\n  isTransient(): boolean {\n    return (\n      this.status >= 500 ||\n      this.type.endsWith('#LimitExceededException') ||\n      this.type.endsWith('#ProvisionedThroughputExceededException') ||\n      this.type.endsWith('#RequestLimitExceeded') ||\n      this.type.endsWith('#ThrottlingException')\n    );\n  }\n}\n","import type AWS from './AWS';\nimport { Results, Paged } from './Results';\nimport AWSError from './AWSError';\nimport retry from '../../helpers/retry';\n\n// https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/Welcome.html\n\nexport type DDBValue =\n  { S: string } |\n  { N: string } | // number\n  { B: string } | // binary (base64)\n  { BOOL: boolean } |\n  { NULL: true } |\n  { M: Record<string, DDBValue> } |\n  { L: DDBValue[] } |\n  { SS: string[] } | // stringset\n  { NS: string[] } | // numberset\n  { BS: string[] }; // binaryset (base64)\n\nexport type DDBItem = Record<string, DDBValue>;\n\ntype DDBType = 'S' | 'N' | 'B' | 'BOOL' | 'NULL' | 'M' | 'L' | 'SS' | 'NS' | 'BS';\ntype DDBKeyType = 'HASH' | 'RANGE';\n\ninterface DDBConsumedCapacity {\n  CapacityUnits: number;\n}\n\ninterface DDBResponse {\n  ConsumedCapacity?: DDBConsumedCapacity | DDBConsumedCapacity[];\n}\n\ninterface DDBReturnedItem extends DDBResponse {\n  Attributes: DDBItem;\n}\n\ninterface DDBGetResponse extends DDBResponse {\n  Item: DDBItem;\n}\n\ninterface DDBBatchGetResponse extends DDBResponse {\n  Responses: Record<string, DDBItem[]>;\n  UnprocessedKeys: Record<string, {\n    Keys: DDBItem[];\n  }>;\n}\n\ninterface DDBBatchWriteResponse extends DDBResponse {\n  UnprocessedItems: Record<string, {\n    DeleteRequest?: {\n      Key: DDBItem;\n    };\n    PutRequest?: {\n      Item: DDBItem;\n    };\n  }[]>;\n}\n\ninterface DDBListTablesResponse extends DDBResponse {\n  TableNames: string[];\n  LastEvaluatedTableName?: string;\n}\n\ninterface DDBScanResponse extends DDBResponse {\n  Items: DDBItem[];\n  LastEvaluatedKey?: DDBItem;\n}\n\nexport interface DDBProvisionedThroughput {\n  ReadCapacityUnits: number;\n  WriteCapacityUnits: number;\n}\n\ninterface DDBGlobalSecondaryIndex {\n  Backfilling?: boolean;\n  IndexName: string;\n  IndexStatus?: string;\n  KeySchema: {\n    AttributeName: string;\n    KeyType: DDBKeyType;\n  }[];\n  Projection?: {\n    NonKeyAttributes?: string[];\n    ProjectionType: string;\n  };\n  ProvisionedThroughput?: DDBProvisionedThroughput;\n}\n\ninterface DDBAttributeDefinition {\n  AttributeName: string;\n  AttributeType: string;\n}\n\ninterface DDBDescribeResponse extends DDBResponse {\n  Table: {\n    AttributeDefinitions: DDBAttributeDefinition[];\n    GlobalSecondaryIndexes?: DDBGlobalSecondaryIndex[];\n    ItemCount: number;\n    KeySchema: {\n      AttributeName: string;\n      KeyType: DDBKeyType;\n    }[];\n    TableStatus: string;\n    ProvisionedThroughput: DDBProvisionedThroughput;\n  };\n}\n\ninterface KeyDefinition {\n  attributeName: string;\n  attributeType: DDBType;\n  keyType: DDBKeyType;\n}\n\ninterface GlobalSecondaryIndexDefinition {\n  indexName: string;\n  keySchema: KeyDefinition[];\n  projectionType?: 'KEYS_ONLY' | 'INCLUDE' | 'ALL';\n  nonKeyAttributes?: string[];\n  throughput?: DDBProvisionedThroughput;\n}\n\nconst AWS_URL_FORMAT = /^([^:]*):\\/\\/dynamodb\\.([^.]+)\\.amazonaws\\.com(\\/?.*)$/;\nconst ResourceInUseException = 'ResourceInUseException';\nconst ResourceNotFoundException = 'ResourceNotFoundException';\n\nfunction ifNotEmpty<T extends any[] | string>(l: T): T | undefined {\n  return l.length ? l : undefined;\n}\n\nfunction flatten(value: DDBItem, keys: string[]): string {\n  return keys.map((key) => JSON.stringify(value[key])).join();\n}\n\ninterface ExpressionDefinition {\n  attributeExpression: (attr: string, value: string) => string;\n  joiner: string | ((items: string[]) => string);\n  attributes: Readonly<DDBItem | string[]>;\n}\n\nfunction escapedExpressions(\n  expressions: Record<string, ExpressionDefinition>,\n): Record<string, unknown> {\n  let i = 0;\n  const attrValues: DDBItem = {};\n  const attrNames: Record<string, string> = {};\n  let hasExpr = false;\n  let hasAnyValues = false;\n  const result: Record<string, unknown> = {};\n\n  Object.keys(expressions).forEach((key) => {\n    const { attributeExpression, joiner, attributes } = expressions[key];\n\n    const parts: string[] = [];\n    const hasValues = !Array.isArray(attributes);\n    const rawAttrNames = Array.isArray(attributes) ? attributes : Object.keys(attributes);\n    if (!rawAttrNames.length) {\n      return;\n    }\n\n    rawAttrNames.forEach((attr) => {\n      const attrName = `#${i}`;\n      const attrValue = `:${i}`;\n      parts.push(attributeExpression(attrName, attrValue));\n      attrNames[attrName] = attr;\n      if (hasValues) {\n        attrValues[attrValue] = (attributes as DDBItem)[attr];\n      }\n      i += 1;\n    });\n    result[key] = typeof joiner === 'string' ? parts.join(joiner) : joiner(parts);\n    hasAnyValues = hasAnyValues || hasValues;\n    hasExpr = true;\n  });\n\n  if (!hasExpr) {\n    return {};\n  }\n\n  return {\n    ...result,\n    ExpressionAttributeValues: hasAnyValues ? attrValues : undefined,\n    ExpressionAttributeNames: attrNames,\n  };\n}\n\nconst projection = (attrs: readonly string[] | undefined): ExpressionDefinition => ({\n  attributeExpression: (attr): string => attr,\n  joiner: ',',\n  attributes: attrs || [],\n});\n\nconst retryPolling = retry(\n  (e) => (AWSError.isType(e, ResourceNotFoundException) || e.message === 'pending'),\n  { timeoutMillis: 60000, maxDelayMillis: 1000, jitter: false },\n);\nconst retryRemaining = retry(\n  (e) => (e.message === 'remaining unprocessed items'),\n);\n\nconst INVALID_NAME_CHARS = /[^-a-zA-Z0-9_.]/g;\n\nexport function escapeName(name: string): string {\n  // no standard escape scheme conforms to DDB restrictions, so this is home-grown:\n  // (does not attempt to ensure no collisions; more important to allow valid\n  // names through unchanged)\n  return name.replace(INVALID_NAME_CHARS, (c) => {\n    const code = c.charCodeAt(0);\n    const hex = code.toString(16);\n    if (hex.length <= 2) {\n      return `_u${hex.padStart(2, '0')}`;\n    }\n    return `_U${hex.padStart(4, '0')}`;\n  }).padEnd(3, '_');\n}\n\ninterface DDBOptions {\n  consistentRead?: boolean;\n}\n\nfunction createAttributeDefinitions(schemas: KeyDefinition[][]): DDBAttributeDefinition[] {\n  const attrs = new Map<string, DDBType>();\n  schemas.forEach((keys) => keys.forEach(({ attributeName, attributeType }) => {\n    if (!attrs.has(attributeName)) {\n      attrs.set(attributeName, attributeType);\n    } else if (attrs.get(attributeName) !== attributeType) {\n      throw new Error(`inconsistent attribute type for ${attributeName}`);\n    }\n  }));\n  return [...attrs.entries()].map(([attributeName, attributeType]) => ({\n    AttributeName: attributeName,\n    AttributeType: attributeType,\n  }));\n}\n\nfunction createSecondaryIndex(i: GlobalSecondaryIndexDefinition): DDBGlobalSecondaryIndex {\n  return {\n    IndexName: i.indexName,\n    KeySchema: i.keySchema.map(({ attributeName, keyType }) => ({\n      AttributeName: attributeName,\n      KeyType: keyType,\n    })),\n    Projection: {\n      ProjectionType: i.projectionType || (i.nonKeyAttributes ? 'INCLUDE' : 'KEYS_ONLY'),\n      NonKeyAttributes: i.nonKeyAttributes,\n    },\n    ProvisionedThroughput: i.throughput,\n  };\n}\n\nfunction indicesMatch(a: GlobalSecondaryIndexDefinition, b: DDBGlobalSecondaryIndex): boolean {\n  if (a.keySchema.length !== b.KeySchema.length) {\n    return false;\n  }\n  return a.keySchema.every((k, i) => (\n    k.attributeName === b.KeySchema[i].AttributeName &&\n    k.keyType === b.KeySchema[i].KeyType\n  ));\n}\n\nexport class DDB {\n  private readonly region: string;\n\n  private readonly consistentRead: boolean;\n\n  private totalCapacityUnits = 0;\n\n  constructor(\n    private readonly aws: AWS,\n    private readonly host: string,\n    { consistentRead = false }: DDBOptions = {},\n  ) {\n    const parts = AWS_URL_FORMAT.exec(host);\n    if (parts) {\n      [, this.region] = parts;\n    } else {\n      this.region = 'us-east-1'; // default region for API calls\n    }\n    this.consistentRead = consistentRead;\n  }\n\n  getConsumedUnits(): number {\n    return this.totalCapacityUnits;\n  }\n\n  getTableNames(): Results<string> {\n    // https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_ListTables.html\n    return new Paged(this.aws, async (lastTableName) => {\n      const response: DDBListTablesResponse = await this.call('ListTables', {\n        ExclusiveStartTableName: lastTableName,\n      });\n      return [response.TableNames, response.LastEvaluatedTableName];\n    }, 10);\n  }\n\n  upsertTable(\n    tableName: string,\n    pKeySchema: KeyDefinition[],\n    secondaryIndices: GlobalSecondaryIndexDefinition[] = [],\n    waitForReady: boolean,\n    throughput?: DDBProvisionedThroughput,\n  ): Promise<boolean> {\n    // https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_CreateTable.html\n    return this.aws.do(async () => {\n      let created = false;\n      try {\n        await this.call('CreateTable', {\n          TableName: tableName,\n          AttributeDefinitions: createAttributeDefinitions([\n            pKeySchema,\n            ...secondaryIndices.map(({ keySchema }) => keySchema),\n          ]),\n          KeySchema: pKeySchema.map(({ attributeName, keyType }) => ({\n            AttributeName: attributeName,\n            KeyType: keyType,\n          })),\n          GlobalSecondaryIndexes: ifNotEmpty(secondaryIndices.map(\n            (i) => createSecondaryIndex(i),\n          )),\n          BillingMode: throughput ? 'PROVISIONED' : 'PAY_PER_REQUEST',\n          ProvisionedThroughput: throughput,\n        });\n        created = true;\n      } catch (e) {\n        if (AWSError.isType(e, ResourceInUseException)) {\n          await this.replaceIndices(tableName, secondaryIndices);\n        } else {\n          throw e;\n        }\n      }\n\n      if (waitForReady) {\n        await this.waitForTable(tableName, true);\n      }\n\n      return created;\n    });\n  }\n\n  describeTable(tableName: string): Promise<DDBDescribeResponse> {\n    // https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_DescribeTable.html\n    return this.call('DescribeTable', { TableName: tableName });\n  }\n\n  waitForTable(tableName: string, waitForIndices: boolean): Promise<void> {\n    return retryPolling(async () => {\n      const desc = await this.describeTable(tableName);\n      if (desc.Table.TableStatus !== 'ACTIVE') {\n        throw new Error('pending');\n      }\n      const indices = desc.Table.GlobalSecondaryIndexes;\n      if (waitForIndices && indices && indices.some((i) => (i.IndexStatus !== 'ACTIVE'))) {\n        throw new Error('pending');\n      }\n    });\n  }\n\n  async deleteTable(tableName: string): Promise<void> {\n    // https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_DeleteTable.html\n    await this.call('DeleteTable', { TableName: tableName });\n  }\n\n  async putItem(tableName: string, item: DDBItem, unique?: string): Promise<void> {\n    // https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_PutItem.html\n    await this.call('PutItem', {\n      TableName: tableName,\n      Item: item,\n      ...escapedExpressions({\n        ConditionExpression: {\n          attributeExpression: (attr): string => `attribute_not_exists(${attr})`,\n          joiner: ' and ',\n          attributes: unique ? [unique] : [],\n        },\n      }),\n      ReturnConsumedCapacity: 'TOTAL',\n    });\n  }\n\n  async updateItem(\n    tableName: string,\n    key: DDBItem,\n    update: DDBItem,\n    condition?: DDBItem,\n  ): Promise<void> {\n    // https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_UpdateItem.html\n    await this.call('UpdateItem', {\n      TableName: tableName,\n      Key: key,\n      ...escapedExpressions({\n        UpdateExpression: {\n          attributeExpression: (attr, value): string => `${attr}=${value}`,\n          joiner: (l): string => `SET ${l.join(',')}`,\n          attributes: update,\n        },\n        ConditionExpression: {\n          attributeExpression: (attr, value): string => `${attr}=${value}`,\n          joiner: ' and ',\n          attributes: condition || {},\n        },\n      }),\n      ReturnConsumedCapacity: 'TOTAL',\n    });\n  }\n\n  async getItem(\n    tableName: string,\n    key: DDBItem,\n    requestedAttrs?: readonly string[],\n  ): Promise<DDBItem | null> {\n    // https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_GetItem.html\n    const data: DDBGetResponse = await this.call('GetItem', {\n      TableName: tableName,\n      Key: key,\n      ...escapedExpressions({ ProjectionExpression: projection(requestedAttrs) }),\n      ConsistentRead: this.consistentRead,\n      ReturnConsumedCapacity: 'TOTAL',\n    });\n\n    // DDB is inconsistent in how it returns 'not found' state:\n    if (!data.Item || !Object.keys(data.Item).length) {\n      return null;\n    }\n    return data.Item;\n  }\n\n  async batchGetItems(\n    tableName: string,\n    keys: DDBItem[],\n    requestedAttrs?: readonly string[],\n  ): Promise<(DDBItem | null)[]> {\n    // https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_BatchGetItem.html\n    if (!keys.length) {\n      return [];\n    }\n    if (keys.length === 1) {\n      return [await this.getItem(tableName, keys[0], requestedAttrs)];\n    }\n\n    const keyAttrs = Object.keys(keys[0]);\n    const fullAttrs = requestedAttrs?.slice();\n    if (fullAttrs) {\n      keyAttrs.forEach((k) => {\n        if (!fullAttrs.includes(k)) {\n          fullAttrs.push(k);\n        }\n      });\n    }\n\n    const indices = new Map<string, number>();\n    keys.forEach((key, i) => indices.set(flatten(key, keyAttrs), i));\n\n    const extracted: (DDBItem | null)[] = keys.map(() => null);\n    const tableQuery = {\n      ...escapedExpressions({ ProjectionExpression: projection(fullAttrs) }),\n      ConsistentRead: this.consistentRead,\n    };\n\n    await this.callBatched(keys, 100, async (batchKeys) => {\n      const data: DDBBatchGetResponse = await this.call('BatchGetItem', {\n        RequestItems: {\n          [tableName]: {\n            ...tableQuery,\n            Keys: batchKeys,\n          },\n        },\n        ReturnConsumedCapacity: 'TOTAL',\n      });\n      data.Responses[tableName].forEach((item) => {\n        const index = indices.get(flatten(item, keyAttrs));\n        if (index !== undefined) {\n          extracted[index] = item;\n        }\n      });\n      return data.UnprocessedKeys[tableName]?.Keys || [];\n    });\n\n    return extracted;\n  }\n\n  batchPutItems(tableName: string, items: DDBItem[]): Promise<void> {\n    // https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_BatchWriteItem.html\n    return this.callBatched(items, 25, async (batchItems) => {\n      const data: DDBBatchWriteResponse = await this.call('BatchWriteItem', {\n        RequestItems: {\n          [tableName]: batchItems.map((item) => ({ PutRequest: { Item: item } })),\n        },\n        ReturnConsumedCapacity: 'TOTAL',\n      });\n      return (data.UnprocessedItems[tableName] || []).map((i) => i.PutRequest!.Item);\n    });\n  }\n\n  batchDeleteItems(tableName: string, keys: DDBItem[]): Promise<void> {\n    // https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_BatchWriteItem.html\n    return this.callBatched(keys, 25, async (batchKeys) => {\n      const data: DDBBatchWriteResponse = await this.call('BatchWriteItem', {\n        RequestItems: {\n          [tableName]: batchKeys.map((key) => ({ DeleteRequest: { Key: key } })),\n        },\n        ReturnConsumedCapacity: 'TOTAL',\n      });\n      return (data.UnprocessedItems[tableName] || []).map((i) => i.DeleteRequest!.Key);\n    });\n  }\n\n  getAllItems(tableName: string, requestedAttrs?: readonly string[]): Results<DDBItem> {\n    // https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_Scan.html\n    const query = {\n      TableName: tableName,\n      ...escapedExpressions({ ProjectionExpression: projection(requestedAttrs) }),\n      ConsistentRead: this.consistentRead,\n      ReturnConsumedCapacity: 'TOTAL',\n    };\n    return new Paged(this.aws, async (lastKey) => {\n      const response: DDBScanResponse = await this.call('Scan', {\n        ...query,\n        ExclusiveStartKey: lastKey,\n      });\n      return [response.Items, response.LastEvaluatedKey];\n    });\n  }\n\n  async getItemsBySecondaryKey(\n    tableName: string,\n    indexName: string,\n    key: DDBItem,\n    requestedAttrs: readonly string[] | undefined,\n    limitOne: boolean,\n  ): Promise<DDBItem[]> {\n    // https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_Query.html\n    const colocatedAttrs = ['id'];\n    const nonColocatedAttrs: string[] = [];\n    (requestedAttrs || []).forEach((attr) => {\n      if (attr !== 'id') {\n        if (Object.hasOwnProperty.call(key, attr)) {\n          colocatedAttrs.push(attr);\n        } else {\n          nonColocatedAttrs.push(attr);\n        }\n      }\n    });\n    const query = {\n      TableName: tableName,\n      IndexName: indexName,\n      ...escapedExpressions({\n        KeyConditionExpression: {\n          attributeExpression: (attr, value): string => `${attr}=${value}`,\n          joiner: ' and ',\n          attributes: key,\n        },\n        ProjectionExpression: projection(colocatedAttrs),\n      }),\n      ConsistentRead: false, // cannot be true for Global Secondary Index\n      ReturnConsumedCapacity: 'TOTAL',\n    };\n    let items: DDBItem[];\n    if (limitOne) {\n      const response: DDBScanResponse = await this.call('Query', {\n        ...query,\n        Limit: 1,\n      });\n      items = response.Items;\n    } else {\n      items = await new Paged(this.aws, async (lastKey) => {\n        const response: DDBScanResponse = await this.call('Query', {\n          ...query,\n          ExclusiveStartKey: lastKey,\n        });\n        return [response.Items, response.LastEvaluatedKey];\n      }).all();\n    }\n\n    if (!items.length || (requestedAttrs && !nonColocatedAttrs.length)) {\n      return items;\n    }\n\n    const pkItems = await this.batchGetItems(\n      tableName,\n      items.map(({ id }) => ({ id })),\n      ifNotEmpty(nonColocatedAttrs),\n    );\n    return items\n      .map((item, i) => (pkItems[i] ? ({ ...item, ...pkItems[i] }) : null))\n      .filter((item) => item) as DDBItem[];\n  }\n\n  async deleteItem(tableName: string, key: DDBItem): Promise<void> {\n    await this.callDelete(tableName, key, false);\n  }\n\n  deleteAndReturnItem(tableName: string, key: DDBItem): Promise<DDBItem> {\n    return this.callDelete(tableName, key, true);\n  }\n\n  private async callDelete(tableName: string, key: DDBItem, returnOld: boolean): Promise<DDBItem> {\n    // https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_DeleteItem.html\n    const response: DDBReturnedItem = await this.call('DeleteItem', {\n      TableName: tableName,\n      Key: key,\n      ...escapedExpressions({\n        ConditionExpression: {\n          attributeExpression: (attr): string => `attribute_exists(${attr})`,\n          joiner: ' and ',\n          attributes: [Object.keys(key)[0]],\n        },\n      }),\n      ReturnConsumedCapacity: 'TOTAL',\n      ReturnValues: returnOld ? 'ALL_OLD' : undefined,\n    });\n    return response.Attributes;\n  }\n\n  private async replaceIndices(\n    tableName: string,\n    secondaryIndices: GlobalSecondaryIndexDefinition[] = [],\n  ): Promise<void> {\n    // https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_UpdateTable.html\n    const existing = await this.describeTable(tableName);\n    const indices = new Map<string, DDBGlobalSecondaryIndex>();\n    const toCreate: GlobalSecondaryIndexDefinition[] = [];\n    const oldIndices = existing.Table.GlobalSecondaryIndexes || [];\n    for (let i = 0; i < oldIndices.length; i += 1) {\n      const idx = oldIndices[i];\n      indices.set(idx.IndexName, idx);\n    }\n    for (let i = 0; i < secondaryIndices.length; i += 1) {\n      const idx = secondaryIndices[i];\n      const old = indices.get(idx.indexName);\n      if (old) {\n        if (!indicesMatch(idx, old)) {\n          throw new Error(`Cannot change existing index definition ${idx.indexName}`);\n        }\n        indices.delete(idx.indexName);\n      } else {\n        toCreate.push(idx);\n      }\n    }\n    const toDelete = [...indices.keys()];\n    /* eslint-disable no-await-in-loop */ // index creation and deletion must be serial\n    for (let i = 0; i < toDelete.length; i += 1) {\n      await this.call('UpdateTable', {\n        TableName: tableName,\n        GlobalSecondaryIndexUpdates: [{\n          Delete: { IndexName: toDelete[i] },\n        }],\n      });\n      // must wait for table to be ACTIVE before next update can be applied\n      await this.waitForTable(tableName, false);\n    }\n    for (let i = 0; i < toCreate.length; i += 1) {\n      await this.call('UpdateTable', {\n        TableName: tableName,\n        AttributeDefinitions: createAttributeDefinitions([toCreate[i].keySchema]),\n        GlobalSecondaryIndexUpdates: [{ Create: createSecondaryIndex(toCreate[i]) }],\n      });\n      // must wait for table to be ACTIVE before next update can be applied\n      await this.waitForTable(tableName, false);\n    }\n    /* eslint-enable no-await-in-loop */\n  }\n\n  private callBatched<T>(\n    items: T[],\n    batchLimit: number,\n    fn: (batchItems: T[]) => Promise<T[]>,\n  ): Promise<void> {\n    const remaining = items.slice();\n    return this.aws.do(() => retryRemaining(async () => {\n      const queue = remaining.slice();\n      remaining.length = 0;\n      while (queue.length) {\n        const batchItems = queue.splice(0, batchLimit);\n\n        /* eslint-disable-next-line no-await-in-loop */ // no benefit from parallelism\n        const retryItems = await fn(batchItems);\n        remaining.push(...retryItems);\n      }\n      if (remaining.length) {\n        throw new Error('remaining unprocessed items');\n      }\n    }));\n  }\n\n  private async call<T extends DDBResponse = DDBResponse>(\n    fnName: string,\n    body?: string | Record<string, unknown> | Buffer,\n  ): Promise<T> {\n    const response = await this.aws.request({\n      method: 'POST',\n      url: this.host,\n      region: this.region,\n      service: 'dynamodb',\n      headers: {\n        'Content-Type': 'application/x-amz-json-1.0',\n        'X-Amz-Target': `DynamoDB_20120810.${fnName}`,\n      },\n      body,\n    });\n    // DynamoDB does not include read/write capacity usage for errors, though\n    // they can consume capacity.\n    // https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/WorkingWithItems.html#WorkingWithItems.ConditionalWrites.ReturnConsumedCapacity\n\n    const data = response.json as T;\n    if (data.ConsumedCapacity) {\n      let capacity;\n      if (Array.isArray(data.ConsumedCapacity)) {\n        capacity = data.ConsumedCapacity.reduce((t, c) => (t + Number(c.CapacityUnits)), 0);\n      } else {\n        capacity = Number(data.ConsumedCapacity.CapacityUnits);\n      }\n      this.totalCapacityUnits += capacity;\n    }\n    return data;\n  }\n}\n","import {\n  DDB,\n  DDBItem,\n  DDBValue,\n  escapeName,\n  DDBProvisionedThroughput,\n} from './api/DDB';\nimport AWSError from './api/AWSError';\nimport type { IDable } from '../interfaces/IDable';\nimport BaseCollection from '../interfaces/BaseCollection';\nimport type { DBKeys } from '../interfaces/DB';\nimport { serialiseValueBin, deserialiseValueBin } from '../helpers/serialiser';\n\nconst ConditionalCheckFailedException = 'ConditionalCheckFailedException';\n\nasync function runAll<T>(\n  values: T[],\n  successesOut: T[],\n  fn: (value: T) => Promise<void>,\n): Promise<void> {\n  const results = await Promise.allSettled(values.map(async (value) => {\n    await fn(value);\n    successesOut.push(value);\n  }));\n  const failures = results.filter((s) => s.status === 'rejected') as PromiseRejectedResult[];\n  if (failures.length) {\n    throw failures[0];\n  }\n}\n\nfunction wrapError(type: string, message: string): (e: unknown) => void {\n  return (e): void => {\n    throw AWSError.isType(e, type) ? new Error(message) : e;\n  };\n}\n\nfunction handleError<T>(\n  type: string,\n  fn: () => Promise<T> | T,\n): (e: unknown) => Promise<T> | T {\n  return (e): (Promise<T> | T) => {\n    if (AWSError.isType(e, type)) {\n      return fn();\n    }\n    throw e;\n  };\n}\n\nconst ignore = (): void => {};\n\nfunction toDynamoValue(value: unknown): DDBValue {\n  // all values must be binary, because keys must be defined\n  // in advance before we know what type of data will be stored\n  // and any column could be a key (or become one in the future)\n  const bin = serialiseValueBin(value);\n  return { B: bin.toString('base64') };\n}\n\nfunction toDynamoItem(value: Record<string, unknown>): DDBItem {\n  const result: DDBItem = {};\n  Object.keys(value).forEach((key) => {\n    result[key] = toDynamoValue(value[key]);\n  });\n  return result;\n}\n\nfunction isDynamoBinary(value: DDBValue): value is { B: string } {\n  return Object.hasOwnProperty.call(value, 'B');\n}\n\nfunction isDynamoStringSet(value: DDBValue): value is { SS: string[] } {\n  return Object.hasOwnProperty.call(value, 'SS');\n}\n\nfunction fromDynamoValue(value: DDBValue): unknown {\n  if (isDynamoBinary(value)) {\n    return deserialiseValueBin(Buffer.from(value.B, 'base64'));\n  }\n  throw new Error('unexpected value type from DDB');\n}\n\nfunction fromDynamoItem<T = Record<string, unknown>>(value: DDBItem): T;\nfunction fromDynamoItem<T = Record<string, unknown>>(value: DDBItem | null | undefined): T | null;\n\nfunction fromDynamoItem<T = Record<string, unknown>>(value: DDBItem | null | undefined): T | null {\n  if (!value) {\n    return null;\n  }\n  const result: Record<string, unknown> = {};\n  Object.keys(value).forEach((key) => {\n    result[key] = fromDynamoValue(value[key]);\n  });\n  return result as T;\n}\n\nfunction toDynamoKey(attr: string, value: DDBValue): DDBValue {\n  if (!isDynamoBinary(value)) {\n    throw new Error('unexpected value type from DDB');\n  }\n  return {\n    B: Buffer.concat([\n      Buffer.from(`${attr}:`, 'utf8'),\n      Buffer.from(value.B, 'base64'),\n    ]).toString('base64'),\n  };\n}\n\nconst INDEX_META_KEY = { B: Buffer.from(':').toString('base64') };\n\nconst indexTable = (tableName: string): string => `${tableName}.`;\n\nexport interface Throughput {\n  read: number;\n  write: number;\n}\n\ntype CollectionThroughputFn = (indexName: string | null) => Throughput | null | undefined;\n\nfunction toDDBThroughput(\n  throughput: Throughput | null | undefined,\n): DDBProvisionedThroughput | undefined {\n  if (!throughput) {\n    return undefined;\n  }\n  return {\n    ReadCapacityUnits: Math.max(1, Math.ceil(throughput.read)),\n    WriteCapacityUnits: Math.max(1, Math.ceil(throughput.write)),\n  };\n}\n\nfunction getCombinedThroughput(\n  keys: string[],\n  throughputFn?: CollectionThroughputFn,\n): Throughput | null {\n  const totalThroughput = { read: 0, write: 0 };\n  let hasThroughput = false;\n  keys.forEach((attr) => {\n    const cur = throughputFn?.(attr);\n    if (cur) {\n      hasThroughput = true;\n      totalThroughput.read += cur.read;\n      totalThroughput.write += cur.write;\n    }\n  });\n  return hasThroughput ? totalThroughput : null;\n}\n\nasync function configureTable(\n  ddb: DDB,\n  tableName: string,\n  nonuniqueKeys: string[],\n  uniqueKeys: string[],\n  throughputFn?: CollectionThroughputFn,\n): Promise<void> {\n  const indexTableName = indexTable(tableName);\n\n  const [created] = await Promise.all<boolean, unknown>([\n    ddb.upsertTable(\n      tableName,\n      [{ attributeName: 'id', attributeType: 'B', keyType: 'HASH' }],\n      nonuniqueKeys.map((attr) => ({\n        indexName: escapeName(attr),\n        keySchema: [{ attributeName: attr, attributeType: 'B', keyType: 'HASH' }],\n        throughput: toDDBThroughput(throughputFn?.(attr)),\n      })),\n      true,\n      toDDBThroughput(throughputFn?.(null)),\n    ),\n    uniqueKeys.length ? ddb.upsertTable(\n      indexTableName,\n      [{ attributeName: 'ix', attributeType: 'B', keyType: 'HASH' }],\n      [],\n      true,\n      toDDBThroughput(getCombinedThroughput(uniqueKeys, throughputFn)),\n    ) : ddb.deleteTable(indexTableName).catch(ignore),\n  ]);\n\n  if (created || !uniqueKeys.length) {\n    return;\n  }\n\n  // table already existed; might need to migrate old data for unique indices\n  const info = await ddb.getItem(indexTableName, { ix: INDEX_META_KEY }, ['unique']);\n  const newKeys = new Set(uniqueKeys);\n  const oldKeys: string[] = [];\n  if (info && isDynamoStringSet(info.unique)) {\n    oldKeys.push(...info.unique.SS.filter((item) => !newKeys.delete(item)));\n  }\n  if (newKeys.size) {\n    // we have new keys which must be populated\n    const attrs = [...newKeys];\n    await ddb.getAllItems(tableName, ['id', ...attrs]).batched(async (items) => {\n      const indexItems: DDBItem[] = [];\n      items.forEach((item) => attrs.forEach((attr) => {\n        indexItems.push({ ix: toDynamoKey(attr, item[attr]), id: item.id });\n      }));\n      return ddb.batchPutItems(indexTableName, indexItems);\n    });\n  } else if (!oldKeys.length) {\n    return; // no change\n  }\n  // do not delete old items; storing them is relatively\n  // cheap compared to scanning and deleting them\n\n  // update stored info about indices\n  await ddb.putItem(indexTableName, { ix: INDEX_META_KEY, unique: { SS: uniqueKeys } });\n}\n\nexport default class DynamoCollection<T extends IDable> extends BaseCollection<T> {\n  private readonly uniqueKeys: (keyof T & string)[] = [];\n\n  public constructor(\n    private readonly ddb: DDB,\n    private readonly tableName: string,\n    keys: DBKeys<T> = {},\n    throughputFn?: CollectionThroughputFn,\n  ) {\n    super(keys);\n\n    const nonuniqueKeys: (keyof T & string)[] = [];\n    Object.entries(keys).forEach(([key, options]) => {\n      if (options?.unique) {\n        this.uniqueKeys.push(key as (keyof T & string));\n      } else {\n        nonuniqueKeys.push(key as (keyof T & string));\n      }\n    });\n\n    this.initAsync(configureTable(\n      ddb,\n      tableName,\n      nonuniqueKeys,\n      this.uniqueKeys,\n      throughputFn,\n    ));\n  }\n\n  get internalTableName(): string {\n    return this.tableName;\n  }\n\n  get internalIndexTableName(): string {\n    return indexTable(this.tableName);\n  }\n\n  protected internalAdd(value: T): Promise<void> {\n    return this.putItem(toDynamoItem(value as any));\n  }\n\n  protected internalUpsert(\n    id: T['id'],\n    update: Partial<T>,\n  ): Promise<void> {\n    const item = toDynamoItem({ id, ...update });\n    const { id: itemId, ...itemNoKey } = item;\n    const key = { id: itemId };\n\n    // optimistically try to update\n    return this.updateItem(key, itemNoKey, key).catch(handleError(\n      ConditionalCheckFailedException,\n\n      // if that fails due to the item not existing, try creating it\n      () => this.putItem(item).catch(handleError(\n        'duplicate id',\n\n        // it that fails due to the item existing, the item was probably\n        // created in the gap between calls; update it\n        () => this.updateItem(key, itemNoKey, key).catch(wrapError(\n          ConditionalCheckFailedException,\n\n          // if it fails again, give up\n          'Failed to upsert item',\n        )),\n      )),\n    ));\n  }\n\n  protected async internalUpdate<K extends keyof T & string>(\n    searchAttribute: K,\n    searchValue: T[K],\n    { id: _, ...update }: Partial<T>,\n  ): Promise<void> {\n    if (searchAttribute === 'id') {\n      await this.updateItem(\n        toDynamoItem({ id: searchValue }),\n        toDynamoItem(update),\n      ).catch(handleError(ConditionalCheckFailedException, ignore));\n    } else {\n      const items = await this.internalGetAll(searchAttribute, searchValue, ['id']);\n      await Promise.all(items.map(({ id }) => this.updateItem(\n        toDynamoItem({ id }),\n        toDynamoItem(update),\n        toDynamoItem({ [searchAttribute]: searchValue }),\n      ).catch(handleError(ConditionalCheckFailedException, ignore))));\n    }\n  }\n\n  protected async internalGet<\n    K extends keyof T & string,\n    F extends readonly (keyof T & string)[]\n  >(\n    searchAttribute: K,\n    searchValue: T[K],\n    returnAttributes?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>> | null> {\n    if (searchAttribute === 'id') {\n      return fromDynamoItem<Pick<T, F[-1]>>(await this.ddb.getItem(\n        this.tableName,\n        toDynamoItem({ id: searchValue }),\n        returnAttributes,\n      ));\n    }\n\n    if (!this.isIndexUnique(searchAttribute)) {\n      const ddbItems = await this.ddb.getItemsBySecondaryKey(\n        this.tableName,\n        escapeName(searchAttribute),\n        toDynamoItem({ [searchAttribute]: searchValue }),\n        returnAttributes,\n        true,\n      );\n      return fromDynamoItem<Pick<T, F[-1]>>(ddbItems[0]);\n    }\n\n    const ddbSearchValue = toDynamoValue(searchValue);\n    const key = await this.ddb.getItem(\n      indexTable(this.tableName),\n      { ix: toDynamoKey(searchAttribute, ddbSearchValue) },\n      ['id'],\n    );\n    if (!key) {\n      return null;\n    }\n    if (!returnAttributes) {\n      return fromDynamoItem<Pick<T, F[-1]>>(await this.ddb.getItem(this.tableName, key));\n    }\n    const ddbItem: DDBItem = {};\n    const filteredReturn = new Set(returnAttributes);\n    if (filteredReturn.delete('id')) {\n      Object.assign(ddbItem, key);\n    }\n    if (filteredReturn.delete(searchAttribute)) {\n      ddbItem[searchAttribute] = ddbSearchValue;\n    }\n    if (filteredReturn.size) {\n      const primaryItem = await this.ddb.getItem(this.tableName, key, [...filteredReturn]);\n      if (!primaryItem) {\n        // index and main table are out of sync;\n        // assume main table is correct and item does not exist\n        return null;\n      }\n      Object.assign(ddbItem, primaryItem);\n    }\n    return fromDynamoItem<Pick<T, F[-1]>>(ddbItem);\n  }\n\n  protected async internalGetAll<\n    K extends keyof T & string,\n    F extends readonly (keyof T & string)[]\n  >(\n    searchAttribute?: K,\n    searchValue?: T[K],\n    returnAttributes?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>>[]> {\n    if (!searchAttribute) {\n      const items = await this.ddb.getAllItems(this.tableName, returnAttributes).all();\n      return items.map(fromDynamoItem) as Pick<T, F[-1]>[];\n    }\n    if (this.isIndexUnique(searchAttribute)) {\n      const item = await this.internalGet(searchAttribute, searchValue!, returnAttributes);\n      return item ? [item] : [];\n    }\n    const items = await this.ddb.getItemsBySecondaryKey(\n      this.tableName,\n      escapeName(searchAttribute),\n      toDynamoItem({ [searchAttribute]: searchValue }),\n      returnAttributes,\n      false,\n    );\n    return items.map(fromDynamoItem) as Pick<T, F[-1]>[];\n  }\n\n  protected async internalRemove<K extends keyof T & string>(\n    searchAttribute: K,\n    searchValue: T[K],\n  ): Promise<number> {\n    if (searchAttribute === 'id') {\n      const success = await this.deleteItem(toDynamoItem({ id: searchValue }));\n      return success ? 1 : 0;\n    }\n    const items = await this.internalGetAll(searchAttribute, searchValue, ['id']);\n    const successes = await Promise.all(items.map(({ id }) => this.deleteItem(\n      toDynamoItem({ id }),\n    )));\n    return successes.filter((success) => success).length;\n  }\n\n  private async atomicPutUniques(\n    id: DDBValue,\n    item: DDBItem,\n    uniqueKeys: (keyof T & string)[],\n    fn: () => Promise<void>,\n  ): Promise<void> {\n    if (!uniqueKeys.length) {\n      await fn();\n      return;\n    }\n\n    const indexTableName = indexTable(this.tableName);\n    const successes: string[] = [];\n    try {\n      await runAll(uniqueKeys, successes, (attr) => this.ddb.putItem(\n        indexTableName,\n        { ix: toDynamoKey(attr, item[attr]), id },\n        'ix',\n      ).catch(wrapError(ConditionalCheckFailedException, `duplicate ${attr}`)));\n      await fn();\n    } catch (e) {\n      await this.ddb.batchDeleteItems(\n        indexTableName,\n        successes.map((attr) => ({ ix: toDynamoKey(attr, item[attr]) })),\n      ).catch(ignore); // best effort to reset state, but ignore errors here\n      throw e;\n    }\n  }\n\n  private async putItem(item: DDBItem): Promise<void> {\n    return this.atomicPutUniques(\n      item.id,\n      item,\n      this.uniqueKeys,\n      () => this.ddb.putItem(\n        this.tableName,\n        item,\n        'id',\n      ).catch(wrapError(ConditionalCheckFailedException, 'duplicate id')),\n    );\n  }\n\n  private async updateItem(key: DDBItem, update: DDBItem, condition?: DDBItem): Promise<void> {\n    const updatedUnique = this.uniqueKeys.filter((a) => Object.hasOwnProperty.call(update, a));\n    if (!updatedUnique.length) {\n      await this.ddb.updateItem(this.tableName, key, update, condition);\n      return;\n    }\n    const old = await this.ddb.getItem(this.tableName, key, updatedUnique);\n    if (!old) {\n      throw new AWSError(400, ConditionalCheckFailedException, 'could not find item to update');\n    }\n    const changedAttrs = updatedUnique.filter((a) => (old[a] as any).B !== (update[a] as any).B);\n    await this.atomicPutUniques(\n      key.id,\n      update,\n      changedAttrs,\n      () => this.ddb.updateItem(this.tableName, key, update, { ...old, ...condition }),\n    );\n    await this.ddb.batchDeleteItems(\n      indexTable(this.tableName),\n      changedAttrs.map((attr) => ({ ix: toDynamoKey(attr, old[attr]) })),\n    );\n  }\n\n  private async deleteItem(key: DDBItem): Promise<boolean> {\n    try {\n      if (!this.uniqueKeys.length) {\n        await this.ddb.deleteItem(this.tableName, key);\n      } else {\n        const item = await this.ddb.deleteAndReturnItem(this.tableName, key);\n        await this.ddb.batchDeleteItems(\n          indexTable(this.tableName),\n          this.uniqueKeys.map((attr) => ({ ix: toDynamoKey(attr, item[attr]) })),\n        );\n      }\n      return true;\n    } catch (e) {\n      if (AWSError.isType(e, ConditionalCheckFailedException)) {\n        return false;\n      }\n      throw e;\n    }\n  }\n}\n","export default class PromiseTracker {\n  private readonly inflight = new Set<Promise<any>>();\n\n  do<T>(fn: () => Promise<T>): Promise<T> {\n    let flightResolve = (): void => {};\n    const flight = new Promise((resolve) => {\n      flightResolve = resolve;\n    }).then(() => {\n      this.inflight.delete(flight);\n    });\n    this.inflight.add(flight);\n    return fn().finally(flightResolve);\n  }\n\n  async wait(): Promise<void> {\n    const current = [...this.inflight];\n    this.inflight.clear();\n    await Promise.allSettled(current);\n  }\n}\n","export default class LruCache<K, V> {\n  private readonly storage = new Map<K, V>();\n\n  public constructor(\n    private readonly capacity: number,\n  ) {}\n\n  public cached(key: K, calc: (key: K) => V): V {\n    const value = this.storage.get(key);\n    if (this.storage.delete(key)) {\n      this.storage.set(key, value!);\n      return value!;\n    }\n    const created = calc(key);\n    this.storage.set(key, created);\n    this.flush();\n    return created;\n  }\n\n  public async cachedAsync(key: K, calc: (key: K) => Promise<V>): Promise<V> {\n    const value = this.storage.get(key);\n    if (this.storage.delete(key)) {\n      this.storage.set(key, value!);\n      return value!;\n    }\n    const created = await calc(key);\n    this.storage.set(key, created);\n    this.flush();\n    return created;\n  }\n\n  public remove(key: K): void {\n    this.storage.delete(key);\n  }\n\n  private flush(): void {\n    while (this.storage.size > this.capacity) {\n      this.storage.delete(this.storage.keys().next().value);\n    }\n  }\n}\n","import { createHash, createHmac } from 'crypto';\nimport https from 'https';\nimport http from 'http';\nimport AWSError from './AWSError';\nimport PromiseTracker from '../../helpers/PromiseTracker';\nimport LruCache from '../../helpers/LruCache';\nimport retry from '../../helpers/retry';\n\ntype Method = 'OPTIONS' | 'GET' | 'HEAD' | 'POST' | 'PUT' | 'DELETE';\n\nconst EMPTY_BUFFER = Buffer.alloc(0);\nconst ISO_TIME_STRIP = /(-|:|\\.[0-9]*)/g;\nconst ALGORITHM = 'AWS4-HMAC-SHA256';\n\nconst withTransientErrorRetry = retry((e) => (!(e instanceof AWSError) || e.isTransient()));\n\nfunction sha256(v: Buffer): string {\n  const hash = createHash('sha256');\n  hash.update(v);\n  return hash.digest('hex');\n}\n\nfunction hmac(key: Buffer, data: string): Buffer {\n  const hash = createHmac('sha256', key);\n  hash.update(data, 'utf8');\n  return hash.digest();\n}\n\ninterface RequestOptions {\n  method: Method;\n  url: URL | string;\n  region: string;\n  service: string;\n  headers?: Record<string, string>;\n  body?: string | Record<string, unknown> | Buffer;\n  date?: Date;\n}\n\ninterface FetchResponse {\n  status: number;\n  json: unknown;\n}\n\ninterface AWSErrorResponse {\n  __type: string;\n  message: string;\n}\n\nexport default class AWS {\n  private readonly baseKey: Buffer;\n\n  private readonly keyCacheDate = new LruCache<string, Buffer>(1);\n\n  private readonly keyCacheRegion = new LruCache<string, Buffer>(4);\n\n  private readonly keyCache = new LruCache<string, Buffer>(16);\n\n  private readonly inflight = new PromiseTracker();\n\n  private closed = false;\n\n  constructor(private readonly keyID: string, secret: string) {\n    this.baseKey = Buffer.from(`AWS4${secret}`, 'utf8');\n  }\n\n  do<T>(fn: () => Promise<T>): Promise<T> {\n    return this.inflight.do(fn);\n  }\n\n  request({\n    method,\n    url,\n    region,\n    service,\n    headers = {},\n    body = EMPTY_BUFFER,\n    date = new Date(),\n  }: RequestOptions): Promise<FetchResponse> {\n    // https://docs.aws.amazon.com/general/latest/gr/sigv4-create-canonical-request.html\n\n    const parsedURL = (url instanceof URL) ? url : new URL(url);\n    if (parsedURL.search) {\n      throw new Error('AWS urls with query strings are not supported');\n    }\n    if (this.closed) {\n      throw new Error('connection closed');\n    }\n\n    let binaryBody: Buffer;\n    if (body instanceof Buffer) {\n      binaryBody = body;\n    } else if (typeof body === 'string') {\n      binaryBody = Buffer.from(body, 'utf8');\n    } else {\n      binaryBody = Buffer.from(JSON.stringify(body), 'utf8');\n    }\n\n    const canonicalTime = date.toISOString().replace(ISO_TIME_STRIP, ''); // YYYYMMDD'T'HHmmSS'Z'\n    const canonicalDate = canonicalTime.substr(0, 8); // YYYYMMDD\n    const credentialScope = `${canonicalDate}/${region}/${service}/aws4_request`;\n    const key = this.getKey(canonicalDate, region, service);\n\n    // AWS requires double-uri-encoding, and pathname uses non-standard encoding\n    const canonicalPath = encodeURI(encodeURI(decodeURI(parsedURL.pathname))) || '/';\n    const canonicalQueryString = '';\n\n    const allHeaders: Record<string, string> = {\n      ...headers,\n      Host: parsedURL.host,\n      'X-Amz-Date': canonicalTime,\n    };\n\n    // string comparison is intended\n    /* eslint-disable-next-line @typescript-eslint/require-array-sort-compare */\n    const headerNames = Object.keys(allHeaders)\n      .map((header) => header.toLowerCase())\n      .sort();\n\n    const canonicalHeaders = headerNames\n      .map((header) => `${header}:${allHeaders[header]}\\n`)\n      .join('');\n    const signedHeaders = headerNames.join(';');\n\n    const canonicalRequest = [\n      method,\n      canonicalPath,\n      canonicalQueryString,\n      canonicalHeaders,\n      signedHeaders,\n      sha256(binaryBody),\n    ].join('\\n');\n\n    const stringToSign = [\n      ALGORITHM,\n      canonicalTime,\n      credentialScope,\n      sha256(Buffer.from(canonicalRequest, 'utf8')),\n    ].join('\\n');\n\n    const signature = hmac(key, stringToSign).toString('hex');\n\n    allHeaders.Authorization = [\n      `${ALGORITHM} Credential=${this.keyID}/${credentialScope}`,\n      `SignedHeaders=${signedHeaders}`,\n      `Signature=${signature}`,\n    ].join(', ');\n\n    delete allHeaders.Host; // will be auto-added by node\n\n    return this.fetch(parsedURL, binaryBody, {\n      method,\n      headers: allHeaders,\n    });\n  }\n\n  async close(): Promise<void> {\n    if (this.closed) {\n      return;\n    }\n    await this.inflight.wait();\n    this.closed = true;\n  }\n\n  private fetch(\n    url: URL,\n    body: Buffer,\n    options: http.RequestOptions,\n  ): Promise<FetchResponse> {\n    if (this.closed) {\n      throw new Error('connection closed');\n    }\n\n    const protocol = (url.protocol === 'https') ? https : http;\n    return this.inflight.do(() => withTransientErrorRetry(() => new Promise((resolve, reject) => {\n      const req = protocol.request(url, options, (res) => {\n        const parts: Buffer[] = [];\n        res.on('data', (chunk) => parts.push(chunk));\n        res.on('end', () => {\n          try {\n            const text = Buffer.concat(parts).toString('utf8');\n            parts.length = 0;\n            const json = JSON.parse(text) as AWSErrorResponse;\n            if (!res.statusCode || res.statusCode >= 300) {\n              /* eslint-disable-next-line no-underscore-dangle */ // part of API\n              reject(new AWSError(res.statusCode || 0, json.__type, json.message));\n            } else {\n              resolve({ status: res.statusCode, json });\n            }\n          } catch (e) {\n            reject(e);\n          }\n        });\n      });\n      req.on('error', reject);\n      req.write(body);\n      req.end();\n    })));\n  }\n\n  private getKey(\n    canonicalDate: string,\n    region: string,\n    service: string,\n  ): Buffer {\n    return this.keyCache.cached(`${canonicalDate}/${region}/${service}`, () => {\n      const kRegion = this.keyCacheRegion.cached(`${canonicalDate}/${region}`, () => hmac(\n        this.keyCacheDate.cached(canonicalDate, () => hmac(this.baseKey, canonicalDate)),\n        region,\n      ));\n      return hmac(hmac(kRegion, service), 'aws4_request');\n    });\n  }\n}\n","import DynamoCollection, { Throughput } from './DynamoCollection';\nimport AWS from './api/AWS';\nimport { DDB, escapeName } from './api/DDB';\nimport type { DBKeys } from '../interfaces/DB';\nimport BaseDB from '../interfaces/BaseDB';\nimport type { IDable } from '../interfaces/IDable';\n\nexport type DbThroughputFn = (\n  tableName: string,\n  indexName: string | null,\n) => Throughput | null | undefined;\n\nconst makeThroughputFn = (params: URLSearchParams) => (\n  tableName: string,\n  indexName: string | null,\n): Throughput | null => {\n  let throughput: string | null = null;\n  if (indexName) {\n    throughput = (\n      params.get(`provision_${tableName}_index_${indexName}`) ||\n      params.get(`provision_${tableName}_index`) ||\n      params.get(`provision_${tableName}`) ||\n      params.get('provision')\n    );\n  } else {\n    throughput = (\n      params.get(`provision_${tableName}`) ||\n      params.get('provision')\n    );\n  }\n  if (!throughput || throughput === '-') {\n    return null;\n  }\n  const parts = throughput.split('.');\n  if (parts.length !== 2) {\n    throw new Error(`unexpected provisioning format for ${tableName} ${indexName || ''}: ${throughput} (expected 'read.write' or '-')`);\n  }\n  return {\n    read: Number.parseInt(parts[0], 10),\n    write: Number.parseInt(parts[1], 10),\n  };\n};\n\nexport default class DynamoDb extends BaseDB {\n  private constructor(\n    private readonly aws: AWS,\n    private readonly ddb: DDB,\n    tableNamePrefix: string,\n    throughputFn?: DbThroughputFn,\n  ) {\n    super((name, keys) => new DynamoCollection(\n      this.ddb,\n      tableNamePrefix + escapeName(name),\n      keys,\n      throughputFn?.bind(null, name),\n    ));\n  }\n\n  public static connect(url: string, throughputFn?: DbThroughputFn): DynamoDb {\n    const parsed = new URL(url);\n    let key;\n    let secret;\n    if (parsed.username) {\n      key = parsed.username;\n      secret = parsed.password;\n    } else {\n      key = process.env.AWS_ACCESS_KEY_ID;\n      secret = process.env.AWS_SECRET_ACCESS_KEY;\n    }\n    if (!key || !secret) {\n      throw new Error('No AWS key / secret specified');\n    }\n    const protocol = (parsed.searchParams.get('tls') === 'false') ? 'http' : 'https';\n    const consistentRead = (parsed.searchParams.get('consistentRead') === 'true');\n    const tableNamePrefix = parsed.pathname.substr(1);\n\n    const aws = new AWS(key, secret);\n    const ddb = new DDB(aws, `${protocol}://${parsed.host}`, { consistentRead });\n    return new DynamoDb(\n      aws,\n      ddb,\n      tableNamePrefix,\n      throughputFn || makeThroughputFn(parsed.searchParams),\n    );\n  }\n\n  public getCollection<T extends IDable>(name: string, keys?: DBKeys<T>): DynamoCollection<T> {\n    return super.getCollection(name, keys) as DynamoCollection<T>;\n  }\n\n  public getDDB(): DDB {\n    return this.ddb;\n  }\n\n  protected internalClose(): Promise<void> {\n    return this.aws.close();\n  }\n}\n","import type {\n  Redis,\n  Pipeline,\n  MultiOptions,\n  Ok,\n} from 'ioredis';\n\n// Thanks, https://stackoverflow.com/a/50014868/1180785\ntype ArgumentTypes<T> = T extends (...args: infer U) => any ? U : never;\n\ntype PipelineVersions<I> = {\n  [K in keyof I]: (...args: ArgumentTypes<I[K]>) => Pipeline & PipelineVersions<I>;\n};\n\ninterface RedisWithExtendedPipeline<I> extends Redis {\n  multi(commands?: string[][], options?: MultiOptions): Pipeline & PipelineVersions<I>;\n  multi(options: { pipeline: false }): Promise<Ok>;\n}\n\nexport type ExtendedRedis<I> = I & RedisWithExtendedPipeline<I>;\n\nexport async function multiExec(\n  client: Redis,\n  commands: string[][],\n): Promise<[unknown, any][] | null> {\n  if (!commands.length) {\n    return [];\n  }\n  return client.multi(commands).exec();\n}\n\nexport function minifyLuaScript(\n  lines: string[],\n  ...argNames: string[]\n): string {\n  let combined = lines.map((ln) => ln.trim()).join(' ');\n  argNames.forEach((name, i) => {\n    combined = combined.replace(new RegExp(`\\\\$${name}\\\\b`, 'g'), `ARGV[${i + 1}]`);\n  });\n  return combined;\n}\n","import type { IDable } from '../interfaces/IDable';\nimport BaseCollection from '../interfaces/BaseCollection';\nimport type { UpdateOptions } from '../interfaces/Collection';\nimport type { DBKeys } from '../interfaces/DB';\nimport {\n  serialiseValue,\n  serialiseRecord,\n  deserialiseRecord,\n} from '../helpers/serialiser';\nimport type RedisConnectionPool from './RedisConnectionPool';\nimport { multiExec } from './helpers';\nimport type { ERedis } from './scripts';\n\ninterface Key<T> {\n  key: keyof T & string;\n  prefix: string;\n}\n\ninterface InternalPatch {\n  sId: string;\n  oldSerialised: Record<string, string | null>;\n  newSerialised: Record<string, string>;\n}\n\nconst notUndefined = <T>(item?: T): item is T => (item !== undefined);\n\nfunction makeIndexKeys(\n  keys: Key<any>[],\n  partialSerialisedValue: Record<string, string | null>,\n): string[] {\n  return keys\n    .filter(({ key }) => partialSerialisedValue[key])\n    .map(({ key, prefix }) => `${prefix}:${partialSerialisedValue[key]}`);\n}\n\nfunction parseItem(\n  item: (string | null)[] | Record<string, string | null>,\n  fields?: readonly string[],\n): Record<string, string | null> {\n  if (!fields) {\n    return item as any;\n  }\n  const result: Record<string, string | null> = {};\n  for (let f = 0; f < fields.length; f += 1) {\n    result[fields[f]] = (item as any)[f];\n  }\n  return result;\n}\n\nfunction itemHasContent(item: Record<string, string | null>): boolean {\n  return Object.values(item).some((v) => (v !== null));\n}\n\nasync function unwatchAll(client: ERedis): Promise<void> {\n  await client.unwatch();\n}\n\nasync function mapAwaitSync<T, O>(\n  values: T[],\n  fn: (value: T) => Promise<O>,\n): Promise<O[]> {\n  const result: O[] = [];\n  for (let i = 0; i < values.length; i += 1) {\n    // eslint-disable-next-line no-await-in-loop\n    result.push(await fn(values[i]));\n  }\n  return result;\n}\n\nexport default class RedisCollection<T extends IDable> extends BaseCollection<T> {\n  private readonly keyPrefixes: { [K in keyof T]?: string } = {};\n\n  private readonly uniqueKeys: Key<T>[] = [];\n\n  private readonly nonUniqueKeys: Key<T>[] = [];\n\n  public constructor(\n    private readonly pool: RedisConnectionPool,\n    private readonly prefix: string,\n    keys: DBKeys<T> = {},\n  ) {\n    super(keys);\n\n    Object.keys(keys).forEach((k) => {\n      const key = k as keyof DBKeys<T>;\n      const keyPrefix = `${prefix}-${key}`;\n      this.keyPrefixes[key] = keyPrefix;\n      const keyInfo = { key, prefix: keyPrefix };\n      if (keys[key]!.unique) {\n        this.uniqueKeys.push(keyInfo);\n      } else {\n        this.nonUniqueKeys.push(keyInfo);\n      }\n    });\n  }\n\n  protected internalAdd(value: T): Promise<void> {\n    const serialised = serialiseRecord(value);\n    return this.pool.withConnection(async (client) => {\n      const added = await this.runAdd(client, serialised, false);\n      if (!added) {\n        throw new Error('duplicate');\n      }\n    });\n  }\n\n  protected internalUpdate<K extends keyof T & string>(\n    searchAttribute: K,\n    searchValue: T[K],\n    update: Partial<T>,\n    { upsert }: UpdateOptions,\n  ): Promise<void> {\n    const patchSerialised = serialiseRecord(update);\n    const sKey = serialiseValue(searchValue);\n\n    if (searchAttribute === 'id') {\n      return this.pool.retryWithConnection(async (client) => {\n        const patch = await this.getUpdatePatch(client, sKey, patchSerialised);\n        if (patch) {\n          await this.runUpdates(client, [patch]);\n        } else if (upsert) {\n          const insertValue = { ...patchSerialised, id: sKey };\n          if (!await this.runAdd(client, insertValue, true)) {\n            throw new Error('duplicate');\n          }\n        }\n      }, unwatchAll);\n    }\n\n    return this.pool.retryWithConnection(async (client) => {\n      const sIds = await this.getAndWatchBySerialisedKey(client, searchAttribute, sKey);\n      const patches = (await mapAwaitSync(\n        sIds,\n        (sId) => this.getUpdatePatch(client, sId, patchSerialised),\n      )).filter(notUndefined);\n      await this.runUpdates(client, patches);\n    }, unwatchAll);\n  }\n\n  protected internalGet<\n    K extends keyof T & string,\n    F extends readonly (keyof T & string)[]\n  >(\n    searchAttribute: K,\n    searchValue: T[K],\n    returnAttributes?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>> | null> {\n    const sKey = serialiseValue(searchValue);\n    return this.pool.retryWithConnection(async (client) => {\n      const sId = (await this.getAndWatchBySerialisedKey(client, searchAttribute, sKey))[0];\n      if (sId === undefined) {\n        return null;\n      }\n      const results = await this.getByKeysKeepWatches(client, [sId], returnAttributes);\n      return results[0] ?? null;\n    }, unwatchAll);\n  }\n\n  protected internalGetAll<\n    K extends keyof T & string,\n    F extends readonly (keyof T & string)[]\n  >(\n    searchAttribute?: K,\n    searchValue?: T[K],\n    returnAttributes?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>>[]> {\n    return this.pool.retryWithConnection(async (client) => {\n      let sIds: string[];\n      if (searchAttribute) {\n        const sKey = serialiseValue(searchValue);\n        sIds = await this.getAndWatchBySerialisedKey(client, searchAttribute, sKey);\n      } else {\n        sIds = await client.keys(this.makeKey('*'));\n        const cut = this.prefix.length + 1;\n        sIds = sIds.map((v) => v.substr(cut));\n      }\n      return this.getByKeysKeepWatches(client, sIds, returnAttributes);\n    }, unwatchAll);\n  }\n\n  protected internalRemove<K extends keyof T & string>(\n    searchAttribute: K,\n    searchValue: T[K],\n  ): Promise<number> {\n    const sKey = serialiseValue(searchValue);\n    const indexedKeys = Object.keys(this.keys);\n    indexedKeys.push('id');\n\n    return this.pool.retryWithConnection(async (client) => {\n      const sIds = await this.getAndWatchBySerialisedKey(client, searchAttribute, sKey);\n      const items = (await mapAwaitSync(\n        sIds,\n        (sId) => this.rawByKeyKeepWatches(client, sId, indexedKeys),\n      )).filter(notUndefined);\n\n      if (items.length === 0) {\n        return 0;\n      }\n\n      const pipeline = client.multi();\n      items.forEach((item) => {\n        const uniqueKeys = makeIndexKeys(this.uniqueKeys, item);\n        const nonUniqueKeys = makeIndexKeys(this.nonUniqueKeys, item);\n        pipeline.remove(\n          1 + uniqueKeys.length + nonUniqueKeys.length,\n          this.makeKey(item.id!),\n          ...uniqueKeys,\n          ...nonUniqueKeys,\n          item.id!,\n        );\n      });\n      await pipeline.exec();\n      return items.length;\n    }, unwatchAll);\n  }\n\n  private makeKey(serialisedId: string): string {\n    return `${this.prefix}:${serialisedId}`;\n  }\n\n  private async runAdd(\n    client: ERedis,\n    { id, ...serialised }: Record<string, string>,\n    checkWatch: boolean,\n  ): Promise<boolean> {\n    const uniqueKeys = makeIndexKeys(this.uniqueKeys, serialised);\n    const nonUniqueKeys = makeIndexKeys(this.nonUniqueKeys, serialised);\n\n    const keyCount = 1 + uniqueKeys.length + nonUniqueKeys.length;\n    const params = [\n      this.makeKey(id),\n      ...uniqueKeys,\n      ...nonUniqueKeys,\n      uniqueKeys.length,\n      'id', // ID is always first in flattened key/value pairs\n      id,\n      ...Object.entries(serialised).flat(),\n    ];\n\n    if (!checkWatch) {\n      return Boolean(await client.add(keyCount, ...params));\n    }\n\n    const result = await client\n      .multi()\n      .add(keyCount, ...params)\n      .exec();\n    if (!result) {\n      throw new Error('transient error');\n    }\n    return Boolean(result[0][1]);\n  }\n\n  private async getUpdatePatch(\n    client: ERedis,\n    sId: string,\n    patchSerialised: Record<string, string>,\n  ): Promise<InternalPatch | undefined> {\n    await client.watch(this.makeKey(sId));\n    const oldSerialised = await this.rawByKeyKeepWatches(\n      client,\n      sId,\n      Object.keys(this.keys).filter((k) => patchSerialised[k]),\n    );\n    if (!oldSerialised) {\n      return undefined;\n    }\n    const newSerialised = { ...patchSerialised };\n    Object.keys(newSerialised).forEach((k) => {\n      if (oldSerialised[k] === newSerialised[k]) {\n        delete newSerialised[k];\n        delete oldSerialised[k];\n      }\n    });\n    return { sId, newSerialised, oldSerialised };\n  }\n\n  private async runUpdates(\n    client: ERedis,\n    patches: InternalPatch[],\n  ): Promise<void> {\n    const argsList = patches\n      .map((patch) => this.makeUpdateArgs(patch))\n      .filter(notUndefined);\n\n    if (!argsList.length) {\n      return;\n    }\n\n    if (argsList.length === 1) {\n      const results = await client.multi()\n        .update(argsList[0][0], argsList[0][1])\n        .exec();\n\n      if (!results) {\n        throw new Error('transient error');\n      }\n      if (!results[0][1]) {\n        throw new Error('duplicate');\n      }\n      return;\n    }\n\n    const updateCheckResults = await mapAwaitSync(\n      argsList,\n      (updateArgs) => client.checkUpdate(updateArgs[0], updateArgs[1]),\n    );\n    if (updateCheckResults.some((r) => !r)) {\n      throw new Error('duplicate');\n    }\n\n    let chain = client.multi();\n    argsList.forEach((updateArgs) => {\n      chain = chain.updateWithoutCheck(updateArgs[0], updateArgs[1]);\n    });\n    const results = await chain.exec();\n\n    if (!results) {\n      throw new Error('transient error');\n    }\n  }\n\n  private makeUpdateArgs(\n    { sId, oldSerialised, newSerialised }: InternalPatch,\n  ): [number, any[]] | undefined {\n    const diff = Object.entries(newSerialised).flat();\n    if (!diff.length) {\n      return undefined; // nothing changed\n    }\n    const patchUniqueKeys = makeIndexKeys(this.uniqueKeys, newSerialised);\n    const patchNonUniqueKeys = makeIndexKeys(this.nonUniqueKeys, newSerialised);\n    const oldUniqueKeys = makeIndexKeys(this.uniqueKeys, oldSerialised);\n    const oldNonUniqueKeys = makeIndexKeys(this.nonUniqueKeys, oldSerialised);\n    if (\n      oldUniqueKeys.length !== patchUniqueKeys.length ||\n      oldNonUniqueKeys.length !== patchNonUniqueKeys.length\n    ) {\n      throw new Error('unexpected key mismatch with old value');\n    }\n    const keyCount = 1 + (patchUniqueKeys.length + patchNonUniqueKeys.length) * 2;\n    const params = [\n      this.makeKey(sId),\n      ...patchUniqueKeys,\n      ...patchNonUniqueKeys,\n      ...oldUniqueKeys,\n      ...oldNonUniqueKeys,\n      patchUniqueKeys.length,\n      patchUniqueKeys.length + patchNonUniqueKeys.length,\n      sId,\n      ...diff,\n    ];\n    return [keyCount, params];\n  }\n\n  private async getByKeysKeepWatches<F extends readonly (keyof T & string)[]>(\n    client: ERedis,\n    serialisedIds: string[],\n    fields?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>>[]> {\n    const results = await multiExec(\n      client,\n      serialisedIds\n        .map((sId) => this.makeKey(sId))\n        .map((k) => (fields ? ['hmget', k, ...fields] : ['hgetall', k])),\n    );\n    if (!results) {\n      throw new Error('transient error');\n    }\n    return results\n      .map(([, item]: [unknown, any]) => parseItem(item, fields))\n      .filter(itemHasContent)\n      .map(deserialiseRecord) as T[];\n  }\n\n  private async rawByKeyKeepWatches(\n    client: ERedis,\n    serialisedId: string,\n    fields?: readonly string[],\n  ): Promise<Record<string, string | null> | undefined> {\n    const key = this.makeKey(serialisedId);\n    let item;\n    if (fields) {\n      if (!fields.length) {\n        // just check existence\n        const exists = await client.exists(key);\n        return exists ? {} : undefined;\n      }\n      item = await client.hmget(key, ...fields);\n    } else {\n      item = await client.hgetall(key);\n    }\n    const parsed = parseItem(item, fields);\n    return itemHasContent(parsed) ? parsed : undefined;\n  }\n\n  private async getAndWatchBySerialisedKey(\n    client: ERedis,\n    keyName: keyof T,\n    serialisedValue: string,\n  ): Promise<string[]> {\n    if (keyName === 'id') {\n      return [serialisedValue];\n    }\n    const keyPrefix = this.keyPrefixes[keyName];\n    if (!keyPrefix) {\n      throw new Error(`Requested key ${keyName} not indexed`);\n    }\n    const keyAddress = `${keyPrefix}:${serialisedValue}`;\n    await client.watch(keyAddress);\n    return client.smembers(keyAddress);\n  }\n}\n","import type { Redis as RedisT } from 'ioredis';\nimport { minifyLuaScript, ExtendedRedis } from './helpers';\n\nexport interface ScriptExtensions {\n  add(keyCount: number, ...keysAndArgs: any[]): Promise<number>;\n  update(keyCount: number, ...keysAndArgs: any[]): Promise<number>;\n  checkUpdate(keyCount: number, ...keysAndArgs: any[]): Promise<number>;\n  updateWithoutCheck(keyCount: number, ...keysAndArgs: any[]): Promise<void>;\n  remove(keyCount: number, ...keysAndArgs: any[]): Promise<void>;\n}\n\nexport type ERedis = ExtendedRedis<ScriptExtensions>;\n\n// KEYS = [id, ...uniqueKeys, ...nonUniqueKeys]\nconst SCRIPT_ADD = minifyLuaScript([\n  'if redis.call(\"exists\",KEYS[1])==1 then',\n  '  return 0',\n  'end',\n  'for k=2,1+tonumber($uniqueKeyCount) do',\n  '  if redis.call(\"exists\",KEYS[k])==1 then',\n  '    return 0',\n  '  end',\n  'end',\n  'redis.call(\"hset\",KEYS[1],unpack(ARGV, 2))',\n  'for k=2,#KEYS do',\n  '  redis.call(\"sadd\",KEYS[k],ARGV[3])',\n  'end',\n  'return 1',\n], 'uniqueKeyCount');\n\nconst FRAG_CHECK_UPDATE = [\n  'for k=2,1+tonumber($uniqueKeyCount) do',\n  '  if redis.call(\"exists\",KEYS[k])==1 then',\n  '    return 0',\n  '  end',\n  'end',\n];\n\nconst FRAG_UPDATE = [\n  'local tkc=tonumber($totalKeyCount)',\n  'redis.call(\"hset\",KEYS[1],unpack(ARGV, 4))',\n  'for k=1,tkc do',\n  '  redis.call(\"smove\",KEYS[1+tkc+k],KEYS[1+k],$id)',\n  'end',\n];\n\n// KEYS = [id, ...patchUniqueKeys, ...patchNonUniqueKeys, ...oldUniqueKeys, ...oldNonUniqueKeys]\nconst SCRIPT_CHECK_UPDATE = minifyLuaScript([\n  ...FRAG_CHECK_UPDATE,\n  'return 1',\n], 'uniqueKeyCount', 'totalKeyCount', 'id');\n\n// KEYS = [id, ...patchUniqueKeys, ...patchNonUniqueKeys, ...oldUniqueKeys, ...oldNonUniqueKeys]\nconst SCRIPT_UPDATE_WITHOUT_CHECK = minifyLuaScript([\n  ...FRAG_UPDATE,\n], 'uniqueKeyCount', 'totalKeyCount', 'id');\n\n// KEYS = [id, ...patchUniqueKeys, ...patchNonUniqueKeys, ...oldUniqueKeys, ...oldNonUniqueKeys]\nconst SCRIPT_UPDATE = minifyLuaScript([\n  ...FRAG_CHECK_UPDATE,\n  ...FRAG_UPDATE,\n  'return 1',\n], 'uniqueKeyCount', 'totalKeyCount', 'id');\n\n// KEYS = [id, ...keys]\nconst SCRIPT_REMOVE = minifyLuaScript([\n  'redis.call(\"del\",KEYS[1])',\n  'for k=2,#KEYS do',\n  '  redis.call(\"srem\",KEYS[k],$id)',\n  'end',\n], 'id');\n\nexport default function defineAllScripts(client: RedisT): ERedis {\n  client.defineCommand('add', { lua: SCRIPT_ADD });\n  client.defineCommand('update', { lua: SCRIPT_UPDATE });\n  client.defineCommand('checkUpdate', { lua: SCRIPT_CHECK_UPDATE });\n  client.defineCommand('updateWithoutCheck', { lua: SCRIPT_UPDATE_WITHOUT_CHECK });\n  client.defineCommand('remove', { lua: SCRIPT_REMOVE });\n\n  return client as ERedis;\n}\n","import type { Redis as RedisT, RedisOptions as RedisOptionsT } from 'ioredis';\nimport defineAllScripts, { ERedis } from './scripts';\nimport retry from '../helpers/retry';\n\ntype RS = new(host?: string, options?: RedisOptionsT) => RedisT;\n\nconst withRetry = retry((e) => (\n  typeof e === 'object' &&\n  e.message === 'transient error'\n));\n\nexport default class RedisConnectionPool {\n  private readonly connections: ERedis[] = [];\n\n  private inUse = 0;\n\n  private queue: ((client: ERedis) => void)[] = [];\n\n  private closingFn?: () => void;\n\n  private closed = false;\n\n  public constructor(\n    private readonly RedisStatic: RS,\n    private readonly url: string,\n    private readonly options: RedisOptionsT,\n    private readonly maxConnections: number,\n  ) {}\n\n  public async withConnection<T>(\n    fn: (c: ERedis) => Promise<T> | T,\n    teardown?: (c: ERedis) => Promise<void> | void,\n  ): Promise<T> {\n    const c = await this.getConnection();\n    try {\n      return await fn(c);\n    } finally {\n      await teardown?.(c);\n      this.returnConnection(c);\n    }\n  }\n\n  public async retryWithConnection<T>(\n    fn: (c: ERedis) => Promise<T> | T,\n    teardown?: (c: ERedis) => Promise<void> | void,\n  ): Promise<T> {\n    return withRetry(() => this.withConnection(fn, teardown));\n  }\n\n  public close(): Promise<void> {\n    if (this.closed) {\n      return Promise.resolve();\n    }\n\n    this.closed = true;\n    if (this.inUse === 0) {\n      this.doClose();\n      return Promise.resolve();\n    }\n\n    return new Promise((resolve): void => {\n      this.closingFn = (): void => {\n        this.doClose();\n        resolve();\n      };\n    });\n  }\n\n  private doClose(): void {\n    this.connections.forEach((c) => c.disconnect());\n    this.connections.length = 0;\n  }\n\n  private async getConnection(): Promise<ERedis> {\n    if (this.closed) {\n      throw new Error('Connection closed');\n    }\n\n    const r = this.connections.pop();\n    if (r) {\n      this.inUse += 1;\n      return r;\n    }\n    if (this.inUse < this.maxConnections) {\n      this.inUse += 1;\n      const client = new this.RedisStatic(this.url, this.options);\n      await client.connect();\n      return defineAllScripts(client);\n    }\n    return new Promise((resolve): void => {\n      this.queue.push(resolve);\n    });\n  }\n\n  private returnConnection(c: ERedis): void {\n    const q = this.queue.shift();\n    if (q) {\n      q(c);\n    } else {\n      this.inUse -= 1;\n      this.connections.push(c);\n      if (this.inUse === 0) {\n        this.closingFn?.();\n      }\n    }\n  }\n}\n","import RedisCollection from './RedisCollection';\nimport type { DBKeys } from '../interfaces/DB';\nimport BaseDB from '../interfaces/BaseDB';\nimport type { IDable } from '../interfaces/IDable';\nimport RedisConnectionPool from './RedisConnectionPool';\n\nexport default class RedisDb extends BaseDB {\n  private constructor(\n    private readonly pool: RedisConnectionPool,\n  ) {\n    super((name, keys) => new RedisCollection(this.pool, name, keys));\n  }\n\n  public static async connect(url: string): Promise<RedisDb> {\n    const { default: RedisStatic } = await import('ioredis');\n    const connectionPoolSize = 5;\n    return new RedisDb(new RedisConnectionPool(\n      RedisStatic,\n      url,\n      { lazyConnect: true },\n      connectionPoolSize,\n    ));\n  }\n\n  public getCollection<T extends IDable>(name: string, keys?: DBKeys<T>): RedisCollection<T> {\n    return super.getCollection(name, keys) as RedisCollection<T>;\n  }\n\n  public getConnectionPool(): RedisConnectionPool {\n    return this.pool;\n  }\n\n  protected internalClose(): Promise<void> {\n    return this.pool.close();\n  }\n}\n","export function quoteHValue(v: string): string {\n  return `\"${v.replace(/([\"\\\\])/g, '\\\\$1')}\"`;\n}\n\nexport function encodeHStore(record: Record<string, string>): string {\n  const result: string[] = [];\n  Object.keys(record).forEach((k) => {\n    result.push(`${quoteHValue(k)}=>${quoteHValue(record[k])}`);\n  });\n  return result.join(',');\n}\n\nexport function decodeHStore(hstore: string): Record<string, string> {\n  const result: Record<string, string> = {};\n  let current = '';\n  let currentKey = '';\n  let quote = false;\n  for (let p = 0; p < hstore.length;) {\n    const c = hstore[p];\n    switch (c) {\n      case ' ':\n      case '\\r':\n      case '\\n':\n      case '\\t':\n        if (quote) {\n          current += c;\n        }\n        break;\n      case '\\\\':\n        current += hstore[p + 1];\n        p += 1;\n        break;\n      case '\"':\n        quote = !quote;\n        break;\n      case '=':\n        if (quote) {\n          current += c;\n        } else if (hstore[p + 1] === '>') {\n          currentKey = current;\n          current = '';\n          p += 1;\n        }\n        break;\n      case ',':\n        if (quote) {\n          current += c;\n        } else {\n          result[currentKey] = current;\n          currentKey = '';\n          current = '';\n        }\n        break;\n      default:\n        current += c;\n        break;\n    }\n    p += 1;\n  }\n  if (currentKey) {\n    result[currentKey] = current;\n  }\n  return result;\n}\n","const DQUOTE_REG = /\"/g;\nexport function quoteIdentifier(msg: string): string {\n  return `\"${msg.replace(DQUOTE_REG, '\"\"')}\"`;\n}\n\nconst SQUOTE_REG = /'/g;\nexport function quoteValue(msg: string): string {\n  // only used for creating indices,\n  // because prepared statements do not support CREATE\n  return `'${msg.replace(SQUOTE_REG, '\\'\\'')}'`;\n}\n\nconst ID_REG = /\\$[A-Z]/g;\nexport function withIdentifiers(\n  base: string,\n  identifiers: Record<string, string>,\n): string {\n  return base.replace(\n    ID_REG,\n    (v) => quoteIdentifier(identifiers[v.substr(1)]),\n  );\n}\n","import type { Pool as PgPoolT, QueryArrayResult as PgQueryArrayResultT } from 'pg';\nimport type { IDable } from '../interfaces/IDable';\nimport BaseCollection from '../interfaces/BaseCollection';\nimport type { DBKeys } from '../interfaces/DB';\nimport type { StateRef } from '../interfaces/BaseDB';\nimport { serialiseValue, deserialiseValue, serialiseRecord } from '../helpers/serialiser';\nimport { encodeHStore, decodeHStore } from './hstore';\nimport { withIdentifiers, quoteValue } from './sql';\n\nconst STATEMENTS = {\n  CREATE_TABLE: [\n    'CREATE TABLE IF NOT EXISTS $T (',\n    'id TEXT NOT NULL PRIMARY KEY,',\n    'data HSTORE NOT NULL',\n    ')',\n  ].join(''),\n\n  GET_INDEX_NAMES: 'SELECT indexname FROM pg_indexes WHERE tablename=$1 AND schemaname=current_schema()',\n\n  CREATE_INDEX: 'CREATE INDEX IF NOT EXISTS $I ON $T USING HASH ((data->$1))',\n  CREATE_UNIQUE_INDEX: 'CREATE UNIQUE INDEX IF NOT EXISTS $I ON $T ((data->$1))',\n  DROP_INDEX: 'DROP INDEX IF EXISTS $I',\n\n  INSERT: 'INSERT INTO $T (id, data) VALUES ($1, $2::hstore)',\n\n  UPDATE: 'UPDATE $T SET data=data||$1::hstore WHERE data->$2=$3 RETURNING id',\n  UPDATE_ID: 'UPDATE $T SET data=data||$1::hstore WHERE id=$2',\n\n  UPSERT_ID: 'INSERT INTO $T (id, data) VALUES ($1, $2::hstore) ON CONFLICT (id) DO UPDATE SET data=$T.data||$2::hstore',\n\n  SELECT_ONE: 'SELECT id, data FROM $T WHERE data->$1=$2 LIMIT 1',\n  SELECT_ALL: 'SELECT id, data FROM $T',\n  SELECT_ALL_BY: 'SELECT id, data FROM $T WHERE data->$1=$2',\n  SELECT_ID: 'SELECT id, data FROM $T WHERE id=$1',\n\n  DELETE: 'DELETE FROM $T WHERE data->$1=$2',\n  DELETE_ID: 'DELETE FROM $T WHERE id=$1',\n};\n\nasync function configureTable(\n  pool: PgPoolT,\n  tableName: string,\n  keys: DBKeys<any> = {},\n): Promise<void> {\n  const c = await pool.connect();\n  try {\n    /* eslint-disable no-await-in-loop */ // client cannot multitask\n\n    await c.query(withIdentifiers(STATEMENTS.CREATE_TABLE, {\n      T: tableName,\n    }));\n\n    const indices = await c.query({\n      rowMode: 'array',\n      text: STATEMENTS.GET_INDEX_NAMES,\n      values: [tableName],\n    });\n    const oldIndexNames = new Set(\n      indices.rows\n        .map((r) => r[0])\n        .filter((i) => (i.startsWith(`${tableName}_i`) || i.startsWith(`${tableName}_u`))),\n    );\n\n    // PostgreSQL does not support prepared statements for CREATE statements,\n    // so we must escape the values manually using quoteValue.\n    const keyEntries = Object.entries(keys);\n    for (let i = 0; i < keyEntries.length; i += 1) {\n      const [k, v] = keyEntries[i];\n      if (v && v.unique) {\n        const name = `${tableName}_u${k}`;\n        if (!oldIndexNames.delete(name)) {\n          await c.query(withIdentifiers(STATEMENTS.CREATE_UNIQUE_INDEX, {\n            T: tableName,\n            I: name,\n          }).replace(/\\$1/g, quoteValue(k)));\n        }\n      } else {\n        const name = `${tableName}_i${k}`;\n        if (!oldIndexNames.delete(name)) {\n          await c.query(withIdentifiers(STATEMENTS.CREATE_INDEX, {\n            T: tableName,\n            I: name,\n          }).replace(/\\$1/g, quoteValue(k)));\n        }\n      }\n    }\n    const indicesToDelete = [...oldIndexNames];\n    for (let i = 0; i < indicesToDelete.length; i += 1) {\n      const idx = indicesToDelete[i];\n      await c.query(withIdentifiers(STATEMENTS.DROP_INDEX, {\n        T: tableName,\n        I: idx,\n      }));\n    }\n\n    /* eslint-enable no-await-in-loop */\n  } finally {\n    c.release();\n  }\n}\n\nfunction toHStore(record: Record<string, unknown>): string {\n  return encodeHStore(serialiseRecord(record));\n}\n\nfunction fromHStore<T>(\n  [id, data]: readonly any[],\n  fields?: readonly string[],\n): T {\n  const rawMap = decodeHStore(data);\n  rawMap.id = id;\n\n  const result: Record<string, unknown> = {};\n\n  if (!fields) {\n    Object.entries(rawMap).forEach(([k, v]) => {\n      result[k] = deserialiseValue(v);\n    });\n    return result as T;\n  }\n\n  fields.forEach((f) => {\n    result[f] = deserialiseValue(rawMap[f]);\n  });\n  return result as T;\n}\n\nexport default class PostgresCollection<T extends IDable> extends BaseCollection<T> {\n  private readonly cachedQueries: Partial<Record<keyof typeof STATEMENTS, string>> = {};\n\n  public constructor(\n    private readonly pool: PgPoolT,\n    private readonly tableName: string,\n    keys: DBKeys<T> = {},\n    private readonly stateRef: StateRef = { closed: false },\n  ) {\n    super(keys);\n\n    this.initAsync(configureTable(pool, tableName, keys));\n  }\n\n  protected async internalAdd({ id, ...rest }: T): Promise<void> {\n    await this.runTableQuery('INSERT', serialiseValue(id), toHStore(rest));\n  }\n\n  protected async internalUpsert(\n    id: T['id'],\n    update: Partial<T>,\n  ): Promise<void> {\n    await this.runTableQuery('UPSERT_ID', serialiseValue(id), toHStore(update));\n  }\n\n  protected async internalUpdate<K extends keyof T & string>(\n    searchAttribute: K,\n    searchValue: T[K],\n    { id, ...rest }: Partial<T>,\n  ): Promise<void> {\n    const sId = serialiseValue(searchValue);\n    const hstore = toHStore(rest);\n\n    if (searchAttribute === 'id') {\n      await this.runTableQuery('UPDATE_ID', hstore, sId);\n    } else {\n      const r = await this.runTableQuery('UPDATE', hstore, searchAttribute, sId);\n      if (id !== undefined && r.rowCount > 0 && r.rows[0][0] !== id) {\n        throw new Error('Cannot update ID');\n      }\n    }\n  }\n\n  protected async internalGet<\n    K extends keyof T & string,\n    F extends readonly (keyof T & string)[]\n  >(\n    searchAttribute: K,\n    searchValue: T[K],\n    returnAttributes?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>> | null> {\n    let raw;\n    if (searchAttribute === 'id') {\n      raw = await this.runTableQuery('SELECT_ID', serialiseValue(searchValue));\n    } else {\n      raw = await this.runTableQuery('SELECT_ONE', searchAttribute, serialiseValue(searchValue));\n    }\n    if (!raw.rowCount) {\n      return null;\n    }\n    return fromHStore<T>(raw.rows[0], returnAttributes);\n  }\n\n  protected async internalGetAll<\n    K extends keyof T & string,\n    F extends readonly (keyof T & string)[]\n  >(\n    searchAttribute?: K,\n    searchValue?: T[K],\n    returnAttributes?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>>[]> {\n    let raw;\n    if (!searchAttribute) {\n      raw = await this.runTableQuery('SELECT_ALL');\n    } else if (searchAttribute === 'id') {\n      raw = await this.runTableQuery('SELECT_ID', serialiseValue(searchValue));\n    } else {\n      raw = await this.runTableQuery('SELECT_ALL_BY', searchAttribute, serialiseValue(searchValue));\n    }\n    return raw.rows.map((v) => fromHStore<T>(v, returnAttributes));\n  }\n\n  protected async internalRemove<K extends keyof T & string>(\n    searchAttribute: K,\n    searchValue: T[K],\n  ): Promise<number> {\n    let raw;\n    if (searchAttribute === 'id') {\n      raw = await this.runTableQuery('DELETE_ID', serialiseValue(searchValue));\n    } else {\n      raw = await this.runTableQuery('DELETE', searchAttribute, serialiseValue(searchValue));\n    }\n    return raw.rowCount;\n  }\n\n  private runTableQuery(\n    queryName: keyof typeof STATEMENTS,\n    ...values: any[]\n  ): Promise<PgQueryArrayResultT<any[]>> {\n    if (this.stateRef.closed) {\n      throw new Error('Connection closed');\n    }\n\n    let cached = this.cachedQueries[queryName];\n    if (!cached) {\n      cached = withIdentifiers(STATEMENTS[queryName], { T: this.tableName });\n      this.cachedQueries[queryName] = cached;\n    }\n\n    return this.pool.query({\n      name: `${this.tableName}_${queryName}`,\n      rowMode: 'array',\n      text: cached,\n      values,\n    });\n  }\n}\n","import type { Pool as PgPoolT } from 'pg';\nimport PostgresCollection from './PostgresCollection';\nimport type { DBKeys } from '../interfaces/DB';\nimport BaseDB from '../interfaces/BaseDB';\nimport type { IDable } from '../interfaces/IDable';\n\nexport default class PostgresDb extends BaseDB {\n  private constructor(\n    private readonly pool: PgPoolT,\n  ) {\n    super((name, keys) => new PostgresCollection(pool, name, keys, this.stateRef));\n  }\n\n  public static async connect(url: string): Promise<PostgresDb> {\n    const { Pool } = await import('pg');\n    const pool = new Pool({ connectionString: url });\n    await pool.query('CREATE EXTENSION IF NOT EXISTS hstore');\n    return new PostgresDb(pool);\n  }\n\n  public getCollection<T extends IDable>(name: string, keys?: DBKeys<T>): PostgresCollection<T> {\n    return super.getCollection(name, keys) as PostgresCollection<T>;\n  }\n\n  public getConnectionPool(): PgPoolT {\n    return this.pool;\n  }\n\n  protected internalClose(): Promise<void> {\n    return this.pool.end();\n  }\n}\n","import type { IDable } from '../interfaces/IDable';\nimport type { Collection, UpdateOptions } from '../interfaces/Collection';\n\nexport type Wrapped<T extends IDable, Fields extends keyof T, FieldStorage> = {\n  [K in keyof T]: K extends 'id' ? T[K] : K extends Fields ? FieldStorage : T[K];\n};\n\nexport interface Wrapper<T extends IDable, K extends keyof T, FieldStorage, CustomData> {\n  wrap: (\n    key: K,\n    value: T[K],\n    processed: CustomData,\n  ) => Promise<FieldStorage> | FieldStorage;\n\n  unwrap: (\n    key: K,\n    value: FieldStorage,\n    processed: CustomData,\n  ) => Promise<T[K]> | T[K];\n\n  preWrap?: (\n    record: Readonly<Partial<T>>,\n  ) => Promise<CustomData> | CustomData;\n\n  preUnwrap?: (\n    record: Readonly<Partial<Wrapped<T, K, FieldStorage>>>,\n  ) => Promise<CustomData> | CustomData;\n\n  preRemove?: (\n    record: Readonly<Pick<Wrapped<T, K, FieldStorage>, 'id'>>,\n  ) => Promise<void> | void;\n}\n\nfunction hasAnyField(\n  value: Record<string, unknown>,\n  fields: readonly string[],\n): boolean {\n  return fields\n    .some((field) => Object.prototype.hasOwnProperty.call(value, field));\n}\n\nexport default class WrappedCollection<\n  T extends IDable,\n  WF extends readonly (keyof Omit<T, 'id'> & string)[],\n  FieldStorage,\n  E,\n  Inner extends Wrapped<T, WF[-1], FieldStorage> = Wrapped<T, WF[-1], FieldStorage>\n> implements Collection<T> {\n  public constructor(\n    private readonly baseCollection: Collection<Inner>,\n    private readonly fields: WF,\n    private readonly wrapper: Wrapper<T, WF[-1], FieldStorage, E>,\n  ) {}\n\n  public async add(entry: T): Promise<void> {\n    return this.baseCollection.add(await this.wrapAll(entry));\n  }\n\n  public async get<\n    K extends keyof T & keyof Inner & string,\n    F extends readonly (keyof T & string)[]\n  >(\n    key: K,\n    value: T[K] & Inner[K],\n    fields?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>> | null> {\n    if (this.fields.includes(key as any)) {\n      throw new Error('Cannot get by wrapped value');\n    }\n    const raw = await this.baseCollection.get(key, value, fields!);\n    return raw ? this.unwrapAll(raw, { [key]: value }) : null;\n  }\n\n  public async getAll<\n    K extends keyof T & keyof Inner & string,\n    F extends readonly (keyof T & string)[]\n  >(\n    key?: K,\n    value?: T[K] & Inner[NonNullable<K>],\n    fields?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>>[]> {\n    if (key !== undefined && this.fields.includes(key as any)) {\n      throw new Error('Cannot get by wrapped value');\n    }\n    const raw = await this.baseCollection.getAll(key!, value!, fields!);\n    const extra = (key !== undefined) ? { [key]: value } : undefined;\n    return Promise.all(raw.map((v) => this.unwrapAll(v, extra)));\n  }\n\n  public async update<K extends keyof T & keyof Inner & string>(\n    key: K,\n    value: T[K] & Inner[K],\n    update: Partial<T>,\n    options?: UpdateOptions,\n  ): Promise<void> {\n    if (this.fields.includes(key as any)) {\n      throw new Error('Cannot update by wrapped value');\n    }\n    const converted = await this.wrapAll(update, { [key]: value });\n    return this.baseCollection.update(key, value, converted, options);\n  }\n\n  public async remove<K extends keyof T & string>(\n    key: K,\n    value: T[K] & Inner[K],\n  ): Promise<number> {\n    if (this.fields.includes(key as any)) {\n      throw new Error('Cannot remove by wrapped value');\n    }\n    if (!this.wrapper.preRemove) {\n      return this.baseCollection.remove(key, value);\n    }\n\n    const items = await this.baseCollection.getAll(key, value, ['id']);\n    await Promise.all(items.map(async (item) => {\n      await this.wrapper.preRemove!(item);\n      await this.baseCollection.remove('id', item.id);\n    }));\n    return items.length;\n  }\n\n  private async wrapAll(\n    v: Readonly<T>,\n    extra?: Record<string, unknown>,\n  ): Promise<Inner>;\n\n  private async wrapAll(\n    v: Readonly<Partial<T>>,\n    extra?: Record<string, unknown>,\n  ): Promise<Partial<Inner>>;\n\n  private async wrapAll(\n    v: Readonly<Partial<T>>,\n    extra?: Record<string, unknown>,\n  ): Promise<Partial<Inner>> {\n    let processed: E;\n    if (this.wrapper.preWrap && hasAnyField(v, this.fields)) {\n      const allFields = extra ? { ...extra, ...v } : v;\n      processed = await this.wrapper.preWrap(allFields);\n    }\n    const converted = { ...v } as any;\n    await Promise.all(this.fields.map(async (k) => {\n      if (Object.prototype.hasOwnProperty.call(v, k)) {\n        converted[k] = await this.wrapper.wrap(k, (v as any)[k], processed);\n      }\n    }));\n    return converted;\n  }\n\n  private async unwrapAll(\n    v: Readonly<Inner>,\n    extra?: Record<string, unknown>,\n  ): Promise<T>;\n\n  private async unwrapAll<K extends keyof T>(\n    v: Readonly<Pick<Inner, K>>,\n    extra?: Record<string, unknown>,\n  ): Promise<Pick<T, K>>;\n\n  private async unwrapAll<K extends keyof T>(\n    v: Readonly<Pick<Inner, K>>,\n    extra?: Record<string, unknown>,\n  ): Promise<Pick<T, K>> {\n    let processed: E;\n    if (this.wrapper.preUnwrap && hasAnyField(v, this.fields)) {\n      const allFields = extra ? { ...extra, ...v } : v;\n      processed = await this.wrapper.preUnwrap(allFields as any);\n    }\n    const converted = { ...v } as any;\n    await Promise.all(this.fields.map(async (k) => {\n      if (Object.prototype.hasOwnProperty.call(v, k)) {\n        converted[k] = await this.wrapper.unwrap(k, (v as any)[k], processed);\n      }\n    }));\n    return converted;\n  }\n}\n","import crypto, { KeyObject } from 'crypto';\nimport type Encryption from './Encryption';\n\nconst ALG = 'aes-256-cbc';\nconst ALG_BUF = Buffer.from(`${ALG}:`, 'utf8');\nconst IV_LEN = 16;\n\nconst nodeEncryptionSync: Encryption<KeyObject, Buffer> = {\n  encrypt: (key: KeyObject, v: Buffer): Buffer => {\n    const iv = crypto.randomBytes(IV_LEN);\n    const cipher = crypto.createCipheriv(ALG, key, iv);\n    const part = cipher.update(v);\n    const final = cipher.final();\n    return Buffer.concat([ALG_BUF, iv, part, final]);\n  },\n\n  decrypt: (key: KeyObject, v: Buffer): Buffer => {\n    if (!v.slice(0, ALG_BUF.length).equals(ALG_BUF)) {\n      throw new Error('Unknown encryption algorithm');\n    }\n\n    const iv = v.slice(ALG_BUF.length, ALG_BUF.length + IV_LEN);\n    const encrypted = v.slice(ALG_BUF.length + IV_LEN);\n\n    const decipher = crypto.createDecipheriv(ALG, key, iv);\n    const part = decipher.update(encrypted);\n    const final = decipher.final();\n\n    return Buffer.concat([part, final]);\n  },\n\n  generateKey: (): KeyObject => crypto\n    .createSecretKey(crypto.randomBytes(32)),\n\n  serialiseKey: (key: KeyObject): Buffer => key.export(),\n\n  deserialiseKey: (data: Buffer): KeyObject => crypto.createSecretKey(data),\n};\n\nexport default nodeEncryptionSync;\n","import type { IDable, IDableBy, IDType } from '../interfaces/IDable';\nimport type { Collection } from '../interfaces/Collection';\nimport LruCache from '../helpers/LruCache';\nimport { serialiseValueBin, deserialiseValueBin } from '../helpers/serialiser';\nimport WrappedCollection, { Wrapped } from './WrappedCollection';\nimport type Encryption from './encryption/Encryption';\nimport nodeEncryptionSync from './encryption/nodeEncryptionSync';\n\nexport interface KeyRecord<ID extends IDType, KeyT> {\n  id: ID;\n  key: KeyT;\n}\n\nexport type Encrypted<T extends IDable, WF extends keyof T> = Wrapped<T, WF, Buffer>;\n\ntype EncryptableKeys<T> = readonly (keyof Omit<T, 'id'> & string)[];\n\ntype Encrypter<ID extends IDType> = <T extends IDableBy<ID>>(\n) => <F extends EncryptableKeys<T>>(\n  fields: F,\n  baseCollection: Collection<Encrypted<T, F[-1]>>,\n) => Collection<T>;\n\n// makeEncrypter provides optional 2-tier function call due to\n// https://github.com/Microsoft/TypeScript/issues/26242\n\nfunction makeEncrypter<ID extends IDType>(\n  wrapper: <T extends IDableBy<ID>, F extends EncryptableKeys<T>>(\n    fields: F,\n    baseCollection: Collection<Encrypted<T, F[-1]>>,\n  ) => Collection<T>,\n): Encrypter<ID> {\n  return (fields?: any, baseCollection?: Collection<any>): any => {\n    if (fields && baseCollection) {\n      // non-typescript API (remove need for extra ())\n      return wrapper(fields, baseCollection) as any;\n    }\n    return wrapper;\n  };\n}\n\nexport interface EncryptionOptions<KeyT = Buffer, SerialisedKeyT = Buffer> {\n  allowRaw?: boolean;\n  encryption?: Encryption<KeyT, SerialisedKeyT>;\n}\n\nexport interface RecordEncryptionOptions {\n  cacheSize?: number;\n}\n\ninterface CustomEncryptionOptions<KeyT, SerialisedKeyT>\n  extends EncryptionOptions<KeyT, SerialisedKeyT> {\n  encryption: Encryption<KeyT, SerialisedKeyT>;\n}\n\nfunction encryptByKey(\n  sKey: Buffer,\n  options?: EncryptionOptions,\n): Encrypter<IDType>;\n\nfunction encryptByKey<KeyT, SerialisedKeyT>(\n  sKey: SerialisedKeyT,\n  options: CustomEncryptionOptions<KeyT, SerialisedKeyT>,\n): Encrypter<IDType>;\n\nfunction encryptByKey<KeyT, SerialisedKeyT>(\n  sKey: SerialisedKeyT,\n  {\n    encryption = nodeEncryptionSync as any,\n    allowRaw = false,\n  }: EncryptionOptions<KeyT, SerialisedKeyT> = {},\n): Encrypter<IDType> {\n  const key = encryption.deserialiseKey(sKey);\n\n  return makeEncrypter(<T extends IDable, F extends EncryptableKeys<T>>(\n    fields: F,\n    baseCollection: Collection<Encrypted<T, F[-1]>>,\n  ) => new WrappedCollection<T, F, Buffer, never>(baseCollection, fields, {\n    wrap: (k, v): Promise<Buffer> | Buffer => encryption.encrypt(key, serialiseValueBin(v)),\n    unwrap: async (k, v): Promise<any> => {\n      if (!(v instanceof Buffer)) {\n        if (allowRaw) {\n          return v; // probably an old record before encryption was added\n        }\n        throw new Error('unencrypted data');\n      }\n      return deserialiseValueBin(await encryption.decrypt(key, v));\n    },\n  }));\n}\n\nfunction encryptByRecord<ID extends IDType>(\n  keyCollection: Collection<KeyRecord<ID, Buffer>>,\n  options?: EncryptionOptions & RecordEncryptionOptions,\n): Encrypter<ID>;\n\nfunction encryptByRecord<ID extends IDType, KeyT, SerialisedKeyT>(\n  keyCollection: Collection<KeyRecord<ID, SerialisedKeyT>>,\n  options: CustomEncryptionOptions<KeyT, SerialisedKeyT> & RecordEncryptionOptions,\n): Encrypter<ID>;\n\nfunction encryptByRecord<ID extends IDType, KeyT, SerialisedKeyT>(\n  keyCollection: Collection<KeyRecord<ID, SerialisedKeyT>>,\n  {\n    encryption = nodeEncryptionSync as any,\n    allowRaw = false,\n    cacheSize = 0,\n  }: EncryptionOptions<KeyT, SerialisedKeyT> & RecordEncryptionOptions = {},\n): Encrypter<ID> {\n  const cache = new LruCache<ID, KeyT>(cacheSize);\n\n  const loadKey = async (\n    generateIfNeeded: boolean,\n    record: { id?: ID },\n  ): Promise<KeyT> => {\n    const { id } = record;\n\n    if (id === undefined) {\n      throw new Error('Must provide ID for encryption');\n    }\n\n    return cache.cachedAsync(id, async () => {\n      const item = await keyCollection.get('id', id, ['key']);\n      if (item) {\n        return encryption.deserialiseKey(item.key);\n      }\n      if (!generateIfNeeded) {\n        throw new Error('No encryption key found for record');\n      }\n      const key = await encryption.generateKey();\n      await keyCollection.add({ id, key: encryption.serialiseKey(key) });\n      return key;\n    });\n  };\n\n  const removeKey = async ({ id }: { id: ID }): Promise<void> => {\n    await keyCollection.remove('id', id);\n    cache.remove(id);\n  };\n\n  // https://github.com/microsoft/TypeScript/issues/39080\n  return makeEncrypter<ID>(<T extends IDableBy<ID>, F extends EncryptableKeys<T>>(\n    fields: F,\n    baseCollection: Collection<Encrypted<T, F[-1]>>,\n  ) => new WrappedCollection<T, F, Buffer, KeyT>(baseCollection, fields, {\n    wrap: (k, v, key): Promise<Buffer> | Buffer => encryption.encrypt(key, serialiseValueBin(v)),\n    unwrap: async (k, v, key): Promise<any> => {\n      if (!(v instanceof Buffer)) {\n        if (allowRaw) {\n          return v; // probably an old record before encryption was added\n        }\n        throw new Error('unencrypted data');\n      }\n      return deserialiseValueBin(await encryption.decrypt(key, v));\n    },\n    preWrap: loadKey.bind(null, true),\n    preUnwrap: loadKey.bind(null, false),\n    preRemove: removeKey,\n  }));\n}\n\nfunction encryptByRecordWithMasterKey<ID extends IDType>(\n  sMasterKey: Buffer,\n  keyCollection: Collection<KeyRecord<ID, Buffer>>,\n  options?: EncryptionOptions & RecordEncryptionOptions,\n): Encrypter<ID>;\n\nfunction encryptByRecordWithMasterKey<ID extends IDType, KeyT, SerialisedKeyT>(\n  sMasterKey: SerialisedKeyT,\n  keyCollection: Collection<KeyRecord<ID, Buffer>>,\n  options: CustomEncryptionOptions<KeyT, SerialisedKeyT> & RecordEncryptionOptions,\n): Encrypter<ID>;\n\nfunction encryptByRecordWithMasterKey<ID extends IDType, KeyT, SerialisedKeyT>(\n  sMasterKey: SerialisedKeyT,\n  keyCollection: Collection<KeyRecord<ID, Buffer>>,\n  options: EncryptionOptions<KeyT, SerialisedKeyT> & RecordEncryptionOptions = {},\n): Encrypter<ID> {\n  const opts = options as CustomEncryptionOptions<KeyT, SerialisedKeyT> & RecordEncryptionOptions;\n  const keyEnc = encryptByKey(sMasterKey, opts);\n  const encKeyCollection = keyEnc<KeyRecord<ID, SerialisedKeyT>>()(\n    ['key'],\n    keyCollection,\n  );\n  return encryptByRecord(encKeyCollection, opts);\n}\n\nexport {\n  encryptByKey,\n  encryptByRecord,\n  encryptByRecordWithMasterKey,\n};\n","import zlib from 'zlib';\nimport { promisify } from 'util';\nimport type { IDable } from '../interfaces/IDable';\nimport type { Collection } from '../interfaces/Collection';\nimport { serialiseValueBin, deserialiseValueBin } from '../helpers/serialiser';\nimport WrappedCollection, { Wrapped } from './WrappedCollection';\n\ntype CompressableKeys<T> = readonly (keyof Omit<T, 'id'> & string)[];\n\nexport type Compressed<T extends IDable, WF extends keyof T> = Wrapped<T, WF, Buffer>;\n\nexport interface CompressOptions {\n  allowRaw?: boolean;\n  allowRawBuffer?: boolean;\n  compressionThresholdBytes?: number;\n}\n\nconst gzipCompress = promisify<Buffer, Buffer>(zlib.gzip);\nconst gzipDecompress = promisify<Buffer, Buffer>(zlib.gunzip);\n\nconst MARK_UNCOMPRESSED = Buffer.of(0);\n\nasync function compressValue(v: unknown, {\n  compressionThresholdBytes = 200,\n}: CompressOptions): Promise<Buffer> {\n  const serialised = serialiseValueBin(v);\n  if (serialised.length >= compressionThresholdBytes) {\n    const gzipped = await gzipCompress(serialised);\n    if (gzipped.length < serialised.length + 1) {\n      return gzipped;\n    }\n  }\n  return Buffer.concat([MARK_UNCOMPRESSED, serialised]);\n}\n\nasync function decompressValue(v: Buffer, {\n  allowRaw = true,\n  allowRawBuffer = false,\n}: CompressOptions): Promise<any> {\n  if (!(v instanceof Buffer)) {\n    if (allowRaw) {\n      return v; // probably an old record before compression was added\n    }\n    throw new Error('unknown compression type');\n  }\n  if (v[0] === 0x1F && v[1] === 0x8B) { // gzip \"magic number\"\n    return deserialiseValueBin(await gzipDecompress(v));\n  }\n  if (v[0] === MARK_UNCOMPRESSED[0]) {\n    return deserialiseValueBin(v.subarray(1));\n  }\n  if (allowRaw && allowRawBuffer) {\n    return v;\n  }\n  throw new Error('unknown compression type');\n}\n\nexport function compress<T extends IDable, F extends CompressableKeys<T>>(\n  fields: F,\n  baseCollection: Collection<Compressed<T, F[-1]>>,\n  options: CompressOptions = {},\n): Collection<T> {\n  return new WrappedCollection<T, F, Buffer, never>(baseCollection, fields, {\n    wrap: (k, v): Promise<Buffer> => compressValue(v, options),\n    unwrap: (k, v): Promise<any> => decompressValue(v, options),\n  });\n}\n","import type { Collection, UpdateOptions } from '../interfaces/Collection';\nimport type { IDable } from '../interfaces/IDable';\n\ntype MigrationFuncs<T, ExtraFetchFields extends readonly (keyof T & string)[]> = {\n  [K in keyof T]?: (\n    stored: T[K] | undefined,\n    record: Readonly<Pick<T, K | ExtraFetchFields[-1]>>,\n  ) => T[K];\n};\n\nclass MigratedCollection<\n  T extends IDable,\n  ExtraFetchFields extends readonly (keyof T & string)[],\n> implements Collection<T> {\n  public constructor(\n    private readonly baseCollection: Collection<T>,\n    private readonly migrations: MigrationFuncs<T, ExtraFetchFields>,\n    private readonly extraFetchFields?: ExtraFetchFields,\n  ) {}\n\n  public async add(entry: T): Promise<void> {\n    return this.baseCollection.add(entry);\n  }\n\n  public async get<\n    K extends keyof T & string,\n    F extends readonly (keyof T & string)[]\n  >(\n    searchAttribute: K,\n    searchValue: T[K],\n    returnAttributes?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>> | null> {\n    const raw = await this.baseCollection.get(\n      searchAttribute,\n      searchValue,\n      this.extendAttributes(returnAttributes)!,\n    );\n    return raw ? this.applyMigration(raw, returnAttributes) : null;\n  }\n\n  public async getAll<\n    K extends keyof T & string,\n    F extends readonly (keyof T & string)[],\n  >(\n    searchAttribute?: K,\n    searchValue?: T[K],\n    returnAttributes?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>>[]> {\n    const raws = await this.baseCollection.getAll(\n      searchAttribute!,\n      searchValue as any,\n      this.extendAttributes(returnAttributes)!,\n    );\n    return raws.map((raw) => this.applyMigration(raw, returnAttributes));\n  }\n\n  public async update<K extends keyof T & string>(\n    searchAttribute: K,\n    searchValue: T[K],\n    update: Partial<T>,\n    options?: UpdateOptions,\n  ): Promise<void> {\n    return this.baseCollection.update(searchAttribute, searchValue, update, options);\n  }\n\n  public async remove<K extends keyof T & string>(\n    searchAttribute: K,\n    searchValue: T[K],\n  ): Promise<number> {\n    return this.baseCollection.remove(searchAttribute, searchValue);\n  }\n\n  private extendAttributes<\n    F extends readonly (keyof T & string)[]\n  >(returnAttributes?: F): readonly (keyof T & string)[] | undefined {\n    if (returnAttributes && this.extraFetchFields) {\n      return [...returnAttributes, ...this.extraFetchFields];\n    }\n    return returnAttributes;\n  }\n\n  private applyMigration<F extends readonly (keyof T & string)[]>(\n    raw: Readonly<Pick<T, ExtraFetchFields[-1] | F[-1]>>,\n    returnAttributes?: F,\n  ): Readonly<Pick<T, F[-1]>> {\n    if (returnAttributes && !returnAttributes.some((attr) => this.migrations[attr])) {\n      return raw;\n    }\n    const result: Pick<T, F[-1]> = { ...raw };\n    const attrs = returnAttributes || Object.keys(this.migrations);\n    attrs.forEach((key: string) => {\n      const attr = key as keyof Pick<T, F[-1]>;\n      const migration = this.migrations[attr];\n      if (migration) {\n        result[attr] = migration(raw[attr], raw);\n      }\n    });\n    return result;\n  }\n}\n\nfunction migrate<T extends IDable>(\n  migrations: MigrationFuncs<T, []>,\n  baseCollection: Collection<T>,\n): Collection<T>;\n\nfunction migrate<\n  T extends IDable,\n  ExtraFetchFields extends readonly (keyof T & string)[],\n>(\n  extraFetchFields: ExtraFetchFields,\n  migrations: MigrationFuncs<T, ExtraFetchFields>,\n  baseCollection: Collection<T>,\n): Collection<T>;\n\nfunction migrate<\n  T extends IDable,\n  ExtraFetchFields extends readonly (keyof T & string)[],\n>(\n  extraFetchFields: MigrationFuncs<T, []> | ExtraFetchFields,\n  migrations: MigrationFuncs<T, ExtraFetchFields> | Collection<T>,\n  baseCollection?: Collection<T>,\n): Collection<T> {\n  if (baseCollection) {\n    return new MigratedCollection(\n      baseCollection,\n      migrations as MigrationFuncs<T, ExtraFetchFields>,\n      extraFetchFields as ExtraFetchFields,\n    );\n  }\n  return new MigratedCollection(\n    migrations as Collection<T>,\n    extraFetchFields as MigrationFuncs<T, []>,\n  );\n}\n\nexport default migrate;\n","import CollectionStorage from './CollectionStorage';\nimport WrappedCollection, { Wrapped } from './wrappers/WrappedCollection';\nimport type Encryption from './wrappers/encryption/Encryption';\nimport {\n  encryptByKey,\n  encryptByRecord,\n  encryptByRecordWithMasterKey,\n  EncryptionOptions,\n  Encrypted,\n} from './wrappers/encrypted';\nimport { compress, Compressed, CompressOptions } from './wrappers/compressed';\nimport migrate from './wrappers/migrated';\nimport type { DB } from './interfaces/DB';\nimport type { Collection } from './interfaces/Collection';\n\nexport type {\n  DB,\n  Collection,\n  Wrapped,\n  Encryption,\n  Encrypted,\n  EncryptionOptions,\n  Compressed,\n  CompressOptions,\n};\n\nexport { default as MemoryDb } from './memory/MemoryDb';\nexport { default as MongoDb } from './mongo/MongoDb';\nexport { default as RedisDb } from './redis/RedisDb';\nexport { default as LruCache } from './helpers/LruCache';\nexport {\n  WrappedCollection,\n  encryptByKey,\n  encryptByRecord,\n  encryptByRecordWithMasterKey,\n  compress,\n  migrate,\n};\nexport {\n  default as nodeEncryptionSync,\n} from './wrappers/encryption/nodeEncryptionSync';\nexport default CollectionStorage;\n","import MemoryDb from './memory/MemoryDb';\nimport MongoDb from './mongo/MongoDb';\nimport DynamoDb from './dynamodb/DynamoDb';\nimport RedisDb from './redis/RedisDb';\nimport PostgresDb from './postgresql/PostgresDb';\nimport type { DB } from './interfaces/DB';\n\nexport default class CollectionStorage {\n  public static async connect(url: string): Promise<DB> {\n    let dbClass;\n    if (url.startsWith('memory')) {\n      dbClass = MemoryDb;\n    } else if (url.startsWith('mongodb')) {\n      dbClass = MongoDb;\n    } else if (url.startsWith('dynamodb')) {\n      dbClass = DynamoDb;\n    } else if (url.startsWith('redis')) {\n      dbClass = RedisDb;\n    } else if (url.startsWith('postgres')) {\n      dbClass = PostgresDb;\n    } else {\n      throw new Error(`Unsupported database connection string: ${url}`);\n    }\n\n    try {\n      return await dbClass.connect(url);\n    } catch (e) {\n      throw new Error(`Failed to connect to database \"${url}\": ${e.message}`);\n    }\n  }\n}\n"],"sourceRoot":""}