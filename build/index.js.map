{"version":3,"sources":["webpack://collection-storage/webpack/universalModuleDefinition","webpack://collection-storage/webpack/bootstrap","webpack://collection-storage/./src/helpers/safeAccess.ts","webpack://collection-storage/./src/interfaces/BaseIndices.ts","webpack://collection-storage/./src/interfaces/BaseCollection.ts","webpack://collection-storage/external \"crypto\"","webpack://collection-storage/./src/helpers/retry.ts","webpack://collection-storage/external \"mongodb\"","webpack://collection-storage/external \"zlib\"","webpack://collection-storage/external \"util\"","webpack://collection-storage/external \"url\"","webpack://collection-storage/external \"https\"","webpack://collection-storage/external \"http\"","webpack://collection-storage/./src/mongo/MongoCollection.ts","webpack://collection-storage/external \"ioredis\"","webpack://collection-storage/external \"pg\"","webpack://collection-storage/./src/helpers/serialiser.ts","webpack://collection-storage/./src/memory/MemoryCollection.ts","webpack://collection-storage/./src/interfaces/BaseDB.ts","webpack://collection-storage/./src/memory/MemoryDb.ts","webpack://collection-storage/./src/mongo/MongoDb.ts","webpack://collection-storage/./src/dynamodb/api/Results.ts","webpack://collection-storage/./src/dynamodb/api/AWSError.ts","webpack://collection-storage/./src/dynamodb/api/DDB.ts","webpack://collection-storage/./src/dynamodb/DynamoCollection.ts","webpack://collection-storage/./src/helpers/PromiseTracker.ts","webpack://collection-storage/./src/helpers/LruCache.ts","webpack://collection-storage/./src/dynamodb/api/AWS.ts","webpack://collection-storage/./src/dynamodb/DynamoDb.ts","webpack://collection-storage/./src/redis/helpers.ts","webpack://collection-storage/./src/redis/RedisCollection.ts","webpack://collection-storage/./src/redis/scripts.ts","webpack://collection-storage/./src/redis/RedisConnectionPool.ts","webpack://collection-storage/./src/redis/RedisDb.ts","webpack://collection-storage/./src/postgresql/hstore.ts","webpack://collection-storage/./src/postgresql/sql.ts","webpack://collection-storage/./src/postgresql/PostgresCollection.ts","webpack://collection-storage/./src/postgresql/PostgresDb.ts","webpack://collection-storage/./src/wrappers/WrappedCollection.ts","webpack://collection-storage/./src/wrappers/encryption/nodeEncryptionSync.ts","webpack://collection-storage/./src/wrappers/cached.ts","webpack://collection-storage/./src/wrappers/encrypted.ts","webpack://collection-storage/./src/wrappers/compressed.ts","webpack://collection-storage/./src/wrappers/migrated.ts","webpack://collection-storage/./src/index.ts","webpack://collection-storage/./src/CollectionStorage.ts"],"names":["root","factory","exports","module","define","amd","global","installedModules","__webpack_require__","moduleId","i","l","modules","call","m","c","d","name","getter","o","Object","defineProperty","enumerable","get","r","Symbol","toStringTag","value","t","mode","__esModule","ns","create","key","bind","n","object","property","prototype","hasOwnProperty","p","s","safeAdd","k","configurable","writable","safeGet","makeKeyValue","result","mapEntries","input","map","keyMapper","entries","forEach","v","newKey","BaseIndices","constructor","keys","this","Map","filter","getIndices","getUniqueIndices","unique","getCustomIndices","isIndex","attribute","has","isUniqueIndex","Boolean","BaseCollection","innerPreAct","preAct","indices","entry","internalAdd","searchAttribute","searchValue","returnAttributes","Error","internalGet","internalGetAll","update","options","undefined","id","upsert","withoutId","internalUpsert","some","internalUpdate","internalRemove","wait","pending","addPending","Promise","resolve","reject","push","internalReady","async","e","f","require","sleep","millis","setTimeout","shouldRetry","timeoutMillis","initialDelayMillis","maxDelayMillis","delayGrowth","jitter","limit","Date","now","currentDelay","attempt","fn","delay","Math","min","random","message","DOT_REG","fieldNameToMongo","encodeURIComponent","replace","fieldNameFromMongo","decodeURIComponent","isBson","_bsontype","valueToMongo","Buffer","MBinary","valueFromMongo","buffer","MONGO_ERROR_IDX","withUpsertRetry","retry","MongoError","code","exec","getErrorIndex","convertToMongo","convertFromMongo","makeMongoSearch","$eq","makeMongoProjection","names","projection","fieldName","configureCollection","collection","existing","indexes","catch","idxToCreate","idxToDelete","Set","idx","delete","keyName","makeIndex","index","match","find","a","b","length","every","aVal","indicesMatch","createIndexes","size","all","idxName","dropIndex","MongoCollection","stateRef","closed","super","initAsync","insertOne","updateOne","$set","query","mongoUpdate","updateMany","includes","findOne","cursor","raw","deleteMany","deletedCount","MARK_BINARY","charCodeAt","MARK_STRING","MARK_BINARY_BUFF","Uint8Array","of","serialiseValue","toString","JSON","stringify","deserialiseValue","type","data","substr","from","parse","serialiseValueBin","concat","deserialiseValueBin","subarray","serialiseRecord","item","deserialiseRecord","serialised","partialDeserialiseRecord","fields","MemoryCollection","simulatedLatency","customIndexData","uniqueIndexDataPtrs","internalCheckDuplicates","set","internalPopulateIndices","updates","internalGetSerialisedIds","sId","oldSerialised","oldValue","newValue","newSerialised","internalRemoveIndices","sIds","sKey","serialisedValue","checkId","add","BaseDB","makeCollection","getCollection","cached","collectionCache","normKeys","sort","join","cachedNormKeys","cachedCol","created","close","syncClose","toAwait","values","allSettled","then","internalClose","globalDbs","initial","getGlobal","MemoryDb","url","parsedUrl","URL","hostname","params","searchParams","Number","db","MongoDb","client","escapeName","MongoClient","default","connect","useNewUrlParser","useUnifiedTopology","getDb","Paged","aws","pageLimit","POSITIVE_INFINITY","batched","consumer","do","lastKey","page","pageItems","nextKey","items","AWSError","status","isType","endsWith","isTransient","AWS_URL_FORMAT","ifNotEmpty","flatten","escapedExpressions","expressions","attrValues","attrNames","hasExpr","hasAnyValues","attributeExpression","joiner","attributes","parts","Array","isArray","attr","attrName","attrValue","rawAttr","ExpressionAttributeValues","ExpressionAttributeNames","attrs","retryPolling","retryRemaining","INVALID_NAME_CHARS","hex","padStart","padEnd","createAttributeDefinitions","schemas","attributeName","attributeType","AttributeName","AttributeType","createSecondaryIndex","IndexName","indexName","KeySchema","keySchema","keyType","KeyType","Projection","ProjectionType","projectionType","nonKeyAttributes","NonKeyAttributes","ProvisionedThroughput","throughput","DDB","host","consistentRead","region","getConsumedUnits","totalCapacityUnits","getTableNames","response","ExclusiveStartTableName","lastTableName","TableNames","LastEvaluatedTableName","upsertTable","tableName","pKeySchema","secondaryIndices","waitForReady","TableName","AttributeDefinitions","GlobalSecondaryIndexes","BillingMode","replaceIndices","waitForTable","describeTable","waitForIndices","desc","Table","TableStatus","IndexStatus","Item","ConditionExpression","ReturnConsumedCapacity","condition","Key","UpdateExpression","requestedAttrs","ProjectionExpression","ConsistentRead","getItem","keyAttrs","fullAttrs","slice","extracted","tableQuery","callBatched","RequestItems","Keys","batchKeys","Responses","UnprocessedKeys","batchPutItems","batchItems","PutRequest","UnprocessedItems","batchDeleteItems","DeleteRequest","getAllItems","ExclusiveStartKey","Items","LastEvaluatedKey","limitOne","colocatedAttrs","nonColocatedAttrs","KeyConditionExpression","Limit","pkItems","batchGetItems","callDelete","deleteAndReturnItem","returnOld","ReturnValues","Attributes","toCreate","oldIndices","old","toDelete","GlobalSecondaryIndexUpdates","Delete","Create","batchLimit","remaining","queue","splice","retryItems","fnName","body","request","method","service","headers","json","ConsumedCapacity","capacity","reduce","CapacityUnits","wrapError","handleError","ignore","toDynamoValue","B","toDynamoItem","isDynamoBinary","fromDynamoValue","fromDynamoItem","toDynamoKey","INDEX_META_KEY","indexTable","toDDBThroughput","ReadCapacityUnits","max","ceil","read","WriteCapacityUnits","write","getCombinedThroughput","throughputFn","totalThroughput","hasThroughput","cur","configureTable","ddb","nonuniqueKeys","uniqueKeys","indexTableName","deleteTable","info","ix","newKeys","oldKeys","SS","indexItems","putItem","DynamoCollection","updateItem","setId","search","getItemsBySecondaryKey","ddbSearchValue","ddbItem","filteredReturn","assign","primaryItem","deleteItem","success","successes","successesOut","failures","reason","runAll","atomicPutUniques","updatedUnique","changedAttrs","PromiseTracker","flightResolve","flight","inflight","finally","current","clear","always","LruCache","flushFn","calc","fresh","storage","remove","peek","next","EMPTY_BUFFER","alloc","ISO_TIME_STRIP","ALGORITHM","withTransientErrorRetry","sha256","hash","createHash","digest","hmac","createHmac","AWS","keyID","secret","baseKey","date","parsedURL","binaryBody","canonicalTime","toISOString","canonicalDate","credentialScope","getKey","canonicalPath","encodeURI","decodeURI","pathname","allHeaders","Host","headerNames","header","toLowerCase","canonicalHeaders","signedHeaders","canonicalRequest","signature","Authorization","fetch","protocol","https","http","req","res","on","chunk","text","statusCode","__type","end","keyCache","kRegion","keyCacheRegion","keyCacheDate","DynamoDb","tableNamePrefix","parsed","username","password","process","env","AWS_ACCESS_KEY_ID","AWS_SECRET_ACCESS_KEY","split","parseInt","getDDB","minifyLuaScript","lines","argNames","combined","ln","trim","RegExp","notUndefined","makeIndexKeys","partialSerialisedValue","prefix","parseItem","field","unwatchAll","unwatch","mapAwaitSync","RedisCollection","pool","keyPrefix","keyPrefixes","keyInfo","nonUniqueKeys","withConnection","runAdd","patchSerialised","retryWithConnection","patch","getUpdatePatch","runUpdates","insertValue","getAndWatchBySerialisedKey","patches","getByKeysKeepWatches","cut","stream","scanStream","makeKey","count","batch","indexedKeys","rawByKeyKeepWatches","pipeline","multi","serialisedId","checkWatch","keyCount","flat","watch","argsList","makeUpdateArgs","results","updateArgs","checkUpdate","chain","updateWithoutCheck","diff","patchUniqueKeys","patchNonUniqueKeys","oldUniqueKeys","oldNonUniqueKeys","serialisedIds","commands","multiExec","hgetall","exists","hmget","keyAddress","smembers","SCRIPT_ADD","FRAG_CHECK_UPDATE","FRAG_UPDATE","SCRIPT_CHECK_UPDATE","SCRIPT_UPDATE_WITHOUT_CHECK","SCRIPT_UPDATE","SCRIPT_REMOVE","withRetry","RedisConnectionPool","RedisStatic","maxConnections","teardown","getConnection","returnConnection","inUse","doClose","closingFn","connections","disconnect","pop","defineCommand","lua","defineAllScripts","q","shift","RedisDb","Command","setReplyTransformer","x","lazyConnect","getConnectionPool","quoteHValue","encodeHStore","record","DQUOTE_REG","SQUOTE_REG","quoteValue","msg","ID_REG","withIdentifiers","base","identifiers","STATEMENTS","CREATE_TABLE","GET_INDEX_NAMES","CREATE_INDEX","CREATE_UNIQUE_INDEX","DROP_INDEX","INSERT","UPDATE","UPDATE_IF_ID","UPDATE_ID","UPSERT_ID","SELECT_ONE","SELECT_ALL","SELECT_ALL_BY","SELECT_ID","DELETE","DELETE_ID","fromHStore","hstore","currentKey","quote","decodeHStore","PostgresCollection","T","rowMode","oldIndexNames","rows","startsWith","keyEntries","I","indicesToDelete","release","runTableQuery","rowCount","queryName","cachedQueries","PostgresDb","Pool","connectionString","hasAnyField","WrappedCollection","baseCollection","wrapper","wrapAll","unwrapAll","getAll","extra","converted","preRemove","processed","preWrap","allFields","wrap","preUnwrap","unwrap","ALG","ALG_BUF","nodeEncryptionSync","encrypt","iv","crypto","randomBytes","cipher","createCipheriv","part","final","decrypt","equals","encrypted","decipher","createDecipheriv","generateKey","createSecretKey","serialiseKey","export","deserialiseKey","appendField","CachedCollection","maxAge","time","cache","removeIndices","storeItem","cacheItem","cachedById","getKeys","allItems","idxKeys","serialisedUpdate","itemKey","populateIndices","removed","partial","sv","idxKey","cachedAsync","isFresh","makeEncrypter","encryptByKey","encryption","allowRaw","encryptByRecord","keyCollection","cacheSize","rawKeyCache","loadKey","generateIfNeeded","serialisedKey","removeKey","encryptByRecordWithMasterKey","sMasterKey","opts","keyEnc","gzipCompress","promisify","zlib","gzip","gzipDecompress","gunzip","MARK_UNCOMPRESSED","compress","compressionThresholdBytes","gzipped","compressValue","allowRawBuffer","decompressValue","MigratedCollection","migrations","extraFetchFields","migratedAttrs","extendAttributes","applyMigration","migration","migrate","CollectionStorage","dbClass"],"mappings":"CAAA,SAA2CA,EAAMC,GAC1B,iBAAZC,SAA0C,iBAAXC,OACxCA,OAAOD,QAAUD,IACQ,mBAAXG,QAAyBA,OAAOC,IAC9CD,OAAO,qBAAsB,GAAIH,GACP,iBAAZC,QACdA,QAAQ,sBAAwBD,IAEhCD,EAAK,sBAAwBC,IAR/B,CASGK,QAAQ,WACX,O,YCTE,IAAIC,EAAmB,GAGvB,SAASC,EAAoBC,GAG5B,GAAGF,EAAiBE,GACnB,OAAOF,EAAiBE,GAAUP,QAGnC,IAAIC,EAASI,EAAiBE,GAAY,CACzCC,EAAGD,EACHE,GAAG,EACHT,QAAS,IAUV,OANAU,EAAQH,GAAUI,KAAKV,EAAOD,QAASC,EAAQA,EAAOD,QAASM,GAG/DL,EAAOQ,GAAI,EAGJR,EAAOD,QA0Df,OArDAM,EAAoBM,EAAIF,EAGxBJ,EAAoBO,EAAIR,EAGxBC,EAAoBQ,EAAI,SAASd,EAASe,EAAMC,GAC3CV,EAAoBW,EAAEjB,EAASe,IAClCG,OAAOC,eAAenB,EAASe,EAAM,CAAEK,YAAY,EAAMC,IAAKL,KAKhEV,EAAoBgB,EAAI,SAAStB,GACX,oBAAXuB,QAA0BA,OAAOC,aAC1CN,OAAOC,eAAenB,EAASuB,OAAOC,YAAa,CAAEC,MAAO,WAE7DP,OAAOC,eAAenB,EAAS,aAAc,CAAEyB,OAAO,KAQvDnB,EAAoBoB,EAAI,SAASD,EAAOE,GAEvC,GADU,EAAPA,IAAUF,EAAQnB,EAAoBmB,IAC/B,EAAPE,EAAU,OAAOF,EACpB,GAAW,EAAPE,GAA8B,iBAAVF,GAAsBA,GAASA,EAAMG,WAAY,OAAOH,EAChF,IAAII,EAAKX,OAAOY,OAAO,MAGvB,GAFAxB,EAAoBgB,EAAEO,GACtBX,OAAOC,eAAeU,EAAI,UAAW,CAAET,YAAY,EAAMK,MAAOA,IACtD,EAAPE,GAA4B,iBAATF,EAAmB,IAAI,IAAIM,KAAON,EAAOnB,EAAoBQ,EAAEe,EAAIE,EAAK,SAASA,GAAO,OAAON,EAAMM,IAAQC,KAAK,KAAMD,IAC9I,OAAOF,GAIRvB,EAAoB2B,EAAI,SAAShC,GAChC,IAAIe,EAASf,GAAUA,EAAO2B,WAC7B,WAAwB,OAAO3B,EAAgB,SAC/C,WAA8B,OAAOA,GAEtC,OADAK,EAAoBQ,EAAEE,EAAQ,IAAKA,GAC5BA,GAIRV,EAAoBW,EAAI,SAASiB,EAAQC,GAAY,OAAOjB,OAAOkB,UAAUC,eAAe1B,KAAKuB,EAAQC,IAGzG7B,EAAoBgC,EAAI,GAIjBhC,EAAoBA,EAAoBiC,EAAI,I,+BClF9C,SAASC,EAAgCvB,EAAiBwB,EAAMhB,GAEjER,EAAEwB,GACJvB,OAAOC,eAAeF,EAAGwB,EAAG,CAC1BhB,QACAiB,cAAc,EACdtB,YAAY,EACZuB,UAAU,IAGZ1B,EAAEwB,GAAKhB,EAUX,SAASmB,EAAQ3B,EAAQwB,GACvB,GAAKvB,OAAOkB,UAAUC,eAAe1B,KAAKM,EAAGwB,GAG7C,OAAOxB,EAAEwB,GAKJ,SAASI,EAAgBd,EAAaN,GAC3C,MAAMqB,EAAS,GAEf,OADAN,EAAQM,EAAQf,EAAKN,GACdqB,EAGF,SAASC,EACdC,EACAC,EACAC,GAEA,MAAMJ,EAAS,GAMf,OALA5B,OAAOiC,QAAQH,GAAOI,QAAQ,EAAEX,EAAGY,MACjC,MAAM5B,EAAQwB,EAAII,GACZC,EAASJ,EAAYA,EAAUT,GAAWA,EAChDD,EAAQM,EAAQQ,EAAQ7B,KAEnBqB,EA9CT,yI,+DCIe,MAAMS,EAGnBC,YAAYC,G,iBAAiB,G,EAAA,U,EAAA,M,sFAC3BC,KAAKD,KAAO,IAAIE,IAAczC,OAAOiC,QAAQM,GAAMG,OAAO,EAAE,CAAEP,KAAOA,IAGhEQ,aACL,MAAO,CAAC,QAASH,KAAKD,KAAKA,QAGtBK,mBACL,MAAO,CAAC,QAAS,IAAIJ,KAAKD,KAAKN,WAAWS,OAAO,EAAE,CAAE3C,KAAOA,aAAX,EAAWA,EAAG8C,QAAQd,IAAI,EAAEhB,KAAOA,IAG/E+B,mBACL,MAAO,IAAIN,KAAKD,KAAKA,QAGhBQ,QAAQC,GACb,MAAsB,OAAdA,GAAsBR,KAAKD,KAAKU,IAAID,GAGvCE,cAAcF,GAAsC,MACzD,OAAOG,QACS,OAAdH,IAAA,UACAR,KAAKD,KAAKpC,IAAI6C,UADd,aACA,EAAgDH,U,sVCzBvC,MAAeO,EAQlBd,YAAYC,GAAiB,qFACrCC,KAAKa,YAAcb,KAAKc,OAAOxC,KAAK0B,MACpCA,KAAKe,QAAU,IAAIlB,EAAYE,GAGjC,UAAiBiB,GAEf,aADMhB,KAAKa,cACJb,KAAKiB,YAAYD,GAG1B,UAIEE,EACAC,EACAC,GAEA,IAAKpB,KAAKe,QAAQR,QAAQW,GACxB,MAAM,IAAIG,MAAO,gBAAeH,GAGlC,aADMlB,KAAKa,cACJb,KAAKsB,YAAYJ,EAAiBC,EAAaC,GAGxD,aAIEF,EACAC,EACAC,GAEA,GAAIF,IAAoBlB,KAAKe,QAAQR,QAAQW,GAC3C,MAAM,IAAIG,MAAO,gBAAeH,GAGlC,aADMlB,KAAKa,cACJb,KAAKuB,eAAeL,EAAiBC,EAAaC,GAG3D,aACEF,EACAC,EACAK,EACAC,EAAyB,IAEzB,GAAwB,OAApBP,QAA0CQ,IAAdF,EAAOG,IAAoBH,EAAOG,KAAOR,EACvE,MAAM,IAAIE,MAAM,oBAElB,GAAII,EAAQG,OAAQ,CAClB,GAAwB,OAApBV,EACF,MAAM,IAAIG,MAAO,8BAA6BH,GAEhD,IAAIW,EAAYL,EAMhB,OALIhE,OAAOkB,UAAUC,eAAe1B,KAAKuE,EAAQ,QAC/CK,E,+VAAY,CAAH,GAAQL,UACVK,EAAUF,UAEb3B,KAAKa,cACJb,KAAK8B,eAAeX,EAAwBU,EAAWJ,GAEhE,IAAKzB,KAAKe,QAAQR,QAAQW,GACxB,MAAM,IAAIG,MAAO,gBAAeH,GAElC,IACGlB,KAAKe,QAAQL,cAAcQ,IAC5B1D,OAAOuC,KAAKyB,GAAQO,KAAMhD,GAAMiB,KAAKe,QAAQL,cAAc3B,IAE3D,MAAM,IAAIsC,MAAM,aAIlB,aADMrB,KAAKa,cACJb,KAAKgC,eAAed,EAAiBC,EAAaK,EAAQC,GAGnE,aACEP,EACAC,GAEA,IAAKnB,KAAKe,QAAQR,QAAQW,GACxB,MAAM,IAAIG,MAAO,gBAAeH,GAGlC,aADMlB,KAAKa,cACJb,KAAKiC,eAAef,EAAiBC,GAO9C,gBAA0Be,GACxB,MAAMC,EAA8C,GAC9CC,EAAa,IAAqB,IAAIC,QAAQ,CAACC,EAASC,KAC5DJ,EAAQK,KAAK,CAACF,EAASC,MAEzBvC,KAAKyC,cAAgBL,EACrBpC,KAAKa,YAAc6B,gBACXN,IACCpC,KAAKc,UAEd,UACQoB,EACN,MAAOS,GAIP,OAHA3C,KAAKyC,cAAgB,IAAqBJ,QAAQE,OAAOI,GACzD3C,KAAKa,YAAc,KAAc,MAAM8B,QACvCR,EAAQzC,QAASkD,GAAMA,EAAE,GAAGD,IAG9B3C,KAAKyC,mBAAgBf,EACrB1B,KAAKa,YAAcb,KAAKc,OAAOxC,KAAK0B,MACpCmC,EAAQzC,QAASkD,GAAMA,EAAE,MAIjB9B,UAEV,kBAIEI,EACAC,EACAC,GAC0C,MAE1C,wBADkBpB,KAAKuB,eAAeL,EAAiBC,EAAaC,IACzD,UAAX,QAAiB,KAGTU,eACRH,EACAH,EACAC,GAEA,OAAOzB,KAAKgC,eAAe,KAAML,EAAIH,EAAQC,M,cClJjDlF,EAAOD,QAAUuG,QAAQ,W,6BCAzB,SAASC,EAAMC,GACb,OAAO,IAAIV,QAASC,GAAiBU,WAAWV,EAASS,IAG5C,KAACE,GACdC,gBAAgB,IAChBC,qBAAqB,GACrBC,iBAAiB,IACjBC,cAAc,EACdC,UAAS,GACP,KAAOZ,UACT,MAAMa,EAAQC,KAAKC,MAAQP,EAC3B,IAAIQ,EAAeP,EACnB,IAAK,IAAIQ,EAAU,GAAKA,GAAW,EACjC,IAEE,aAAaC,IACb,MAAOjB,GACP,IAAKM,EAAYN,GACf,MAAMA,EAGR,MAAMkB,EACJC,KAAKC,IAAIL,EAAcN,IACtBE,EAASQ,KAAKE,SAAW,GAI5B,GAFAN,GAAgBL,EAEZG,KAAKC,MAAQI,EAAQN,EAEvB,MADAZ,EAAEsB,SAAY,mBAAkBN,cAC1BhB,QAIFG,EAAMe,M,cClClBtH,EAAOD,QAAUuG,QAAQ,Y,cCAzBtG,EAAOD,QAAUuG,QAAQ,S,cCAzBtG,EAAOD,QAAUuG,QAAQ,S,cCAzBtG,EAAOD,QAAUuG,QAAQ,Q,cCAzBtG,EAAOD,QAAUuG,QAAQ,U,cCAzBtG,EAAOD,QAAUuG,QAAQ,S,8DCAzB,+EAcA,MAGMqB,EAAU,MAChB,SAASC,EAAiB9G,GACxB,MAJS,OAILA,EALW,MAQF,cAATA,EAEK,cAEF+G,mBAAmB/G,GAAMgH,QAAQH,EAAS,OAGnD,SAASI,EAAmBjH,GAC1B,MAhBe,QAgBXA,EAfK,KAkBFkH,mBAAmBlH,GAG5B,SAASmH,EAAO7E,GACd,OACEgB,QAAQhB,IACK,iBAANA,GAEPgB,QAAShB,EAAU8E,WAIvB,SAASC,EAAa/E,GACpB,GAAIA,aAAagF,OACf,OAAO,IAAIC,SAAQjF,GAErB,GAAI6E,EAAO7E,GACT,MAAM,IAAI0B,MAAM,0CAElB,OAAO1B,EAGT,SAASkF,EAAelF,GACtB,OAAI6E,EAAO7E,GACFA,EAAEmF,OAEJnF,EAGT,MAAMoF,EAAkB,kCAKxB,MAAMC,EAAkBC,YAAOtC,GAC7BA,aAAauC,cACF,OAAXvC,EAAEwC,MACmB,SAPvB,SAAuBxC,GAAuB,MAC5C,OAAO,UAAAoC,EAAgBK,KAAKzC,EAAEsB,gBAAvB,eAAkC,KAAM,GAM/CoB,CAAc1C,IAGhB,SAAS2C,EACPvH,GAEA,OAAOsB,YAAWtB,EAAO2G,EAAcP,GAGzC,SAASoB,EACPxH,GAEA,OAAKA,EAGEsB,YAAWtB,EAAO8G,EAAgBP,GAFhC,KAKX,SAASkB,EAAgBnH,EAAaN,GACpC,OAAOoB,YAAagF,EAAiB9F,GAAM,CAAEoH,IAAKf,EAAa3G,KAGjE,SAAS2H,EACPC,GAEA,MAAMC,EAAqC,GAK3C,OAJID,IACFC,EAAU,IAAa,EACvBD,EAAMjG,QAASmG,GAAc/G,YAAQ8G,EAAYzB,EAAiB0B,GAAY,KAEzED,EA4BTlD,eAAeoD,EACbC,EACAhG,EAAoB,IAEpB,MAAMiG,QAA+BD,EAAWE,UAAUC,MAAM,IAAM,IAChEC,EAAoC,GACpCC,EAAc,IAAIC,IAAIL,EAASzG,IAAK+G,GAAQA,EAAIjJ,OACtD+I,EAAYG,OAAO,QAEnB/I,OAAOiC,QAAQM,GACZR,IAAI,EAAEiH,EAAS/E,KA7BpB,SAAmB+E,EAAiB/E,EAAsB,IACxD,MAAMpB,EAASM,QAAQc,EAAQpB,QAC/B,MAAO,CACLhC,IAAKc,YAAagF,EAAiBqC,GAAUnG,EAAS,EAAI,UAC1DA,UAyB6BoG,CAAUD,EAAS/E,IAC/C/B,QAASgH,IACR,MAAMC,EAAQX,EAASY,KAAMN,GAvBnC,SAAsBO,EAAuBC,GAC3C,GAAInG,QAAQkG,EAAExG,UAAYM,QAAQmG,EAAEzG,QAClC,OAAO,EAET,MAAMN,EAAOvC,OAAOiC,QAAQoH,EAAExI,KAC9B,OAAIb,OAAOuC,KAAK+G,EAAEzI,KAAK0I,SAAWhH,EAAKgH,QAGhChH,EAAKiH,MAAM,EAAEjI,EAAGkI,KAAWA,IAAS/H,YAAQ4H,EAAEzI,IAAKU,IAejBmI,CAAaZ,EAAKI,IACnDC,EACFP,EAAYG,OAAOI,EAAMtJ,MAEzB8I,EAAY3D,KAAKkE,KAGnBP,EAAYY,cACRhB,EAAWoB,cAAchB,GAE7BC,EAAYgB,YACR/E,QAAQgF,IAAI,IAAIjB,GAAa7G,IAAK+H,GAAYvB,EAAWwB,UAAUD,KAI9D,MAAME,UAA0C5G,IACtDd,YACYiG,EACjBhG,EAAkB,GACD0H,EAAqB,CAAEC,QAAQ,IAEhDC,MAAM5H,GADN,KAHiBgG,aAGjB,KADiB0B,WAGjBzH,KAAK4H,UAAU9B,EAAoBC,EAAYhG,IAGvCe,SACR,GAAId,KAAKyH,SAASC,OAChB,MAAM,IAAIrG,MAAM,qBAIpB,kBAA4BtD,SACpBiC,KAAK+F,WAAW8B,UAAUvC,EAAevH,IAGjD,qBACE4D,EACAH,SAEMwD,EAAgB,IAAMhF,KAAK+F,WAAW+B,UAC1CtC,EAAgB,KAAM7D,GACtB,CAAEoG,KAAMzC,EAAe9D,IACvB,CAAEI,QAAQ,KAId,qBACEV,EACAC,EACAK,GAEA,MAAMwG,EAAQxC,EAAgBtE,EAAiBC,GACzC8G,EAAc,CAAEF,KAAMzC,EAAe9D,IAC3C,IACMxB,KAAKe,QAAQL,cAAcQ,SACvBlB,KAAK+F,WAAW+B,UAAUE,EAAOC,SAEjCjI,KAAK+F,WAAWmC,WAAWF,EAAOC,GAE1C,MAAOtF,GACP,MAAIA,EAAEsB,QAAQkE,SAAS,0CACf,IAAI9G,MAAM,oBAEVsB,GAKZ,kBAIEzB,EACAC,EACAC,GAMA,OAAOmE,QAJWvF,KAAK+F,WAAWqC,QAChC5C,EAAgBtE,EAAiBC,GACjC,CAAEyE,WAAYF,EAAoBtE,MAKtC,qBAIEF,EACAC,EACAC,GAEA,MAAMiH,EAASrI,KAAK+F,WAAWa,KAC7B1F,EAAkBsE,EAAgBtE,EAAiBC,GAAe,GAClE,CAAEyE,WAAYF,EAAoBtE,KAG9BhC,EAA2B,GAGjC,aAFMiJ,EAAO3I,QAAS4I,GAAQlJ,EAAOoD,KAAK+C,EAAoB+C,KAEvDlJ,EAGT,qBACE8B,EACAC,GAKA,aAHqBnB,KAAK+F,WAAWwC,WACnC/C,EAAgBtE,EAAiBC,KAErBqH,cAAgB,K,cCzPlCjM,EAAOD,QAAUuG,QAAQ,Y,cCAzBtG,EAAOD,QAAUuG,QAAQ,O,wjBCUzB,MACM4F,EAAc,IAAIC,WAAW,GAC7BC,EAAc,IAAID,WAAW,GAE7BE,EAAmBC,WAAWC,GAAGL,GAahC,SAASM,EAAehL,GAC7B,OAAIA,aAAiB4G,OACX,IAAG5G,EAAMiL,SAAS,UAEP,iBAAVjL,EACD,IAAGA,EAEQ,kBAAVA,EACFA,EAAQ,IAAM,IAET,OAAVA,EACK,IAED,IAAGkL,KAAKC,UAAUnL,GAGrB,SAASoL,EAAiBpL,GAC/B,MAAMqL,EAAOrL,EAAM,GACbsL,EAAOtL,EAAMuL,OAAO,GAC1B,OAAQF,GACN,IAAK,IAAK,OAAOzE,OAAO4E,KAAKF,EAAM,UACnC,IAAK,IAAK,OAAOA,EACjB,IAAK,IAAK,OAAO,EACjB,IAAK,IAAK,OAAO,EACjB,IAAK,IAAK,OAAO,KACjB,IAAK,IAAK,OAAOJ,KAAKO,MAAMH,GAC5B,QACE,GA5CkB,iBA4CElB,SAASiB,GAC3B,OAAOH,KAAKO,MAAMzL,GAEpB,MAAM,IAAIsD,MAAO,qBAAoB+H,IAIpC,SAASK,EAAkB1L,GAChC,OAAIA,aAAiB4G,OACZA,OAAO+E,OAAO,CAACd,EAAkB7K,IAEnC4G,OAAO4E,KAAKR,EAAehL,GAAQ,QAGrC,SAAS4L,EAAoB5L,GAClC,GAAqB,iBAAVA,EACT,OAAOoL,EAAiBpL,GAG1B,MAAMqL,EAAOrL,EAAM,GACnB,OAAIqL,IAASX,EACJ1K,EAAM6L,SAAS,GAEpBR,IAAST,EACJ5K,EAAM6L,SAAS,GAAGZ,SAAS,QAE7BG,EAAiBpL,EAAMiL,SAAS,SAKlC,SAASa,EAAmBC,GACjC,OAAO,IAAI7J,IAAIzC,OAAOiC,QAAQqK,GAC3BvK,IAAI,EAAER,EAAGY,KAAO,CAACZ,EAAuBgK,EAAepJ,MAGrD,SAASoK,EAAqBC,GACnC,MAAM5K,EAAS,GAEf,OADA4K,EAAWtK,QAAQ,CAACC,EAAGZ,IAAMD,YAAQM,EAAQL,EAAGoK,EAAiBxJ,KAC1DP,EAGF,SAAS6K,EACdD,EACAE,GAEA,IAAKA,EACH,OAAOH,EAAkBC,GAE3B,MAAM5K,EAAS,GAOf,OANA8K,EAAOxK,QAASX,IACd,MAAMuJ,EAAM0B,EAAWrM,IAAIoB,GACvBuJ,GACFxJ,YAAQM,EAAQL,EAAGoK,EAAiBb,MAGjClJ,E,urBCzFM,MAAM+K,UAA2CvJ,IAOvDd,YACLC,EAAkB,GACDqK,EAAmB,EACnB3C,EAAqB,CAAEC,QAAQ,IAEhDC,MAAM5H,GADN,KAFiBqK,mBAEjB,KADiB3C,WACjB,cAVsB,IAAIxH,KAU1B,sEAGAD,KAAKqK,gBAAkB,IAAIpK,IAAID,KAAKe,QAAQT,mBAAmBf,IAAKR,GAAO,CAACA,EAAG,IAAIkB,OAEnFD,KAAKsK,oBAAsBtK,KAAKe,QAAQX,mBACrCF,OAAQnB,GAAa,OAANA,GACfQ,IAAKR,GAAO,CAACA,EAAGiB,KAAKqK,gBAAgB1M,IAAIoB,KAGpC+B,SACR,GAAId,KAAKyH,SAASC,OAChB,MAAM,IAAIrG,MAAM,qBAElB,OAlCJ,SAAe0B,GACb,GAAKA,EAKL,OAAO,IAAIV,QAASC,GAAiBU,WAAWV,EAASS,IA4BhDD,CAAM9C,KAAKoK,kBAGpB,kBAA4BrM,GAC1B,MAAMiM,EAAaH,EAAgB9L,GACnCiC,KAAKuK,wBAAwBP,GAAY,GACzChK,KAAKqJ,KAAKmB,IAAIR,EAAWrM,IAAI,MAAQqM,GACrChK,KAAKyK,wBAAwBT,GAGrBlI,eACRH,EACAH,GAEA,OAAIxB,KAAKqJ,KAAK5I,IAAIsI,EAAepH,IACxB3B,KAAKgC,eAAe,KAAML,EAAIH,GAEhCxB,KAAKiB,YAAL,GAAmBU,MAAOH,IAGnC,qBACEN,EACAC,EACAK,GAEA,MAEMkJ,EAFO1K,KAAK2K,yBAAyBzJ,EAAiBC,GAEvC5B,IAAKqL,IACxB,MAAMC,EAAgB7K,KAAKqJ,KAAK1L,IAAIiN,GAC9BE,EAAWf,EAAkBc,GAC7BE,EAAW,EAAH,KAAQD,GAAatJ,GACnC,GAAIuJ,EAASpJ,KAAOmJ,EAASnJ,GAC3B,MAAM,IAAIN,MAAM,oBAGlB,MAAO,CAAEwJ,gBAAeG,cADFnB,EAAgBkB,MAIxCL,EAAQhL,QAAQ,EAAGmL,mBAAoB7K,KAAKiL,sBAAsBJ,IAClE,IACEH,EAAQhL,QAAQ,EAAGsL,mBAAoBhL,KAAKuK,wBAAwBS,GAAe,IACnF,MAAOrI,GAEP,MADA+H,EAAQhL,QAAQ,EAAGmL,mBAAoB7K,KAAKyK,wBAAwBI,IAC9DlI,EAER+H,EAAQhL,QAAQ,EAAGsL,oBACjBhL,KAAKqJ,KAAKmB,IAAIQ,EAAcrN,IAAI,MAAQqN,GACxChL,KAAKyK,wBAAwBO,KAIjC,qBAIE9J,EACAC,EACAC,GAEA,IAAI8J,EAMJ,OAJEA,EADEhK,EACKlB,KAAK2K,yBAAyBzJ,EAAiBC,GAE/C,IAAInB,KAAKqJ,KAAKtJ,QAEhBmL,EAAK3L,IAAKqL,GAAQX,EAAyBjK,KAAKqJ,KAAK1L,IAAIiN,GAAOxJ,IAGzE,qBACEF,EACAC,GAEA,MAAM+J,EAAOlL,KAAK2K,yBAAyBzJ,EAAiBC,GAO5D,OANA+J,EAAKxL,QAASkL,IACZ,MAAMC,EAAgB7K,KAAKqJ,KAAK1L,IAAIiN,GACpC5K,KAAKiL,sBAAsBJ,GAC3B7K,KAAKqJ,KAAK9C,OAAOqE,KAGZM,EAAKnE,OAGN4D,yBACNzJ,EACAC,GAEA,MAAMgK,EAAOpC,EAAe5H,GAC5B,GAAwB,OAApBD,EACF,OAAOlB,KAAKqJ,KAAK5I,IAAI0K,GAAQ,CAACA,GAAQ,GAExC,MAAMzE,EAAQ1G,KAAKqK,gBAAgB1M,IAAIuD,GACvC,IAAKwF,EACH,MAAM,IAAIrF,MAAO,iBAAgBH,iBAEnC,MAAMgK,EAAOxE,EAAM/I,IAAIwN,GACvB,OAAOD,EAAO,IAAIA,GAAQ,GAGpBX,wBAAwBa,EAAgCC,GAC9D,GAAIA,GAAWrL,KAAKqJ,KAAK5I,IAAI2K,EAAgBzN,IAAI,OAC/C,MAAM,IAAI0D,MAAM,aAElBrB,KAAKsK,oBAAoB5K,QAAQ,EAAErB,EAAKqI,MACtC,GAAIA,EAAMjG,IAAI2K,EAAgBzN,IAAIU,IAChC,MAAM,IAAIgD,MAAM,eAKdoJ,wBAAwBW,GAC9B,MAAMzJ,EAAKyJ,EAAgBzN,IAAI,MAC/BqC,KAAKqK,gBAAgB3K,QAAQ,CAACgH,EAAOrI,KACnC,MAAMsB,EAAIyL,EAAgBzN,IAAIU,GAC9B,IAAId,EAAImJ,EAAM/I,IAAIgC,GACbpC,IACHA,EAAI,IAAI8I,IACRK,EAAM8D,IAAI7K,EAAGpC,IAEfA,EAAE+N,IAAI3J,KAIFsJ,sBAAsBG,GAC5B,MAAMzJ,EAAKyJ,EAAgBzN,IAAI,MAC/BqC,KAAKqK,gBAAgB3K,QAAQ,CAACgH,EAAOrI,KACnC,MAAMsB,EAAIyL,EAAgBzN,IAAIU,GACxBd,EAAImJ,EAAM/I,IAAIgC,GACpBpC,EAAEgJ,OAAO5E,GACJpE,EAAE6J,MACLV,EAAMH,OAAO5G,M,wHClKN,MAAe4L,EAK5BzL,YACmB0L,GAIjB,KAJiBA,iBAIjB,kBATsC,CAAE9D,QAAQ,IAShD,yBAPiC,IAAIzH,KAShCwL,cAAgCpO,EAAc0C,GACnD,MAAM2L,EAAS1L,KAAK2L,gBAAgBhO,IAAIN,GAClCuO,GFXoBrO,EEWKwC,GFHzB,IAJQvC,OAAOuC,KAAKxC,GACzBsO,OACAtM,IAAKR,GAAO,GAAEkK,KAAKC,UAAUnK,MAAMkK,KAAKC,UAAU3L,EAAEwB,OACpD+M,KAAK,QALC,OAFJ,IAAuBvO,EEY1B,GAAImO,EAAQ,CACV,MAAOK,EAAgBC,GAAaN,EACpC,GAAIE,IAAaG,EACf,MAAM,IAAI1K,MAAO,+BAA8BhE,0BAEjD,OAAO2O,EAET,MAAMC,EAAUjM,KAAKwL,eAAenO,EAAM0C,GAE1C,OADAC,KAAK2L,gBAAgBnB,IAAInN,EAAM,CAACuO,EAAUK,IACnCA,EAGTC,QACE,GAAIlM,KAAKyH,SAASC,OAChB,OAEF1H,KAAKmM,YACL,MAAMC,EAAU,IAAIpM,KAAK2L,gBAAgBU,UACtC9M,IAAI,EAAE,CAAEpC,MAAJ,0BAAY,EAAAA,GAA8BsF,qBAA1C,aAAW,YAClB,OAAOJ,QAAQiK,WAAWF,GAASG,KAAK,IAAMvM,KAAKwM,iBAG3CL,YACRnM,KAAKyH,SAASC,QAAS,EAIf8E,kBCvCZ,MAAMC,EAVN,SAAsBpP,EAAcqP,GAClC,MAAM1G,EAAYtJ,OAAeW,GACjC,OAAI2I,IAIHtJ,OAAeW,GAAQqP,EACjBA,GAGSC,CAChB,4BACA,IAAI1M,KAGS,MAAM2M,UAAiBrB,EAC7BzL,aAAY,iBAAEsK,EAAmB,GAAM,IAC5CzC,MAAM,CAACtK,EAAM0C,IAAS,IAAIoK,EAAiBpK,EAAMqK,EAAkBpK,KAAKyH,WAG1E,eAAsBoF,GACpB,MAAMC,EAAY,IAAIC,MAAIF,GACpBxP,EAAOyP,EAAUE,SACvB,GAAI3P,GAAQoP,EAAUhM,IAAIpD,GACxB,OAAOoP,EAAU9O,IAAIN,GAEvB,MAAM4P,EAASH,EAAUI,aACnB9C,EAAmB+C,OAAOF,EAAOtP,IAAI,qBACrCyP,EAAK,IAAIR,EAAS,CAAExC,qBAI1B,OAHI/M,GACFoP,EAAUjC,IAAInN,EAAM+P,GAEfA,EAGF3B,cAAgCpO,EAAc0C,GACnD,OAAO4H,MAAM8D,cAAcpO,EAAM0C,GAG5BmM,QACLlM,KAAKmM,aCpCM,MAAMkB,UAAgB9B,EAC3BzL,YACWwN,EACjB9F,GAEAG,MAAM,CAACtK,EAAM0C,IAAS,IAAIyH,EACxBxH,KAAKsN,OAAOF,KAAKrH,WAVvB,SAAoB1I,GAClB,OAAO+G,mBAAmB/G,GASMkQ,CAAWlQ,IACvC0C,EACAC,KAAKyH,WAJP,KAFiB6F,SAUnB,qBAA4BT,GAC1B,MAAM,YAAEW,SAAsB,QAAN,qBAAa,KAEnCC,QAASjG,SACD,QAAN,qBAAwC,KACtC8F,QAAeE,EAAYE,QAAQb,EAAK,CAC5Cc,iBAAiB,EACjBC,oBAAoB,IAEtB,OAAO,IAAIP,EAAQC,EAAQ9F,GAGtBiE,cAAgCpO,EAAc0C,GACnD,OAAO4H,MAAM8D,cAAcpO,EAAM0C,GAG5B8N,QACL,OAAO7N,KAAKsN,OAAOF,KAGXZ,gBACR,OAAOxM,KAAKsN,OAAOpB,SCnChB,MAAM4B,EACXhO,YACmBiO,EACAnK,EACAoK,EAAYb,OAAOc,mBACpC,KAHiBF,MAGjB,KAFiBnK,KAEjB,KADiBoK,YAGnBE,QAAQC,GACN,OAAOnO,KAAK+N,IAAIK,GAAG1L,UACjB,IAAI2L,EAEJ,IAAK,IAAIC,EAAO,EAAGA,EAAOtO,KAAKgO,UAAWM,GAAQ,EAAG,CACnD,MAAOC,EAAWC,SAA2BxO,KAAK4D,GAAGyK,GAGrD,SAFMF,EAASI,GACfF,EAAUG,GACLH,EACH,OAIJ,MAAM,IAAIhN,MAAM,oBAIpB,YACE,MAAMoN,EAAa,GAInB,aAHMzO,KAAKkO,QAASpR,IAClB2R,EAAMjM,QAAQ1F,KAET2R,GCnCI,MAAMC,UAAiBrN,MACpCvB,YACmB6O,EACAvF,EACjBnF,GAEA0D,MAAO,aAAYgH,YAAiBvF,eAAkBnF,KADtD,KAHiB0K,SAGjB,KAFiBvF,OAMnB,cAAczG,EAAYyG,GACxB,OACGzG,aAAa+L,GAAY/L,EAAEiM,OAAOxF,IAClCzG,aAAatB,OAASsB,EAAEsB,UAAYmF,EAIzCwF,OAAOxF,GACL,OAAOpJ,KAAKoJ,KAAKyF,SAAU,IAAGzF,IAAWpJ,KAAKoJ,OAASA,EAGzD0F,cACE,OACE9O,KAAK2O,QAAU,KACf3O,KAAKoJ,KAAKyF,SAAS,4BACnB7O,KAAKoJ,KAAKyF,SAAS,4CACnB7O,KAAKoJ,KAAKyF,SAAS,0BACnB7O,KAAKoJ,KAAKyF,SAAS,yB,ksBC8FzB,MAAME,EAAiB,yDAIvB,SAASC,EAAqCjS,GAC5C,OAAOA,EAAEgK,OAAShK,OAAI2E,EAGxB,SAASuN,EAAQlR,EAAgBgC,GAE/B,OAAOA,EAAKR,IAAKlB,GAAQ4K,KAAKC,UAAUnL,EAAMM,KAAOyN,OASvD,SAASoD,EACPC,GAEA,IAAIrS,EAAI,EACR,MAAMsS,EAAsB,GACtBC,EAAoC,GAC1C,IAAIC,GAAU,EACVC,GAAe,EACnB,MAAMnQ,EAAkC,GAoCxC,OAlCA5B,OAAOiC,QAAQ0P,GAAazP,QAAQ,EAAErB,GAAOmR,sBAAqBC,SAAQC,kBACxE,MAAMC,EAAkB,GACxB,GAAIC,MAAMC,QAAQH,GAAa,CAC7B,IAAKA,EAAW3I,OACd,OAEF2I,EAAWhQ,QAASoQ,IAClB,MAAMC,EAAY,IAAGjT,EACfkT,EAAa,IAAGlT,EACtB6S,EAAMnN,KAAKgN,EAAoBO,EAAUC,IACzClR,YAAQuQ,EAAWU,EAAUD,GAC7BhT,GAAK,QAEF,CACL,MAAMmT,EAAUzS,OAAOiC,QAAQiQ,GAC/B,IAAKO,EAAQlJ,OACX,OAEFkJ,EAAQvQ,QAAQ,EAAEoQ,EAAM/R,MACtB,MAAMgS,EAAY,IAAGjT,EACfkT,EAAa,IAAGlT,EACtB6S,EAAMnN,KAAKgN,EAAoBO,EAAUC,IACzClR,YAAQuQ,EAAWU,EAAUD,GAC7BhR,YAAQsQ,EAAYY,EAAWjS,GAC/BjB,GAAK,IAEPyS,GAAe,EAIjBnQ,EAAOf,GAAyB,iBAAXoR,EAAsBE,EAAM7D,KAAK2D,GAAUA,EAAOE,GACvEL,GAAU,IAGPA,EAIL,OACKlQ,GADL,IAEE8Q,0BAA2BX,EAAeH,OAAa1N,EACvDyO,yBAA0Bd,IANnB,GAUX,MAAMzJ,EAAcwK,IAAD,CACjBZ,oBAAsBM,GAAiBA,EACvCL,OAAQ,IACRC,WAAYU,GAAS,KAGjBC,EAAepL,YAClBtC,GAAO+L,EAASE,OAAOjM,EA/EQ,8BA+EuC,YAAdA,EAAEsB,QAC3D,CAAEf,cAAe,IAAOE,eAAgB,IAAME,QAAQ,IAElDgN,EAAiBrL,YACpBtC,GAAqB,gCAAdA,EAAEsB,SAGNsM,EAAqB,mBAEpB,SAAShD,EAAWlQ,GAIzB,OAAOA,EAAKgH,QAAQkM,EAAqBpT,IACvC,MACMqT,EADOrT,EAAEuL,WAAW,GACTM,SAAS,IAC1B,OAAIwH,EAAIzJ,QAAU,EACR,KAAIyJ,EAAIC,SAAS,EAAG,KAEtB,KAAID,EAAIC,SAAS,EAAG,OAC3BC,OAAO,EAAG,KAOf,SAASC,EAA2BC,GAClC,MAAMR,EAAQ,IAAInQ,IAQlB,OAPA2Q,EAAQlR,QAASK,GAASA,EAAKL,QAAQ,EAAGmR,gBAAeC,oBACvD,GAAKV,EAAM3P,IAAIoQ,IAER,GAAIT,EAAMzS,IAAIkT,KAAmBC,EACtC,MAAM,IAAIzP,MAAO,mCAAkCwP,QAFnDT,EAAM5F,IAAIqG,EAAeC,MAKtB,IAAIV,EAAM3Q,WAAWF,IAAI,EAAEsR,EAAeC,MAAjB,CAC9BC,cAAeF,EACfG,cAAeF,KAInB,SAASG,EAAqBnU,GAC5B,MAAO,CACLoU,UAAWpU,EAAEqU,UACbC,UAAWtU,EAAEuU,UAAU9R,IAAI,EAAGsR,gBAAeS,cAAlB,CACzBP,cAAeF,EACfU,QAASD,KAEXE,WAAY,CACVC,eAAgB3U,EAAE4U,iBAAmB5U,EAAE6U,iBAAmB,UAAY,aACtEC,iBAAkB9U,EAAE6U,kBAEtBE,sBAAuB/U,EAAEgV,YAI7B,SAAS5K,EAAaL,EAAmCC,GACvD,OAAID,EAAEwK,UAAUtK,SAAWD,EAAEsK,UAAUrK,QAGhCF,EAAEwK,UAAUrK,MAAM,CAACjI,EAAGjC,IAC3BiC,EAAE8R,gBAAkB/J,EAAEsK,UAAUtU,GAAGiU,eACnChS,EAAEuS,UAAYxK,EAAEsK,UAAUtU,GAAGyU,SAI1B,MAAMQ,EAOXjS,YACmBiO,EACAiE,GACjB,eAAEC,GAAiB,GAAsB,IACzC,KAHiBlE,MAGjB,KAFiBiE,OAEjB,oFAN2B,GAO3B,MAAMrC,EAAQZ,EAAe3J,KAAK4M,GAC9BrC,GACF,CAAG3P,KAAKkS,QAAUvC,EAElB3P,KAAKkS,OAAS,YAEhBlS,KAAKiS,eAAiBA,EAGxBE,mBACE,OAAOnS,KAAKoS,mBAGdC,gBAEE,OAAO,IAAIvE,EAAM9N,KAAK+N,IAAKrL,UACzB,MAAM4P,QAAwCtS,KAAK/C,KAAK,aAAc,CACpEsV,wBAAyBC,IAE3B,MAAO,CAACF,EAASG,WAAYH,EAASI,yBACrC,IAGLC,YACEC,EACAC,EACAC,EAAqD,GACrDC,EACAjB,GAGA,OAAO9R,KAAK+N,IAAIK,GAAG1L,UACjB,IAAIuJ,GAAU,EACd,UACQjM,KAAK/C,KAAK,cAAe,CAC7B+V,UAAWJ,EACXK,qBAAsBtC,EAA2B,CAC/CkC,KACGC,EAAiBvT,IAAI,EAAG8R,eAAgBA,KAE7CD,UAAWyB,EAAWtT,IAAI,EAAGsR,gBAAeS,cAAlB,CACxBP,cAAeF,EACfU,QAASD,KAEX4B,uBAAwBlE,EAAW8D,EAAiBvT,IACjDzC,GAAMmU,EAAqBnU,KAE9BqW,YAAarB,EAAa,cAAgB,kBAC1CD,sBAAuBC,IAEzB7F,GAAU,EACV,MAAOtJ,GACP,IAAI+L,EAASE,OAAOjM,EAnNG,0BAsNrB,MAAMA,QAFA3C,KAAKoT,eAAeR,EAAWE,GAUzC,OAJIC,SACI/S,KAAKqT,aAAaT,GAAW,GAG9B3G,IAIXqH,cAAcV,GAEZ,OAAO5S,KAAK/C,KAAK,gBAAiB,CAAE+V,UAAWJ,IAGjDS,aAAaT,EAAmBW,GAC9B,OAAOlD,EAAa3N,UAClB,MAAM8Q,QAAaxT,KAAKsT,cAAcV,GACtC,GAA+B,WAA3BY,EAAKC,MAAMC,YACb,MAAM,IAAIrS,MAAM,WAElB,MAAMN,EAAUyS,EAAKC,MAAMP,uBAC3B,GAAIK,GAAkBxS,GAAWA,EAAQgB,KAAMjF,GAAyB,WAAlBA,EAAE6W,aACtD,MAAM,IAAItS,MAAM,aAKtB,kBAAkBuR,SAEV5S,KAAK/C,KAAK,cAAe,CAAE+V,UAAWJ,IAG9C,cAAcA,EAAmB9I,EAAezJ,SAExCL,KAAK/C,KAAK,UAAV,KACJ+V,UAAWJ,EACXgB,KAAM9J,GACHoF,EAAmB,CACpB2E,oBAAqB,CACnBrE,oBAAsBM,GAAkB,wBAAuBA,KAC/DL,OAAQ,QACRC,WAAYrP,EAAS,CAACA,GAAU,OAPhC,IAUJyT,uBAAwB,WAI5B,iBACElB,EACAvU,EACAmD,EACAuS,SAGM/T,KAAK/C,KAAK,aAAV,KACJ+V,UAAWJ,EACXoB,IAAK3V,GACF6Q,EAAmB,CACpB+E,iBAAkB,CAChBzE,oBAAqB,CAACM,EAAM/R,IAAmB,GAAE+R,KAAQ/R,IACzD0R,OAAS1S,GAAe,OAAMA,EAAE+O,KAAK,KACrC4D,WAAYlO,GAEdqS,oBAAqB,CACnBrE,oBAAqB,CAACM,EAAM/R,IAAmB,GAAE+R,KAAQ/R,IACzD0R,OAAQ,QACRC,WAAYqE,GAAa,OAZzB,IAeJD,uBAAwB,WAI5B,cACElB,EACAvU,EACA6V,GAGA,MAAM7K,QAA6BrJ,KAAK/C,KAAK,UAAV,KACjC+V,UAAWJ,EACXoB,IAAK3V,GACF6Q,EAAmB,CAAEiF,qBAAsBvO,EAAWsO,MAHxB,IAIjCE,eAAgBpU,KAAKiS,eACrB6B,uBAAwB,WAI1B,OAAKzK,EAAKuK,MAASpW,OAAOuC,KAAKsJ,EAAKuK,MAAM7M,OAGnCsC,EAAKuK,KAFH,KAKX,oBACEhB,EACA7S,EACAmU,GAGA,IAAKnU,EAAKgH,OACR,MAAO,GAET,GAAoB,IAAhBhH,EAAKgH,OACP,MAAO,OAAO/G,KAAKqU,QAAQzB,EAAW7S,EAAK,GAAImU,IAGjD,MAAMI,EAAW9W,OAAOuC,KAAKA,EAAK,IAC5BwU,EAAYL,aAAH,EAAGA,EAAgBM,QAC9BD,GACFD,EAAS5U,QAASX,IACXwV,EAAUpM,SAASpJ,IACtBwV,EAAU/R,KAAKzD,KAKrB,MAAMgC,EAAU,IAAId,IACpBF,EAAKL,QAAQ,CAACrB,EAAKvB,IAAMiE,EAAQyJ,IAAIyE,EAAQ5Q,EAAKiW,GAAWxX,IAE7D,MAAM2X,EAAgC1U,EAAKR,IAAI,IAAM,MAC/CmV,EAAa,OACdxF,EAAmB,CAAEiF,qBAAsBvO,EAAW2O,MAD3C,IAEdH,eAAgBpU,KAAKiS,iBAoBvB,aAjBMjS,KAAK2U,YAAY5U,EAAM,IAAK2C,UAAqB,MACrD,MAAM2G,QAAkCrJ,KAAK/C,KAAK,eAAgB,CAChE2X,aAAczV,YAAayT,EAAD,EAAC,KACtB8B,GADqB,IAExBG,KAAMC,KAERhB,uBAAwB,UAQ1B,OANA5U,YAAQmK,EAAK0L,UAAWnC,GAAYlT,QAASoK,IAC3C,MAAMpD,EAAQ3F,EAAQpD,IAAIsR,EAAQnF,EAAMwK,SAC1B5S,IAAVgF,IACF+N,EAAU/N,GAASoD,MAGhB,UAAA5K,YAAQmK,EAAK2L,gBAAiBpC,UAA9B,eAA0CiC,OAAQ,KAGpDJ,EAGTQ,cAAcrC,EAAmBnE,GAE/B,OAAOzO,KAAK2U,YAAYlG,EAAO,GAAI/L,UACjC,MAAM2G,QAAoCrJ,KAAK/C,KAAK,iBAAkB,CACpE2X,aAAczV,YAAayT,EAAWsC,EAAW3V,IAAKuK,IAAD,CACnDqL,WAAY,CAAEvB,KAAM9J,OAEtBgK,uBAAwB,UAE1B,OAAQ5U,YAAQmK,EAAK+L,iBAAkBxC,IAAc,IAAIrT,IAAKzC,GAAMA,EAAEqY,WAAYvB,QAItFyB,iBAAiBzC,EAAmB7S,GAElC,OAAOC,KAAK2U,YAAY5U,EAAM,GAAI2C,UAChC,MAAM2G,QAAoCrJ,KAAK/C,KAAK,iBAAkB,CACpE2X,aAAczV,YAAayT,EAAWkC,EAAUvV,IAAKlB,IAAD,CAClDiX,cAAe,CAAEtB,IAAK3V,OAExByV,uBAAwB,UAE1B,OAAQ5U,YAAQmK,EAAK+L,iBAAkBxC,IAAc,IAAIrT,IAAKzC,GAAMA,EAAEwY,cAAetB,OAIzFuB,YAAY3C,EAAmBsB,GAE7B,MAAMlM,EAAQ,KACZgL,UAAWJ,GACR1D,EAAmB,CAAEiF,qBAAsBvO,EAAWsO,MAFhD,IAGTE,eAAgBpU,KAAKiS,eACrB6B,uBAAwB,UAE1B,OAAO,IAAIhG,EAAM9N,KAAK+N,IAAKrL,UACzB,MAAM4P,QAAkCtS,KAAK/C,KAAK,OAAV,OACnC+K,GADmC,IAEtCwN,kBAAmBnH,KAErB,MAAO,CAACiE,EAASmD,MAAOnD,EAASoD,oBAIrC,6BACE9C,EACAzB,EACA9S,EACA6V,EACAyB,GAGA,MAAMC,EAAiB,CAAC,MAClBC,EAA8B,IACnC3B,GAAkB,IAAIxU,QAASoQ,IACjB,OAATA,IACEtS,OAAOkB,UAAUC,eAAe1B,KAAKoB,EAAKyR,GAC5C8F,EAAepT,KAAKsN,GAEpB+F,EAAkBrT,KAAKsN,MAI7B,MAAM9H,EAAQ,KACZgL,UAAWJ,EACX1B,UAAWC,GACRjC,EAAmB,CACpB4G,uBAAwB,CACtBtG,oBAAqB,CAACM,EAAM/R,IAAmB,GAAE+R,KAAQ/R,IACzD0R,OAAQ,QACRC,WAAYrR,GAEd8V,qBAAsBvO,EAAWgQ,MAT1B,IAWTxB,gBAAgB,EAChBN,uBAAwB,UAE1B,IAAIrF,EACJ,GAAIkH,EAAU,CAKZlH,SAJwCzO,KAAK/C,KAAK,QAAV,OACnC+K,GADmC,IAEtC+N,MAAO,MAEQN,WAEjBhH,QAAc,IAAIX,EAAM9N,KAAK+N,IAAKrL,UAChC,MAAM4P,QAAkCtS,KAAK/C,KAAK,QAAV,OACnC+K,GADmC,IAEtCwN,kBAAmBnH,KAErB,MAAO,CAACiE,EAASmD,MAAOnD,EAASoD,oBAChCrO,MAGL,IAAKoH,EAAM1H,QAAWmN,IAAmB2B,EAAkB9O,OACzD,OAAO0H,EAGT,MAAMuH,QAAgBhW,KAAKiW,cACzBrD,EACAnE,EAAMlP,IAAI,EAAGoC,SAAH,CAAeA,QACzBqN,EAAW6G,IAEb,OAAOpH,EACJlP,IAAI,CAACuK,EAAMhN,IAAOkZ,EAAQlZ,GAAR,OAAmBgN,GAASkM,EAAQlZ,IAAQ,MAC9DoD,OAAQ4J,GAASA,GAGtB,iBAAiB8I,EAAmBvU,SAC5B2B,KAAKkW,WAAWtD,EAAWvU,GAAK,GAGxC8X,oBAAoBvD,EAAmBvU,GACrC,OAAO2B,KAAKkW,WAAWtD,EAAWvU,GAAK,GAGzC,iBAAyBuU,EAAmBvU,EAAc+X,GAexD,aAbwCpW,KAAK/C,KAAK,aAAV,KACtC+V,UAAWJ,EACXoB,IAAK3V,GACF6Q,EAAmB,CACpB2E,oBAAqB,CACnBrE,oBAAsBM,GAAkB,oBAAmBA,KAC3DL,OAAQ,QACRC,WAAY,CAAClS,OAAOuC,KAAK1B,GAAK,QAPI,IAUtCyV,uBAAwB,QACxBuC,aAAcD,EAAY,eAAY1U,MAExB4U,WAGlB,qBACE1D,EACAE,EAAqD,IAGrD,MAAM9M,QAAiBhG,KAAKsT,cAAcV,GACpC7R,EAAU,IAAId,IACdsW,EAA6C,GAC7CC,EAAaxQ,EAASyN,MAAMP,wBAA0B,GAC5D,IAAK,IAAIpW,EAAI,EAAGA,EAAI0Z,EAAWzP,OAAQjK,GAAK,EAAG,CAC7C,MAAMwJ,EAAMkQ,EAAW1Z,GACvBiE,EAAQyJ,IAAIlE,EAAI4K,UAAW5K,GAE7B,IAAK,IAAIxJ,EAAI,EAAGA,EAAIgW,EAAiB/L,OAAQjK,GAAK,EAAG,CACnD,MAAMwJ,EAAMwM,EAAiBhW,GACvB2Z,EAAM1V,EAAQpD,IAAI2I,EAAI6K,WAC5B,GAAIsF,EAAK,CACP,IAAKvP,EAAaZ,EAAKmQ,GACrB,MAAM,IAAIpV,MAAO,2CAA0CiF,EAAI6K,WAEjEpQ,EAAQwF,OAAOD,EAAI6K,gBAEnBoF,EAAS/T,KAAK8D,GAGlB,MAAMoQ,EAAW,IAAI3V,EAAQhB,QAE7B,IAAK,IAAIjD,EAAI,EAAGA,EAAI4Z,EAAS3P,OAAQjK,GAAK,QAClCkD,KAAK/C,KAAK,cAAe,CAC7B+V,UAAWJ,EACX+D,4BAA6B,CAAC,CAC5BC,OAAQ,CAAE1F,UAAWwF,EAAS5Z,cAI5BkD,KAAKqT,aAAaT,GAAW,GAErC,IAAK,IAAI9V,EAAI,EAAGA,EAAIyZ,EAASxP,OAAQjK,GAAK,QAClCkD,KAAK/C,KAAK,cAAe,CAC7B+V,UAAWJ,EACXK,qBAAsBtC,EAA2B,CAAC4F,EAASzZ,GAAGuU,YAC9DsF,4BAA6B,CAAC,CAAEE,OAAQ5F,EAAqBsF,EAASzZ,cAGlEkD,KAAKqT,aAAaT,GAAW,GAK/B+B,YACNlG,EACAqI,EACAlT,GAEA,MAAMmT,EAAYtI,EAAM+F,QACxB,OAAOxU,KAAK+N,IAAIK,GAAG,IAAMkC,EAAe5N,UACtC,MAAMsU,EAAQD,EAAUvC,QAExB,IADAuC,EAAUhQ,OAAS,EACZiQ,EAAMjQ,QAAQ,CACnB,MAAMmO,EAAa8B,EAAMC,OAAO,EAAGH,GAG7BI,QAAmBtT,EAAGsR,GAC5B6B,EAAUvU,QAAQ0U,GAEpB,GAAIH,EAAUhQ,OACZ,MAAM,IAAI1F,MAAM,kCAKtB,WACE8V,EACAC,GAEA,MAeM/N,SAfiBrJ,KAAK+N,IAAIsJ,QAAQ,CACtCC,OAAQ,OACRzK,IAAK7M,KAAKgS,KACVE,OAAQlS,KAAKkS,OACbqF,QAAS,WACTC,QAAS,CACP,eAAgB,6BAChB,eAAiB,qBAAoBL,GAEvCC,UAMoBK,KACtB,GAAIpO,EAAKqO,iBAAkB,CACzB,IAAIC,EAEFA,EADE/H,MAAMC,QAAQxG,EAAKqO,kBACVrO,EAAKqO,iBAAiBE,OAAO,CAAC5Z,EAAGb,IAAOa,EAAImP,OAAOhQ,EAAE0a,eAAiB,GAEtE1K,OAAO9D,EAAKqO,iBAAiBG,eAE1C7X,KAAKoS,oBAAsBuF,EAE7B,OAAOtO,G,urBCjrBX,SAASyO,EAAU1O,EAAcnF,GAC/B,OAAQtB,IACN,MAAM+L,EAASE,OAAOjM,EAAGyG,GAAQ,IAAI/H,MAAM4C,GAAWtB,GAI1D,SAASoV,EACP3O,EACAxF,GAEA,OAAQjB,IACN,GAAI+L,EAASE,OAAOjM,EAAGyG,GACrB,OAAOxF,IAET,MAAMjB,GAIV,MAAMqV,EAAS,OAEf,SAASC,EAAcla,GAKrB,MAAO,CAAEma,EADGzO,EAAkB1L,GACdiL,SAAS,WAG3B,SAASmP,EAAapa,GACpB,OAAOsB,YAAWtB,EAAOka,GAG3B,SAASG,EAAera,GACtB,OAAOP,OAAOkB,UAAUC,eAAe1B,KAAKc,EAAO,KAOrD,SAASsa,EAAgBta,GACvB,GAAIqa,EAAera,GACjB,OAAO4L,EAAoBhF,OAAO4E,KAAKxL,EAAMma,EAAG,WAElD,MAAM,IAAI7W,MAAM,kCAMlB,SAASiX,GAA4Cva,GACnD,OAAKA,EAGEsB,YAAWtB,EAAOsa,GAFhB,KAKX,SAASE,GAAYzI,EAAc/R,GACjC,IAAKqa,EAAera,GAClB,MAAM,IAAIsD,MAAM,kCAElB,MAAO,CACL6W,EAAGvT,OAAO+E,OAAO,CACf/E,OAAO4E,KAAQuG,EAAF,IAAW,QACxBnL,OAAO4E,KAAKxL,EAAMma,EAAG,YACpBlP,SAAS,WAIhB,MAAMwP,GAAiB,CAAEN,EAAGvT,OAAO4E,KAAK,KAAKP,SAAS,WAEhDyP,GAAc7F,GAAiCA,EAAF,IASnD,SAAS8F,GACP5G,GAEA,GAAKA,EAGL,MAAO,CACL6G,kBAAmB7U,KAAK8U,IAAI,EAAG9U,KAAK+U,KAAK/G,EAAWgH,OACpDC,mBAAoBjV,KAAK8U,IAAI,EAAG9U,KAAK+U,KAAK/G,EAAWkH,SAIzD,SAASC,GACPlZ,EACAmZ,GAEA,MAAMC,EAAkB,CAAEL,KAAM,EAAGE,MAAO,GAC1C,IAAII,GAAgB,EASpB,OARArZ,EAAKL,QAASoQ,IACZ,MAAMuJ,EAAMH,aAAH,EAAGA,EAAepJ,GACvBuJ,IACFD,GAAgB,EAChBD,EAAgBL,MAAQO,EAAIP,KAC5BK,EAAgBH,OAASK,EAAIL,SAG1BI,EAAgBD,EAAkB,KAG3CzW,eAAe4W,GACbC,EACA3G,EACA4G,EACAC,EACAP,GAEA,MAAMQ,EAAiBjB,GAAW7F,IAE3B3G,SAAiB5J,QAAQgF,IAAsB,CACpDkS,EAAI5G,YACFC,EACA,CAAC,CAAE/B,cAAe,KAAMC,cAAe,IAAKQ,QAAS,SACrDkI,EAAcja,IAAKuQ,IAAD,CAChBqB,UAAW5D,EAAWuC,GACtBuB,UAAW,CAAC,CAAER,cAAef,EAAMgB,cAAe,IAAKQ,QAAS,SAChEQ,WAAY4G,GAAgBQ,aAAD,EAACA,EAAepJ,QAE7C,EACA4I,GAAgBQ,aAAD,EAACA,EAAe,QAEjCO,EAAW1S,OAASwS,EAAI5G,YACtB+G,EACA,CAAC,CAAE7I,cAAe,KAAMC,cAAe,IAAKQ,QAAS,SACrD,IACA,EACAoH,GAAgBO,GAAsBQ,EAAYP,KAChDK,EAAII,YAAYD,GAAgBxT,MAAM8R,KAG5C,GAAI/L,IAAYwN,EAAW1S,OACzB,OAIF,MAAM6S,QAAaL,EAAIlF,QAAQqF,EAAgB,CAAEG,GAAIrB,IAAkB,CAAC,WAClEsB,EAAU,IAAIzT,IAAIoT,GAClBM,EAAoB,GA9G5B,IAA2Bhc,EAkHzB,GAHI6b,IA/GqB7b,EA+GK6b,EAAKvZ,OA9G5B7C,OAAOkB,UAAUC,eAAe1B,KAAKc,EAAO,QA+GjDgc,EAAQvX,QAAQoX,EAAKvZ,OAAO2Z,GAAG9Z,OAAQ4J,IAAUgQ,EAAQvT,OAAOuD,KAE9DgQ,EAAQ1S,KAAM,CAEhB,MAAMgJ,EAAQ,IAAI0J,SACZP,EAAIhE,YAAY3C,EAAW,CAAC,QAASxC,IAAQlC,QAAQxL,UACzD,MAAMuX,EAAwB,GAQ9B,OAPAxL,EAAM/O,QAASoK,GAASsG,EAAM1Q,QAASoQ,IACrC,MAAM/R,EAAQmB,YAAQ4K,EAAMgG,GAC5B,IAAK/R,EACH,MAAM,IAAIsD,MAAO,iDAAgDyO,MAEnEmK,EAAWzX,KAAK,CAAEqX,GAAItB,GAAYzI,EAAM/R,GAAQ4D,GAAImI,EAAKnI,QAEpD4X,EAAItE,cAAcyE,EAAgBO,UAEtC,IAAKF,EAAQhT,OAClB,aAMIwS,EAAIW,QAAQR,EAAgB,CAAEG,GAAIrB,GAAgBnY,OAAQ,CAAE2Z,GAAIP,KAGzD,MAAMU,WAA2CvZ,IAGvDd,YACYyZ,EACA3G,EACjB7S,EAAkB,GAClBmZ,GAEAvR,MAAM5H,GADN,KAJiBwZ,MAIjB,KAHiB3G,YAGjB,oBAPkD,IAUlD,MAAM4G,EAAsC,GAC5Chc,OAAOiC,QAAQM,GAAML,QAAQ,EAAErB,EAAKoD,MAC9BA,WAASpB,OACXL,KAAKyZ,WAAWjX,KAAKnE,GAErBmb,EAAchX,KAAKnE,KAIvB2B,KAAK4H,UAAU0R,GACbC,EACA3G,EACA4G,EACAxZ,KAAKyZ,WACLP,IAIJ,wBACE,OAAOlZ,KAAK4S,UAGd,6BACE,OAAO6F,GAAWzY,KAAK4S,WAGf3R,YAAYlD,GACpB,OAAOiC,KAAKka,QAAQ/B,EAAapa,IAGzB+D,eACRH,EACAH,GAEA,MAAMsI,EAAOqO,EAAa,GAAExW,MAAOH,IAC7BnD,EAAM,CAAEsD,GAAImI,EAAKnI,IAIvB,cAHOmI,EAAKnI,GAGL3B,KAAKoa,WAAW/b,EAAKyL,EAAMzL,GAAK6H,MAAM6R,EAjPT,kCAqPlC,IAAM/X,KAAKka,QAAL,OAAkB7b,GAAQyL,IAAQ5D,MAAM6R,EAC5C,eAIA,IAAM/X,KAAKoa,WAAW/b,EAAKyL,EAAMzL,GAAK6H,MAAM4R,EA1PZ,kCA8P9B,8BAMR,qBACE5W,EACAC,EACA2I,GAEA,MAAMtI,EAAS2W,EAAarO,GACtBuQ,EAAQvQ,EAAKnI,GAGnB,UAFOH,EAAOG,GAEU,OAApBT,QACIlB,KAAKoa,WACTjC,EAAa,CAAExW,GAAIR,IACnBK,GACA0E,MAAM6R,EAjR0B,kCAiRmBC,QAChD,CACL,MAAMvJ,QAAczO,KAAKuB,eAAeL,EAAiBC,EAAa,CAAC,OACvE,IAAKsN,EAAM1H,OACT,OAEF,GAAIsT,IAAU5L,EAAM1H,OAAS,GAAK0H,EAAM,GAAG9M,KAAO0Y,GAChD,MAAM,IAAIhZ,MAAM,oBAElB,MAAMiZ,EAASnC,EAAahZ,YAAa+B,EAAiBC,UACpDkB,QAAQgF,IAAIoH,EAAMlP,IAAI,EAAGoC,QAAS3B,KAAKoa,WAC3CjC,EAAa,CAAExW,OACfH,EACA8Y,GACApU,MAAM6R,EA/R0B,kCA+RmBC,OAIzD,kBAIE9W,EACAC,EACAC,GAEA,GAAwB,OAApBF,EACF,OAAOoX,SAAqCtY,KAAKuZ,IAAIlF,QACnDrU,KAAK4S,UACLuF,EAAa,CAAExW,GAAIR,IACnBC,IAIJ,IAAKpB,KAAKe,QAAQL,cAAcQ,GAAkB,CAQhD,OAAOoX,UAPgBtY,KAAKuZ,IAAIgB,uBAC9Bva,KAAK4S,UACLrF,EAAWrM,GACXiX,EAAahZ,YAAa+B,EAAiBC,IAC3CC,GACA,IAE6C,IAGjD,MAAMoZ,EAAiBvC,EAAc9W,GAC/B9C,QAAY2B,KAAKuZ,IAAIlF,QACzBoE,GAAWzY,KAAK4S,WAChB,CAAEiH,GAAItB,GAAYrX,EAAiBsZ,IACnC,CAAC,OAEH,IAAKnc,EACH,OAAO,KAET,IAAK+C,EACH,OAAOkX,SAAqCtY,KAAKuZ,IAAIlF,QAAQrU,KAAK4S,UAAWvU,IAE/E,MAAMoc,EAAmB,GACnBC,EAAiB,IAAIrU,IAAIjF,GAO/B,GANIsZ,EAAenU,OAAO,OACxB/I,OAAOmd,OAAOF,EAASpc,GAErBqc,EAAenU,OAAOrF,KACxBuZ,EAAQvZ,GAAmBsZ,GAEzBE,EAAetT,KAAM,CACvB,MAAMwT,QAAoB5a,KAAKuZ,IAAIlF,QAAQrU,KAAK4S,UAAWvU,EAAK,IAAIqc,IACpE,IAAKE,EAGH,OAAO,KAETpd,OAAOmd,OAAOF,EAASG,GAEzB,OAAOtC,GAA+BmC,GAGxC,qBAIEvZ,EACAC,EACAC,GAEA,IAAKF,EAAiB,CAEpB,aADoBlB,KAAKuZ,IAAIhE,YAAYvV,KAAK4S,UAAWxR,GAAkBiG,OAC9D9H,IAAI+Y,IAEnB,GAAItY,KAAKe,QAAQL,cAAcQ,GAAkB,CAC/C,MAAM4I,QAAa9J,KAAKsB,YAAYJ,EAAiBC,EAAcC,GACnE,OAAO0I,EAAO,CAACA,GAAQ,GASzB,aAPoB9J,KAAKuZ,IAAIgB,uBAC3Bva,KAAK4S,UACLrF,EAAWrM,GACXiX,EAAahZ,YAAa+B,EAAiBC,IAC3CC,GACA,IAEW7B,IAAI+Y,IAGnB,qBACEpX,EACAC,GAEA,GAAwB,OAApBD,EAA0B,CAE5B,aADsBlB,KAAK6a,WAAW1C,EAAa,CAAExW,GAAIR,KACxC,EAAI,EAEvB,MAAMsN,QAAczO,KAAKuB,eAAeL,EAAiBC,EAAa,CAAC,OAIvE,aAHwBkB,QAAQgF,IAAIoH,EAAMlP,IAAI,EAAGoC,QAAS3B,KAAK6a,WAC7D1C,EAAa,CAAExW,WAEAzB,OAAQ4a,GAAYA,GAAS/T,OAGhD,uBACEpF,EACAmI,EACA2P,EACA7V,GAEA,IAAK6V,EAAW1S,OAEd,kBADMnD,IAIR,MAAM8V,EAAiBjB,GAAWzY,KAAK4S,WACjCmI,EAAsB,GAC5B,UAlZJrY,eACE2J,EACA2O,EACApX,GAEA,MAIMqX,SAJgB5Y,QAAQiK,WAAWD,EAAO9M,IAAImD,gBAC5CkB,EAAG7F,GACTid,EAAaxY,KAAKzE,OAEKmC,OAAQrB,GAAmB,aAAbA,EAAE8P,QACzC,GAAIsM,EAASlU,OACX,MAAMkU,EAAS,GAAGC,OAwYVC,CAAO1B,EAAYsB,EAAYjL,GAAS9P,KAAKuZ,IAAIW,QACrDR,EACA,CAAEG,GAAItB,GAAYzI,EAAMhG,EAAKgG,IAAQnO,MACrC,MACAuE,MAAM4R,EAzZ0B,kCAyZkB,aAAYhI,WAC1DlM,IACN,MAAOjB,GAKP,YAJM3C,KAAKuZ,IAAIlE,iBACbqE,EACAqB,EAAUxb,IAAKuQ,IAAD,CAAa+J,GAAItB,GAAYzI,EAAMhG,EAAKgG,QACtD5J,MAAM8R,GACFrV,GAIV,cAAsBmH,GACpB,OAAO9J,KAAKob,iBACVtR,EAAKnI,GACLmI,EACA9J,KAAKyZ,WACL,IAAMzZ,KAAKuZ,IAAIW,QACbla,KAAK4S,UACL9I,EACA,MACA5D,MAAM4R,EA7a0B,kCA6aiB,kBAIvD,iBAAyBzZ,EAAcmD,EAAiBuS,GACtD,MAAMsH,EAAgBrb,KAAKyZ,WACxBvZ,OAAQ2G,GAAMrJ,OAAOkB,UAAUC,eAAe1B,KAAKuE,EAAQqF,IAE9D,IAAKwU,EAActU,OAEjB,kBADM/G,KAAKuZ,IAAIa,WAAWpa,KAAK4S,UAAWvU,EAAKmD,EAAQuS,GAGzD,MAAM0C,QAAYzW,KAAKuZ,IAAIlF,QAAQrU,KAAK4S,UAAWvU,EAAKgd,GACxD,IAAK5E,EACH,MAAM,IAAI/H,EAAS,IA3be,kCA2buB,iCAE3D,MAAM4M,EAAeD,EAAcnb,OAAQ2G,GAAO4P,EAAI5P,GAAWqR,IAAO1W,EAAOqF,GAAWqR,SACpFlY,KAAKob,iBACT/c,EAAIsD,GACJH,EACA8Z,EACA,IAAMtb,KAAKuZ,IAAIa,WAAWpa,KAAK4S,UAAWvU,EAAKmD,EAAzC,OAAsDiV,GAAQ1C,WAEhE/T,KAAKuZ,IAAIlE,iBACboD,GAAWzY,KAAK4S,WAChB0I,EAAa/b,IAAKuQ,IAAD,CAAa+J,GAAItB,GAAYzI,EAAM2G,EAAI3G,QAI5D,iBAAyBzR,GACvB,IACE,GAAK2B,KAAKyZ,WAAW1S,OAEd,CACL,MAAM+C,QAAa9J,KAAKuZ,IAAIpD,oBAAoBnW,KAAK4S,UAAWvU,SAC1D2B,KAAKuZ,IAAIlE,iBACboD,GAAWzY,KAAK4S,WAChB5S,KAAKyZ,WAAWla,IAAKuQ,IAAD,CAAa+J,GAAItB,GAAYzI,EAAMhG,EAAKgG,mBALxD9P,KAAKuZ,IAAIsB,WAAW7a,KAAK4S,UAAWvU,GAQ5C,OAAO,EACP,MAAOsE,GACP,GAAI+L,EAASE,OAAOjM,EAvdc,mCAwdhC,OAAO,EAET,MAAMA,I,6DCxeG,MAAM4Y,GAAe,c,YAAA,K,EAAA,W,EACN,IAAIlV,I,6FAEhC+H,GAAMxK,GACJ,IAAI4X,EAAgB,OACpB,MAAMC,EAAS,IAAIpZ,QAASC,IAC1BkZ,EAAgBlZ,IACfiK,KAAK,KACNvM,KAAK0b,SAASnV,OAAOkV,KAGvB,OADAzb,KAAK0b,SAASpQ,IAAImQ,GACX7X,IAAK+X,QAAQH,GAGtB,aACE,MAAMI,EAAU,IAAI5b,KAAK0b,UACzB1b,KAAK0b,SAASG,cACRxZ,QAAQiK,WAAWsP,ICjB7B,MAAME,GAAS,KAAe,EAEf,MAAMC,GAGZjc,YACY6X,EACAqE,G,UACjB,KAFiBrE,WAEjB,KADiBqE,U,EACjB,K,EAAA,U,EALyB,IAAI/b,I,6FAOxByL,OACLrN,EACA4d,EACAC,EAA+BJ,IAE/B,MAAM/d,EAAQiC,KAAKmc,QAAQxe,IAAIU,GAC/B,GAAI2B,KAAKmc,QAAQ5V,OAAOlI,GAAM,OAC5B,GAAI6d,EAAMne,GAER,OADAiC,KAAKmc,QAAQ3R,IAAInM,EAAKN,GACfA,EAET,UAAAiC,KAAKgc,eAAL,cAAAhc,KAAejC,GAEjB,MAAMkO,EAAUgQ,EAAK5d,GAErB,OADA2B,KAAKiB,YAAY5C,EAAK4N,GACfA,EAGT,kBACE5N,EACA4d,EACAC,EAA+BJ,IAE/B,MAAM/d,EAAQiC,KAAKmc,QAAQxe,IAAIU,GAC/B,GAAI2B,KAAKmc,QAAQ5V,OAAOlI,GAAM,OAC5B,GAAI6d,EAAMne,GAER,OADAiC,KAAKmc,QAAQ3R,IAAInM,EAAKN,GACfA,EAET,UAAAiC,KAAKgc,eAAL,cAAAhc,KAAejC,GAEjB,MAAMkO,QAAgBgQ,EAAK5d,GAE3B,OADA2B,KAAKiB,YAAY5C,EAAK4N,GACfA,EAGFX,IAAIjN,EAAQN,GACjBiC,KAAKoc,OAAO/d,GACZ2B,KAAKiB,YAAY5C,EAAKN,GAGjBse,KAAKhe,GACV,OAAO2B,KAAKmc,QAAQxe,IAAIU,GAGnB+d,OAAO/d,GACZ,GAAI2B,KAAKgc,QAAS,CAChB,MAAMje,EAAQiC,KAAKmc,QAAQxe,IAAIU,GAC3B2B,KAAKmc,QAAQ5V,OAAOlI,IACtB2B,KAAKgc,QAAQje,QAGfiC,KAAKmc,QAAQ5V,OAAOlI,GAIjBwd,QACL7b,KAAKmc,QAAQN,QAGP5a,YAAY5C,EAAQN,GAG1B,IAFAiC,KAAKmc,QAAQ3R,IAAInM,EAAKN,GAEfiC,KAAKmc,QAAQ/U,KAAOpH,KAAK2X,UAC9B3X,KAAKoc,OAAOpc,KAAKmc,QAAQpc,OAAOuc,OAAOve,Q,6rBChE7C,MAAMwe,GAAe5X,OAAO6X,MAAM,GAC5BC,GAAiB,kBACjBC,GAAY,mBAEZC,GAA0B1X,YAAOtC,KAASA,aAAa+L,IAAa/L,EAAEmM,eAE5E,SAAS8N,GAAOjd,GACd,MAAMkd,EAAOC,sBAAW,UAExB,OADAD,EAAKrb,OAAO7B,GACLkd,EAAKE,OAAO,OAGrB,SAASC,GAAK3e,EAAagL,GACzB,MAAMwT,EAAOI,sBAAW,SAAU5e,GAElC,OADAwe,EAAKrb,OAAO6H,EAAM,QACXwT,EAAKE,SAuBC,MAAMG,GAanBpd,YAA6Bqd,EAAeC,GAAgB,KAA/BD,QAA+B,iDAV5B,IAAIpB,GAAyB,IAUD,yBAR1B,IAAIA,GAAyB,IAQH,mBANhC,IAAIA,GAAyB,KAMG,mBAJhC,IAAIR,IAI4B,kBAF3C,GAGfvb,KAAKqd,QAAU1Y,OAAO4E,KAAM,OAAM6T,EAAU,QAG9ChP,GAAMxK,GACJ,OAAO5D,KAAK0b,SAAStN,GAAGxK,GAG1ByT,SAAQ,OACNC,EADM,IAENzK,EAFM,OAGNqF,EAHM,QAINqF,EAJM,QAKNC,EAAU,GALJ,KAMNJ,EAAOmF,GAND,KAONe,EAAO,IAAI9Z,OAIX,MAAM+Z,EAAa1Q,aAAeE,IAAOF,EAAM,IAAIE,IAAIF,GACvD,GAAI0Q,EAAUjD,OACZ,MAAM,IAAIjZ,MAAM,iDAElB,GAAIrB,KAAK0H,OACP,MAAM,IAAIrG,MAAM,qBAGlB,IAAImc,EAEFA,EADEpG,aAAgBzS,OACLyS,EACY,iBAATA,EACHzS,OAAO4E,KAAK6N,EAAM,QAElBzS,OAAO4E,KAAKN,KAAKC,UAAUkO,GAAO,QAGjD,MAAMqG,EAAgBH,EAAKI,cAAcrZ,QAAQoY,GAAgB,IAC3DkB,EAAgBF,EAAcnU,OAAO,EAAG,GACxCsU,EAAmB,GAAED,KAAiBzL,KAAUqF,iBAChDlZ,EAAM2B,KAAK6d,OAAOF,EAAezL,EAAQqF,GAGzCuG,EAAgBC,UAAUA,UAAUC,UAAUT,EAAUU,aAAe,IAGvEC,EAAqC,SACtC1G,GADmC,IAEtC2G,KAAMZ,EAAUvL,KAChB,aAAcyL,IAGVW,EAAc5gB,OAAOuC,KAAKme,GAC7B3e,IAAK8e,GAAWA,EAAOC,eACvBzS,OAEG0S,EAAmBH,EACtB7e,IAAK8e,GAAY,GAAEA,KAAUH,EAAWG,QACxCvS,KAAK,IACF0S,EAAgBJ,EAAYtS,KAAK,KAEjC2S,EAAmB,CACvBnH,EACAwG,EAnB2B,GAqB3BS,EACAC,EACA5B,GAAOY,IACP1R,KAAK,MASD4S,EAAY1B,GAAK3e,EAPF,CACnBqe,GACAe,EACAG,EACAhB,GAAOjY,OAAO4E,KAAKkV,EAAkB,UACrC3S,KAAK,OAEmC9C,SAAS,OAUnD,OARAkV,EAAWS,cAAgB,CACxB,GAAEjC,iBAAwB1c,KAAKmd,SAASS,IACxC,iBAAgBY,EAChB,aAAYE,GACb5S,KAAK,aAEAoS,EAAWC,KAEXne,KAAK4e,MAAMrB,EAAWC,EAAY,CACvClG,SACAE,QAAS0G,IAIb,cACMle,KAAK0H,eAGH1H,KAAK0b,SAASxZ,OACpBlC,KAAK0H,QAAS,GAGRkX,MACN/R,EACAuK,EACA3V,GAEA,GAAIzB,KAAK0H,OACP,MAAM,IAAIrG,MAAM,qBAGlB,MAAMwd,EAA6B,UAAjBhS,EAAIgS,SAAwBC,KAAQC,KACtD,OAAO/e,KAAK0b,SAAStN,GAAG,IAAMuO,GAAwB,IAAM,IAAIta,QAAQ,CAACC,EAASC,KAChF,MAAMyc,EAAMH,EAASxH,QAAQxK,EAAKpL,EAAUwd,IAC1C,MAAMtP,EAAkB,GACxBsP,EAAIC,GAAG,OAASC,GAAUxP,EAAMnN,KAAK2c,IACrCF,EAAIC,GAAG,MAAO,KACZ,IACE,MAAME,EAAOza,OAAO+E,OAAOiG,GAAO3G,SAAS,QAC3C2G,EAAM5I,OAAS,EACf,MAAM0Q,EAAOxO,KAAKO,MAAM4V,IACnBH,EAAII,YAAcJ,EAAII,YAAc,IAEvC9c,EAAO,IAAImM,EAASuQ,EAAII,YAAc,EAAG5H,EAAK6H,OAAQ7H,EAAKxT,UAE3D3B,EAAQ,CAAEqM,OAAQsQ,EAAII,WAAY5H,SAEpC,MAAO9U,GACPJ,EAAOI,QAIbqc,EAAIE,GAAG,QAAS3c,GAChByc,EAAIhG,MAAM5B,GACV4H,EAAIO,UAIA1B,OACNF,EACAzL,EACAqF,GAEA,OAAOvX,KAAKwf,SAAS9T,OAAQ,GAAEiS,KAAiBzL,KAAUqF,IAAW,KACnE,MAAMkI,EAAUzf,KAAK0f,eAAehU,OAAQ,GAAEiS,KAAiBzL,IAAU,IAAM8K,GAC7Ehd,KAAK2f,aAAajU,OAAOiS,EAAe,IAAMX,GAAKhd,KAAKqd,QAASM,IACjEzL,IAEF,OAAO8K,GAAKA,GAAKyC,EAASlI,GAAU,mBCpK3B,MAAMqI,WAAiBrU,EAC5BzL,YACWiO,EACAwL,EACjBsG,EACA3G,GAEAvR,MAAM,CAACtK,EAAM0C,IAAS,IAAIoa,GACxBna,KAAKuZ,IACLsG,EAAkBtS,EAAWlQ,GAC7B0C,EACAmZ,aAJoB,EAIpBA,EAAc5a,KAAK,KAAMjB,KAL3B,KAJiB0Q,MAIjB,KAHiBwL,MAYnB,eAAsB1M,EAAaqM,GACjC,MAAM4G,EAAS,IAAI/S,IAAIF,GACvB,IAAIxO,EACA+e,EAQJ,GAPI0C,EAAOC,UACT1hB,EAAMyhB,EAAOC,SACb3C,EAAS0C,EAAOE,WAEhB3hB,EAAM4hB,QAAQC,IAAIC,kBAClB/C,EAAS6C,QAAQC,IAAIE,wBAElB/hB,IAAQ+e,EACX,MAAM,IAAI/b,MAAM,iCAElB,MAAMwd,EAA+C,UAAnCiB,EAAO5S,aAAavP,IAAI,OAAsB,OAAS,QACnEsU,EAAgE,SAA9C6N,EAAO5S,aAAavP,IAAI,kBAC1CkiB,EAAkBC,EAAO7B,SAAS3U,OAAO,GAEzCyE,EAAM,IAAImP,GAAI7e,EAAK+e,GACnB7D,EAAM,IAAIxH,EAAIhE,EAAM,GAAE8Q,OAAciB,EAAO9N,OAAQ,CAAEC,mBAC3D,OAAO,IAAI2N,GACT7R,EACAwL,EACAsG,EACA3G,IAtEoBjM,EAsEa6S,EAAO5S,aAtEQ,CACpD0F,EACAzB,KAEA,IAAIW,EAA4B,KAchC,GAZEA,EADEX,EAEAlE,EAAOtP,IAAK,aAAYiV,WAAmBzB,MAC3ClE,EAAOtP,IAAK,aAAYiV,YACxB3F,EAAOtP,IAAK,aAAYiV,IACxB3F,EAAOtP,IAAI,aAIXsP,EAAOtP,IAAK,aAAYiV,IACxB3F,EAAOtP,IAAI,cAGVmU,GAA6B,MAAfA,EACjB,OAAO,KAET,MAAMnC,EAAQmC,EAAWuO,MAAM,KAC/B,GAAqB,IAAjB1Q,EAAM5I,OACR,MAAM,IAAI1F,MAAO,sCAAqCuR,KAAazB,GAAa,OAAOW,oCAEzF,MAAO,CACLgH,KAAM3L,OAAOmT,SAAS3Q,EAAM,GAAI,IAChCqJ,MAAO7L,OAAOmT,SAAS3Q,EAAM,GAAI,QA3BX1C,MA0EjBxB,cAAgCpO,EAAc0C,GACnD,OAAO4H,MAAM8D,cAAcpO,EAAM0C,GAG5BwgB,SACL,OAAOvgB,KAAKuZ,IAGJ/M,gBACR,OAAOxM,KAAK+N,IAAI7B,SChEb,SAASsU,GACdC,KACGC,GAEH,IAAIC,EAAWF,EAAMlhB,IAAKqhB,GAAOA,EAAGC,QAAQ/U,KAAK,KAIjD,OAHA4U,EAAShhB,QAAQ,CAACrC,EAAMP,KACtB6jB,EAAWA,EAAStc,QAAQ,IAAIyc,OAAQ,MAAKzjB,OAAW,KAAO,QAAOP,EAAI,QAErE6jB,E,yHCdT,MAAMI,GAAmBjX,QAAkCpI,IAAToI,EAElD,SAASkX,GACPjhB,EACAkhB,GAEA,OAAOlhB,EACJG,OAAO,EAAG7B,SAAU4iB,EAAuBxgB,IAAIpC,IAC/CkB,IAAI,EAAGlB,MAAK6iB,YAAc,GAAEA,KAAUD,EAAuBtjB,IAAIU,MAGtE,SAAS8iB,GACPrX,EACAI,GAEA,IAAKJ,EAAK/C,OACR,OAEF,MAAM3H,EAAS,IAAIa,IACnB,GAAIiK,EAEFA,EAAOxK,QAAQ,CAAC0hB,EAAO1a,KACrB,MAAM/G,EAAImK,EAAKpD,GACX/G,GACFP,EAAOoL,IAAI4W,EAAOzhB,UAKtB,IAAK,IAAI7C,EAAI,EAAGA,EAAIgN,EAAK/C,OAAQjK,GAAK,EAAG,CACvC,MAAMskB,EAAQtX,EAAKhN,GACb6C,EAAImK,EAAKhN,EAAI,GACf6C,GACFP,EAAOoL,IAAI4W,EAA6BzhB,GAI9C,OAAOP,EAAOgI,KAAO,EAAIhI,OAASsC,EAGpCgB,eAAe2e,GAAW/T,SAClBA,EAAOgU,UAGf5e,eAAe6e,GACblV,EACAzI,GAEA,MAAMxE,EAAc,GACpB,IAAK,IAAItC,EAAI,EAAGA,EAAIuP,EAAOtF,OAAQjK,GAAK,EAEtCsC,EAAOoD,WAAWoB,EAAGyI,EAAOvP,KAE9B,OAAOsC,EAGM,MAAMoiB,WAA0C5gB,IAOtDd,YACY2hB,EACAP,EACjBnhB,EAAkB,IAElB4H,MAAM5H,GADN,KAHiB0hB,OAGjB,KAFiBP,SAEjB,sBAV6B,IAAIjhB,KAUjC,qBARsC,IAQtC,wBANyC,IASzCD,KAAKe,QAAQT,mBAAmBZ,QAASrB,IACvC,MAAMqjB,EAAa,GAAER,KAAU7iB,IAC/B2B,KAAK2hB,YAAYnX,IAAInM,EAAKqjB,GAC1B,MAAME,EAAU,CAAEvjB,MAAK6iB,OAAQQ,GAC3B1hB,KAAKe,QAAQL,cAAcrC,GAC7B2B,KAAKyZ,WAAWjX,KAAKof,GAErB5hB,KAAK6hB,cAAcrf,KAAKof,KAKpB3gB,YAAYlD,GACpB,MAAMiM,EAAaH,EAAgB9L,GACnC,OAAOiC,KAAKyhB,KAAKK,eAAepf,UAE9B,UADoB1C,KAAK+hB,OAAOzU,EAAQtD,GAAY,GAElD,MAAM,IAAI3I,MAAM,eAKZW,eACRd,EACAC,EACAK,GACA,OAAEI,IAEF,MAAMogB,EAAkBnY,EAAgBrI,GAClC2J,EAAOpC,EAAe5H,GAE5B,MAAwB,OAApBD,EACKlB,KAAKyhB,KAAKQ,oBAAoBvf,UACnC,MAAMwf,QAAcliB,KAAKmiB,eAAe7U,EAAQnC,EAAM6W,GACtD,GAAIE,QACIliB,KAAKoiB,WAAW9U,EAAQ,CAAC4U,SAC1B,GAAItgB,EAAQ,CACjB,MAAMygB,EAAc,IAAIpiB,IAAI+hB,GAAiBxX,IAAI,KAAMW,GACvD,UAAWnL,KAAK+hB,OAAOzU,EAAQ+U,GAAa,GAC1C,MAAM,IAAIhhB,MAAM,eAGnBggB,IAGErhB,KAAKyhB,KAAKQ,oBAAoBvf,UACnC,MAAMwI,QAAalL,KAAKsiB,2BAA2BhV,EAAQpM,EAAiBiK,GAC5E,IAAKD,EAAKnE,OACR,OAEF,GACEvF,EAAOG,IACa,OAApBT,IACCgK,EAAKnE,OAAS,GAAKgC,EAAevH,EAAOG,MAAQuJ,EAAK,IAEvD,MAAM,IAAI7J,MAAM,oBAElB,MAAMkhB,SAAiBhB,GACrBrW,EACCN,GAAQ5K,KAAKmiB,eAAe7U,EAAQ1C,EAAKoX,KACzC9hB,OAAO6gB,UACJ/gB,KAAKoiB,WAAW9U,EAAQiV,IAC7BlB,IAGK/f,YAIRJ,EACAC,EACAC,GAEA,MAAM+J,EAAOpC,EAAe5H,GAC5B,OAAOnB,KAAKyhB,KAAKQ,oBAAoBvf,UAAkB,MACrD,MAAMkI,SAAa5K,KAAKsiB,2BAA2BhV,EAAQpM,EAAiBiK,IAAO,GACnF,QAAYzJ,IAARkJ,EACF,OAAO,KAGT,wBADsB5K,KAAKwiB,qBAAqBlV,EAAQ,CAAC1C,GAAMxJ,IAChD,UAAf,QAAqB,MACpBigB,IAGK9f,eAIRL,EACAC,EACAC,GAEA,GAAIF,EACF,OAAOlB,KAAKyhB,KAAKQ,oBAAoBvf,UACnC,MAAMyI,EAAOpC,EAAe5H,GACtB+J,QAAalL,KAAKsiB,2BAA2BhV,EAAQpM,EAAiBiK,GAC5E,OAAOnL,KAAKwiB,qBAAqBlV,EAAQpC,EAAM9J,IAC9CigB,IAGL,MAAMoB,EAAMziB,KAAKkhB,OAAOna,OAAS,EACjC,OAAO/G,KAAKyhB,KAAKQ,oBAAoBvf,UACnC,MAAMggB,EAASpV,EAAOqV,WAAW,CAAEhc,MAAO3G,KAAK4iB,QAAQ,KAAMC,MAAO,MAC9DzjB,EAA2B,GAEjC,UAAW,MAAM0jB,KAASJ,EAAQ,CAChC,MAAMxX,EAAQ4X,EAAmBvjB,IAAKI,GAAMA,EAAE2J,OAAOmZ,IACrDrjB,EAAOoD,cAAcxC,KAAKwiB,qBAAqBlV,EAAQpC,EAAM9J,IAE/D,OAAOhC,GACNiiB,IAGKpf,eACRf,EACAC,GAEA,MAAMgK,EAAOpC,EAAe5H,GACtB4hB,EAAc/iB,KAAKe,QAAQZ,aAEjC,OAAOH,KAAKyhB,KAAKQ,oBAAoBvf,UACnC,MAAMwI,QAAalL,KAAKsiB,2BAA2BhV,EAAQpM,EAAiBiK,GACtEsD,SAAe8S,GACnBrW,EACCN,GAAQ5K,KAAKgjB,oBAAoB1V,EAAQ1C,EAAKmY,KAC9C7iB,OAAO6gB,IAEV,GAAqB,IAAjBtS,EAAM1H,OACR,OAAO,EAGT,MAAMkc,EAAW3V,EAAO4V,QAcxB,OAbAzU,EAAM/O,QAASoK,IACb,MAAMnI,EAAKmI,EAAKnM,IAAI,MACd8b,EAAauH,GAAchhB,KAAKyZ,WAAY3P,GAC5C+X,EAAgBb,GAAchhB,KAAK6hB,cAAe/X,GACxDmZ,EAAS7G,OACP,EAAI3C,EAAW1S,OAAS8a,EAAc9a,OACtC/G,KAAK4iB,QAAQjhB,MACV8X,KACAoI,EACHlgB,WAGEshB,EAAS7d,OACRqJ,EAAM1H,QACZsa,IAGGuB,QAAQO,GACd,MAAQ,GAAEnjB,KAAKkhB,UAAUiC,IAG3B,aACE7V,EACAtD,EACAoZ,GAEA,MAAMzhB,EAAKqI,EAAWrM,IAAI,MACpB8b,EAAauH,GAAchhB,KAAKyZ,WAAYzP,GAC5C6X,EAAgBb,GAAchhB,KAAK6hB,cAAe7X,GAElDqZ,EAAW,EAAI5J,EAAW1S,OAAS8a,EAAc9a,OACjDkG,EAAS,CACbjN,KAAK4iB,QAAQjhB,MACV8X,KACAoI,EACHpI,EAAW1S,OACX,KACApF,KACG,IAAIqI,EAAWvK,WAAWS,OAAO,EAAEnB,KAAa,OAANA,GAAYukB,QAG3D,IAAKF,EACH,OAAOziB,cAAc2M,EAAOhC,IAAI+X,KAAapW,IAG/C,MAAM7N,QAAekO,EAClB4V,QACA5X,IAAI+X,KAAapW,GACjB7H,OACH,IAAKhG,EACH,MAAM,IAAIiC,MAAM,mBAElB,OAAOV,QAAQvB,EAAO,GAAG,IAG3B,qBACEkO,EACA1C,EACAoX,SAEM1U,EAAOiW,MAAMvjB,KAAK4iB,QAAQhY,IAChC,MAAMC,QAAsB7K,KAAKgjB,oBAC/B1V,EACA1C,EACA5K,KAAKe,QAAQT,mBAAmBJ,OAAQnB,GAAMijB,EAAgBvhB,IAAI1B,KAEpE,IAAK8L,EACH,OAEF,MAAMG,EAAgB,IAAI/K,IAAI+hB,GAO9B,OANAA,EAAgBtiB,QAAQ,CAACnB,EAAGQ,KACtB8L,EAAclN,IAAIoB,KAAOR,IAC3ByM,EAAczE,OAAOxH,GACrB8L,EAActE,OAAOxH,MAGlB,CAAE6L,MAAKI,gBAAeH,iBAG/B,iBACEyC,EACAiV,GAEA,MAAMiB,EAAWjB,EACdhjB,IAAK2iB,GAAUliB,KAAKyjB,eAAevB,IACnChiB,OAAO6gB,IAEV,IAAKyC,EAASzc,OACZ,OAGF,GAAwB,IAApByc,EAASzc,OAAc,CACzB,MAAM2c,QAAgBpW,EAAO4V,QAC1B1hB,OAAOgiB,EAAS,GAAG,GAAIA,EAAS,GAAG,IACnCpe,OAEH,IAAKse,EACH,MAAM,IAAIriB,MAAM,mBAElB,IAAKqiB,EAAQ,GAAG,GACd,MAAM,IAAIriB,MAAM,aAElB,OAOF,UAJiCkgB,GAC/BiC,EACCG,GAAerW,EAAOsW,YAAYD,EAAW,GAAIA,EAAW,MAExC5hB,KAAMnE,IAAOA,GAClC,MAAM,IAAIyD,MAAM,aAGlB,IAAIwiB,EAAQvW,EAAO4V,QACnBM,EAAS9jB,QAASikB,IAChBE,EAAQA,EAAMC,mBAAmBH,EAAW,GAAIA,EAAW,MAI7D,UAFsBE,EAAMze,OAG1B,MAAM,IAAI/D,MAAM,mBAIZoiB,gBACN,IAAE7Y,EAAF,cAAOC,EAAP,cAAsBG,IAEtB,IAAKA,EAAc5D,KACjB,OAEF,MAAM2c,EAAO,IAAI/Y,EAAcvL,WAAW6jB,OACpCU,EAAkBhD,GAAchhB,KAAKyZ,WAAYzO,GACjDiZ,EAAqBjD,GAAchhB,KAAK6hB,cAAe7W,GACvDkZ,EAAgBlD,GAAchhB,KAAKyZ,WAAY5O,GAC/CsZ,EAAmBnD,GAAchhB,KAAK6hB,cAAehX,GAC3D,GACEqZ,EAAcnd,SAAWid,EAAgBjd,QACzCod,EAAiBpd,SAAWkd,EAAmBld,OAE/C,MAAM,IAAI1F,MAAM,0CAclB,MAAO,CAZU,EAA2D,GAAtD2iB,EAAgBjd,OAASkd,EAAmBld,QACnD,CACb/G,KAAK4iB,QAAQhY,MACVoZ,KACAC,KACAC,KACAC,EACHH,EAAgBjd,OAChBid,EAAgBjd,OAASkd,EAAmBld,OAC5C6D,KACGmZ,IAKP,2BACEzW,EACA8W,EACAla,GAEA,MAAMwZ,QD/WHhhB,eACL4K,EACA+W,GAEA,OAAKA,EAAStd,OAGPuG,EAAO4V,MAAMmB,GAAUjf,OAFrB,GC0Wekf,CACpBhX,EACA8W,EACG7kB,IAAKqL,GAAQ5K,KAAK4iB,QAAQhY,IAC1BrL,IAAKR,GAAOmL,EAAS,CAAC,QAASnL,KAAMmL,GAAU,CAAC,UAAWnL,KAEhE,IAAK2kB,EACH,MAAM,IAAIriB,MAAM,mBAElB,OAAOqiB,EACJnkB,IAAI,EAAE,CAAEuK,KAAUqX,GAAarX,EAAMI,IACrChK,OAAO6gB,IACPxhB,IAAIwK,GAGT,0BACEuD,EACA6V,EACAjZ,GAEA,MAAM7L,EAAM2B,KAAK4iB,QAAQO,GACzB,IAAKjZ,EACH,OAAOiX,SAAiB7T,EAAOiX,QAAQlmB,IAEzC,IAAK6L,EAAOnD,OAAQ,CAGlB,aADqBuG,EAAOkX,OAAOnmB,GACnB,IAAI4B,SAAQyB,EAE9B,OAAOyf,SAAgB7T,EAAOmX,MAAMpmB,KAAQ6L,GAASA,GAGvD,iCACEoD,EACA9G,EACA4E,GAEA,GAAgB,OAAZ5E,EACF,MAAO,CAAC4E,GAEV,MAAMsW,EAAY1hB,KAAK2hB,YAAYhkB,IAAI6I,GACvC,IAAKkb,EACH,MAAM,IAAIrgB,MAAO,iBAAgBmF,iBAEnC,MAAMke,EAAc,GAAEhD,KAAatW,IAEnC,aADMkC,EAAOiW,MAAMmB,GACZpX,EAAOqX,SAASD,ICpa3B,MAAME,GAAapE,GAAgB,CACjC,0CACA,aACA,MACA,yCACA,4CACA,eACA,QACA,MACA,6CACA,mBACA,uCACA,MACA,YACC,kBAEGqE,GAAoB,CACxB,yCACA,4CACA,eACA,QACA,OAGIC,GAAc,CAClB,qCACA,6CACA,iBACA,oDACA,OAIIC,GAAsBvE,GAAgB,IACvCqE,GACH,YACC,iBAAkB,gBAAiB,MAGhCG,GAA8BxE,GAAgB,IAC/CsE,IACF,iBAAkB,gBAAiB,MAGhCG,GAAgBzE,GAAgB,IACjCqE,MACAC,GACH,YACC,iBAAkB,gBAAiB,MAGhCI,GAAgB1E,GAAgB,CACpC,4BACA,mBACA,mCACA,OACC,M,yHChEH,MAAM2E,GAAYlgB,YAAOtC,GACV,iBAANA,GACO,oBAAdA,EAAEsB,SAGW,MAAMmhB,GAWZtlB,YACYulB,EACAxY,EACApL,EACA6jB,GACjB,KAJiBD,cAIjB,KAHiBxY,MAGjB,KAFiBpL,UAEjB,KADiB6jB,iBACjB,sBAfuC,IAevC,gBAbc,GAad,gBAX4C,IAW5C,8CAPe,GASjB,qBACE1hB,EACA2hB,GAEA,MAAMpoB,QAAU6C,KAAKwlB,gBACrB,IACE,aAAa5hB,EAAGzG,GADlB,cAGQooB,aAAN,EAAMA,EAAWpoB,IACjB6C,KAAKylB,iBAAiBtoB,IAI1B,0BACEyG,EACA2hB,GAEA,OAAOJ,GAAU,IAAMnlB,KAAK8hB,eAAele,EAAI2hB,IAG1CrZ,QACL,OAAIlM,KAAK0H,OACArF,QAAQC,WAGjBtC,KAAK0H,QAAS,EACK,IAAf1H,KAAK0lB,OACP1lB,KAAK2lB,UACEtjB,QAAQC,WAGV,IAAID,QAASC,IAClBtC,KAAK4lB,UAAY,KACf5lB,KAAK2lB,UACLrjB,QAKEqjB,UACN3lB,KAAK6lB,YAAYnmB,QAASvC,GAAMA,EAAE2oB,cAClC9lB,KAAK6lB,YAAY9e,OAAS,EAG5B,sBACE,GAAI/G,KAAK0H,OACP,MAAM,IAAIrG,MAAM,qBAGlB,MAAMzD,EAAIoC,KAAK6lB,YAAYE,MAC3B,GAAInoB,EAEF,OADAoC,KAAK0lB,OAAS,EACP9nB,EAET,GAAIoC,KAAK0lB,MAAQ1lB,KAAKslB,eAAgB,CACpCtlB,KAAK0lB,OAAS,EACd,MAAMpY,EAAS,IAAItN,KAAKqlB,YAAYrlB,KAAK6M,IAAK7M,KAAKyB,SAEnD,aADM6L,EAAOI,UDdJ,SAA0BJ,GAOvC,OANAA,EAAO0Y,cAAc,MAAO,CAAEC,IAAKrB,KACnCtX,EAAO0Y,cAAc,SAAU,CAAEC,IAAKhB,KACtC3X,EAAO0Y,cAAc,cAAe,CAAEC,IAAKlB,KAC3CzX,EAAO0Y,cAAc,qBAAsB,CAAEC,IAAKjB,KAClD1X,EAAO0Y,cAAc,SAAU,CAAEC,IAAKf,KAE/B5X,ECQI4Y,CAAiB5Y,GAE1B,OAAO,IAAIjL,QAASC,IAClBtC,KAAKgX,MAAMxU,KAAKF,KAIZmjB,iBAAiBtoB,GACvB,MAAMgpB,EAAInmB,KAAKgX,MAAMoP,QAMG,MALpBD,EACFA,EAAEhpB,IAEF6C,KAAK0lB,OAAS,EACd1lB,KAAK6lB,YAAYrjB,KAAKrF,GACH,IAAf6C,KAAK0lB,QACP,UAAA1lB,KAAK4lB,iBAAL,cAAA5lB,SChGO,MAAMqmB,WAAgB9a,EAC3BzL,YACW2hB,GAEjB9Z,MAAM,CAACtK,EAAM0C,IAAS,IAAIyhB,GAAgBxhB,KAAKyhB,KAAMpkB,EAAM0C,IAD3D,KADiB0hB,OAKnB,qBAA4B5U,GAC1B,MAAQY,QAAS4X,SAAsB,QAAN,qBAAa,KAG9CA,EAAYiB,QAAQC,oBAAoB,UAAYC,GAAMA,GAE1D,OAAO,IAAIH,GAAQ,IAAIjB,GACrBC,EACAxY,EACA,CAAE4Z,aAAa,GAJU,IAStBhb,cAAgCpO,EAAc0C,GACnD,OAAO4H,MAAM8D,cAAcpO,EAAM0C,GAG5B2mB,oBACL,OAAO1mB,KAAKyhB,KAGJjV,gBACR,OAAOxM,KAAKyhB,KAAKvV,SCpCd,SAASya,GAAYhnB,GAC1B,MAAQ,IAAGA,EAAE0E,QAAQ,WAAY,WAG5B,SAASuiB,GAAaC,GAC3B,MAAMznB,EAAmB,GAIzB,OAHAynB,EAAOnnB,QAAQ,CAACC,EAAGZ,KACjBK,EAAOoD,KAAM,GAAEmkB,GAAY5nB,OAAO4nB,GAAYhnB,QAEzCP,EAAO0M,KAAK,KCTrB,MAAMgb,GAAa,KAKnB,MAAMC,GAAa,KACZ,SAASC,GAAWC,GAGzB,MAAQ,IAAGA,EAAI5iB,QAAQ0iB,GAAY,SAGrC,MAAMG,GAAS,WACR,SAASC,GACdC,EACAC,GAEA,OAAOD,EAAK/iB,QACV6iB,GACCvnB,GAjBK,IAiBiB0nB,EAAY1nB,EAAE2J,OAAO,IAjB/BjF,QAAQyiB,GAAY,UCOrC,MAAMQ,GAAa,CACjBC,aAAc,CACZ,kCACA,gCACA,uBACA,KACAzb,KAAK,IAEP0b,gBAAiB,sFAEjBC,aAAc,8DACdC,oBAAqB,0DACrBC,WAAY,0BAEZC,OAAQ,oDAERC,OAAQ,qEACRC,aAAc,gHACdC,UAAW,kDAEXC,UAAW,4GAEXC,WAAY,oDACZC,WAAY,0BACZC,cAAe,4CACfC,UAAW,sCAEXC,OAAQ,mCACRC,UAAW,8BAiEb,SAASC,IACN5mB,EAAI0H,GACLa,GAEA,OAAOD,EF9FF,SAAsBue,GAC3B,MAAMppB,EAAS,IAAIa,IACnB,IAAI2b,EAAU,GACV6M,EAAa,GACbC,GAAQ,EACZ,IAAK,IAAI9pB,EAAI,EAAGA,EAAI4pB,EAAOzhB,QAAS,CAClC,MAAM5J,EAAIqrB,EAAO5pB,GACjB,OAAQzB,GACN,IAAK,IACL,IAAK,KACL,IAAK,KACL,IAAK,KACCurB,IACF9M,GAAWze,GAEb,MACF,IAAK,KACHye,GAAW4M,EAAO5pB,EAAI,GACtBA,GAAK,EACL,MACF,IAAK,IACH8pB,GAASA,EACT,MACF,IAAK,IACCA,EACF9M,GAAWze,EACgB,MAAlBqrB,EAAO5pB,EAAI,KACpB6pB,EAAa7M,EACbA,EAAU,GACVhd,GAAK,GAEP,MACF,IAAK,IACC8pB,EACF9M,GAAWze,GAEXiC,EAAOoL,IAAIie,EAAY7M,GACvB6M,EAAa,GACb7M,EAAU,IAEZ,MACF,QACEA,GAAWze,EAGfyB,GAAK,EAKP,OAHI6pB,GACFrpB,EAAOoL,IAAIie,EAAY7M,GAElBxc,EE4C+BupB,CAAatf,GAAMmB,IAAI,KAAM7I,GAAsBuI,GAG5E,MAAM0e,WAA6ChoB,IAGzDd,YACY2hB,EACA7O,EACjB7S,EAAkB,GACD0H,EAAqB,CAAEC,QAAQ,I,UAEhDC,MAAM5H,GADN,KAJiB0hB,OAIjB,KAHiB7O,YAGjB,KADiBnL,W,EACjB,K,EAAA,gB,EAP+B,IAAIxH,I,6FAUnCD,KAAK4H,UAhFTlF,eACE+e,EACA7O,EACA7S,EAAoB,IAEpB,MAAM5C,QAAUskB,EAAK/T,UACrB,UAGQvQ,EAAE6K,MAAMmf,GAAgBG,GAAWC,aAAc,CACrDsB,EAAGjW,KAGL,MAAM7R,QAAgB5D,EAAE6K,MAAM,CAC5B8gB,QAAS,QACT1J,KAAMkI,GAAWE,gBACjBnb,OAAQ,CAACuG,KAELmW,EAAgB,IAAI1iB,IACxBtF,EAAQioB,KACLzpB,IAAK3B,GAAMA,EAAE,IACbsC,OAAQpD,GAAOA,EAAEmsB,WAAcrW,EAAF,OAAoB9V,EAAEmsB,WAAcrW,EAAF,QAK9DsW,EAAa1rB,OAAOiC,QAAQM,GAClC,IAAK,IAAIjD,EAAI,EAAGA,EAAIosB,EAAWniB,OAAQjK,GAAK,EAAG,CAC7C,MAAOiC,EAAGY,GAAKupB,EAAWpsB,GAC1B,GAAI6C,GAAKA,EAAEU,OAAQ,CACjB,MAAMhD,EAAQ,GAAEuV,MAAc7T,IACzBgqB,EAAcxiB,OAAOlJ,UAClBF,EAAE6K,MAAMmf,GAAgBG,GAAWI,oBAAqB,CAC5DmB,EAAGjW,EACHuW,EAAG9rB,IACFgH,QAAQ,OAAQ2iB,GAAWjoB,SAE3B,CACL,MAAM1B,EAAQ,GAAEuV,MAAc7T,IACzBgqB,EAAcxiB,OAAOlJ,UAClBF,EAAE6K,MAAMmf,GAAgBG,GAAWG,aAAc,CACrDoB,EAAGjW,EACHuW,EAAG9rB,IACFgH,QAAQ,OAAQ2iB,GAAWjoB,MAIpC,MAAMqqB,EAAkB,IAAIL,GAC5B,IAAK,IAAIjsB,EAAI,EAAGA,EAAIssB,EAAgBriB,OAAQjK,GAAK,EAAG,CAClD,MAAMwJ,EAAM8iB,EAAgBtsB,SACtBK,EAAE6K,MAAMmf,GAAgBG,GAAWK,WAAY,CACnDkB,EAAGjW,EACHuW,EAAG7iB,MA9CT,QAoDEnJ,EAAEksB,WAsBa/P,CAAemI,EAAM7O,EAAW7S,IAGjD,kBAA4B+J,GAC1B,MAAME,EAAaH,EAAgBC,GAC7BnI,EAAKqI,EAAWrM,IAAI,MAC1BqM,EAAWzD,OAAO,YACZvG,KAAKspB,cAAc,SAAU3nB,EAAIilB,GAAa5c,IAGtD,qBACErI,EACAH,SAEMxB,KAAKspB,cACT,YACAvgB,EAAepH,GACfilB,GAAa/c,EAAgBrI,KAIjC,qBACEN,EACAC,EACA2I,GAEA,MAAMc,EAAM7B,EAAe5H,GACrB6I,EAAaH,EAAgBC,GAC7BnI,EAAKqI,EAAWrM,IAAI,MAC1BqM,EAAWzD,OAAO,MAClB,MAAMiiB,EAAS5B,GAAa5c,GAE5B,GAAwB,OAApB9I,QACIlB,KAAKspB,cAAc,YAAad,EAAQ5d,QACzC,QAAWlJ,IAAPC,EACT,UACQ3B,KAAKspB,cAAc,eAAgBd,EAAQtnB,EAAiB0J,EAAKjJ,GACvE,MAAOgB,GACP,MAAIA,EAAEsB,QAAQkE,SAAS,oBAKf,IAAI9G,MAAM,oBAEVsB,aAIJ3C,KAAKspB,cAAc,SAAUd,EAAQtnB,EAAiB0J,GAIhE,kBAIE1J,EACAC,EACAC,GAEA,IAAIkH,EAMJ,OAJEA,EADsB,OAApBpH,QACUlB,KAAKspB,cAAc,YAAavgB,EAAe5H,UAE/CnB,KAAKspB,cAAc,aAAcpoB,EAAiB6H,EAAe5H,IAE1EmH,EAAIihB,SAGFhB,GAAiBjgB,EAAI0gB,KAAK,GAAI5nB,GAF5B,KAKX,qBAIEF,EACAC,EACAC,GAEA,IAAIkH,EAQJ,OAJEA,EAHGpH,EAE0B,OAApBA,QACGlB,KAAKspB,cAAc,YAAavgB,EAAe5H,UAE/CnB,KAAKspB,cAAc,gBAAiBpoB,EAAiB6H,EAAe5H,UAJpEnB,KAAKspB,cAAc,cAM1BhhB,EAAI0gB,KAAKzpB,IAAKI,GAAM4oB,GAAiB5oB,EAAGyB,IAGjD,qBACEF,EACAC,GAEA,IAAImH,EAMJ,OAJEA,EADsB,OAApBpH,QACUlB,KAAKspB,cAAc,YAAavgB,EAAe5H,UAE/CnB,KAAKspB,cAAc,SAAUpoB,EAAiB6H,EAAe5H,IAEpEmH,EAAIihB,SAGLD,cACNE,KACGnd,GAEH,GAAIrM,KAAKyH,SAASC,OAChB,MAAM,IAAIrG,MAAM,qBAGlB,IAAIqK,EAAS1L,KAAKypB,cAAc9rB,IAAI6rB,GAMpC,OALK9d,IACHA,EAASyb,GAAgBG,GAAWkC,GAAY,CAAEX,EAAG7oB,KAAK4S,YAC1D5S,KAAKypB,cAAcjf,IAAIgf,EAAW9d,IAG7B1L,KAAKyhB,KAAKzZ,MAAM,CACrB3K,KAAO,GAAE2C,KAAK4S,aAAa4W,IAC3BV,QAAS,QACT1J,KAAM1T,EACNW,YC7OS,MAAMqd,WAAmBne,EAC9BzL,YACW2hB,GAEjB9Z,MAAM,CAACtK,EAAM0C,IAAS,IAAI6oB,GAAmBnH,EAAMpkB,EAAM0C,EAAMC,KAAKyH,WADpE,KADiBga,OAKnB,qBAA4B5U,GAC1B,MAAM,KAAE8c,SAAe,QAAN,qBAAa,KACxBlI,EAAO,IAAIkI,EAAK,CAAEC,iBAAkB/c,IAE1C,aADM4U,EAAKzZ,MAAM,yCACV,IAAI0hB,GAAWjI,GAGjBhW,cAAgCpO,EAAc0C,GACnD,OAAO4H,MAAM8D,cAAcpO,EAAM0C,GAG5B2mB,oBACL,OAAO1mB,KAAKyhB,KAGJjV,gBACR,OAAOxM,KAAKyhB,KAAKlC,O,6rBCKrB,SAASsK,GACP9rB,EACAmM,GAEA,OAAOA,EACJnI,KAAMqf,GAAU5jB,OAAOkB,UAAUC,eAAe1B,KAAKc,EAAOqjB,IAGlD,MAAM0I,GAOZhqB,YACYiqB,EACA7f,EACA8f,GACjB,KAHiBD,iBAGjB,KAFiB7f,SAEjB,KADiB8f,UAEjB9f,EAAOxK,QAAS0hB,IACd,GAAI2I,EAAehpB,QAAQL,cAAc0gB,GACvC,MAAM,IAAI/f,MAAO,4BAA2B+f,KAKlD,UAAiBpgB,GACf,OAAOhB,KAAK+pB,eAAeze,UAAUtL,KAAKiqB,QAAQjpB,IAGpD,UAIE3C,EACAN,EACAmM,GAEA,GAAIlK,KAAKkK,OAAO/B,SAAS9J,GACvB,MAAM,IAAIgD,MAAM,+BAElB,MAAMiH,QAAYtI,KAAK+pB,eAAepsB,IAAIU,EAAKN,EAAOmM,GACtD,OAAO5B,EAAMtI,KAAKkqB,UAAU5hB,EAAKnJ,YAAad,EAAKN,IAAU,KAG/D,aAIEM,EACAN,EACAmM,GAEA,QAAYxI,IAARrD,GAAqB2B,KAAKkK,OAAO/B,SAAS9J,GAC5C,MAAM,IAAIgD,MAAM,+BAElB,MAAMiH,QAAYtI,KAAK+pB,eAAeI,OAAO9rB,EAAMN,EAAQmM,GACrDkgB,OAAiB1oB,IAARrD,EAAqBc,YAAad,EAAKN,QAAS2D,EAC/D,OAAOW,QAAQgF,IAAIiB,EAAI/I,IAAKI,GAAMK,KAAKkqB,UAAUvqB,EAAGyqB,KAGtD,aACE/rB,EACAN,EACAyD,EACAC,GAEA,GAAIzB,KAAKkK,OAAO/B,SAAS9J,GACvB,MAAM,IAAIgD,MAAM,kCAElB,MAAMgpB,QAAkBrqB,KAAKiqB,QAAQzoB,EAAQrC,YAAad,EAAKN,IAC/D,OAAOiC,KAAK+pB,eAAevoB,OAAOnD,EAAKN,EAAOssB,EAAW5oB,GAG3D,aACEpD,EACAN,GAEA,GAAIiC,KAAKkK,OAAO/B,SAAS9J,GACvB,MAAM,IAAIgD,MAAM,kCAElB,IAAKrB,KAAKgqB,QAAQM,UAChB,OAAOtqB,KAAK+pB,eAAe3N,OAAO/d,EAAKN,GAGzC,MAAM0Q,QAAczO,KAAK+pB,eAAeI,OAAO9rB,EAAKN,EAAO,CAAC,OAK5D,aAJMsE,QAAQgF,IAAIoH,EAAMlP,IAAImD,gBACpB1C,KAAKgqB,QAAQM,UAAWxgB,SACxB9J,KAAK+pB,eAAe3N,OAAO,KAAMtS,EAAKnI,OAEvC8M,EAAM1H,OAGf,cACE,OAAO/G,KAAK+pB,eAAehpB,QAa7B,cACEpB,EACAyqB,GAEA,IAAIG,EACJ,GAAIvqB,KAAKgqB,QAAQQ,SAAWX,GAAYlqB,EAAGK,KAAKkK,QAAS,CACvD,MAAMugB,EAAYL,EAAQ,SAAKA,GAAUzqB,GAAMA,EAC/C4qB,QAAkBvqB,KAAKgqB,QAAQQ,QAAQC,GAEzC,MAAMJ,EAAY,MAAK1qB,GAOvB,aANM0C,QAAQgF,IAAIrH,KAAKkK,OAAO3K,IAAImD,UAC5BlF,OAAOkB,UAAUC,eAAe1B,KAAK0C,EAAGZ,KAE1CsrB,EAAUtrB,SAAWiB,KAAKgqB,QAAQU,KAAK3rB,EAAIY,EAAUZ,GAAIwrB,OAGtDF,EAaT,gBACE1qB,EACAyqB,GAEA,IAAIG,EACJ,GAAIvqB,KAAKgqB,QAAQW,WAAad,GAAYlqB,EAAGK,KAAKkK,QAAS,CACzD,MAAMugB,EAAYL,EAAQ,SAAKA,GAAUzqB,GAAMA,EAC/C4qB,QAAkBvqB,KAAKgqB,QAAQW,UAAUF,GAE3C,MAAMJ,EAAY,MAAK1qB,GAOvB,aANM0C,QAAQgF,IAAIrH,KAAKkK,OAAO3K,IAAImD,UAC5BlF,OAAOkB,UAAUC,eAAe1B,KAAK0C,EAAGZ,KAE1CsrB,EAAUtrB,SAAWiB,KAAKgqB,QAAQY,OAAO7rB,EAAIY,EAAUZ,GAAIwrB,OAGxDF,GCxLX,MAAMQ,GAAM,cACNC,GAAUnmB,OAAO4E,KAAQshB,GAAF,IAAU,QAmCxBE,OAhC2C,CACxDC,QAAS,CAAC3sB,EAAgBsB,KACxB,MAAMsrB,EAAKC,KAAOC,YAJP,IAKLC,EAASF,KAAOG,eAAeR,GAAKxsB,EAAK4sB,GACzCK,EAAOF,EAAO5pB,OAAO7B,GACrB4rB,EAAQH,EAAOG,QACrB,OAAO5mB,OAAO+E,OAAO,CAACohB,GAASG,EAAIK,EAAMC,KAG3CC,QAAS,CAACntB,EAAgBsB,KACxB,IAAKA,EAAE6U,MAAM,EAAGsW,GAAQ/jB,QAAQ0kB,OAAOX,IACrC,MAAM,IAAIzpB,MAAM,gCAGlB,MAAM4pB,EAAKtrB,EAAE6U,MAAMsW,GAAQ/jB,OAAQ+jB,GAAQ/jB,OAhBhC,IAiBL2kB,EAAY/rB,EAAE6U,MAAMsW,GAAQ/jB,OAjBvB,IAmBL4kB,EAAWT,KAAOU,iBAAiBf,GAAKxsB,EAAK4sB,GAC7CK,EAAOK,EAASnqB,OAAOkqB,GACvBH,EAAQI,EAASJ,QAEvB,OAAO5mB,OAAO+E,OAAO,CAAC4hB,EAAMC,KAG9BM,YAAa,IAAiBX,KAC3BY,gBAAgBZ,KAAOC,YAAY,KAEtCY,aAAe1tB,GAA2BA,EAAI2tB,SAE9CC,eAAiB5iB,GAA4B6hB,KAAOY,gBAAgBziB,I,8eCbtE,SAAS6iB,GACPhiB,EACAkgB,GAEA,OAAKlgB,GAAUA,EAAO/B,SAASiiB,GACtBlgB,EAEF,IAAIA,EAAQkgB,GAGrB,MAAM+B,GASGrsB,YACYiqB,GACjB,SACEpS,EAAWxK,OAAOc,kBADpB,OAEEme,EAASjf,OAAOc,kBAFlB,KAGEoe,EAAO7oB,KAAKC,MAEd,KANiBsmB,iBAMjB,0GACA/pB,KAAKosB,OAASA,EACdpsB,KAAKqsB,KAAOA,EACZrsB,KAAKssB,MAAQ,IAAIvQ,GAASpE,EAAU3X,KAAKusB,cAAcjuB,KAAK0B,OAC5DA,KAAKqK,gBAAkB,IAAIpK,IAAI8pB,EAAehpB,QAAQT,mBACnDf,IAAKR,GAAO,CAACA,EAAG,IAAIkB,OAGzB,UAAiBe,SACThB,KAAK+pB,eAAeze,IAAItK,GAC9BhB,KAAKwsB,UAAU3iB,EAAgB7I,IAAQ,GAGzC,UAIE3C,EACAN,EACAmM,GAEA,GAAY,OAAR7L,EAAc,CAChB,MAAMouB,QAAkBzsB,KAAK0sB,WAAW3uB,EAAkBmM,GAC1D,OAAKuiB,EAAUziB,WAGRC,EAAyBwiB,EAAUziB,WAAYE,GAF7C,KAIX,GAAIlK,KAAKe,QAAQL,cAAcrC,GAAM,CACnC,MAAM0B,EAAOC,KAAK2sB,QAAQtuB,EAAKN,GAC/B,GAAIgC,EAAKgH,OAAQ,CACf,MAAM0lB,QAAkBzsB,KAAK0sB,WAAWvjB,EAAiBpJ,EAAK,IAAgBmsB,GAAYhiB,EAAQ7L,IAClG,GAAIouB,EAAUziB,YAAcyiB,EAAUziB,WAAWrM,IAAIU,KAAS0K,EAAehL,GAC3E,OAAOkM,EAAyBwiB,EAAUziB,WAAYE,IAK5D,MAAMJ,QAAa9J,KAAK+pB,eAAepsB,IAAIU,EAAKN,EAAOmuB,GAAYhiB,EAAQ,OAM3E,OALIJ,EACF9J,KAAKwsB,UAAU3iB,EAAgBC,GAAMU,IAAInM,EAAK0K,EAAehL,IAAS4C,QAAQuJ,IAE9ElK,KAAK2sB,QAAQtuB,EAAKN,GAAO2B,QAASX,GAAMiB,KAAKssB,MAAMlQ,OAAOrd,IAErD+K,EAGT,aAIEzL,EACAN,EACAmM,GAEA,IAAK7L,EAAK,CACR,MAAMuuB,QAAiB5sB,KAAK+pB,eAAeI,SAG3C,OAFAnqB,KAAKssB,MAAMzQ,QACX+Q,EAASltB,QAASoK,GAAS9J,KAAKwsB,UAAU3iB,EAAgBC,IAAO,IAC1D8iB,EAET,GAAI5sB,KAAKe,QAAQL,cAAcrC,GAAM,CACnC,MAAMyL,QAAa9J,KAAKrC,IAAIU,EAAKN,EAAQmM,GACzC,OAAOJ,EAAO,CAACA,GAAQ,GAEzB,MAAM2E,QAAczO,KAAK+pB,eAAeI,OAAO9rB,EAAKN,EAAQmuB,GAAYhiB,EAAQ,OAChF,GAAIlK,KAAKe,QAAQR,QAAQlC,GAAM,CAC7B,MAAMwuB,EAAU,IAAIxmB,IAAIrG,KAAK2sB,QAAQtuB,EAAKN,IAC1C0Q,EAAM/O,QAAQ,EAAGiC,QAASkrB,EAAQtmB,OAAOwC,EAAepH,KACxDkrB,EAAQntB,QAASX,GAAMiB,KAAKssB,MAAMlQ,OAAOrd,IAE3C,OAAImL,IAAWA,EAAO/B,SAAS,MACtBsG,EAAMlP,IAAK,IAAD,IAAC,GAAEoC,GAAH,wBAEZ8M,EAGT,aACEpQ,EACAN,EACAyD,EACAC,SAEMzB,KAAK+pB,eAAevoB,OAAOnD,EAAKN,EAAOyD,EAAQC,GACrD,MAAM1B,EAAOC,KAAK2sB,QAAQtuB,EAAKN,GACzB+uB,EAAmBjjB,EAAgBrI,GACzCzB,EAAKL,QAASqtB,IACZ,MAAMjjB,EAAO9J,KAAKssB,MAAMjQ,KAAK0Q,IACvB,WAAE/iB,GAAeF,EACnBE,IACFhK,KAAKusB,cAAcziB,GACnBgjB,EAAiBptB,QAAQ,CAACC,EAAGZ,KAC3BiL,EAAWQ,IAAIzL,EAAGY,KAEpBK,KAAKgtB,gBAAgBljB,OAGpB/J,EAAKgH,QAAN,MAAgBtF,KAASG,QAAkB,OAARvD,GACrC2B,KAAKwsB,UAAU3iB,EAAgBrI,GAAQgJ,IAAI,KAAMzB,EAAehL,KAAS,GAI7E,aACEM,EACAN,GAEA,MAAMkvB,QAAgBjtB,KAAK+pB,eAAe3N,OAAO/d,EAAKN,GAMtD,OALIkvB,EAAU,GACZjtB,KAAK2sB,QAAQtuB,EAAKN,GAAO2B,QAASX,IAChCiB,KAAKssB,MAAMhhB,IAAIvM,EAAG,CAAEiL,WAAY,KAAMkjB,SAAS,EAAOb,KAAMrsB,KAAKqsB,WAG9DY,EAGT,cACE,OAAOjtB,KAAK+pB,eAAehpB,QAGrB4rB,QAAoCtuB,EAAQN,GAAuB,MACzE,MAAMovB,EAAKpkB,EAAehL,GAC1B,GAAY,OAARM,EACF,MAAO,CAAC8uB,GAEV,MAAMptB,EAAI,UAAGC,KAAKqK,gBAAgB1M,IAAIU,UAA5B,aAAG,EAA+BV,IAAIwvB,GAChD,OAAOptB,EAAO,IAAIA,GAAQ,GAGpBitB,iBAAgB,WAAEhjB,IACxB,IAAKA,EACH,OAGF,MAAMrI,EAAKqI,EAAWrM,IAAI,MAC1BqC,KAAKqK,gBAAgB3K,QAAQ,CAAC4G,EAAKwJ,KACjC,MAAM/R,EAAQiM,EAAWrM,IAAImS,GAC7B,IAAK/R,EACH,OAEF,IAAI8uB,EAAUvmB,EAAI3I,IAAII,GACtB,GAAK8uB,EAGE,GAAIA,EAAQzlB,MAAQpH,KAAKe,QAAQL,cAAcoP,GAAO,CAC3D,MAAMsd,EAAS,IAAIP,GAAS,GACxBO,IAAWzrB,IACb3B,KAAKssB,MAAMlQ,OAAOgR,GAClB9mB,EAAIkE,IAAIzM,EAAO,IAAIsI,IAAI,CAAC1E,WAG1BkrB,EAAQvhB,IAAI3J,QATZkrB,EAAU,IAAIxmB,IAAI,CAAC1E,IACnB2E,EAAIkE,IAAIzM,EAAO8uB,KAabN,eAAc,WAAEviB,IACtB,IAAKA,EACH,OAGF,MAAMrI,EAAKqI,EAAWrM,IAAI,MAC1BqC,KAAKqK,gBAAgB3K,QAAQ,CAAC4G,EAAKwJ,KACjC,MAAM/R,EAAQiM,EAAWrM,IAAImS,GAC7B,IAAK/R,EACH,OAEF,MAAM8uB,EAAUvmB,EAAI3I,IAAII,GACxB8uB,EAAQtmB,OAAO5E,GACVkrB,EAAQzlB,MACXd,EAAIC,OAAOxI,KAKTyuB,UAAUxiB,EAA2BkjB,GAC3C,MAAMT,EAAY,CAAEziB,aAAYkjB,UAASb,KAAMrsB,KAAKqsB,QACpDrsB,KAAKgtB,gBAAgBP,GACrBzsB,KAAKssB,MAAMhhB,IAAItB,EAAWrM,IAAI,MAAQ8uB,GAGhCC,WACN/qB,EACAuI,GAEA,MAAM7L,EAAM0K,EAAepH,GAC3B,OAAO3B,KAAKssB,MAAMe,YAAYhvB,EAAKqE,UACjC,MAAMoH,QAAa9J,KAAK+pB,eAAepsB,IAAI,KAAMgE,EAAIuI,GAC/CuiB,EAAY,CAChBziB,WAAYF,EAAOD,EAAgBC,GAAMU,IAAI,KAAMnM,GAAO,KAC1D6uB,QAASvsB,QAAQuJ,GACjBmiB,KAAMrsB,KAAKqsB,QAGb,OADArsB,KAAKgtB,gBAAgBP,GACdA,GACNzsB,KAAKstB,QAAQpjB,IAGVojB,QAAQpjB,GACd,MAAO,EAAGF,aAAYkjB,UAASb,YACzBrsB,KAAKqsB,OAASA,EAAOrsB,KAAKosB,WAGzBpiB,IAAekjB,KAGfhjB,GAGEA,EAAOlD,MAAOoa,GAAUpX,EAAWvJ,IAAI2gB,M,qXCtOpD,SAASmM,GACPvD,GAKA,MAAO,CAAC9f,EAAc6f,IAChB7f,GAAU6f,EAELC,EAAQ9f,EAAQ6f,GAElBC,EA4BX,SAASwD,GACPriB,GACA,WACEsiB,EAAa1C,GADf,SAEE2C,GAAW,GACgC,IAE7C,MAAMrvB,EAAMovB,EAAWxB,eAAe9gB,GAEtC,OAAOoiB,GAAc,CACnBrjB,EACA6f,IACG,IAAID,GAAuCC,EAAgB7f,EAAQ,CACtEwgB,KAAM,CAAC3rB,EAAGY,IAAgC8tB,EAAWzC,QAAQ3sB,EAAKoL,EAAkB9J,IACpFirB,OAAQloB,MAAO3D,EAAGY,KAChB,KAAMA,aAAagF,QAAS,CAC1B,GAAI+oB,EACF,OAAO/tB,EAET,MAAM,IAAI0B,MAAM,oBAElB,OAAOsI,QAA0B8jB,EAAWjC,QAAQntB,EAAKsB,QAe/D,SAASguB,GACPC,EACA,EAKuE,IACxD,IANf,WACEH,EAAa1C,GADf,SAEE2C,GAAW,EAFb,SAGElO,GAGa,EACf,GADe,2CACWqO,UACxB,MAAM,IAAIxsB,MAAM,mFAGdme,IAEFoO,EDiJG,SACL7D,EACAtoB,EAAwB,IAExB,YACwBC,IAArBD,EAAQkW,UAA0BlW,EAAQkW,UAAY,QACnCjW,IAAnBD,EAAQ2qB,QAAwB3qB,EAAQ2qB,OAAS,EAE3CrC,EAEF,IAAIoC,GAAoBpC,EAAgBtoB,GC3J7B6qB,CAAMsB,EAAepO,IAGvC,MAAMsO,EAAc,IAAI/R,GAA+B,MAEjDgS,EAAUrrB,MACdsrB,EACAnH,KAEA,MAAM,GAAEllB,GAAOklB,EAEf,QAAWnlB,IAAPC,EACF,MAAM,IAAIN,MAAM,kCAGlB,MAAMyI,QAAa8jB,EAAcjwB,IAAI,KAAMgE,EAAI,CAAC,QAChD,GAAImI,EACF,OAAOgkB,EAAYpiB,OAAO5B,EAAKzL,IAAK,IAAMovB,EAAWxB,eAAeniB,EAAKzL,MAE3E,IAAK2vB,EACH,MAAM,IAAI3sB,MAAM,sCAElB,MAAMhD,QAAYovB,EAAW5B,cACvBoC,EAAgBR,EAAW1B,aAAa1tB,GAG9C,aAFMuvB,EAActiB,IAAI,CAAE3J,KAAItD,IAAK4vB,IACnCH,EAAYxiB,IAAI2iB,EAAe5vB,GACxBA,GAGH6vB,EAAYxrB,OAASf,eACnBisB,EAAcxR,OAAO,KAAMza,IAInC,OAAO4rB,GAAkB,CACvBrjB,EACA6f,IACG,IAAID,GAAsCC,EAAgB7f,EAAQ,CACrEwgB,KAAM,CAAC3rB,EAAGY,EAAGtB,IAAkCovB,EAAWzC,QAAQ3sB,EAAKoL,EAAkB9J,IACzFirB,OAAQloB,MAAO3D,EAAGY,EAAGtB,KACnB,KAAMsB,aAAagF,QAAS,CAC1B,GAAI+oB,EACF,OAAO/tB,EAET,MAAM,IAAI0B,MAAM,oBAElB,OAAOsI,QAA0B8jB,EAAWjC,QAAQntB,EAAKsB,KAE3D6qB,QAASuD,EAAQzvB,KAAK,MAAM,GAC5BqsB,UAAWoD,EAAQzvB,KAAK,MAAM,GAC9BgsB,UAAW4D,KAgBf,SAASC,GACPC,EACAR,EACAnsB,EAA6E,IAE7E,MAAM4sB,EAAO5sB,EAMb,OAAOksB,GALQH,GAAaY,EAAYC,EACfC,GACvB,CAAC,OACDV,GAEuCS,G,+BCjL3C,MAAME,GAAeC,qBAA0BC,KAAKC,MAC9CC,GAAiBH,qBAA0BC,KAAKG,QAEhDC,GAAoBlqB,OAAOmE,GAAG,GAqC7B,SAASgmB,GACd5kB,EACA6f,EACAtoB,EAA2B,IAE3B,OAAO,IAAIqoB,GAAuCC,EAAgB7f,EAAQ,CACxEwgB,KAAM,CAAC3rB,EAAGY,IAzCd+C,eAA6B/C,GAAY,0BACvCovB,EAA4B,MAE5B,MAAM/kB,EAAaP,EAAkB9J,GACrC,GAAIqK,EAAWjD,QAAUgoB,EAA2B,CAClD,MAAMC,QAAgBT,GAAavkB,GACnC,GAAIglB,EAAQjoB,OAASiD,EAAWjD,OAAS,EACvC,OAAOioB,EAGX,OAAOrqB,OAAO+E,OAAO,CAACmlB,GAAmB7kB,IA+BNilB,CAActvB,EAAG8B,GAClDmpB,OAAQ,CAAC7rB,EAAGY,IA7BhB+C,eAA+B/C,GAAW,SACxC+tB,GAAW,EAD6B,eAExCwB,GAAiB,IAEjB,KAAMvvB,aAAagF,QAAS,CAC1B,GAAI+oB,EACF,OAAO/tB,EAET,MAAM,IAAI0B,MAAM,4BAElB,GAAa,KAAT1B,EAAE,IAAwB,MAATA,EAAE,GACrB,OAAOgK,QAA0BglB,GAAehvB,IAElD,GAAIA,EAAE,KAAOkvB,GAAkB,GAC7B,OAAOllB,EAAoBhK,EAAEiK,SAAS,IAExC,GAAI8jB,GAAYwB,EACd,OAAOvvB,EAET,MAAM,IAAI0B,MAAM,4BAUkB8tB,CAAgBxvB,EAAG8B,K,wVCnDvD,MAAM2tB,GAQGtvB,YACYiqB,EACjBsF,EACiBC,GACjB,KAHiBvF,iBAGjB,KADiBuF,mBACjB,6DACAtvB,KAAKqvB,WAAa,IAAIpvB,IAAIzC,OAAOiC,QAAQ4vB,IACzCrvB,KAAKuvB,cAAgB,IAAIvvB,KAAKqvB,WAAWtvB,QAG3C,UAAiBiB,GACf,OAAOhB,KAAK+pB,eAAeze,IAAItK,GAGjC,UAIEE,EACAC,EACAC,GAEA,MAAMkH,QAAYtI,KAAK+pB,eAAepsB,IACpCuD,EACAC,EACAnB,KAAKwvB,iBAAiBpuB,IAExB,OAAOkH,EAAMtI,KAAKyvB,eAAennB,EAAKlH,GAAoB,KAG5D,aAIEF,EACAC,EACAC,GAOA,aALmBpB,KAAK+pB,eAAeI,OACrCjpB,EACAC,EACAnB,KAAKwvB,iBAAiBpuB,KAEZ7B,IAAK+I,GAAQtI,KAAKyvB,eAAennB,EAAKlH,IAGpD,aACEF,EACAC,EACAK,EACAC,GAEA,OAAOzB,KAAK+pB,eAAevoB,OAAON,EAAiBC,EAAaK,EAAQC,GAG1E,aACEP,EACAC,GAEA,OAAOnB,KAAK+pB,eAAe3N,OAAOlb,EAAiBC,GAGrD,cACE,OAAOnB,KAAK+pB,eAAehpB,QAGrByuB,iBAENpuB,GACA,OAAIA,GAAoBpB,KAAKsvB,iBACpB,IAAIluB,KAAqBpB,KAAKsvB,kBAEhCluB,EAGDquB,eACNnnB,EACAlH,GAEA,GAAIA,IAAqBA,EAAiBW,KAAM+N,GAAS9P,KAAKqvB,WAAW5uB,IAAIqP,IAC3E,OAAOxH,EAET,MAAMlJ,E,kWAAyB,IAAKkJ,GAQpC,OAPclH,GAAoBpB,KAAKuvB,eACjC7vB,QAASoQ,IACb,MAAM4f,EAAY1vB,KAAKqvB,WAAW1xB,IAAImS,GAClC4f,IACFtwB,EAAO0Q,GAAQ4f,EAAUxwB,YAAQoJ,EAAKwH,GAAOxH,MAG1ClJ,GAuCIuwB,OArBf,SAIEL,EACAD,EACAtF,GAEA,OAAIA,EACK,IAAIqF,GACTrF,EACAsF,EACAC,GAGG,IAAIF,GACTC,EACAC,ICxGWM,UClCA,MACb,qBAA4B/iB,GAC1B,IAAIgjB,EACJ,GAAIhjB,EAAIoc,WAAW,UACjB4G,EAAUjjB,OACL,GAAIC,EAAIoc,WAAW,WACxB4G,EAAUxiB,OACL,GAAIR,EAAIoc,WAAW,YACxB4G,EAAUjQ,QACL,GAAI/S,EAAIoc,WAAW,SACxB4G,EAAUxJ,OACL,KAAIxZ,EAAIoc,WAAW,YAGxB,MAAM,IAAI5nB,MAAO,2CAA0CwL,GAF3DgjB,EAAUnG,GAKZ,IACE,aAAamG,EAAQniB,QAAQb,GAC7B,MAAOlK,GACP,MAAM,IAAItB,MAAO,kCAAiCwL,OAASlK,EAAEsB","file":"index.js","sourcesContent":["(function webpackUniversalModuleDefinition(root, factory) {\n\tif(typeof exports === 'object' && typeof module === 'object')\n\t\tmodule.exports = factory();\n\telse if(typeof define === 'function' && define.amd)\n\t\tdefine(\"collection-storage\", [], factory);\n\telse if(typeof exports === 'object')\n\t\texports[\"collection-storage\"] = factory();\n\telse\n\t\troot[\"collection-storage\"] = factory();\n})(global, function() {\nreturn "," \t// The module cache\n \tvar installedModules = {};\n\n \t// The require function\n \tfunction __webpack_require__(moduleId) {\n\n \t\t// Check if module is in cache\n \t\tif(installedModules[moduleId]) {\n \t\t\treturn installedModules[moduleId].exports;\n \t\t}\n \t\t// Create a new module (and put it into the cache)\n \t\tvar module = installedModules[moduleId] = {\n \t\t\ti: moduleId,\n \t\t\tl: false,\n \t\t\texports: {}\n \t\t};\n\n \t\t// Execute the module function\n \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n \t\t// Flag the module as loaded\n \t\tmodule.l = true;\n\n \t\t// Return the exports of the module\n \t\treturn module.exports;\n \t}\n\n\n \t// expose the modules object (__webpack_modules__)\n \t__webpack_require__.m = modules;\n\n \t// expose the module cache\n \t__webpack_require__.c = installedModules;\n\n \t// define getter function for harmony exports\n \t__webpack_require__.d = function(exports, name, getter) {\n \t\tif(!__webpack_require__.o(exports, name)) {\n \t\t\tObject.defineProperty(exports, name, { enumerable: true, get: getter });\n \t\t}\n \t};\n\n \t// define __esModule on exports\n \t__webpack_require__.r = function(exports) {\n \t\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n \t\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n \t\t}\n \t\tObject.defineProperty(exports, '__esModule', { value: true });\n \t};\n\n \t// create a fake namespace object\n \t// mode & 1: value is a module id, require it\n \t// mode & 2: merge all properties of value into the ns\n \t// mode & 4: return value when already ns object\n \t// mode & 8|1: behave like require\n \t__webpack_require__.t = function(value, mode) {\n \t\tif(mode & 1) value = __webpack_require__(value);\n \t\tif(mode & 8) return value;\n \t\tif((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;\n \t\tvar ns = Object.create(null);\n \t\t__webpack_require__.r(ns);\n \t\tObject.defineProperty(ns, 'default', { enumerable: true, value: value });\n \t\tif(mode & 2 && typeof value != 'string') for(var key in value) __webpack_require__.d(ns, key, function(key) { return value[key]; }.bind(null, key));\n \t\treturn ns;\n \t};\n\n \t// getDefaultExport function for compatibility with non-harmony modules\n \t__webpack_require__.n = function(module) {\n \t\tvar getter = module && module.__esModule ?\n \t\t\tfunction getDefault() { return module['default']; } :\n \t\t\tfunction getModuleExports() { return module; };\n \t\t__webpack_require__.d(getter, 'a', getter);\n \t\treturn getter;\n \t};\n\n \t// Object.prototype.hasOwnProperty.call\n \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n\n \t// __webpack_public_path__\n \t__webpack_require__.p = \"\";\n\n\n \t// Load entry module and return exports\n \treturn __webpack_require__(__webpack_require__.s = 10);\n","export function safeAdd<K extends keyof any, V>(o: Record<K, V>, k: K, value: V): void {\n  /* eslint-disable no-param-reassign */ // purpose of this function\n  if (o[k]) {\n    Object.defineProperty(o, k, {\n      value,\n      configurable: true,\n      enumerable: true,\n      writable: true,\n    });\n  } else {\n    o[k] = value;\n  }\n  /* eslint-enable no-param-reassign */\n}\n\nfunction safeGet<T, K extends keyof T>(o: T, k: K): T[K] | undefined;\n/* eslint-disable-next-line @typescript-eslint/ban-types */ // \"any non-nullish value\" is intended\nfunction safeGet(o: object, k: string): unknown;\n\n/* eslint-disable-next-line @typescript-eslint/explicit-module-boundary-types */ // types above\nfunction safeGet(o: any, k: keyof any): unknown {\n  if (!Object.prototype.hasOwnProperty.call(o, k)) {\n    return undefined;\n  }\n  return o[k];\n}\n\nexport { safeGet };\n\nexport function makeKeyValue<V>(key: string, value: V): { [k: string]: V } {\n  const result = {} as Record<string, V>;\n  safeAdd(result, key, value);\n  return result;\n}\n\nexport function mapEntries<K extends keyof any, A, B>(\n  input: Record<K, A>,\n  map: (a: A) => B,\n  keyMapper?: (k: K) => K,\n): Record<K, B> {\n  const result = {} as Record<K, B>;\n  Object.entries(input).forEach(([k, v]) => {\n    const value = map(v as A);\n    const newKey = keyMapper ? keyMapper(k as K) : (k as K);\n    safeAdd(result, newKey, value);\n  });\n  return result;\n}\n","import type { Indices, KeyOptions } from './Collection';\nimport type { IDable } from './IDable';\nimport type { DBKeys } from './DB';\n\nexport default class BaseIndices<T extends IDable> implements Indices<T> {\n  private readonly keys: Map<string & keyof T, KeyOptions>;\n\n  constructor(keys: DBKeys<T>) {\n    this.keys = new Map<any, any>(Object.entries(keys).filter(([, v]) => v));\n  }\n\n  public getIndices(): (string & keyof T)[] {\n    return ['id', ...this.keys.keys()];\n  }\n\n  public getUniqueIndices(): (string & keyof T)[] {\n    return ['id', ...[...this.keys.entries()].filter(([, o]) => o?.unique).map(([n]) => n)];\n  }\n\n  public getCustomIndices(): (string & keyof T)[] {\n    return [...this.keys.keys()];\n  }\n\n  public isIndex(attribute: string | keyof T): boolean {\n    return (attribute === 'id' || this.keys.has(attribute as (string & keyof T)));\n  }\n\n  public isUniqueIndex(attribute: string | keyof T): boolean {\n    return Boolean(\n      attribute === 'id' ||\n      this.keys.get(attribute as (string & keyof T))?.unique,\n    );\n  }\n}\n","import type { Collection, UpdateOptions, Indices } from './Collection';\nimport type { IDable } from './IDable';\nimport type { DBKeys } from './DB';\nimport BaseIndices from './BaseIndices';\n\nexport default abstract class BaseCollection<T extends IDable> implements Collection<T> {\n  public readonly indices: Readonly<Indices<T>>;\n\n  // actually read publicly by BaseDB but we don't want this to be a user-accessible property\n  protected internalReady?: () => Promise<void>;\n\n  private innerPreAct: () => Promise<void> | void;\n\n  protected constructor(keys: DBKeys<T>) {\n    this.innerPreAct = this.preAct.bind(this);\n    this.indices = new BaseIndices(keys);\n  }\n\n  public async add(entry: T): Promise<void> {\n    await this.innerPreAct();\n    return this.internalAdd(entry);\n  }\n\n  public async get<\n    K extends string & keyof T,\n    F extends readonly (string & keyof T)[]\n  >(\n    searchAttribute: K,\n    searchValue: T[K],\n    returnAttributes?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>> | null> {\n    if (!this.indices.isIndex(searchAttribute)) {\n      throw new Error(`No index for ${searchAttribute}`);\n    }\n    await this.innerPreAct();\n    return this.internalGet(searchAttribute, searchValue, returnAttributes);\n  }\n\n  public async getAll<\n    K extends string & keyof T,\n    F extends readonly (string & keyof T)[]\n  >(\n    searchAttribute?: K,\n    searchValue?: T[K],\n    returnAttributes?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>>[]> {\n    if (searchAttribute && !this.indices.isIndex(searchAttribute)) {\n      throw new Error(`No index for ${searchAttribute}`);\n    }\n    await this.innerPreAct();\n    return this.internalGetAll(searchAttribute, searchValue, returnAttributes);\n  }\n\n  public async update<K extends string & keyof T>(\n    searchAttribute: K,\n    searchValue: T[K],\n    update: Partial<T>,\n    options: UpdateOptions = {},\n  ): Promise<void> {\n    if (searchAttribute === 'id' && update.id !== undefined && update.id !== searchValue) {\n      throw new Error('Cannot update ID');\n    }\n    if (options.upsert) {\n      if (searchAttribute !== 'id') {\n        throw new Error(`Can only upsert by ID, not ${searchAttribute}`);\n      }\n      let withoutId = update;\n      if (Object.prototype.hasOwnProperty.call(update, 'id')) {\n        withoutId = { ...update };\n        delete withoutId.id;\n      }\n      await this.innerPreAct();\n      return this.internalUpsert(searchValue as T['id'], withoutId, options);\n    }\n    if (!this.indices.isIndex(searchAttribute)) {\n      throw new Error(`No index for ${searchAttribute}`);\n    }\n    if (\n      !this.indices.isUniqueIndex(searchAttribute) &&\n      Object.keys(update).some((k) => this.indices.isUniqueIndex(k))\n    ) {\n      throw new Error('duplicate');\n    }\n\n    await this.innerPreAct();\n    return this.internalUpdate(searchAttribute, searchValue, update, options);\n  }\n\n  public async remove<K extends string & keyof T>(\n    searchAttribute: K,\n    searchValue: T[K],\n  ): Promise<number> {\n    if (!this.indices.isIndex(searchAttribute)) {\n      throw new Error(`No index for ${searchAttribute}`);\n    }\n    await this.innerPreAct();\n    return this.internalRemove(searchAttribute, searchValue);\n  }\n\n  // Subclass constructors can call this with a promise that will resolve when\n  // they are ready to be used. BaseCollection will automatically ensure that\n  // other interactions are queued until this promise resolves.\n  // (this call will always succeed; you can safely ignore the promise returned)\n  protected async initAsync(wait: Promise<unknown>): Promise<void> {\n    const pending: [() => void, (e: Error) => void][] = [];\n    const addPending = (): Promise<void> => new Promise((resolve, reject) => {\n      pending.push([resolve, reject]);\n    });\n    this.internalReady = addPending;\n    this.innerPreAct = async (): Promise<void> => {\n      await addPending();\n      return this.preAct();\n    };\n    try {\n      await wait;\n    } catch (e) {\n      this.internalReady = (): Promise<void> => Promise.reject(e);\n      this.innerPreAct = (): void => { throw e; };\n      pending.forEach((f) => f[1](e));\n      return;\n    }\n    this.internalReady = undefined;\n    this.innerPreAct = this.preAct.bind(this);\n    pending.forEach((f) => f[0]());\n  }\n\n  // eslint-disable-next-line class-methods-use-this\n  protected preAct(): Promise<void> | void {}\n\n  protected async internalGet<\n    K extends string & keyof T,\n    F extends readonly (string & keyof T)[]\n  >(\n    searchAttribute: K,\n    searchValue: T[K],\n    returnAttributes?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>> | null> {\n    const all = await this.internalGetAll(searchAttribute, searchValue, returnAttributes);\n    return all[0] ?? null;\n  }\n\n  protected internalUpsert(\n    id: T['id'],\n    update: Partial<T>,\n    options: UpdateOptions,\n  ): Promise<void> {\n    return this.internalUpdate('id', id, update, options);\n  }\n\n  protected abstract internalAdd(entry: T): Promise<void>;\n\n  protected abstract internalGetAll<\n    K extends string & keyof T,\n    F extends readonly (string & keyof T)[]\n  >(\n    searchAttribute?: K,\n    searchValue?: T[K],\n    fields?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>>[]>;\n\n  protected abstract internalUpdate<K extends string & keyof T>(\n    searchAttribute: K,\n    searchValue: T[K],\n    update: Partial<T>,\n    options: UpdateOptions,\n  ): Promise<void>;\n\n  protected abstract internalRemove<K extends string & keyof T>(\n    searchAttribute: K,\n    searchValue: T[K],\n  ): Promise<number>;\n}\n","module.exports = require(\"crypto\");","function sleep(millis: number): Promise<void> | null {\n  return new Promise((resolve): any => setTimeout(resolve, millis));\n}\n\nexport default (shouldRetry: (e: any) => boolean, {\n  timeoutMillis = 60000,\n  initialDelayMillis = 20,\n  maxDelayMillis = 5000,\n  delayGrowth = 2,\n  jitter = true,\n} = {}) => async <T>(fn: () => Promise<T> | T): Promise<T> => {\n  const limit = Date.now() + timeoutMillis;\n  let currentDelay = initialDelayMillis;\n  for (let attempt = 1; ; attempt += 1) {\n    try {\n      // eslint-disable-next-line no-await-in-loop\n      return await fn();\n    } catch (e) {\n      if (!shouldRetry(e)) {\n        throw e;\n      }\n\n      const delay = (\n        Math.min(currentDelay, maxDelayMillis) *\n        (jitter ? Math.random() : 1)\n      );\n      currentDelay *= delayGrowth;\n\n      if (Date.now() + delay > limit) {\n        e.message += ` (timeout after ${attempt} attempts)`;\n        throw e;\n      }\n\n      // eslint-disable-next-line no-await-in-loop\n      await sleep(delay);\n    }\n  }\n};\n","module.exports = require(\"mongodb\");","module.exports = require(\"zlib\");","module.exports = require(\"util\");","module.exports = require(\"url\");","module.exports = require(\"https\");","module.exports = require(\"http\");","import {\n  Collection as MCollection,\n  Binary as MBinary,\n  IndexSpecification,\n  MongoError,\n} from 'mongodb';\nimport type { IDable } from '../interfaces/IDable';\nimport BaseCollection from '../interfaces/BaseCollection';\nimport type { KeyOptions } from '../interfaces/Collection';\nimport type { DBKeys } from '../interfaces/DB';\nimport type { StateRef } from '../interfaces/BaseDB';\nimport { makeKeyValue, mapEntries, safeAdd, safeGet } from '../helpers/safeAccess';\nimport retry from '../helpers/retry';\n\nconst MONGO_ID = '_id';\nconst ID = 'id';\n\nconst DOT_REG = /\\./g;\nfunction fieldNameToMongo(name: string): string {\n  if (name === ID) {\n    return MONGO_ID;\n  }\n  if (name === '__proto__') {\n    // mongodb library itself cannot handle __proto__, so we encode the first underscore\n    return '%5F_proto__';\n  }\n  return encodeURIComponent(name).replace(DOT_REG, '%2E');\n}\n\nfunction fieldNameFromMongo(name: string): string {\n  if (name === MONGO_ID) {\n    return ID;\n  }\n  return decodeURIComponent(name);\n}\n\nfunction isBson(v: unknown): v is MBinary {\n  return (\n    Boolean(v) &&\n    typeof v === 'object' &&\n    /* eslint-disable-next-line no-underscore-dangle */\n    Boolean((v as any)._bsontype)\n  );\n}\n\nfunction valueToMongo(v: unknown): unknown {\n  if (v instanceof Buffer) {\n    return new MBinary(v);\n  }\n  if (isBson(v)) {\n    throw new Error('Must use Buffer to provide binary data');\n  }\n  return v;\n}\n\nfunction valueFromMongo(v: unknown): unknown {\n  if (isBson(v)) {\n    return v.buffer;\n  }\n  return v;\n}\n\nconst MONGO_ERROR_IDX = /^.*? index: ([^ ]+) dup key:.*$/;\nfunction getErrorIndex(e: MongoError): string {\n  return MONGO_ERROR_IDX.exec(e.message)?.[1] || '';\n}\n\nconst withUpsertRetry = retry((e) => (\n  e instanceof MongoError &&\n  e.code === 11000 &&\n  getErrorIndex(e) === '_id_'\n));\n\nfunction convertToMongo<T extends Partial<IDable>>(\n  value: T,\n): Record<string, unknown> {\n  return mapEntries(value, valueToMongo, fieldNameToMongo);\n}\n\nfunction convertFromMongo<T extends Partial<IDable>>(\n  value: Record<string, unknown> | null,\n): T | null {\n  if (!value) {\n    return null;\n  }\n  return mapEntries(value, valueFromMongo, fieldNameFromMongo) as T;\n}\n\nfunction makeMongoSearch(key: string, value: unknown): Record<string, unknown> {\n  return makeKeyValue(fieldNameToMongo(key), { $eq: valueToMongo(value) });\n}\n\nfunction makeMongoProjection(\n  names?: readonly string[],\n): Record<string, number> {\n  const projection: Record<string, number> = {};\n  if (names) {\n    projection[MONGO_ID] = 0;\n    names.forEach((fieldName) => safeAdd(projection, fieldNameToMongo(fieldName), 1));\n  }\n  return projection;\n}\n\ninterface MongoIndex {\n  name: string;\n  key: Record<string, -1 | 0 | 1 | 'hashed'>;\n  unique?: boolean;\n}\n\nfunction makeIndex(keyName: string, options: KeyOptions = {}): IndexSpecification {\n  const unique = Boolean(options.unique);\n  return {\n    key: makeKeyValue(fieldNameToMongo(keyName), unique ? 1 : 'hashed'),\n    unique,\n  };\n}\n\nfunction indicesMatch(a: IndexSpecification, b: IndexSpecification): boolean {\n  if (Boolean(a.unique) !== Boolean(b.unique)) {\n    return false;\n  }\n  const keys = Object.entries(a.key);\n  if (Object.keys(b.key).length !== keys.length) {\n    return false;\n  }\n  return keys.every(([k, aVal]) => (aVal === safeGet(b.key, k)));\n}\n\nasync function configureCollection(\n  collection: MCollection,\n  keys: DBKeys<any> = {},\n): Promise<void> {\n  const existing: MongoIndex[] = await collection.indexes().catch(() => []);\n  const idxToCreate: IndexSpecification[] = [];\n  const idxToDelete = new Set(existing.map((idx) => idx.name));\n  idxToDelete.delete('_id_'); // MongoDB implicit primary key\n\n  Object.entries(keys)\n    .map(([keyName, options]) => makeIndex(keyName, options))\n    .forEach((index) => {\n      const match = existing.find((idx) => indicesMatch(idx, index));\n      if (match) {\n        idxToDelete.delete(match.name);\n      } else {\n        idxToCreate.push(index);\n      }\n    });\n  if (idxToCreate.length) {\n    await collection.createIndexes(idxToCreate);\n  }\n  if (idxToDelete.size) {\n    await Promise.all([...idxToDelete].map((idxName) => collection.dropIndex(idxName)));\n  }\n}\n\nexport default class MongoCollection<T extends IDable> extends BaseCollection<T> {\n  public constructor(\n    private readonly collection: MCollection,\n    keys: DBKeys<T> = {},\n    private readonly stateRef: StateRef = { closed: false },\n  ) {\n    super(keys);\n    this.initAsync(configureCollection(collection, keys));\n  }\n\n  protected preAct(): void {\n    if (this.stateRef.closed) {\n      throw new Error('Connection closed');\n    }\n  }\n\n  protected async internalAdd(value: T): Promise<void> {\n    await this.collection.insertOne(convertToMongo(value));\n  }\n\n  protected async internalUpsert(\n    id: T['id'],\n    update: Partial<T>,\n  ): Promise<void> {\n    await withUpsertRetry(() => this.collection.updateOne(\n      makeMongoSearch('id', id),\n      { $set: convertToMongo(update) },\n      { upsert: true },\n    ));\n  }\n\n  protected async internalUpdate<K extends string & keyof T>(\n    searchAttribute: K,\n    searchValue: T[K],\n    update: Partial<T>,\n  ): Promise<void> {\n    const query = makeMongoSearch(searchAttribute, searchValue);\n    const mongoUpdate = { $set: convertToMongo(update) };\n    try {\n      if (this.indices.isUniqueIndex(searchAttribute)) {\n        await this.collection.updateOne(query, mongoUpdate);\n      } else {\n        await this.collection.updateMany(query, mongoUpdate);\n      }\n    } catch (e) {\n      if (e.message.includes('would modify the immutable field \\'_id\\'')) {\n        throw new Error('Cannot update ID');\n      } else {\n        throw e;\n      }\n    }\n  }\n\n  protected async internalGet<\n    K extends string & keyof T,\n    F extends readonly (string & keyof T)[]\n  >(\n    searchAttribute: K,\n    searchValue: T[K],\n    returnAttributes?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>> | null> {\n    const raw = await this.collection.findOne(\n      makeMongoSearch(searchAttribute, searchValue),\n      { projection: makeMongoProjection(returnAttributes) },\n    );\n    return convertFromMongo<T>(raw);\n  }\n\n  protected async internalGetAll<\n    K extends string & keyof T,\n    F extends readonly (string & keyof T)[]\n  >(\n    searchAttribute?: K,\n    searchValue?: T[K],\n    returnAttributes?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>>[]> {\n    const cursor = this.collection.find(\n      searchAttribute ? makeMongoSearch(searchAttribute, searchValue) : {},\n      { projection: makeMongoProjection(returnAttributes) },\n    );\n\n    const result: Pick<T, F[-1]>[] = [];\n    await cursor.forEach((raw) => result.push(convertFromMongo<T>(raw)!));\n\n    return result;\n  }\n\n  protected async internalRemove<K extends string & keyof T>(\n    searchAttribute: K,\n    searchValue: T[K],\n  ): Promise<number> {\n    const result = await this.collection.deleteMany(\n      makeMongoSearch(searchAttribute, searchValue),\n    );\n    return result.deletedCount || 0;\n  }\n}\n","module.exports = require(\"ioredis\");","module.exports = require(\"pg\");","// B = base64 binary\n// b = raw binary (*Bin functions only)\n// s = raw utf8 string\n// t = true\n// f = false\n// n = null\n// J = JSON (also accepts any plain JSON value for compatibility)\n\nimport { safeAdd } from './safeAccess';\n\nconst JSON_INIT_CHARS = '{[\"0123456789-'; // t/f/n are dedicated values\nconst MARK_BINARY = 'b'.charCodeAt(0);\nconst MARK_STRING = 's'.charCodeAt(0);\n\nconst MARK_BINARY_BUFF = Uint8Array.of(MARK_BINARY);\n\nexport function canonicalJSON(o: Record<string, unknown> | undefined): string {\n  if (!o) {\n    return 'null';\n  }\n  const content = Object.keys(o)\n    .sort()\n    .map((k) => `${JSON.stringify(k)}:${JSON.stringify(o[k])}`)\n    .join(',');\n  return `{${content}}`;\n}\n\nexport function serialiseValue(value: unknown): string {\n  if (value instanceof Buffer) {\n    return `B${value.toString('base64')}`;\n  }\n  if (typeof value === 'string') {\n    return `s${value}`;\n  }\n  if (typeof value === 'boolean') {\n    return value ? 't' : 'f';\n  }\n  if (value === null) {\n    return 'n';\n  }\n  return `J${JSON.stringify(value)}`;\n}\n\nexport function deserialiseValue(value: string): unknown {\n  const type = value[0];\n  const data = value.substr(1);\n  switch (type) {\n    case 'B': return Buffer.from(data, 'base64');\n    case 's': return data;\n    case 't': return true;\n    case 'f': return false;\n    case 'n': return null;\n    case 'J': return JSON.parse(data);\n    default:\n      if (JSON_INIT_CHARS.includes(type)) {\n        return JSON.parse(value);\n      }\n      throw new Error(`Unknown data type ${type}`);\n  }\n}\n\nexport function serialiseValueBin(value: unknown): Buffer {\n  if (value instanceof Buffer) {\n    return Buffer.concat([MARK_BINARY_BUFF, value]);\n  }\n  return Buffer.from(serialiseValue(value), 'utf8');\n}\n\nexport function deserialiseValueBin(value: Buffer | string): unknown {\n  if (typeof value === 'string') {\n    return deserialiseValue(value);\n  }\n\n  const type = value[0];\n  if (type === MARK_BINARY) {\n    return value.subarray(1);\n  }\n  if (type === MARK_STRING) {\n    return value.subarray(1).toString('utf8');\n  }\n  return deserialiseValue(value.toString('utf8'));\n}\n\nexport type Serialised<T> = Map<string & keyof T, string>;\n\nexport function serialiseRecord<T>(item: T): Serialised<T> {\n  return new Map(Object.entries(item)\n    .map(([k, v]) => [k as string & keyof T, serialiseValue(v)]));\n}\n\nexport function deserialiseRecord<T>(serialised: Serialised<T>): T {\n  const result = {} as T;\n  serialised.forEach((v, k) => safeAdd(result, k, deserialiseValue(v)));\n  return result;\n}\n\nexport function partialDeserialiseRecord<T, F extends readonly (string & keyof T)[]>(\n  serialised: Serialised<T>,\n  fields?: F,\n): Pick<T, F[-1]> {\n  if (!fields) {\n    return deserialiseRecord(serialised);\n  }\n  const result = {} as T;\n  fields.forEach((k) => {\n    const raw = serialised.get(k);\n    if (raw) {\n      safeAdd(result, k, deserialiseValue(raw));\n    }\n  });\n  return result;\n}\n","import type { IDable } from '../interfaces/IDable';\nimport BaseCollection from '../interfaces/BaseCollection';\nimport type { DBKeys } from '../interfaces/DB';\nimport type { StateRef } from '../interfaces/BaseDB';\nimport {\n  serialiseValue,\n  serialiseRecord,\n  deserialiseRecord,\n  Serialised,\n  partialDeserialiseRecord,\n} from '../helpers/serialiser';\n\nfunction sleep(millis: number): Promise<void> | void {\n  if (!millis) {\n    return undefined;\n  }\n\n  // Simulate data access delays to ensure non-flakey e2e tests, etc.\n  return new Promise((resolve): any => setTimeout(resolve, millis));\n}\n\nexport default class MemoryCollection<T extends IDable> extends BaseCollection<T> {\n  private readonly data = new Map<string, Serialised<T>>();\n\n  private readonly customIndexData: Map<string & keyof T, Map<string, Set<string>>>;\n\n  private readonly uniqueIndexDataPtrs: [string & keyof T, Map<string, Set<string>>][];\n\n  public constructor(\n    keys: DBKeys<T> = {},\n    private readonly simulatedLatency = 0,\n    private readonly stateRef: StateRef = { closed: false },\n  ) {\n    super(keys);\n\n    this.customIndexData = new Map(this.indices.getCustomIndices().map((k) => ([k, new Map()])));\n\n    this.uniqueIndexDataPtrs = this.indices.getUniqueIndices()\n      .filter((k) => (k !== 'id'))\n      .map((k) => ([k, this.customIndexData.get(k)!]));\n  }\n\n  protected preAct(): Promise<void> | void {\n    if (this.stateRef.closed) {\n      throw new Error('Connection closed');\n    }\n    return sleep(this.simulatedLatency);\n  }\n\n  protected async internalAdd(value: T): Promise<void> {\n    const serialised = serialiseRecord(value);\n    this.internalCheckDuplicates(serialised, true);\n    this.data.set(serialised.get('id')!, serialised);\n    this.internalPopulateIndices(serialised);\n  }\n\n  protected internalUpsert(\n    id: T['id'],\n    update: Partial<T>,\n  ): Promise<void> {\n    if (this.data.has(serialiseValue(id))) {\n      return this.internalUpdate('id', id, update);\n    }\n    return this.internalAdd({ id, ...update } as T);\n  }\n\n  protected async internalUpdate<K extends string & keyof T>(\n    searchAttribute: K,\n    searchValue: T[K],\n    update: Partial<T>,\n  ): Promise<void> {\n    const sIds = this.internalGetSerialisedIds(searchAttribute, searchValue);\n\n    const updates = sIds.map((sId) => {\n      const oldSerialised = this.data.get(sId)!;\n      const oldValue = deserialiseRecord(oldSerialised);\n      const newValue = { ...oldValue, ...update };\n      if (newValue.id !== oldValue.id) {\n        throw new Error('Cannot update ID');\n      }\n      const newSerialised = serialiseRecord(newValue);\n      return { oldSerialised, newSerialised };\n    });\n\n    updates.forEach(({ oldSerialised }) => this.internalRemoveIndices(oldSerialised));\n    try {\n      updates.forEach(({ newSerialised }) => this.internalCheckDuplicates(newSerialised, false));\n    } catch (e) {\n      updates.forEach(({ oldSerialised }) => this.internalPopulateIndices(oldSerialised));\n      throw e;\n    }\n    updates.forEach(({ newSerialised }) => {\n      this.data.set(newSerialised.get('id')!, newSerialised);\n      this.internalPopulateIndices(newSerialised);\n    });\n  }\n\n  protected async internalGetAll<\n    K extends string & keyof T,\n    F extends readonly (string & keyof T)[]\n  >(\n    searchAttribute?: K,\n    searchValue?: T[K],\n    returnAttributes?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>>[]> {\n    let sIds: string[];\n    if (searchAttribute) {\n      sIds = this.internalGetSerialisedIds(searchAttribute, searchValue!);\n    } else {\n      sIds = [...this.data.keys()];\n    }\n    return sIds.map((sId) => partialDeserialiseRecord(this.data.get(sId)!, returnAttributes));\n  }\n\n  protected async internalRemove<K extends string & keyof T>(\n    searchAttribute: K,\n    searchValue: T[K],\n  ): Promise<number> {\n    const sIds = this.internalGetSerialisedIds(searchAttribute, searchValue);\n    sIds.forEach((sId) => {\n      const oldSerialised = this.data.get(sId)!;\n      this.internalRemoveIndices(oldSerialised);\n      this.data.delete(sId);\n    });\n\n    return sIds.length;\n  }\n\n  private internalGetSerialisedIds<K extends string & keyof T>(\n    searchAttribute: K,\n    searchValue: T[K],\n  ): string[] {\n    const sKey = serialiseValue(searchValue);\n    if (searchAttribute === 'id') {\n      return this.data.has(sKey) ? [sKey] : [];\n    }\n    const index = this.customIndexData.get(searchAttribute);\n    if (!index) {\n      throw new Error(`Requested key ${searchAttribute} not indexed`);\n    }\n    const sIds = index.get(sKey);\n    return sIds ? [...sIds] : []; // convert set to array\n  }\n\n  private internalCheckDuplicates(serialisedValue: Serialised<T>, checkId: boolean): void {\n    if (checkId && this.data.has(serialisedValue.get('id')!)) {\n      throw new Error('duplicate');\n    }\n    this.uniqueIndexDataPtrs.forEach(([key, index]) => {\n      if (index.has(serialisedValue.get(key)!)) {\n        throw new Error('duplicate');\n      }\n    });\n  }\n\n  private internalPopulateIndices(serialisedValue: Serialised<T>): void {\n    const id = serialisedValue.get('id')!;\n    this.customIndexData.forEach((index, key) => {\n      const v = serialisedValue.get(key)!;\n      let o = index.get(v);\n      if (!o) {\n        o = new Set<string>();\n        index.set(v, o);\n      }\n      o.add(id);\n    });\n  }\n\n  private internalRemoveIndices(serialisedValue: Serialised<T>): void {\n    const id = serialisedValue.get('id')!;\n    this.customIndexData.forEach((index, key) => {\n      const v = serialisedValue.get(key)!;\n      const o = index.get(v)!;\n      o.delete(id);\n      if (!o.size) {\n        index.delete(v);\n      }\n    });\n  }\n}\n","import type { Collection } from './Collection';\nimport type { IDable } from './IDable';\nimport type { DB, DBKeys } from './DB';\nimport { canonicalJSON } from '../helpers/serialiser';\n\nexport interface StateRef {\n  closed: boolean;\n}\n\ninterface AsyncCollection<T extends IDable> extends Collection<T> {\n  internalReady?: () => Promise<void>;\n}\n\nexport default abstract class BaseDB implements DB {\n  protected readonly stateRef: StateRef = { closed: false };\n\n  private readonly collectionCache = new Map<string, [string, Collection<any>]>();\n\n  constructor(\n    private readonly makeCollection: <T extends IDable>(\n      name: string,\n      keys?: DBKeys<T>,\n    ) => Collection<T>,\n  ) {}\n\n  public getCollection<T extends IDable>(name: string, keys?: DBKeys<T>): Collection<T> {\n    const cached = this.collectionCache.get(name);\n    const normKeys = canonicalJSON(keys);\n    if (cached) {\n      const [cachedNormKeys, cachedCol] = cached;\n      if (normKeys !== cachedNormKeys) {\n        throw new Error(`Cannot requuest collection '${name}' with different keys`);\n      }\n      return cachedCol;\n    }\n    const created = this.makeCollection(name, keys) as AsyncCollection<T>;\n    this.collectionCache.set(name, [normKeys, created]);\n    return created;\n  }\n\n  close(): Promise<void> | void {\n    if (this.stateRef.closed) {\n      return undefined;\n    }\n    this.syncClose();\n    const toAwait = [...this.collectionCache.values()]\n      .map(([, c]) => (c as AsyncCollection<IDable>).internalReady?.());\n    return Promise.allSettled(toAwait).then(() => this.internalClose());\n  }\n\n  protected syncClose(): void {\n    this.stateRef.closed = true;\n  }\n\n  // eslint-disable-next-line class-methods-use-this\n  protected internalClose(): Promise<void> | void {}\n}\n","import { URL } from 'url';\nimport MemoryCollection from './MemoryCollection';\nimport type { DBKeys } from '../interfaces/DB';\nimport type { IDable } from '../interfaces/IDable';\nimport BaseDB from '../interfaces/BaseDB';\n\nfunction getGlobal<T>(name: string, initial: T): T {\n  const existing = (global as any)[name];\n  if (existing) {\n    return existing;\n  }\n\n  (global as any)[name] = initial;\n  return initial;\n}\n\nconst globalDbs = getGlobal(\n  'collectionStorageInMemory',\n  new Map<string, MemoryDb>(),\n);\n\nexport default class MemoryDb extends BaseDB {\n  public constructor({ simulatedLatency = 0 } = {}) {\n    super((name, keys) => new MemoryCollection(keys, simulatedLatency, this.stateRef));\n  }\n\n  public static connect(url: string): MemoryDb {\n    const parsedUrl = new URL(url);\n    const name = parsedUrl.hostname;\n    if (name && globalDbs.has(name)) {\n      return globalDbs.get(name)!;\n    }\n    const params = parsedUrl.searchParams;\n    const simulatedLatency = Number(params.get('simulatedLatency'));\n    const db = new MemoryDb({ simulatedLatency });\n    if (name) {\n      globalDbs.set(name, db);\n    }\n    return db;\n  }\n\n  public getCollection<T extends IDable>(name: string, keys?: DBKeys<T>): MemoryCollection<T> {\n    return super.getCollection(name, keys) as MemoryCollection<T>;\n  }\n\n  public close(): void {\n    this.syncClose();\n  }\n}\n","import type { Db as MongoDbT, MongoClient as MongoClientT } from 'mongodb';\nimport type { DBKeys } from '../interfaces/DB';\nimport BaseDB from '../interfaces/BaseDB';\nimport type { IDable } from '../interfaces/IDable';\nimport type MongoCollectionT from './MongoCollection';\n\nfunction escapeName(name: string): string {\n  return encodeURIComponent(name);\n}\n\nexport default class MongoDb extends BaseDB {\n  private constructor(\n    private readonly client: MongoClientT,\n    MongoCollection: typeof MongoCollectionT,\n  ) {\n    super((name, keys) => new MongoCollection(\n      this.client.db().collection(escapeName(name)),\n      keys,\n      this.stateRef,\n    ));\n  }\n\n  public static async connect(url: string): Promise<MongoDb> {\n    const { MongoClient } = await import('mongodb');\n    const {\n      default: MongoCollection,\n    } = await import(/* webpackMode: \"eager\" */ './MongoCollection');\n    const client = await MongoClient.connect(url, {\n      useNewUrlParser: true,\n      useUnifiedTopology: true,\n    });\n    return new MongoDb(client, MongoCollection);\n  }\n\n  public getCollection<T extends IDable>(name: string, keys?: DBKeys<T>): MongoCollectionT<T> {\n    return super.getCollection(name, keys) as MongoCollectionT<T>;\n  }\n\n  public getDb(): MongoDbT {\n    return this.client.db();\n  }\n\n  protected internalClose(): Promise<void> {\n    return this.client.close();\n  }\n}\n","import type AWS from './AWS';\n\nexport interface Results<I> {\n  batched(consumer: (items: Readonly<I[]>) => (Promise<void> | void)): Promise<void> | void;\n\n  all(): Promise<Readonly<I[]>> | Readonly<I[]>;\n}\n\nexport class Paged<K, I> implements Results<I> {\n  constructor(\n    private readonly aws: AWS,\n    private readonly fn: (start: K | undefined) => Promise<[I[], K]>,\n    private readonly pageLimit = Number.POSITIVE_INFINITY,\n  ) {}\n\n  batched(consumer: (items: I[]) => (Promise<void> | void)): Promise<void> {\n    return this.aws.do(async () => {\n      let lastKey: K | undefined;\n      /* eslint-disable no-await-in-loop */ // pagination must be serial\n      for (let page = 0; page < this.pageLimit; page += 1) {\n        const [pageItems, nextKey]: [I[], K] = await this.fn(lastKey);\n        await consumer(pageItems);\n        lastKey = nextKey;\n        if (!lastKey) {\n          return;\n        }\n      }\n      /* eslint-enable no-await-in-loop */\n      throw new Error('Too many items');\n    });\n  }\n\n  async all(): Promise<I[]> {\n    const items: I[] = [];\n    await this.batched((i) => {\n      items.push(...i);\n    });\n    return items;\n  }\n}\n","// https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Programming.Errors.html\n\nexport default class AWSError extends Error {\n  constructor(\n    private readonly status: number,\n    private readonly type: string,\n    message: string,\n  ) {\n    super(`AWS error ${status}; type: ${type}; message: ${message}`);\n  }\n\n  static isType(e: unknown, type: string): boolean {\n    return (\n      (e instanceof AWSError && e.isType(type)) ||\n      (e instanceof Error && e.message === type)\n    );\n  }\n\n  isType(type: string): boolean {\n    return this.type.endsWith(`#${type}`) || this.type === type;\n  }\n\n  isTransient(): boolean {\n    return (\n      this.status >= 500 ||\n      this.type.endsWith('#LimitExceededException') ||\n      this.type.endsWith('#ProvisionedThroughputExceededException') ||\n      this.type.endsWith('#RequestLimitExceeded') ||\n      this.type.endsWith('#ThrottlingException')\n    );\n  }\n}\n","import type AWS from './AWS';\nimport { Results, Paged } from './Results';\nimport AWSError from './AWSError';\nimport retry from '../../helpers/retry';\nimport { makeKeyValue, safeAdd, safeGet } from '../../helpers/safeAccess';\n\n// https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/Welcome.html\n\nexport type DDBValue =\n  { S: string } |\n  { N: string } | // number\n  { B: string } | // binary (base64)\n  { BOOL: boolean } |\n  { NULL: true } |\n  { M: Record<string, DDBValue> } |\n  { L: DDBValue[] } |\n  { SS: string[] } | // stringset\n  { NS: string[] } | // numberset\n  { BS: string[] }; // binaryset (base64)\n\nexport type DDBItem = Record<string, DDBValue>;\n\ntype DDBType = 'S' | 'N' | 'B' | 'BOOL' | 'NULL' | 'M' | 'L' | 'SS' | 'NS' | 'BS';\ntype DDBKeyType = 'HASH' | 'RANGE';\n\ninterface DDBConsumedCapacity {\n  CapacityUnits: number;\n}\n\ninterface DDBResponse {\n  ConsumedCapacity?: DDBConsumedCapacity | DDBConsumedCapacity[];\n}\n\ninterface DDBReturnedItem extends DDBResponse {\n  Attributes: DDBItem;\n}\n\ninterface DDBGetResponse extends DDBResponse {\n  Item: DDBItem;\n}\n\ninterface DDBBatchGetResponse extends DDBResponse {\n  Responses: Record<string, DDBItem[]>;\n  UnprocessedKeys: Record<string, {\n    Keys: DDBItem[];\n  }>;\n}\n\ninterface DDBBatchWriteResponse extends DDBResponse {\n  UnprocessedItems: Record<string, {\n    DeleteRequest?: {\n      Key: DDBItem;\n    };\n    PutRequest?: {\n      Item: DDBItem;\n    };\n  }[]>;\n}\n\ninterface DDBListTablesResponse extends DDBResponse {\n  TableNames: string[];\n  LastEvaluatedTableName?: string;\n}\n\ninterface DDBScanResponse extends DDBResponse {\n  Items: DDBItem[];\n  LastEvaluatedKey?: DDBItem;\n}\n\nexport interface DDBProvisionedThroughput {\n  ReadCapacityUnits: number;\n  WriteCapacityUnits: number;\n}\n\ninterface DDBGlobalSecondaryIndex {\n  Backfilling?: boolean;\n  IndexName: string;\n  IndexStatus?: string;\n  KeySchema: {\n    AttributeName: string;\n    KeyType: DDBKeyType;\n  }[];\n  Projection?: {\n    NonKeyAttributes?: string[];\n    ProjectionType: string;\n  };\n  ProvisionedThroughput?: DDBProvisionedThroughput;\n}\n\ninterface DDBAttributeDefinition {\n  AttributeName: string;\n  AttributeType: string;\n}\n\ninterface DDBDescribeResponse extends DDBResponse {\n  Table: {\n    AttributeDefinitions: DDBAttributeDefinition[];\n    GlobalSecondaryIndexes?: DDBGlobalSecondaryIndex[];\n    ItemCount: number;\n    KeySchema: {\n      AttributeName: string;\n      KeyType: DDBKeyType;\n    }[];\n    TableStatus: string;\n    ProvisionedThroughput: DDBProvisionedThroughput;\n  };\n}\n\ninterface KeyDefinition {\n  attributeName: string;\n  attributeType: DDBType;\n  keyType: DDBKeyType;\n}\n\ninterface GlobalSecondaryIndexDefinition {\n  indexName: string;\n  keySchema: KeyDefinition[];\n  projectionType?: 'KEYS_ONLY' | 'INCLUDE' | 'ALL';\n  nonKeyAttributes?: string[];\n  throughput?: DDBProvisionedThroughput;\n}\n\nconst AWS_URL_FORMAT = /^([^:]*):\\/\\/dynamodb\\.([^.]+)\\.amazonaws\\.com(\\/?.*)$/;\nconst ResourceInUseException = 'ResourceInUseException';\nconst ResourceNotFoundException = 'ResourceNotFoundException';\n\nfunction ifNotEmpty<T extends any[] | string>(l: T): T | undefined {\n  return l.length ? l : undefined;\n}\n\nfunction flatten(value: DDBItem, keys: string[]): string {\n  // this is only used for internal short-term lookups, so securing value[key] is not necessary\n  return keys.map((key) => JSON.stringify(value[key])).join();\n}\n\ninterface ExpressionDefinition {\n  attributeExpression: (attr: string, value: string) => string;\n  joiner: string | ((items: string[]) => string);\n  attributes: Readonly<DDBItem | string[]>;\n}\n\nfunction escapedExpressions(\n  expressions: Record<string, ExpressionDefinition>,\n): Record<string, unknown> {\n  let i = 0;\n  const attrValues: DDBItem = {};\n  const attrNames: Record<string, string> = {};\n  let hasExpr = false;\n  let hasAnyValues = false;\n  const result: Record<string, unknown> = {};\n\n  Object.entries(expressions).forEach(([key, { attributeExpression, joiner, attributes }]) => {\n    const parts: string[] = [];\n    if (Array.isArray(attributes)) {\n      if (!attributes.length) {\n        return;\n      }\n      attributes.forEach((attr) => {\n        const attrName = `#${i}`;\n        const attrValue = `:${i}`;\n        parts.push(attributeExpression(attrName, attrValue));\n        safeAdd(attrNames, attrName, attr);\n        i += 1;\n      });\n    } else {\n      const rawAttr = Object.entries(attributes);\n      if (!rawAttr.length) {\n        return;\n      }\n      rawAttr.forEach(([attr, value]) => {\n        const attrName = `#${i}`;\n        const attrValue = `:${i}`;\n        parts.push(attributeExpression(attrName, attrValue));\n        safeAdd(attrNames, attrName, attr);\n        safeAdd(attrValues, attrValue, value);\n        i += 1;\n      });\n      hasAnyValues = true;\n    }\n\n    // key is trusted\n    result[key] = typeof joiner === 'string' ? parts.join(joiner) : joiner(parts);\n    hasExpr = true;\n  });\n\n  if (!hasExpr) {\n    return {};\n  }\n\n  return {\n    ...result,\n    ExpressionAttributeValues: hasAnyValues ? attrValues : undefined,\n    ExpressionAttributeNames: attrNames,\n  };\n}\n\nconst projection = (attrs: readonly string[] | undefined): ExpressionDefinition => ({\n  attributeExpression: (attr): string => attr,\n  joiner: ',',\n  attributes: attrs || [],\n});\n\nconst retryPolling = retry(\n  (e) => (AWSError.isType(e, ResourceNotFoundException) || e.message === 'pending'),\n  { timeoutMillis: 60000, maxDelayMillis: 1000, jitter: false },\n);\nconst retryRemaining = retry(\n  (e) => (e.message === 'remaining unprocessed items'),\n);\n\nconst INVALID_NAME_CHARS = /[^-a-zA-Z0-9_.]/g;\n\nexport function escapeName(name: string): string {\n  // no standard escape scheme conforms to DDB restrictions, so this is home-grown:\n  // (does not attempt to ensure no collisions; more important to allow valid\n  // names through unchanged)\n  return name.replace(INVALID_NAME_CHARS, (c) => {\n    const code = c.charCodeAt(0);\n    const hex = code.toString(16);\n    if (hex.length <= 2) {\n      return `_u${hex.padStart(2, '0')}`;\n    }\n    return `_U${hex.padStart(4, '0')}`;\n  }).padEnd(3, '_');\n}\n\ninterface DDBOptions {\n  consistentRead?: boolean;\n}\n\nfunction createAttributeDefinitions(schemas: KeyDefinition[][]): DDBAttributeDefinition[] {\n  const attrs = new Map<string, DDBType>();\n  schemas.forEach((keys) => keys.forEach(({ attributeName, attributeType }) => {\n    if (!attrs.has(attributeName)) {\n      attrs.set(attributeName, attributeType);\n    } else if (attrs.get(attributeName) !== attributeType) {\n      throw new Error(`inconsistent attribute type for ${attributeName}`);\n    }\n  }));\n  return [...attrs.entries()].map(([attributeName, attributeType]) => ({\n    AttributeName: attributeName,\n    AttributeType: attributeType,\n  }));\n}\n\nfunction createSecondaryIndex(i: GlobalSecondaryIndexDefinition): DDBGlobalSecondaryIndex {\n  return {\n    IndexName: i.indexName,\n    KeySchema: i.keySchema.map(({ attributeName, keyType }) => ({\n      AttributeName: attributeName,\n      KeyType: keyType,\n    })),\n    Projection: {\n      ProjectionType: i.projectionType || (i.nonKeyAttributes ? 'INCLUDE' : 'KEYS_ONLY'),\n      NonKeyAttributes: i.nonKeyAttributes,\n    },\n    ProvisionedThroughput: i.throughput,\n  };\n}\n\nfunction indicesMatch(a: GlobalSecondaryIndexDefinition, b: DDBGlobalSecondaryIndex): boolean {\n  if (a.keySchema.length !== b.KeySchema.length) {\n    return false;\n  }\n  return a.keySchema.every((k, i) => (\n    k.attributeName === b.KeySchema[i].AttributeName &&\n    k.keyType === b.KeySchema[i].KeyType\n  ));\n}\n\nexport class DDB {\n  private readonly region: string;\n\n  private readonly consistentRead: boolean;\n\n  private totalCapacityUnits = 0;\n\n  constructor(\n    private readonly aws: AWS,\n    private readonly host: string,\n    { consistentRead = false }: DDBOptions = {},\n  ) {\n    const parts = AWS_URL_FORMAT.exec(host);\n    if (parts) {\n      [, this.region] = parts;\n    } else {\n      this.region = 'us-east-1'; // default region for API calls\n    }\n    this.consistentRead = consistentRead;\n  }\n\n  getConsumedUnits(): number {\n    return this.totalCapacityUnits;\n  }\n\n  getTableNames(): Results<string> {\n    // https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_ListTables.html\n    return new Paged(this.aws, async (lastTableName) => {\n      const response: DDBListTablesResponse = await this.call('ListTables', {\n        ExclusiveStartTableName: lastTableName,\n      });\n      return [response.TableNames, response.LastEvaluatedTableName];\n    }, 10);\n  }\n\n  upsertTable(\n    tableName: string,\n    pKeySchema: KeyDefinition[],\n    secondaryIndices: GlobalSecondaryIndexDefinition[] = [],\n    waitForReady: boolean,\n    throughput?: DDBProvisionedThroughput,\n  ): Promise<boolean> {\n    // https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_CreateTable.html\n    return this.aws.do(async () => {\n      let created = false;\n      try {\n        await this.call('CreateTable', {\n          TableName: tableName,\n          AttributeDefinitions: createAttributeDefinitions([\n            pKeySchema,\n            ...secondaryIndices.map(({ keySchema }) => keySchema),\n          ]),\n          KeySchema: pKeySchema.map(({ attributeName, keyType }) => ({\n            AttributeName: attributeName,\n            KeyType: keyType,\n          })),\n          GlobalSecondaryIndexes: ifNotEmpty(secondaryIndices.map(\n            (i) => createSecondaryIndex(i),\n          )),\n          BillingMode: throughput ? 'PROVISIONED' : 'PAY_PER_REQUEST',\n          ProvisionedThroughput: throughput,\n        });\n        created = true;\n      } catch (e) {\n        if (AWSError.isType(e, ResourceInUseException)) {\n          await this.replaceIndices(tableName, secondaryIndices);\n        } else {\n          throw e;\n        }\n      }\n\n      if (waitForReady) {\n        await this.waitForTable(tableName, true);\n      }\n\n      return created;\n    });\n  }\n\n  describeTable(tableName: string): Promise<DDBDescribeResponse> {\n    // https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_DescribeTable.html\n    return this.call('DescribeTable', { TableName: tableName });\n  }\n\n  waitForTable(tableName: string, waitForIndices: boolean): Promise<void> {\n    return retryPolling(async () => {\n      const desc = await this.describeTable(tableName);\n      if (desc.Table.TableStatus !== 'ACTIVE') {\n        throw new Error('pending');\n      }\n      const indices = desc.Table.GlobalSecondaryIndexes;\n      if (waitForIndices && indices && indices.some((i) => (i.IndexStatus !== 'ACTIVE'))) {\n        throw new Error('pending');\n      }\n    });\n  }\n\n  async deleteTable(tableName: string): Promise<void> {\n    // https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_DeleteTable.html\n    await this.call('DeleteTable', { TableName: tableName });\n  }\n\n  async putItem(tableName: string, item: DDBItem, unique?: string): Promise<void> {\n    // https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_PutItem.html\n    await this.call('PutItem', {\n      TableName: tableName,\n      Item: item,\n      ...escapedExpressions({\n        ConditionExpression: {\n          attributeExpression: (attr): string => `attribute_not_exists(${attr})`,\n          joiner: ' and ',\n          attributes: unique ? [unique] : [],\n        },\n      }),\n      ReturnConsumedCapacity: 'TOTAL',\n    });\n  }\n\n  async updateItem(\n    tableName: string,\n    key: DDBItem,\n    update: DDBItem,\n    condition?: DDBItem,\n  ): Promise<void> {\n    // https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_UpdateItem.html\n    await this.call('UpdateItem', {\n      TableName: tableName,\n      Key: key,\n      ...escapedExpressions({\n        UpdateExpression: {\n          attributeExpression: (attr, value): string => `${attr}=${value}`,\n          joiner: (l): string => `SET ${l.join(',')}`,\n          attributes: update,\n        },\n        ConditionExpression: {\n          attributeExpression: (attr, value): string => `${attr}=${value}`,\n          joiner: ' and ',\n          attributes: condition || {},\n        },\n      }),\n      ReturnConsumedCapacity: 'TOTAL',\n    });\n  }\n\n  async getItem(\n    tableName: string,\n    key: DDBItem,\n    requestedAttrs?: readonly string[],\n  ): Promise<DDBItem | null> {\n    // https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_GetItem.html\n    const data: DDBGetResponse = await this.call('GetItem', {\n      TableName: tableName,\n      Key: key,\n      ...escapedExpressions({ ProjectionExpression: projection(requestedAttrs) }),\n      ConsistentRead: this.consistentRead,\n      ReturnConsumedCapacity: 'TOTAL',\n    });\n\n    // DDB is inconsistent in how it returns 'not found' state:\n    if (!data.Item || !Object.keys(data.Item).length) {\n      return null;\n    }\n    return data.Item;\n  }\n\n  async batchGetItems(\n    tableName: string,\n    keys: DDBItem[],\n    requestedAttrs?: readonly string[],\n  ): Promise<(DDBItem | null)[]> {\n    // https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_BatchGetItem.html\n    if (!keys.length) {\n      return [];\n    }\n    if (keys.length === 1) {\n      return [await this.getItem(tableName, keys[0], requestedAttrs)];\n    }\n\n    const keyAttrs = Object.keys(keys[0]);\n    const fullAttrs = requestedAttrs?.slice();\n    if (fullAttrs) {\n      keyAttrs.forEach((k) => {\n        if (!fullAttrs.includes(k)) {\n          fullAttrs.push(k);\n        }\n      });\n    }\n\n    const indices = new Map<string, number>();\n    keys.forEach((key, i) => indices.set(flatten(key, keyAttrs), i));\n\n    const extracted: (DDBItem | null)[] = keys.map(() => null);\n    const tableQuery = {\n      ...escapedExpressions({ ProjectionExpression: projection(fullAttrs) }),\n      ConsistentRead: this.consistentRead,\n    };\n\n    await this.callBatched(keys, 100, async (batchKeys) => {\n      const data: DDBBatchGetResponse = await this.call('BatchGetItem', {\n        RequestItems: makeKeyValue(tableName, {\n          ...tableQuery,\n          Keys: batchKeys,\n        }),\n        ReturnConsumedCapacity: 'TOTAL',\n      });\n      safeGet(data.Responses, tableName)!.forEach((item) => {\n        const index = indices.get(flatten(item, keyAttrs));\n        if (index !== undefined) {\n          extracted[index] = item;\n        }\n      });\n      return safeGet(data.UnprocessedKeys, tableName)?.Keys || [];\n    });\n\n    return extracted;\n  }\n\n  batchPutItems(tableName: string, items: DDBItem[]): Promise<void> {\n    // https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_BatchWriteItem.html\n    return this.callBatched(items, 25, async (batchItems) => {\n      const data: DDBBatchWriteResponse = await this.call('BatchWriteItem', {\n        RequestItems: makeKeyValue(tableName, batchItems.map((item) => ({\n          PutRequest: { Item: item },\n        }))),\n        ReturnConsumedCapacity: 'TOTAL',\n      });\n      return (safeGet(data.UnprocessedItems, tableName) || []).map((i) => i.PutRequest!.Item);\n    });\n  }\n\n  batchDeleteItems(tableName: string, keys: DDBItem[]): Promise<void> {\n    // https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_BatchWriteItem.html\n    return this.callBatched(keys, 25, async (batchKeys) => {\n      const data: DDBBatchWriteResponse = await this.call('BatchWriteItem', {\n        RequestItems: makeKeyValue(tableName, batchKeys.map((key) => ({\n          DeleteRequest: { Key: key },\n        }))),\n        ReturnConsumedCapacity: 'TOTAL',\n      });\n      return (safeGet(data.UnprocessedItems, tableName) || []).map((i) => i.DeleteRequest!.Key);\n    });\n  }\n\n  getAllItems(tableName: string, requestedAttrs?: readonly string[]): Results<DDBItem> {\n    // https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_Scan.html\n    const query = {\n      TableName: tableName,\n      ...escapedExpressions({ ProjectionExpression: projection(requestedAttrs) }),\n      ConsistentRead: this.consistentRead,\n      ReturnConsumedCapacity: 'TOTAL',\n    };\n    return new Paged(this.aws, async (lastKey) => {\n      const response: DDBScanResponse = await this.call('Scan', {\n        ...query,\n        ExclusiveStartKey: lastKey,\n      });\n      return [response.Items, response.LastEvaluatedKey];\n    });\n  }\n\n  async getItemsBySecondaryKey(\n    tableName: string,\n    indexName: string,\n    key: DDBItem,\n    requestedAttrs: readonly string[] | undefined,\n    limitOne: boolean,\n  ): Promise<DDBItem[]> {\n    // https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_Query.html\n    const colocatedAttrs = ['id'];\n    const nonColocatedAttrs: string[] = [];\n    (requestedAttrs || []).forEach((attr) => {\n      if (attr !== 'id') {\n        if (Object.prototype.hasOwnProperty.call(key, attr)) {\n          colocatedAttrs.push(attr);\n        } else {\n          nonColocatedAttrs.push(attr);\n        }\n      }\n    });\n    const query = {\n      TableName: tableName,\n      IndexName: indexName,\n      ...escapedExpressions({\n        KeyConditionExpression: {\n          attributeExpression: (attr, value): string => `${attr}=${value}`,\n          joiner: ' and ',\n          attributes: key,\n        },\n        ProjectionExpression: projection(colocatedAttrs),\n      }),\n      ConsistentRead: false, // cannot be true for Global Secondary Index\n      ReturnConsumedCapacity: 'TOTAL',\n    };\n    let items: DDBItem[];\n    if (limitOne) {\n      const response: DDBScanResponse = await this.call('Query', {\n        ...query,\n        Limit: 1,\n      });\n      items = response.Items;\n    } else {\n      items = await new Paged(this.aws, async (lastKey) => {\n        const response: DDBScanResponse = await this.call('Query', {\n          ...query,\n          ExclusiveStartKey: lastKey,\n        });\n        return [response.Items, response.LastEvaluatedKey];\n      }).all();\n    }\n\n    if (!items.length || (requestedAttrs && !nonColocatedAttrs.length)) {\n      return items;\n    }\n\n    const pkItems = await this.batchGetItems(\n      tableName,\n      items.map(({ id }) => ({ id })),\n      ifNotEmpty(nonColocatedAttrs),\n    );\n    return items\n      .map((item, i) => (pkItems[i] ? ({ ...item, ...pkItems[i] }) : null))\n      .filter((item) => item) as DDBItem[];\n  }\n\n  async deleteItem(tableName: string, key: DDBItem): Promise<void> {\n    await this.callDelete(tableName, key, false);\n  }\n\n  deleteAndReturnItem(tableName: string, key: DDBItem): Promise<DDBItem> {\n    return this.callDelete(tableName, key, true);\n  }\n\n  private async callDelete(tableName: string, key: DDBItem, returnOld: boolean): Promise<DDBItem> {\n    // https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_DeleteItem.html\n    const response: DDBReturnedItem = await this.call('DeleteItem', {\n      TableName: tableName,\n      Key: key,\n      ...escapedExpressions({\n        ConditionExpression: {\n          attributeExpression: (attr): string => `attribute_exists(${attr})`,\n          joiner: ' and ',\n          attributes: [Object.keys(key)[0]],\n        },\n      }),\n      ReturnConsumedCapacity: 'TOTAL',\n      ReturnValues: returnOld ? 'ALL_OLD' : undefined,\n    });\n    return response.Attributes;\n  }\n\n  private async replaceIndices(\n    tableName: string,\n    secondaryIndices: GlobalSecondaryIndexDefinition[] = [],\n  ): Promise<void> {\n    // https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_UpdateTable.html\n    const existing = await this.describeTable(tableName);\n    const indices = new Map<string, DDBGlobalSecondaryIndex>();\n    const toCreate: GlobalSecondaryIndexDefinition[] = [];\n    const oldIndices = existing.Table.GlobalSecondaryIndexes || [];\n    for (let i = 0; i < oldIndices.length; i += 1) {\n      const idx = oldIndices[i];\n      indices.set(idx.IndexName, idx);\n    }\n    for (let i = 0; i < secondaryIndices.length; i += 1) {\n      const idx = secondaryIndices[i];\n      const old = indices.get(idx.indexName);\n      if (old) {\n        if (!indicesMatch(idx, old)) {\n          throw new Error(`Cannot change existing index definition ${idx.indexName}`);\n        }\n        indices.delete(idx.indexName);\n      } else {\n        toCreate.push(idx);\n      }\n    }\n    const toDelete = [...indices.keys()];\n    /* eslint-disable no-await-in-loop */ // index creation and deletion must be serial\n    for (let i = 0; i < toDelete.length; i += 1) {\n      await this.call('UpdateTable', {\n        TableName: tableName,\n        GlobalSecondaryIndexUpdates: [{\n          Delete: { IndexName: toDelete[i] },\n        }],\n      });\n      // must wait for table to be ACTIVE before next update can be applied\n      await this.waitForTable(tableName, false);\n    }\n    for (let i = 0; i < toCreate.length; i += 1) {\n      await this.call('UpdateTable', {\n        TableName: tableName,\n        AttributeDefinitions: createAttributeDefinitions([toCreate[i].keySchema]),\n        GlobalSecondaryIndexUpdates: [{ Create: createSecondaryIndex(toCreate[i]) }],\n      });\n      // must wait for table to be ACTIVE before next update can be applied\n      await this.waitForTable(tableName, false);\n    }\n    /* eslint-enable no-await-in-loop */\n  }\n\n  private callBatched<T>(\n    items: T[],\n    batchLimit: number,\n    fn: (batchItems: T[]) => Promise<T[]>,\n  ): Promise<void> {\n    const remaining = items.slice();\n    return this.aws.do(() => retryRemaining(async () => {\n      const queue = remaining.slice();\n      remaining.length = 0;\n      while (queue.length) {\n        const batchItems = queue.splice(0, batchLimit);\n\n        /* eslint-disable-next-line no-await-in-loop */ // no benefit from parallelism\n        const retryItems = await fn(batchItems);\n        remaining.push(...retryItems);\n      }\n      if (remaining.length) {\n        throw new Error('remaining unprocessed items');\n      }\n    }));\n  }\n\n  private async call<T extends DDBResponse = DDBResponse>(\n    fnName: string,\n    body?: string | Record<string, unknown> | Buffer,\n  ): Promise<T> {\n    const response = await this.aws.request({\n      method: 'POST',\n      url: this.host,\n      region: this.region,\n      service: 'dynamodb',\n      headers: {\n        'Content-Type': 'application/x-amz-json-1.0',\n        'X-Amz-Target': `DynamoDB_20120810.${fnName}`,\n      },\n      body,\n    });\n    // DynamoDB does not include read/write capacity usage for errors, though\n    // they can consume capacity.\n    // https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/WorkingWithItems.html#WorkingWithItems.ConditionalWrites.ReturnConsumedCapacity\n\n    const data = response.json as T;\n    if (data.ConsumedCapacity) {\n      let capacity;\n      if (Array.isArray(data.ConsumedCapacity)) {\n        capacity = data.ConsumedCapacity.reduce((t, c) => (t + Number(c.CapacityUnits)), 0);\n      } else {\n        capacity = Number(data.ConsumedCapacity.CapacityUnits);\n      }\n      this.totalCapacityUnits += capacity;\n    }\n    return data;\n  }\n}\n","import {\n  DDB,\n  DDBItem,\n  DDBValue,\n  escapeName,\n  DDBProvisionedThroughput,\n} from './api/DDB';\nimport AWSError from './api/AWSError';\nimport type { IDable } from '../interfaces/IDable';\nimport BaseCollection from '../interfaces/BaseCollection';\nimport type { DBKeys } from '../interfaces/DB';\nimport { serialiseValueBin, deserialiseValueBin } from '../helpers/serialiser';\nimport { makeKeyValue, mapEntries, safeGet } from '../helpers/safeAccess';\n\nconst ConditionalCheckFailedException = 'ConditionalCheckFailedException';\n\nasync function runAll<T>(\n  values: T[],\n  successesOut: T[],\n  fn: (value: T) => Promise<void>,\n): Promise<void> {\n  const results = await Promise.allSettled(values.map(async (value) => {\n    await fn(value);\n    successesOut.push(value);\n  }));\n  const failures = results.filter((s) => s.status === 'rejected') as PromiseRejectedResult[];\n  if (failures.length) {\n    throw failures[0].reason;\n  }\n}\n\nfunction wrapError(type: string, message: string): (e: unknown) => void {\n  return (e): void => {\n    throw AWSError.isType(e, type) ? new Error(message) : e;\n  };\n}\n\nfunction handleError<T>(\n  type: string,\n  fn: () => Promise<T> | T,\n): (e: unknown) => Promise<T> | T {\n  return (e): (Promise<T> | T) => {\n    if (AWSError.isType(e, type)) {\n      return fn();\n    }\n    throw e;\n  };\n}\n\nconst ignore = (): void => {};\n\nfunction toDynamoValue(value: unknown): DDBValue {\n  // all values must be binary, because keys must be defined\n  // in advance before we know what type of data will be stored\n  // and any column could be a key (or become one in the future)\n  const bin = serialiseValueBin(value);\n  return { B: bin.toString('base64') };\n}\n\nfunction toDynamoItem(value: Record<string, unknown>): DDBItem {\n  return mapEntries(value, toDynamoValue);\n}\n\nfunction isDynamoBinary(value: DDBValue): value is { B: string } {\n  return Object.prototype.hasOwnProperty.call(value, 'B');\n}\n\nfunction isDynamoStringSet(value: DDBValue): value is { SS: string[] } {\n  return Object.prototype.hasOwnProperty.call(value, 'SS');\n}\n\nfunction fromDynamoValue(value: DDBValue): unknown {\n  if (isDynamoBinary(value)) {\n    return deserialiseValueBin(Buffer.from(value.B, 'base64'));\n  }\n  throw new Error('unexpected value type from DDB');\n}\n\nfunction fromDynamoItem<T = Record<string, unknown>>(value: DDBItem): T;\nfunction fromDynamoItem<T = Record<string, unknown>>(value: DDBItem | null | undefined): T | null;\n\nfunction fromDynamoItem<T = Record<string, unknown>>(value: DDBItem | null | undefined): T | null {\n  if (!value) {\n    return null;\n  }\n  return mapEntries(value, fromDynamoValue) as T;\n}\n\nfunction toDynamoKey(attr: string, value: DDBValue): DDBValue {\n  if (!isDynamoBinary(value)) {\n    throw new Error('unexpected value type from DDB');\n  }\n  return {\n    B: Buffer.concat([\n      Buffer.from(`${attr}:`, 'utf8'),\n      Buffer.from(value.B, 'base64'),\n    ]).toString('base64'),\n  };\n}\n\nconst INDEX_META_KEY = { B: Buffer.from(':').toString('base64') };\n\nconst indexTable = (tableName: string): string => `${tableName}.`;\n\nexport interface Throughput {\n  read: number;\n  write: number;\n}\n\ntype CollectionThroughputFn = (indexName: string | null) => Throughput | null | undefined;\n\nfunction toDDBThroughput(\n  throughput: Throughput | null | undefined,\n): DDBProvisionedThroughput | undefined {\n  if (!throughput) {\n    return undefined;\n  }\n  return {\n    ReadCapacityUnits: Math.max(1, Math.ceil(throughput.read)),\n    WriteCapacityUnits: Math.max(1, Math.ceil(throughput.write)),\n  };\n}\n\nfunction getCombinedThroughput(\n  keys: string[],\n  throughputFn?: CollectionThroughputFn,\n): Throughput | null {\n  const totalThroughput = { read: 0, write: 0 };\n  let hasThroughput = false;\n  keys.forEach((attr) => {\n    const cur = throughputFn?.(attr);\n    if (cur) {\n      hasThroughput = true;\n      totalThroughput.read += cur.read;\n      totalThroughput.write += cur.write;\n    }\n  });\n  return hasThroughput ? totalThroughput : null;\n}\n\nasync function configureTable(\n  ddb: DDB,\n  tableName: string,\n  nonuniqueKeys: string[],\n  uniqueKeys: string[],\n  throughputFn?: CollectionThroughputFn,\n): Promise<void> {\n  const indexTableName = indexTable(tableName);\n\n  const [created] = await Promise.all<boolean, unknown>([\n    ddb.upsertTable(\n      tableName,\n      [{ attributeName: 'id', attributeType: 'B', keyType: 'HASH' }],\n      nonuniqueKeys.map((attr) => ({\n        indexName: escapeName(attr),\n        keySchema: [{ attributeName: attr, attributeType: 'B', keyType: 'HASH' }],\n        throughput: toDDBThroughput(throughputFn?.(attr)),\n      })),\n      true,\n      toDDBThroughput(throughputFn?.(null)),\n    ),\n    uniqueKeys.length ? ddb.upsertTable(\n      indexTableName,\n      [{ attributeName: 'ix', attributeType: 'B', keyType: 'HASH' }],\n      [],\n      true,\n      toDDBThroughput(getCombinedThroughput(uniqueKeys, throughputFn)),\n    ) : ddb.deleteTable(indexTableName).catch(ignore),\n  ]);\n\n  if (created || !uniqueKeys.length) {\n    return;\n  }\n\n  // table already existed; might need to migrate old data for unique indices\n  const info = await ddb.getItem(indexTableName, { ix: INDEX_META_KEY }, ['unique']);\n  const newKeys = new Set(uniqueKeys);\n  const oldKeys: string[] = [];\n  if (info && isDynamoStringSet(info.unique)) {\n    oldKeys.push(...info.unique.SS.filter((item) => !newKeys.delete(item)));\n  }\n  if (newKeys.size) {\n    // we have new keys which must be populated\n    const attrs = [...newKeys];\n    await ddb.getAllItems(tableName, ['id', ...attrs]).batched(async (items) => {\n      const indexItems: DDBItem[] = [];\n      items.forEach((item) => attrs.forEach((attr) => {\n        const value = safeGet(item, attr);\n        if (!value) {\n          throw new Error(`Unable to migrate existing data (no value for ${attr})`);\n        }\n        indexItems.push({ ix: toDynamoKey(attr, value), id: item.id });\n      }));\n      return ddb.batchPutItems(indexTableName, indexItems);\n    });\n  } else if (!oldKeys.length) {\n    return; // no change\n  }\n  // do not delete old items; storing them is relatively\n  // cheap compared to scanning and deleting them\n\n  // update stored info about indices\n  await ddb.putItem(indexTableName, { ix: INDEX_META_KEY, unique: { SS: uniqueKeys } });\n}\n\nexport default class DynamoCollection<T extends IDable> extends BaseCollection<T> {\n  private readonly uniqueKeys: (string & keyof T)[] = [];\n\n  public constructor(\n    private readonly ddb: DDB,\n    private readonly tableName: string,\n    keys: DBKeys<T> = {},\n    throughputFn?: CollectionThroughputFn,\n  ) {\n    super(keys);\n\n    const nonuniqueKeys: (string & keyof T)[] = [];\n    Object.entries(keys).forEach(([key, options]) => {\n      if (options?.unique) {\n        this.uniqueKeys.push(key as (string & keyof T));\n      } else {\n        nonuniqueKeys.push(key as (string & keyof T));\n      }\n    });\n\n    this.initAsync(configureTable(\n      ddb,\n      tableName,\n      nonuniqueKeys,\n      this.uniqueKeys,\n      throughputFn,\n    ));\n  }\n\n  get internalTableName(): string {\n    return this.tableName;\n  }\n\n  get internalIndexTableName(): string {\n    return indexTable(this.tableName);\n  }\n\n  protected internalAdd(value: T): Promise<void> {\n    return this.putItem(toDynamoItem(value as any));\n  }\n\n  protected internalUpsert(\n    id: T['id'],\n    update: Partial<T>,\n  ): Promise<void> {\n    const item = toDynamoItem({ id, ...update });\n    const key = { id: item.id };\n    delete item.id;\n\n    // optimistically try to update\n    return this.updateItem(key, item, key).catch(handleError(\n      ConditionalCheckFailedException,\n\n      // if that fails due to the item not existing, try creating it\n      () => this.putItem({ ...key, ...item }).catch(handleError(\n        'duplicate id',\n\n        // it that fails due to the item existing, the item was probably\n        // created in the gap between calls; update it\n        () => this.updateItem(key, item, key).catch(wrapError(\n          ConditionalCheckFailedException,\n\n          // if it fails again, give up\n          'Failed to upsert item',\n        )),\n      )),\n    ));\n  }\n\n  protected async internalUpdate<K extends string & keyof T>(\n    searchAttribute: K,\n    searchValue: T[K],\n    item: Partial<T>,\n  ): Promise<void> {\n    const update = toDynamoItem(item);\n    const setId = item.id;\n    delete update.id;\n\n    if (searchAttribute === 'id') {\n      await this.updateItem(\n        toDynamoItem({ id: searchValue }),\n        update,\n      ).catch(handleError(ConditionalCheckFailedException, ignore));\n    } else {\n      const items = await this.internalGetAll(searchAttribute, searchValue, ['id']);\n      if (!items.length) {\n        return;\n      }\n      if (setId && (items.length > 1 || items[0].id !== setId)) {\n        throw new Error('Cannot update ID');\n      }\n      const search = toDynamoItem(makeKeyValue(searchAttribute, searchValue));\n      await Promise.all(items.map(({ id }) => this.updateItem(\n        toDynamoItem({ id }),\n        update,\n        search,\n      ).catch(handleError(ConditionalCheckFailedException, ignore))));\n    }\n  }\n\n  protected async internalGet<\n    K extends string & keyof T,\n    F extends readonly (string & keyof T)[]\n  >(\n    searchAttribute: K,\n    searchValue: T[K],\n    returnAttributes?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>> | null> {\n    if (searchAttribute === 'id') {\n      return fromDynamoItem<Pick<T, F[-1]>>(await this.ddb.getItem(\n        this.tableName,\n        toDynamoItem({ id: searchValue }),\n        returnAttributes,\n      ));\n    }\n\n    if (!this.indices.isUniqueIndex(searchAttribute)) {\n      const ddbItems = await this.ddb.getItemsBySecondaryKey(\n        this.tableName,\n        escapeName(searchAttribute),\n        toDynamoItem(makeKeyValue(searchAttribute, searchValue)),\n        returnAttributes,\n        true,\n      );\n      return fromDynamoItem<Pick<T, F[-1]>>(ddbItems[0]);\n    }\n\n    const ddbSearchValue = toDynamoValue(searchValue);\n    const key = await this.ddb.getItem(\n      indexTable(this.tableName),\n      { ix: toDynamoKey(searchAttribute, ddbSearchValue) },\n      ['id'],\n    );\n    if (!key) {\n      return null;\n    }\n    if (!returnAttributes) {\n      return fromDynamoItem<Pick<T, F[-1]>>(await this.ddb.getItem(this.tableName, key));\n    }\n    const ddbItem: DDBItem = {};\n    const filteredReturn = new Set(returnAttributes);\n    if (filteredReturn.delete('id')) {\n      Object.assign(ddbItem, key);\n    }\n    if (filteredReturn.delete(searchAttribute)) {\n      ddbItem[searchAttribute] = ddbSearchValue;\n    }\n    if (filteredReturn.size) {\n      const primaryItem = await this.ddb.getItem(this.tableName, key, [...filteredReturn]);\n      if (!primaryItem) {\n        // index and main table are out of sync;\n        // assume main table is correct and item does not exist\n        return null;\n      }\n      Object.assign(ddbItem, primaryItem);\n    }\n    return fromDynamoItem<Pick<T, F[-1]>>(ddbItem);\n  }\n\n  protected async internalGetAll<\n    K extends string & keyof T,\n    F extends readonly (string & keyof T)[]\n  >(\n    searchAttribute?: K,\n    searchValue?: T[K],\n    returnAttributes?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>>[]> {\n    if (!searchAttribute) {\n      const items = await this.ddb.getAllItems(this.tableName, returnAttributes).all();\n      return items.map(fromDynamoItem) as Pick<T, F[-1]>[];\n    }\n    if (this.indices.isUniqueIndex(searchAttribute)) {\n      const item = await this.internalGet(searchAttribute, searchValue!, returnAttributes);\n      return item ? [item] : [];\n    }\n    const items = await this.ddb.getItemsBySecondaryKey(\n      this.tableName,\n      escapeName(searchAttribute),\n      toDynamoItem(makeKeyValue(searchAttribute, searchValue)),\n      returnAttributes,\n      false,\n    );\n    return items.map(fromDynamoItem) as Pick<T, F[-1]>[];\n  }\n\n  protected async internalRemove<K extends string & keyof T>(\n    searchAttribute: K,\n    searchValue: T[K],\n  ): Promise<number> {\n    if (searchAttribute === 'id') {\n      const success = await this.deleteItem(toDynamoItem({ id: searchValue }));\n      return success ? 1 : 0;\n    }\n    const items = await this.internalGetAll(searchAttribute, searchValue, ['id']);\n    const successes = await Promise.all(items.map(({ id }) => this.deleteItem(\n      toDynamoItem({ id }),\n    )));\n    return successes.filter((success) => success).length;\n  }\n\n  private async atomicPutUniques(\n    id: DDBValue,\n    item: DDBItem,\n    uniqueKeys: (string & keyof T)[],\n    fn: () => Promise<void>,\n  ): Promise<void> {\n    if (!uniqueKeys.length) {\n      await fn();\n      return;\n    }\n\n    const indexTableName = indexTable(this.tableName);\n    const successes: string[] = [];\n    try {\n      await runAll(uniqueKeys, successes, (attr) => this.ddb.putItem(\n        indexTableName,\n        { ix: toDynamoKey(attr, item[attr]), id },\n        'ix',\n      ).catch(wrapError(ConditionalCheckFailedException, `duplicate ${attr}`)));\n      await fn();\n    } catch (e) {\n      await this.ddb.batchDeleteItems(\n        indexTableName,\n        successes.map((attr) => ({ ix: toDynamoKey(attr, item[attr]) })),\n      ).catch(ignore); // best effort to reset state, but ignore errors here\n      throw e;\n    }\n  }\n\n  private async putItem(item: DDBItem): Promise<void> {\n    return this.atomicPutUniques(\n      item.id,\n      item,\n      this.uniqueKeys,\n      () => this.ddb.putItem(\n        this.tableName,\n        item,\n        'id',\n      ).catch(wrapError(ConditionalCheckFailedException, 'duplicate id')),\n    );\n  }\n\n  private async updateItem(key: DDBItem, update: DDBItem, condition?: DDBItem): Promise<void> {\n    const updatedUnique = this.uniqueKeys\n      .filter((a) => Object.prototype.hasOwnProperty.call(update, a));\n\n    if (!updatedUnique.length) {\n      await this.ddb.updateItem(this.tableName, key, update, condition);\n      return;\n    }\n    const old = await this.ddb.getItem(this.tableName, key, updatedUnique);\n    if (!old) {\n      throw new AWSError(400, ConditionalCheckFailedException, 'could not find item to update');\n    }\n    const changedAttrs = updatedUnique.filter((a) => (old[a] as any).B !== (update[a] as any).B);\n    await this.atomicPutUniques(\n      key.id,\n      update,\n      changedAttrs,\n      () => this.ddb.updateItem(this.tableName, key, update, { ...old, ...condition }),\n    );\n    await this.ddb.batchDeleteItems(\n      indexTable(this.tableName),\n      changedAttrs.map((attr) => ({ ix: toDynamoKey(attr, old[attr]) })),\n    );\n  }\n\n  private async deleteItem(key: DDBItem): Promise<boolean> {\n    try {\n      if (!this.uniqueKeys.length) {\n        await this.ddb.deleteItem(this.tableName, key);\n      } else {\n        const item = await this.ddb.deleteAndReturnItem(this.tableName, key);\n        await this.ddb.batchDeleteItems(\n          indexTable(this.tableName),\n          this.uniqueKeys.map((attr) => ({ ix: toDynamoKey(attr, item[attr]) })),\n        );\n      }\n      return true;\n    } catch (e) {\n      if (AWSError.isType(e, ConditionalCheckFailedException)) {\n        return false;\n      }\n      throw e;\n    }\n  }\n}\n","export default class PromiseTracker {\n  private readonly inflight = new Set<Promise<any>>();\n\n  do<T>(fn: () => Promise<T>): Promise<T> {\n    let flightResolve = (): void => {};\n    const flight = new Promise((resolve) => {\n      flightResolve = resolve;\n    }).then(() => {\n      this.inflight.delete(flight);\n    });\n    this.inflight.add(flight);\n    return fn().finally(flightResolve);\n  }\n\n  async wait(): Promise<void> {\n    const current = [...this.inflight];\n    this.inflight.clear();\n    await Promise.allSettled(current);\n  }\n}\n","const always = (): boolean => true;\n\nexport default class LruCache<K, V> {\n  private readonly storage = new Map<K, V>();\n\n  public constructor(\n    private readonly capacity: number,\n    private readonly flushFn?: (value: V) => void,\n  ) {}\n\n  public cached(\n    key: K,\n    calc: (key: K) => V,\n    fresh: (value: V) => boolean = always,\n  ): V {\n    const value = this.storage.get(key);\n    if (this.storage.delete(key)) {\n      if (fresh(value!)) {\n        this.storage.set(key, value!);\n        return value!;\n      }\n      this.flushFn?.(value!);\n    }\n    const created = calc(key);\n    this.internalAdd(key, created);\n    return created;\n  }\n\n  public async cachedAsync(\n    key: K,\n    calc: (key: K) => Promise<V>,\n    fresh: (value: V) => boolean = always,\n  ): Promise<V> {\n    const value = this.storage.get(key);\n    if (this.storage.delete(key)) {\n      if (fresh(value!)) {\n        this.storage.set(key, value!);\n        return value!;\n      }\n      this.flushFn?.(value!);\n    }\n    const created = await calc(key);\n    this.internalAdd(key, created);\n    return created;\n  }\n\n  public add(key: K, value: V): void {\n    this.remove(key);\n    this.internalAdd(key, value);\n  }\n\n  public peek(key: K): V | undefined {\n    return this.storage.get(key);\n  }\n\n  public remove(key: K): void {\n    if (this.flushFn) {\n      const value = this.storage.get(key);\n      if (this.storage.delete(key)) {\n        this.flushFn(value!);\n      }\n    } else {\n      this.storage.delete(key);\n    }\n  }\n\n  public clear(): void {\n    this.storage.clear();\n  }\n\n  private internalAdd(key: K, value: V): void {\n    this.storage.set(key, value);\n\n    while (this.storage.size > this.capacity) {\n      this.remove(this.storage.keys().next().value);\n    }\n  }\n}\n","import { createHash, createHmac } from 'crypto';\nimport https from 'https';\nimport http from 'http';\nimport AWSError from './AWSError';\nimport PromiseTracker from '../../helpers/PromiseTracker';\nimport LruCache from '../../helpers/LruCache';\nimport retry from '../../helpers/retry';\n\ntype Method = 'OPTIONS' | 'GET' | 'HEAD' | 'POST' | 'PUT' | 'DELETE';\n\nconst EMPTY_BUFFER = Buffer.alloc(0);\nconst ISO_TIME_STRIP = /(-|:|\\.[0-9]*)/g;\nconst ALGORITHM = 'AWS4-HMAC-SHA256';\n\nconst withTransientErrorRetry = retry((e) => (!(e instanceof AWSError) || e.isTransient()));\n\nfunction sha256(v: Buffer): string {\n  const hash = createHash('sha256');\n  hash.update(v);\n  return hash.digest('hex');\n}\n\nfunction hmac(key: Buffer, data: string): Buffer {\n  const hash = createHmac('sha256', key);\n  hash.update(data, 'utf8');\n  return hash.digest();\n}\n\ninterface RequestOptions {\n  method: Method;\n  url: URL | string;\n  region: string;\n  service: string;\n  headers?: Record<string, string>;\n  body?: string | Record<string, unknown> | Buffer;\n  date?: Date;\n}\n\ninterface FetchResponse {\n  status: number;\n  json: unknown;\n}\n\ninterface AWSErrorResponse {\n  __type: string;\n  message: string;\n}\n\nexport default class AWS {\n  private readonly baseKey: Buffer;\n\n  private readonly keyCacheDate = new LruCache<string, Buffer>(1);\n\n  private readonly keyCacheRegion = new LruCache<string, Buffer>(4);\n\n  private readonly keyCache = new LruCache<string, Buffer>(16);\n\n  private readonly inflight = new PromiseTracker();\n\n  private closed = false;\n\n  constructor(private readonly keyID: string, secret: string) {\n    this.baseKey = Buffer.from(`AWS4${secret}`, 'utf8');\n  }\n\n  do<T>(fn: () => Promise<T>): Promise<T> {\n    return this.inflight.do(fn);\n  }\n\n  request({\n    method,\n    url,\n    region,\n    service,\n    headers = {},\n    body = EMPTY_BUFFER,\n    date = new Date(),\n  }: RequestOptions): Promise<FetchResponse> {\n    // https://docs.aws.amazon.com/general/latest/gr/sigv4-create-canonical-request.html\n\n    const parsedURL = (url instanceof URL) ? url : new URL(url);\n    if (parsedURL.search) {\n      throw new Error('AWS urls with query strings are not supported');\n    }\n    if (this.closed) {\n      throw new Error('Connection closed');\n    }\n\n    let binaryBody: Buffer;\n    if (body instanceof Buffer) {\n      binaryBody = body;\n    } else if (typeof body === 'string') {\n      binaryBody = Buffer.from(body, 'utf8');\n    } else {\n      binaryBody = Buffer.from(JSON.stringify(body), 'utf8');\n    }\n\n    const canonicalTime = date.toISOString().replace(ISO_TIME_STRIP, ''); // YYYYMMDD'T'HHmmSS'Z'\n    const canonicalDate = canonicalTime.substr(0, 8); // YYYYMMDD\n    const credentialScope = `${canonicalDate}/${region}/${service}/aws4_request`;\n    const key = this.getKey(canonicalDate, region, service);\n\n    // AWS requires double-uri-encoding, and pathname uses non-standard encoding\n    const canonicalPath = encodeURI(encodeURI(decodeURI(parsedURL.pathname))) || '/';\n    const canonicalQueryString = '';\n\n    const allHeaders: Record<string, string> = {\n      ...headers,\n      Host: parsedURL.host,\n      'X-Amz-Date': canonicalTime,\n    };\n\n    const headerNames = Object.keys(allHeaders)\n      .map((header) => header.toLowerCase())\n      .sort();\n\n    const canonicalHeaders = headerNames\n      .map((header) => `${header}:${allHeaders[header]}\\n`)\n      .join('');\n    const signedHeaders = headerNames.join(';');\n\n    const canonicalRequest = [\n      method,\n      canonicalPath,\n      canonicalQueryString,\n      canonicalHeaders,\n      signedHeaders,\n      sha256(binaryBody),\n    ].join('\\n');\n\n    const stringToSign = [\n      ALGORITHM,\n      canonicalTime,\n      credentialScope,\n      sha256(Buffer.from(canonicalRequest, 'utf8')),\n    ].join('\\n');\n\n    const signature = hmac(key, stringToSign).toString('hex');\n\n    allHeaders.Authorization = [\n      `${ALGORITHM} Credential=${this.keyID}/${credentialScope}`,\n      `SignedHeaders=${signedHeaders}`,\n      `Signature=${signature}`,\n    ].join(', ');\n\n    delete allHeaders.Host; // will be auto-added by node\n\n    return this.fetch(parsedURL, binaryBody, {\n      method,\n      headers: allHeaders,\n    });\n  }\n\n  async close(): Promise<void> {\n    if (this.closed) {\n      return;\n    }\n    await this.inflight.wait();\n    this.closed = true;\n  }\n\n  private fetch(\n    url: URL,\n    body: Buffer,\n    options: http.RequestOptions,\n  ): Promise<FetchResponse> {\n    if (this.closed) {\n      throw new Error('Connection closed');\n    }\n\n    const protocol = (url.protocol === 'https') ? https : http;\n    return this.inflight.do(() => withTransientErrorRetry(() => new Promise((resolve, reject) => {\n      const req = protocol.request(url, options, (res) => {\n        const parts: Buffer[] = [];\n        res.on('data', (chunk) => parts.push(chunk));\n        res.on('end', () => {\n          try {\n            const text = Buffer.concat(parts).toString('utf8');\n            parts.length = 0;\n            const json = JSON.parse(text) as AWSErrorResponse;\n            if (!res.statusCode || res.statusCode >= 300) {\n              /* eslint-disable-next-line no-underscore-dangle */ // part of API\n              reject(new AWSError(res.statusCode || 0, json.__type, json.message));\n            } else {\n              resolve({ status: res.statusCode, json });\n            }\n          } catch (e) {\n            reject(e);\n          }\n        });\n      });\n      req.on('error', reject);\n      req.write(body);\n      req.end();\n    })));\n  }\n\n  private getKey(\n    canonicalDate: string,\n    region: string,\n    service: string,\n  ): Buffer {\n    return this.keyCache.cached(`${canonicalDate}/${region}/${service}`, () => {\n      const kRegion = this.keyCacheRegion.cached(`${canonicalDate}/${region}`, () => hmac(\n        this.keyCacheDate.cached(canonicalDate, () => hmac(this.baseKey, canonicalDate)),\n        region,\n      ));\n      return hmac(hmac(kRegion, service), 'aws4_request');\n    });\n  }\n}\n","import DynamoCollection, { Throughput } from './DynamoCollection';\nimport AWS from './api/AWS';\nimport { DDB, escapeName } from './api/DDB';\nimport type { DBKeys } from '../interfaces/DB';\nimport BaseDB from '../interfaces/BaseDB';\nimport type { IDable } from '../interfaces/IDable';\n\nexport type DbThroughputFn = (\n  tableName: string,\n  indexName: string | null,\n) => Throughput | null | undefined;\n\nconst makeThroughputFn = (params: URLSearchParams) => (\n  tableName: string,\n  indexName: string | null,\n): Throughput | null => {\n  let throughput: string | null = null;\n  if (indexName) {\n    throughput = (\n      params.get(`provision_${tableName}_index_${indexName}`) ||\n      params.get(`provision_${tableName}_index`) ||\n      params.get(`provision_${tableName}`) ||\n      params.get('provision')\n    );\n  } else {\n    throughput = (\n      params.get(`provision_${tableName}`) ||\n      params.get('provision')\n    );\n  }\n  if (!throughput || throughput === '-') {\n    return null;\n  }\n  const parts = throughput.split('.');\n  if (parts.length !== 2) {\n    throw new Error(`unexpected provisioning format for ${tableName} ${indexName || ''}: ${throughput} (expected 'read.write' or '-')`);\n  }\n  return {\n    read: Number.parseInt(parts[0], 10),\n    write: Number.parseInt(parts[1], 10),\n  };\n};\n\nexport default class DynamoDb extends BaseDB {\n  private constructor(\n    private readonly aws: AWS,\n    private readonly ddb: DDB,\n    tableNamePrefix: string,\n    throughputFn?: DbThroughputFn,\n  ) {\n    super((name, keys) => new DynamoCollection(\n      this.ddb,\n      tableNamePrefix + escapeName(name),\n      keys,\n      throughputFn?.bind(null, name),\n    ));\n  }\n\n  public static connect(url: string, throughputFn?: DbThroughputFn): DynamoDb {\n    const parsed = new URL(url);\n    let key;\n    let secret;\n    if (parsed.username) {\n      key = parsed.username;\n      secret = parsed.password;\n    } else {\n      key = process.env.AWS_ACCESS_KEY_ID;\n      secret = process.env.AWS_SECRET_ACCESS_KEY;\n    }\n    if (!key || !secret) {\n      throw new Error('No AWS key / secret specified');\n    }\n    const protocol = (parsed.searchParams.get('tls') === 'false') ? 'http' : 'https';\n    const consistentRead = (parsed.searchParams.get('consistentRead') === 'true');\n    const tableNamePrefix = parsed.pathname.substr(1);\n\n    const aws = new AWS(key, secret);\n    const ddb = new DDB(aws, `${protocol}://${parsed.host}`, { consistentRead });\n    return new DynamoDb(\n      aws,\n      ddb,\n      tableNamePrefix,\n      throughputFn || makeThroughputFn(parsed.searchParams),\n    );\n  }\n\n  public getCollection<T extends IDable>(name: string, keys?: DBKeys<T>): DynamoCollection<T> {\n    return super.getCollection(name, keys) as DynamoCollection<T>;\n  }\n\n  public getDDB(): DDB {\n    return this.ddb;\n  }\n\n  protected internalClose(): Promise<void> {\n    return this.aws.close();\n  }\n}\n","import type {\n  Redis,\n  Pipeline,\n  MultiOptions,\n  Ok,\n} from 'ioredis';\n\n// Thanks, https://stackoverflow.com/a/50014868/1180785\ntype ArgumentTypes<T> = T extends (...args: infer U) => any ? U : never;\n\ntype PipelineVersions<I> = {\n  [K in keyof I]: (...args: ArgumentTypes<I[K]>) => Pipeline & PipelineVersions<I>;\n};\n\ninterface RedisWithExtendedPipeline<I> extends Redis {\n  multi(commands?: string[][], options?: MultiOptions): Pipeline & PipelineVersions<I>;\n  multi(options: { pipeline: false }): Promise<Ok>;\n}\n\nexport type ExtendedRedis<I> = I & RedisWithExtendedPipeline<I>;\n\nexport async function multiExec(\n  client: Redis,\n  commands: string[][],\n): Promise<[unknown, any][] | null> {\n  if (!commands.length) {\n    return [];\n  }\n  return client.multi(commands).exec();\n}\n\nexport function minifyLuaScript(\n  lines: string[],\n  ...argNames: string[]\n): string {\n  let combined = lines.map((ln) => ln.trim()).join(' ');\n  argNames.forEach((name, i) => {\n    combined = combined.replace(new RegExp(`\\\\$${name}\\\\b`, 'g'), `ARGV[${i + 1}]`);\n  });\n  return combined;\n}\n","import type { IDable } from '../interfaces/IDable';\nimport BaseCollection from '../interfaces/BaseCollection';\nimport type { UpdateOptions } from '../interfaces/Collection';\nimport type { DBKeys } from '../interfaces/DB';\nimport {\n  serialiseValue,\n  serialiseRecord,\n  deserialiseRecord,\n  Serialised,\n} from '../helpers/serialiser';\nimport type RedisConnectionPool from './RedisConnectionPool';\nimport { multiExec } from './helpers';\nimport type { ERedis } from './scripts';\n\ninterface Key<T> {\n  key: string & keyof T;\n  prefix: string;\n}\n\ninterface InternalPatch<T> {\n  sId: string;\n  oldSerialised: Serialised<T>;\n  newSerialised: Serialised<T>;\n}\n\nconst notUndefined = <T>(item?: T): item is T => (item !== undefined);\n\nfunction makeIndexKeys<T>(\n  keys: Key<T>[],\n  partialSerialisedValue: Serialised<T>,\n): string[] {\n  return keys\n    .filter(({ key }) => partialSerialisedValue.has(key))\n    .map(({ key, prefix }) => `${prefix}:${partialSerialisedValue.get(key)}`);\n}\n\nfunction parseItem<T>(\n  item: (string | null)[],\n  fields?: readonly (string & keyof T)[],\n): Serialised<T> | undefined {\n  if (!item.length) {\n    return undefined;\n  }\n  const result = new Map<string & keyof T, string>();\n  if (fields) {\n    // item is values in same order as fields\n    fields.forEach((field, index) => {\n      const v = item[index];\n      if (v) {\n        result.set(field, v);\n      }\n    });\n  } else {\n    // item is key1, value1, key2, value2, ...\n    for (let i = 0; i < item.length; i += 2) {\n      const field = item[i];\n      const v = item[i + 1];\n      if (v) {\n        result.set(field as (string & keyof T), v);\n      }\n    }\n  }\n  return result.size > 0 ? result : undefined;\n}\n\nasync function unwatchAll(client: ERedis): Promise<void> {\n  await client.unwatch();\n}\n\nasync function mapAwaitSync<T, O>(\n  values: T[],\n  fn: (value: T) => Promise<O>,\n): Promise<O[]> {\n  const result: O[] = [];\n  for (let i = 0; i < values.length; i += 1) {\n    // eslint-disable-next-line no-await-in-loop\n    result.push(await fn(values[i]));\n  }\n  return result;\n}\n\nexport default class RedisCollection<T extends IDable> extends BaseCollection<T> {\n  private readonly keyPrefixes = new Map<string & keyof T, string>();\n\n  private readonly uniqueKeys: Key<T>[] = [];\n\n  private readonly nonUniqueKeys: Key<T>[] = [];\n\n  public constructor(\n    private readonly pool: RedisConnectionPool,\n    private readonly prefix: string,\n    keys: DBKeys<T> = {},\n  ) {\n    super(keys);\n\n    this.indices.getCustomIndices().forEach((key) => {\n      const keyPrefix = `${prefix}-${key}`;\n      this.keyPrefixes.set(key, keyPrefix);\n      const keyInfo = { key, prefix: keyPrefix };\n      if (this.indices.isUniqueIndex(key)) {\n        this.uniqueKeys.push(keyInfo);\n      } else {\n        this.nonUniqueKeys.push(keyInfo);\n      }\n    });\n  }\n\n  protected internalAdd(value: T): Promise<void> {\n    const serialised = serialiseRecord(value);\n    return this.pool.withConnection(async (client) => {\n      const added = await this.runAdd(client, serialised, false);\n      if (!added) {\n        throw new Error('duplicate');\n      }\n    });\n  }\n\n  protected internalUpdate<K extends string & keyof T>(\n    searchAttribute: K,\n    searchValue: T[K],\n    update: Partial<T>,\n    { upsert }: UpdateOptions,\n  ): Promise<void> {\n    const patchSerialised = serialiseRecord(update);\n    const sKey = serialiseValue(searchValue);\n\n    if (searchAttribute === 'id') {\n      return this.pool.retryWithConnection(async (client) => {\n        const patch = await this.getUpdatePatch(client, sKey, patchSerialised);\n        if (patch) {\n          await this.runUpdates(client, [patch]);\n        } else if (upsert) {\n          const insertValue = new Map(patchSerialised).set('id', sKey);\n          if (!await this.runAdd(client, insertValue, true)) {\n            throw new Error('duplicate');\n          }\n        }\n      }, unwatchAll);\n    }\n\n    return this.pool.retryWithConnection(async (client) => {\n      const sIds = await this.getAndWatchBySerialisedKey(client, searchAttribute, sKey);\n      if (!sIds.length) {\n        return;\n      }\n      if (\n        update.id &&\n        searchAttribute !== 'id' &&\n        (sIds.length > 1 || serialiseValue(update.id) !== sIds[0])\n      ) {\n        throw new Error('Cannot update ID');\n      }\n      const patches = (await mapAwaitSync(\n        sIds,\n        (sId) => this.getUpdatePatch(client, sId, patchSerialised),\n      )).filter(notUndefined);\n      await this.runUpdates(client, patches);\n    }, unwatchAll);\n  }\n\n  protected internalGet<\n    K extends string & keyof T,\n    F extends readonly (string & keyof T)[]\n  >(\n    searchAttribute: K,\n    searchValue: T[K],\n    returnAttributes?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>> | null> {\n    const sKey = serialiseValue(searchValue);\n    return this.pool.retryWithConnection(async (client) => {\n      const sId = (await this.getAndWatchBySerialisedKey(client, searchAttribute, sKey))[0];\n      if (sId === undefined) {\n        return null;\n      }\n      const results = await this.getByKeysKeepWatches(client, [sId], returnAttributes);\n      return results[0] ?? null;\n    }, unwatchAll);\n  }\n\n  protected internalGetAll<\n    K extends string & keyof T,\n    F extends readonly (string & keyof T)[]\n  >(\n    searchAttribute?: K,\n    searchValue?: T[K],\n    returnAttributes?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>>[]> {\n    if (searchAttribute) {\n      return this.pool.retryWithConnection(async (client) => {\n        const sKey = serialiseValue(searchValue);\n        const sIds = await this.getAndWatchBySerialisedKey(client, searchAttribute, sKey);\n        return this.getByKeysKeepWatches(client, sIds, returnAttributes);\n      }, unwatchAll);\n    }\n\n    const cut = this.prefix.length + 1;\n    return this.pool.retryWithConnection(async (client) => {\n      const stream = client.scanStream({ match: this.makeKey('*'), count: 100 });\n      const result: Pick<T, F[-1]>[] = [];\n      /* eslint-disable-next-line no-restricted-syntax */ // supported natively in Node 10+\n      for await (const batch of stream) {\n        const sIds = (batch as string[]).map((v) => v.substr(cut));\n        result.push(...await this.getByKeysKeepWatches(client, sIds, returnAttributes));\n      }\n      return result;\n    }, unwatchAll);\n  }\n\n  protected internalRemove<K extends string & keyof T>(\n    searchAttribute: K,\n    searchValue: T[K],\n  ): Promise<number> {\n    const sKey = serialiseValue(searchValue);\n    const indexedKeys = this.indices.getIndices();\n\n    return this.pool.retryWithConnection(async (client) => {\n      const sIds = await this.getAndWatchBySerialisedKey(client, searchAttribute, sKey);\n      const items = (await mapAwaitSync(\n        sIds,\n        (sId) => this.rawByKeyKeepWatches(client, sId, indexedKeys),\n      )).filter(notUndefined);\n\n      if (items.length === 0) {\n        return 0;\n      }\n\n      const pipeline = client.multi();\n      items.forEach((item) => {\n        const id = item.get('id')!;\n        const uniqueKeys = makeIndexKeys(this.uniqueKeys, item);\n        const nonUniqueKeys = makeIndexKeys(this.nonUniqueKeys, item);\n        pipeline.remove(\n          1 + uniqueKeys.length + nonUniqueKeys.length,\n          this.makeKey(id),\n          ...uniqueKeys,\n          ...nonUniqueKeys,\n          id,\n        );\n      });\n      await pipeline.exec();\n      return items.length;\n    }, unwatchAll);\n  }\n\n  private makeKey(serialisedId: string): string {\n    return `${this.prefix}:${serialisedId}`;\n  }\n\n  private async runAdd(\n    client: ERedis,\n    serialised: Serialised<T>,\n    checkWatch: boolean,\n  ): Promise<boolean> {\n    const id = serialised.get('id')!;\n    const uniqueKeys = makeIndexKeys(this.uniqueKeys, serialised);\n    const nonUniqueKeys = makeIndexKeys(this.nonUniqueKeys, serialised);\n\n    const keyCount = 1 + uniqueKeys.length + nonUniqueKeys.length;\n    const params = [\n      this.makeKey(id),\n      ...uniqueKeys,\n      ...nonUniqueKeys,\n      uniqueKeys.length,\n      'id', // ID is always first in flattened key/value pairs\n      id,\n      ...[...serialised.entries()].filter(([k]) => k !== 'id').flat(),\n    ];\n\n    if (!checkWatch) {\n      return Boolean(await client.add(keyCount, ...params));\n    }\n\n    const result = await client\n      .multi()\n      .add(keyCount, ...params)\n      .exec();\n    if (!result) {\n      throw new Error('transient error');\n    }\n    return Boolean(result[0][1]);\n  }\n\n  private async getUpdatePatch(\n    client: ERedis,\n    sId: string,\n    patchSerialised: Serialised<T>,\n  ): Promise<InternalPatch<T> | undefined> {\n    await client.watch(this.makeKey(sId));\n    const oldSerialised = await this.rawByKeyKeepWatches(\n      client,\n      sId,\n      this.indices.getCustomIndices().filter((k) => patchSerialised.has(k)),\n    );\n    if (!oldSerialised) {\n      return undefined;\n    }\n    const newSerialised = new Map(patchSerialised);\n    patchSerialised.forEach((n, k) => {\n      if (oldSerialised.get(k) === n) {\n        newSerialised.delete(k);\n        oldSerialised.delete(k);\n      }\n    });\n    return { sId, newSerialised, oldSerialised };\n  }\n\n  private async runUpdates(\n    client: ERedis,\n    patches: InternalPatch<T>[],\n  ): Promise<void> {\n    const argsList = patches\n      .map((patch) => this.makeUpdateArgs(patch))\n      .filter(notUndefined);\n\n    if (!argsList.length) {\n      return;\n    }\n\n    if (argsList.length === 1) {\n      const results = await client.multi()\n        .update(argsList[0][0], argsList[0][1])\n        .exec();\n\n      if (!results) {\n        throw new Error('transient error');\n      }\n      if (!results[0][1]) {\n        throw new Error('duplicate');\n      }\n      return;\n    }\n\n    const updateCheckResults = await mapAwaitSync(\n      argsList,\n      (updateArgs) => client.checkUpdate(updateArgs[0], updateArgs[1]),\n    );\n    if (updateCheckResults.some((r) => !r)) {\n      throw new Error('duplicate');\n    }\n\n    let chain = client.multi();\n    argsList.forEach((updateArgs) => {\n      chain = chain.updateWithoutCheck(updateArgs[0], updateArgs[1]);\n    });\n    const results = await chain.exec();\n\n    if (!results) {\n      throw new Error('transient error');\n    }\n  }\n\n  private makeUpdateArgs(\n    { sId, oldSerialised, newSerialised }: InternalPatch<T>,\n  ): [number, unknown[]] | undefined {\n    if (!newSerialised.size) {\n      return undefined; // nothing changed\n    }\n    const diff = [...newSerialised.entries()].flat();\n    const patchUniqueKeys = makeIndexKeys(this.uniqueKeys, newSerialised);\n    const patchNonUniqueKeys = makeIndexKeys(this.nonUniqueKeys, newSerialised);\n    const oldUniqueKeys = makeIndexKeys(this.uniqueKeys, oldSerialised);\n    const oldNonUniqueKeys = makeIndexKeys(this.nonUniqueKeys, oldSerialised);\n    if (\n      oldUniqueKeys.length !== patchUniqueKeys.length ||\n      oldNonUniqueKeys.length !== patchNonUniqueKeys.length\n    ) {\n      throw new Error('unexpected key mismatch with old value');\n    }\n    const keyCount = 1 + (patchUniqueKeys.length + patchNonUniqueKeys.length) * 2;\n    const params = [\n      this.makeKey(sId),\n      ...patchUniqueKeys,\n      ...patchNonUniqueKeys,\n      ...oldUniqueKeys,\n      ...oldNonUniqueKeys,\n      patchUniqueKeys.length,\n      patchUniqueKeys.length + patchNonUniqueKeys.length,\n      sId,\n      ...diff,\n    ];\n    return [keyCount, params];\n  }\n\n  private async getByKeysKeepWatches<F extends readonly (string & keyof T)[]>(\n    client: ERedis,\n    serialisedIds: string[],\n    fields?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>>[]> {\n    const results = await multiExec(\n      client,\n      serialisedIds\n        .map((sId) => this.makeKey(sId))\n        .map((k) => (fields ? ['hmget', k, ...fields] : ['hgetall', k])),\n    );\n    if (!results) {\n      throw new Error('transient error');\n    }\n    return results\n      .map(([, item]) => parseItem<T>(item, fields))\n      .filter(notUndefined)\n      .map(deserialiseRecord);\n  }\n\n  private async rawByKeyKeepWatches(\n    client: ERedis,\n    serialisedId: string,\n    fields?: readonly (string & keyof T)[],\n  ): Promise<Serialised<T> | undefined> {\n    const key = this.makeKey(serialisedId);\n    if (!fields) {\n      return parseItem((await client.hgetall(key)) as unknown as string[]);\n    }\n    if (!fields.length) {\n      // just check existence\n      const exists = await client.exists(key);\n      return exists ? new Map() : undefined;\n    }\n    return parseItem(await client.hmget(key, ...fields), fields);\n  }\n\n  private async getAndWatchBySerialisedKey(\n    client: ERedis,\n    keyName: string & keyof T,\n    serialisedValue: string,\n  ): Promise<string[]> {\n    if (keyName === 'id') {\n      return [serialisedValue];\n    }\n    const keyPrefix = this.keyPrefixes.get(keyName);\n    if (!keyPrefix) {\n      throw new Error(`Requested key ${keyName} not indexed`);\n    }\n    const keyAddress = `${keyPrefix}:${serialisedValue}`;\n    await client.watch(keyAddress);\n    return client.smembers(keyAddress);\n  }\n}\n","import type { Redis as RedisT } from 'ioredis';\nimport { minifyLuaScript, ExtendedRedis } from './helpers';\n\nexport interface ScriptExtensions {\n  add(keyCount: number, ...keysAndArgs: unknown[]): Promise<number>;\n  update(keyCount: number, ...keysAndArgs: unknown[]): Promise<number>;\n  checkUpdate(keyCount: number, ...keysAndArgs: unknown[]): Promise<number>;\n  updateWithoutCheck(keyCount: number, ...keysAndArgs: unknown[]): Promise<void>;\n  remove(keyCount: number, ...keysAndArgs: unknown[]): Promise<void>;\n}\n\nexport type ERedis = ExtendedRedis<ScriptExtensions>;\n\n// KEYS = [id, ...uniqueKeys, ...nonUniqueKeys]\nconst SCRIPT_ADD = minifyLuaScript([\n  'if redis.call(\"exists\",KEYS[1])==1 then',\n  '  return 0',\n  'end',\n  'for k=2,1+tonumber($uniqueKeyCount) do',\n  '  if redis.call(\"exists\",KEYS[k])==1 then',\n  '    return 0',\n  '  end',\n  'end',\n  'redis.call(\"hset\",KEYS[1],unpack(ARGV, 2))',\n  'for k=2,#KEYS do',\n  '  redis.call(\"sadd\",KEYS[k],ARGV[3])',\n  'end',\n  'return 1',\n], 'uniqueKeyCount');\n\nconst FRAG_CHECK_UPDATE = [\n  'for k=2,1+tonumber($uniqueKeyCount) do',\n  '  if redis.call(\"exists\",KEYS[k])==1 then',\n  '    return 0',\n  '  end',\n  'end',\n];\n\nconst FRAG_UPDATE = [\n  'local tkc=tonumber($totalKeyCount)',\n  'redis.call(\"hset\",KEYS[1],unpack(ARGV, 4))',\n  'for k=1,tkc do',\n  '  redis.call(\"smove\",KEYS[1+tkc+k],KEYS[1+k],$id)',\n  'end',\n];\n\n// KEYS = [id, ...patchUniqueKeys, ...patchNonUniqueKeys, ...oldUniqueKeys, ...oldNonUniqueKeys]\nconst SCRIPT_CHECK_UPDATE = minifyLuaScript([\n  ...FRAG_CHECK_UPDATE,\n  'return 1',\n], 'uniqueKeyCount', 'totalKeyCount', 'id');\n\n// KEYS = [id, ...patchUniqueKeys, ...patchNonUniqueKeys, ...oldUniqueKeys, ...oldNonUniqueKeys]\nconst SCRIPT_UPDATE_WITHOUT_CHECK = minifyLuaScript([\n  ...FRAG_UPDATE,\n], 'uniqueKeyCount', 'totalKeyCount', 'id');\n\n// KEYS = [id, ...patchUniqueKeys, ...patchNonUniqueKeys, ...oldUniqueKeys, ...oldNonUniqueKeys]\nconst SCRIPT_UPDATE = minifyLuaScript([\n  ...FRAG_CHECK_UPDATE,\n  ...FRAG_UPDATE,\n  'return 1',\n], 'uniqueKeyCount', 'totalKeyCount', 'id');\n\n// KEYS = [id, ...keys]\nconst SCRIPT_REMOVE = minifyLuaScript([\n  'redis.call(\"del\",KEYS[1])',\n  'for k=2,#KEYS do',\n  '  redis.call(\"srem\",KEYS[k],$id)',\n  'end',\n], 'id');\n\nexport default function defineAllScripts(client: RedisT): ERedis {\n  client.defineCommand('add', { lua: SCRIPT_ADD });\n  client.defineCommand('update', { lua: SCRIPT_UPDATE });\n  client.defineCommand('checkUpdate', { lua: SCRIPT_CHECK_UPDATE });\n  client.defineCommand('updateWithoutCheck', { lua: SCRIPT_UPDATE_WITHOUT_CHECK });\n  client.defineCommand('remove', { lua: SCRIPT_REMOVE });\n\n  return client as ERedis;\n}\n","import type { Redis as RedisT, RedisOptions as RedisOptionsT } from 'ioredis';\nimport defineAllScripts, { ERedis } from './scripts';\nimport retry from '../helpers/retry';\n\ntype RS = new(host?: string, options?: RedisOptionsT) => RedisT;\n\nconst withRetry = retry((e) => (\n  typeof e === 'object' &&\n  e.message === 'transient error'\n));\n\nexport default class RedisConnectionPool {\n  private readonly connections: ERedis[] = [];\n\n  private inUse = 0;\n\n  private queue: ((client: ERedis) => void)[] = [];\n\n  private closingFn?: () => void;\n\n  private closed = false;\n\n  public constructor(\n    private readonly RedisStatic: RS,\n    private readonly url: string,\n    private readonly options: RedisOptionsT,\n    private readonly maxConnections: number,\n  ) {}\n\n  public async withConnection<T>(\n    fn: (c: ERedis) => Promise<T> | T,\n    teardown?: (c: ERedis) => Promise<void> | void,\n  ): Promise<T> {\n    const c = await this.getConnection();\n    try {\n      return await fn(c);\n    } finally {\n      await teardown?.(c);\n      this.returnConnection(c);\n    }\n  }\n\n  public async retryWithConnection<T>(\n    fn: (c: ERedis) => Promise<T> | T,\n    teardown?: (c: ERedis) => Promise<void> | void,\n  ): Promise<T> {\n    return withRetry(() => this.withConnection(fn, teardown));\n  }\n\n  public close(): Promise<void> {\n    if (this.closed) {\n      return Promise.resolve();\n    }\n\n    this.closed = true;\n    if (this.inUse === 0) {\n      this.doClose();\n      return Promise.resolve();\n    }\n\n    return new Promise((resolve): void => {\n      this.closingFn = (): void => {\n        this.doClose();\n        resolve();\n      };\n    });\n  }\n\n  private doClose(): void {\n    this.connections.forEach((c) => c.disconnect());\n    this.connections.length = 0;\n  }\n\n  private async getConnection(): Promise<ERedis> {\n    if (this.closed) {\n      throw new Error('Connection closed');\n    }\n\n    const r = this.connections.pop();\n    if (r) {\n      this.inUse += 1;\n      return r;\n    }\n    if (this.inUse < this.maxConnections) {\n      this.inUse += 1;\n      const client = new this.RedisStatic(this.url, this.options);\n      await client.connect();\n      return defineAllScripts(client);\n    }\n    return new Promise((resolve): void => {\n      this.queue.push(resolve);\n    });\n  }\n\n  private returnConnection(c: ERedis): void {\n    const q = this.queue.shift();\n    if (q) {\n      q(c);\n    } else {\n      this.inUse -= 1;\n      this.connections.push(c);\n      if (this.inUse === 0) {\n        this.closingFn?.();\n      }\n    }\n  }\n}\n","import RedisCollection from './RedisCollection';\nimport type { DBKeys } from '../interfaces/DB';\nimport BaseDB from '../interfaces/BaseDB';\nimport type { IDable } from '../interfaces/IDable';\nimport RedisConnectionPool from './RedisConnectionPool';\n\nexport default class RedisDb extends BaseDB {\n  private constructor(\n    private readonly pool: RedisConnectionPool,\n  ) {\n    super((name, keys) => new RedisCollection(this.pool, name, keys));\n  }\n\n  public static async connect(url: string): Promise<RedisDb> {\n    const { default: RedisStatic } = await import('ioredis');\n    // The built in reply transformer can only be disabled globally :(\n    // See https://github.com/luin/ioredis/issues/1267\n    RedisStatic.Command.setReplyTransformer('hgetall', (x) => x);\n    const connectionPoolSize = 5;\n    return new RedisDb(new RedisConnectionPool(\n      RedisStatic,\n      url,\n      { lazyConnect: true },\n      connectionPoolSize,\n    ));\n  }\n\n  public getCollection<T extends IDable>(name: string, keys?: DBKeys<T>): RedisCollection<T> {\n    return super.getCollection(name, keys) as RedisCollection<T>;\n  }\n\n  public getConnectionPool(): RedisConnectionPool {\n    return this.pool;\n  }\n\n  protected internalClose(): Promise<void> {\n    return this.pool.close();\n  }\n}\n","export function quoteHValue(v: string): string {\n  return `\"${v.replace(/([\"\\\\])/g, '\\\\$1')}\"`;\n}\n\nexport function encodeHStore(record: Map<string, string>): string {\n  const result: string[] = [];\n  record.forEach((v, k) => {\n    result.push(`${quoteHValue(k)}=>${quoteHValue(v)}`);\n  });\n  return result.join(',');\n}\n\nexport function decodeHStore(hstore: string): Map<string, string> {\n  const result = new Map<string, string>();\n  let current = '';\n  let currentKey = '';\n  let quote = false;\n  for (let p = 0; p < hstore.length;) {\n    const c = hstore[p];\n    switch (c) {\n      case ' ':\n      case '\\r':\n      case '\\n':\n      case '\\t':\n        if (quote) {\n          current += c;\n        }\n        break;\n      case '\\\\':\n        current += hstore[p + 1];\n        p += 1;\n        break;\n      case '\"':\n        quote = !quote;\n        break;\n      case '=':\n        if (quote) {\n          current += c;\n        } else if (hstore[p + 1] === '>') {\n          currentKey = current;\n          current = '';\n          p += 1;\n        }\n        break;\n      case ',':\n        if (quote) {\n          current += c;\n        } else {\n          result.set(currentKey, current);\n          currentKey = '';\n          current = '';\n        }\n        break;\n      default:\n        current += c;\n        break;\n    }\n    p += 1;\n  }\n  if (currentKey) {\n    result.set(currentKey, current);\n  }\n  return result;\n}\n","const DQUOTE_REG = /\"/g;\nexport function quoteIdentifier(msg: string): string {\n  return `\"${msg.replace(DQUOTE_REG, '\"\"')}\"`;\n}\n\nconst SQUOTE_REG = /'/g;\nexport function quoteValue(msg: string): string {\n  // only used for creating indices,\n  // because prepared statements do not support CREATE\n  return `'${msg.replace(SQUOTE_REG, '\\'\\'')}'`;\n}\n\nconst ID_REG = /\\$[A-Z]/g;\nexport function withIdentifiers(\n  base: string, // expects trusted (internal) source\n  identifiers: Record<string, string>,\n): string {\n  return base.replace(\n    ID_REG,\n    (v) => quoteIdentifier(identifiers[v.substr(1)]),\n  );\n}\n","import type { Pool as PgPoolT, QueryArrayResult as PgQueryArrayResultT } from 'pg';\nimport type { IDable } from '../interfaces/IDable';\nimport BaseCollection from '../interfaces/BaseCollection';\nimport type { DBKeys } from '../interfaces/DB';\nimport type { StateRef } from '../interfaces/BaseDB';\nimport { serialiseValue, serialiseRecord, partialDeserialiseRecord, Serialised } from '../helpers/serialiser';\nimport { encodeHStore, decodeHStore } from './hstore';\nimport { withIdentifiers, quoteValue } from './sql';\n\nconst STATEMENTS = {\n  CREATE_TABLE: [\n    'CREATE TABLE IF NOT EXISTS $T (',\n    'id TEXT NOT NULL PRIMARY KEY,',\n    'data HSTORE NOT NULL',\n    ')',\n  ].join(''),\n\n  GET_INDEX_NAMES: 'SELECT indexname FROM pg_indexes WHERE tablename=$1 AND schemaname=current_schema()',\n\n  CREATE_INDEX: 'CREATE INDEX IF NOT EXISTS $I ON $T USING HASH ((data->$1))',\n  CREATE_UNIQUE_INDEX: 'CREATE UNIQUE INDEX IF NOT EXISTS $I ON $T ((data->$1))',\n  DROP_INDEX: 'DROP INDEX IF EXISTS $I',\n\n  INSERT: 'INSERT INTO $T (id, data) VALUES ($1, $2::hstore)',\n\n  UPDATE: 'UPDATE $T SET data=data||$1::hstore WHERE data->$2=$3 RETURNING id',\n  UPDATE_IF_ID: 'UPDATE $T SET data=data||$1::hstore WHERE data->$2=$3 RETURNING CASE WHEN id<>$4 THEN LENGTH(id)/0 ELSE 1 END',\n  UPDATE_ID: 'UPDATE $T SET data=data||$1::hstore WHERE id=$2',\n\n  UPSERT_ID: 'INSERT INTO $T (id, data) VALUES ($1, $2::hstore) ON CONFLICT (id) DO UPDATE SET data=$T.data||$2::hstore',\n\n  SELECT_ONE: 'SELECT id, data FROM $T WHERE data->$1=$2 LIMIT 1',\n  SELECT_ALL: 'SELECT id, data FROM $T',\n  SELECT_ALL_BY: 'SELECT id, data FROM $T WHERE data->$1=$2',\n  SELECT_ID: 'SELECT id, data FROM $T WHERE id=$1',\n\n  DELETE: 'DELETE FROM $T WHERE data->$1=$2',\n  DELETE_ID: 'DELETE FROM $T WHERE id=$1',\n};\n\nasync function configureTable(\n  pool: PgPoolT,\n  tableName: string,\n  keys: DBKeys<any> = {},\n): Promise<void> {\n  const c = await pool.connect();\n  try {\n    /* eslint-disable no-await-in-loop */ // client cannot multitask\n\n    await c.query(withIdentifiers(STATEMENTS.CREATE_TABLE, {\n      T: tableName,\n    }));\n\n    const indices = await c.query({\n      rowMode: 'array',\n      text: STATEMENTS.GET_INDEX_NAMES,\n      values: [tableName],\n    });\n    const oldIndexNames = new Set(\n      indices.rows\n        .map((r) => r[0])\n        .filter((i) => (i.startsWith(`${tableName}_i`) || i.startsWith(`${tableName}_u`))),\n    );\n\n    // PostgreSQL does not support prepared statements for CREATE statements,\n    // so we must escape the values manually using quoteValue.\n    const keyEntries = Object.entries(keys);\n    for (let i = 0; i < keyEntries.length; i += 1) {\n      const [k, v] = keyEntries[i];\n      if (v && v.unique) {\n        const name = `${tableName}_u${k}`;\n        if (!oldIndexNames.delete(name)) {\n          await c.query(withIdentifiers(STATEMENTS.CREATE_UNIQUE_INDEX, {\n            T: tableName,\n            I: name,\n          }).replace(/\\$1/g, quoteValue(k)));\n        }\n      } else {\n        const name = `${tableName}_i${k}`;\n        if (!oldIndexNames.delete(name)) {\n          await c.query(withIdentifiers(STATEMENTS.CREATE_INDEX, {\n            T: tableName,\n            I: name,\n          }).replace(/\\$1/g, quoteValue(k)));\n        }\n      }\n    }\n    const indicesToDelete = [...oldIndexNames];\n    for (let i = 0; i < indicesToDelete.length; i += 1) {\n      const idx = indicesToDelete[i];\n      await c.query(withIdentifiers(STATEMENTS.DROP_INDEX, {\n        T: tableName,\n        I: idx,\n      }));\n    }\n\n    /* eslint-enable no-await-in-loop */\n  } finally {\n    c.release();\n  }\n}\n\nfunction fromHStore<T, F extends readonly (string & keyof T)[]>(\n  [id, data]: [string, string],\n  fields?: F,\n): Pick<T, F[-1]> {\n  return partialDeserialiseRecord<T, F>(decodeHStore(data).set('id', id) as Serialised<T>, fields);\n}\n\nexport default class PostgresCollection<T extends IDable> extends BaseCollection<T> {\n  private readonly cachedQueries = new Map<keyof typeof STATEMENTS, string>();\n\n  public constructor(\n    private readonly pool: PgPoolT,\n    private readonly tableName: string,\n    keys: DBKeys<T> = {},\n    private readonly stateRef: StateRef = { closed: false },\n  ) {\n    super(keys);\n\n    this.initAsync(configureTable(pool, tableName, keys));\n  }\n\n  protected async internalAdd(item: T): Promise<void> {\n    const serialised = serialiseRecord(item);\n    const id = serialised.get('id');\n    serialised.delete('id');\n    await this.runTableQuery('INSERT', id, encodeHStore(serialised));\n  }\n\n  protected async internalUpsert(\n    id: T['id'],\n    update: Partial<T>,\n  ): Promise<void> {\n    await this.runTableQuery(\n      'UPSERT_ID',\n      serialiseValue(id),\n      encodeHStore(serialiseRecord(update)),\n    );\n  }\n\n  protected async internalUpdate<K extends string & keyof T>(\n    searchAttribute: K,\n    searchValue: T[K],\n    item: Partial<T>,\n  ): Promise<void> {\n    const sId = serialiseValue(searchValue);\n    const serialised = serialiseRecord(item);\n    const id = serialised.get('id');\n    serialised.delete('id');\n    const hstore = encodeHStore(serialised);\n\n    if (searchAttribute === 'id') {\n      await this.runTableQuery('UPDATE_ID', hstore, sId);\n    } else if (id !== undefined) {\n      try {\n        await this.runTableQuery('UPDATE_IF_ID', hstore, searchAttribute, sId, id);\n      } catch (e) {\n        if (e.message.includes('division by zero')) {\n          // We use /0 to intentionally throw an error in UPDATE_IF_ID to distinguish between\n          // the case of no records found to update, vs. found a record but did not match ID.\n          // Being an error, it causes an automatic rollback of any other changes.\n          // Nothing else can cause a /0 error in this statement.\n          throw new Error('Cannot update ID');\n        } else {\n          throw e;\n        }\n      }\n    } else {\n      await this.runTableQuery('UPDATE', hstore, searchAttribute, sId);\n    }\n  }\n\n  protected async internalGet<\n    K extends string & keyof T,\n    F extends readonly (string & keyof T)[]\n  >(\n    searchAttribute: K,\n    searchValue: T[K],\n    returnAttributes?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>> | null> {\n    let raw: PgQueryArrayResultT<[string, string]>;\n    if (searchAttribute === 'id') {\n      raw = await this.runTableQuery('SELECT_ID', serialiseValue(searchValue));\n    } else {\n      raw = await this.runTableQuery('SELECT_ONE', searchAttribute, serialiseValue(searchValue));\n    }\n    if (!raw.rowCount) {\n      return null;\n    }\n    return fromHStore<T, F>(raw.rows[0], returnAttributes);\n  }\n\n  protected async internalGetAll<\n    K extends string & keyof T,\n    F extends readonly (string & keyof T)[]\n  >(\n    searchAttribute?: K,\n    searchValue?: T[K],\n    returnAttributes?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>>[]> {\n    let raw: PgQueryArrayResultT<[string, string]>;\n    if (!searchAttribute) {\n      raw = await this.runTableQuery('SELECT_ALL');\n    } else if (searchAttribute === 'id') {\n      raw = await this.runTableQuery('SELECT_ID', serialiseValue(searchValue));\n    } else {\n      raw = await this.runTableQuery('SELECT_ALL_BY', searchAttribute, serialiseValue(searchValue));\n    }\n    return raw.rows.map((v) => fromHStore<T, F>(v, returnAttributes));\n  }\n\n  protected async internalRemove<K extends string & keyof T>(\n    searchAttribute: K,\n    searchValue: T[K],\n  ): Promise<number> {\n    let raw: PgQueryArrayResultT<[]>;\n    if (searchAttribute === 'id') {\n      raw = await this.runTableQuery('DELETE_ID', serialiseValue(searchValue));\n    } else {\n      raw = await this.runTableQuery('DELETE', searchAttribute, serialiseValue(searchValue));\n    }\n    return raw.rowCount;\n  }\n\n  private runTableQuery<R extends any[] = unknown[]>(\n    queryName: keyof typeof STATEMENTS,\n    ...values: unknown[]\n  ): Promise<PgQueryArrayResultT<R>> {\n    if (this.stateRef.closed) {\n      throw new Error('Connection closed');\n    }\n\n    let cached = this.cachedQueries.get(queryName);\n    if (!cached) {\n      cached = withIdentifiers(STATEMENTS[queryName], { T: this.tableName });\n      this.cachedQueries.set(queryName, cached);\n    }\n\n    return this.pool.query({\n      name: `${this.tableName}_${queryName}`,\n      rowMode: 'array',\n      text: cached,\n      values,\n    });\n  }\n}\n","import type { Pool as PgPoolT } from 'pg';\nimport PostgresCollection from './PostgresCollection';\nimport type { DBKeys } from '../interfaces/DB';\nimport BaseDB from '../interfaces/BaseDB';\nimport type { IDable } from '../interfaces/IDable';\n\nexport default class PostgresDb extends BaseDB {\n  private constructor(\n    private readonly pool: PgPoolT,\n  ) {\n    super((name, keys) => new PostgresCollection(pool, name, keys, this.stateRef));\n  }\n\n  public static async connect(url: string): Promise<PostgresDb> {\n    const { Pool } = await import('pg');\n    const pool = new Pool({ connectionString: url });\n    await pool.query('CREATE EXTENSION IF NOT EXISTS hstore');\n    return new PostgresDb(pool);\n  }\n\n  public getCollection<T extends IDable>(name: string, keys?: DBKeys<T>): PostgresCollection<T> {\n    return super.getCollection(name, keys) as PostgresCollection<T>;\n  }\n\n  public getConnectionPool(): PgPoolT {\n    return this.pool;\n  }\n\n  protected internalClose(): Promise<void> {\n    return this.pool.end();\n  }\n}\n","import type { Collection, UpdateOptions, Indices } from '../interfaces/Collection';\nimport type { IDable } from '../interfaces/IDable';\nimport { makeKeyValue } from '../helpers/safeAccess';\n\nexport type Wrapped<T extends IDable, Fields extends keyof T, FieldStorage> = {\n  [K in keyof T]: K extends 'id' ? T[K] : K extends Fields ? FieldStorage : T[K];\n};\n\nexport interface Wrapper<T extends IDable, K extends keyof T, FieldStorage, CustomData> {\n  wrap: (\n    key: K,\n    value: T[K],\n    processed: CustomData,\n  ) => Promise<FieldStorage> | FieldStorage;\n\n  unwrap: (\n    key: K,\n    value: FieldStorage,\n    processed: CustomData,\n  ) => Promise<T[K]> | T[K];\n\n  preWrap?: (\n    record: Readonly<Partial<T>>,\n  ) => Promise<CustomData> | CustomData;\n\n  preUnwrap?: (\n    record: Readonly<Partial<Wrapped<T, K, FieldStorage>>>,\n  ) => Promise<CustomData> | CustomData;\n\n  preRemove?: (\n    record: Readonly<Pick<Wrapped<T, K, FieldStorage>, 'id'>>,\n  ) => Promise<void> | void;\n}\n\nfunction hasAnyField(\n  value: Record<string, unknown>,\n  fields: readonly string[],\n): boolean {\n  return fields\n    .some((field) => Object.prototype.hasOwnProperty.call(value, field));\n}\n\nexport default class WrappedCollection<\n  T extends IDable,\n  WF extends readonly (keyof Omit<T, 'id'> & string)[],\n  FieldStorage,\n  E,\n  Inner extends Wrapped<T, WF[-1], FieldStorage> = Wrapped<T, WF[-1], FieldStorage>\n> implements Collection<T> {\n  public constructor(\n    private readonly baseCollection: Collection<Inner>,\n    private readonly fields: WF,\n    private readonly wrapper: Wrapper<T, WF[-1], FieldStorage, E>,\n  ) {\n    fields.forEach((field) => {\n      if (baseCollection.indices.isUniqueIndex(field)) {\n        throw new Error(`Cannot wrap unique index ${field}`);\n      }\n    });\n  }\n\n  public async add(entry: T): Promise<void> {\n    return this.baseCollection.add(await this.wrapAll(entry));\n  }\n\n  public async get<\n    K extends keyof T & keyof Inner & string,\n    F extends readonly (string & keyof T)[]\n  >(\n    key: K,\n    value: T[K] & Inner[K],\n    fields?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>> | null> {\n    if (this.fields.includes(key as any)) {\n      throw new Error('Cannot get by wrapped value');\n    }\n    const raw = await this.baseCollection.get(key, value, fields!);\n    return raw ? this.unwrapAll(raw, makeKeyValue(key, value)) : null;\n  }\n\n  public async getAll<\n    K extends keyof T & keyof Inner & string,\n    F extends readonly (string & keyof T)[]\n  >(\n    key?: K,\n    value?: T[K] & Inner[NonNullable<K>],\n    fields?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>>[]> {\n    if (key !== undefined && this.fields.includes(key as any)) {\n      throw new Error('Cannot get by wrapped value');\n    }\n    const raw = await this.baseCollection.getAll(key!, value!, fields!);\n    const extra = (key !== undefined) ? makeKeyValue(key, value) : undefined;\n    return Promise.all(raw.map((v) => this.unwrapAll(v, extra)));\n  }\n\n  public async update<K extends keyof T & keyof Inner & string>(\n    key: K,\n    value: T[K] & Inner[K],\n    update: Partial<T>,\n    options?: UpdateOptions,\n  ): Promise<void> {\n    if (this.fields.includes(key as any)) {\n      throw new Error('Cannot update by wrapped value');\n    }\n    const converted = await this.wrapAll(update, makeKeyValue(key, value));\n    return this.baseCollection.update(key, value, converted, options);\n  }\n\n  public async remove<K extends string & keyof T>(\n    key: K,\n    value: T[K] & Inner[K],\n  ): Promise<number> {\n    if (this.fields.includes(key as any)) {\n      throw new Error('Cannot remove by wrapped value');\n    }\n    if (!this.wrapper.preRemove) {\n      return this.baseCollection.remove(key, value);\n    }\n\n    const items = await this.baseCollection.getAll(key, value, ['id']);\n    await Promise.all(items.map(async (item) => {\n      await this.wrapper.preRemove!(item);\n      await this.baseCollection.remove('id', item.id);\n    }));\n    return items.length;\n  }\n\n  public get indices(): Indices<T> {\n    return this.baseCollection.indices as Indices<T>;\n  }\n\n  private async wrapAll(\n    v: Readonly<T>,\n    extra?: Record<string, unknown>,\n  ): Promise<Inner>;\n\n  private async wrapAll(\n    v: Readonly<Partial<T>>,\n    extra?: Record<string, unknown>,\n  ): Promise<Partial<Inner>>;\n\n  private async wrapAll(\n    v: Readonly<Partial<T>>,\n    extra?: Record<string, unknown>,\n  ): Promise<Partial<Inner>> {\n    let processed: E;\n    if (this.wrapper.preWrap && hasAnyField(v, this.fields)) {\n      const allFields = extra ? { ...extra, ...v } : v;\n      processed = await this.wrapper.preWrap(allFields);\n    }\n    const converted = { ...v } as any;\n    await Promise.all(this.fields.map(async (k) => {\n      if (Object.prototype.hasOwnProperty.call(v, k)) {\n        // this is safe because converted is initialised from v, and k is in v\n        converted[k] = await this.wrapper.wrap(k, (v as any)[k], processed);\n      }\n    }));\n    return converted;\n  }\n\n  private async unwrapAll(\n    v: Readonly<Inner>,\n    extra?: Record<string, unknown>,\n  ): Promise<T>;\n\n  private async unwrapAll<K extends keyof T>(\n    v: Readonly<Pick<Inner, K>>,\n    extra?: Record<string, unknown>,\n  ): Promise<Pick<T, K>>;\n\n  private async unwrapAll<K extends keyof T>(\n    v: Readonly<Pick<Inner, K>>,\n    extra?: Record<string, unknown>,\n  ): Promise<Pick<T, K>> {\n    let processed: E;\n    if (this.wrapper.preUnwrap && hasAnyField(v, this.fields)) {\n      const allFields = extra ? { ...extra, ...v } : v;\n      processed = await this.wrapper.preUnwrap(allFields as any);\n    }\n    const converted = { ...v } as any;\n    await Promise.all(this.fields.map(async (k) => {\n      if (Object.prototype.hasOwnProperty.call(v, k)) {\n        // this is safe because converted is initialised from v, and k is in v\n        converted[k] = await this.wrapper.unwrap(k, (v as any)[k], processed);\n      }\n    }));\n    return converted;\n  }\n}\n","import crypto, { KeyObject } from 'crypto';\nimport type Encryption from './Encryption';\n\nconst ALG = 'aes-256-cbc';\nconst ALG_BUF = Buffer.from(`${ALG}:`, 'utf8');\nconst IV_LEN = 16;\n\nconst nodeEncryptionSync: Encryption<KeyObject, Buffer> = {\n  encrypt: (key: KeyObject, v: Buffer): Buffer => {\n    const iv = crypto.randomBytes(IV_LEN);\n    const cipher = crypto.createCipheriv(ALG, key, iv);\n    const part = cipher.update(v);\n    const final = cipher.final();\n    return Buffer.concat([ALG_BUF, iv, part, final]);\n  },\n\n  decrypt: (key: KeyObject, v: Buffer): Buffer => {\n    if (!v.slice(0, ALG_BUF.length).equals(ALG_BUF)) {\n      throw new Error('Unknown encryption algorithm');\n    }\n\n    const iv = v.slice(ALG_BUF.length, ALG_BUF.length + IV_LEN);\n    const encrypted = v.slice(ALG_BUF.length + IV_LEN);\n\n    const decipher = crypto.createDecipheriv(ALG, key, iv);\n    const part = decipher.update(encrypted);\n    const final = decipher.final();\n\n    return Buffer.concat([part, final]);\n  },\n\n  generateKey: (): KeyObject => crypto\n    .createSecretKey(crypto.randomBytes(32)),\n\n  serialiseKey: (key: KeyObject): Buffer => key.export(),\n\n  deserialiseKey: (data: Buffer): KeyObject => crypto.createSecretKey(data),\n};\n\nexport default nodeEncryptionSync;\n","import type { Collection, UpdateOptions, Indices } from '../interfaces/Collection';\nimport type { IDable } from '../interfaces/IDable';\nimport LruCache from '../helpers/LruCache';\nimport {\n  serialiseValue,\n  deserialiseValue,\n  serialiseRecord,\n  partialDeserialiseRecord,\n  Serialised,\n} from '../helpers/serialiser';\n\nexport interface CacheOptions {\n  capacity?: number;\n  maxAge?: number;\n  time?: () => number;\n}\n\ninterface CacheItem<T> {\n  serialised: Serialised<T> | null;\n  partial: boolean;\n  time: number;\n}\n\nfunction appendField<T extends string, K extends string>(\n  fields: Readonly<T[]> | undefined,\n  extra: K,\n): Readonly<(T | K)[]> | undefined {\n  if (!fields || fields.includes(extra as unknown as T)) {\n    return fields;\n  }\n  return [...fields, extra];\n}\n\nclass CachedCollection<T extends IDable> implements Collection<T> {\n  private readonly maxAge: number;\n\n  private readonly time: () => number;\n\n  private readonly cache: LruCache<string, CacheItem<T>>;\n\n  private readonly customIndexData: Map<string & keyof T, Map<string, Set<string>>>;\n\n  public constructor(\n    private readonly baseCollection: Collection<T>,\n    {\n      capacity = Number.POSITIVE_INFINITY,\n      maxAge = Number.POSITIVE_INFINITY,\n      time = Date.now,\n    }: CacheOptions,\n  ) {\n    this.maxAge = maxAge;\n    this.time = time;\n    this.cache = new LruCache(capacity, this.removeIndices.bind(this));\n    this.customIndexData = new Map(baseCollection.indices.getCustomIndices()\n      .map((k) => ([k, new Map()])));\n  }\n\n  public async add(entry: T): Promise<void> {\n    await this.baseCollection.add(entry);\n    this.storeItem(serialiseRecord(entry), false);\n  }\n\n  public async get<\n    K extends string & keyof T,\n    F extends readonly (string & keyof T)[]\n  >(\n    key: K,\n    value: T[K],\n    fields?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>> | null> {\n    if (key === 'id') {\n      const cacheItem = await this.cachedById(value as T['id'], fields);\n      if (!cacheItem.serialised) {\n        return null;\n      }\n      return partialDeserialiseRecord(cacheItem.serialised, fields);\n    }\n    if (this.indices.isUniqueIndex(key)) {\n      const keys = this.getKeys(key, value);\n      if (keys.length) {\n        const cacheItem = await this.cachedById(deserialiseValue(keys[0]) as T['id'], appendField(fields, key));\n        if (cacheItem.serialised && cacheItem.serialised.get(key) === serialiseValue(value)) {\n          return partialDeserialiseRecord(cacheItem.serialised, fields);\n        }\n      }\n    }\n\n    const item = await this.baseCollection.get(key, value, appendField(fields, 'id')!);\n    if (item) {\n      this.storeItem(serialiseRecord(item).set(key, serialiseValue(value)), Boolean(fields));\n    } else {\n      this.getKeys(key, value).forEach((k) => this.cache.remove(k));\n    }\n    return item;\n  }\n\n  public async getAll<\n    K extends string & keyof T,\n    F extends readonly (string & keyof T)[]\n  >(\n    key?: K,\n    value?: T[NonNullable<K>],\n    fields?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>>[]> {\n    if (!key) {\n      const allItems = await this.baseCollection.getAll();\n      this.cache.clear();\n      allItems.forEach((item) => this.storeItem(serialiseRecord(item), false));\n      return allItems;\n    }\n    if (this.indices.isUniqueIndex(key)) {\n      const item = await this.get(key, value!, fields);\n      return item ? [item] : [];\n    }\n    const items = await this.baseCollection.getAll(key, value!, appendField(fields, 'id')!);\n    if (this.indices.isIndex(key)) {\n      const idxKeys = new Set(this.getKeys(key, value!));\n      items.forEach(({ id }) => idxKeys.delete(serialiseValue(id)));\n      idxKeys.forEach((k) => this.cache.remove(k));\n    }\n    if (fields && !fields.includes('id')) {\n      return items.map(({ id, ...restItem }) => (restItem as Pick<T, F[-1]>));\n    }\n    return items;\n  }\n\n  public async update<K extends string & keyof T>(\n    key: K,\n    value: T[K],\n    update: Partial<T>,\n    options?: UpdateOptions,\n  ): Promise<void> {\n    await this.baseCollection.update(key, value, update, options);\n    const keys = this.getKeys(key, value);\n    const serialisedUpdate = serialiseRecord(update);\n    keys.forEach((itemKey) => {\n      const item = this.cache.peek(itemKey)!;\n      const { serialised } = item;\n      if (serialised) {\n        this.removeIndices(item);\n        serialisedUpdate.forEach((v, k) => {\n          serialised.set(k, v);\n        });\n        this.populateIndices(item);\n      }\n    });\n    if (!keys.length && options?.upsert && key === 'id') {\n      this.storeItem(serialiseRecord(update).set('id', serialiseValue(value)), true);\n    }\n  }\n\n  public async remove<K extends string & keyof T>(\n    key: K,\n    value: T[K],\n  ): Promise<number> {\n    const removed = await this.baseCollection.remove(key, value);\n    if (removed > 0) {\n      this.getKeys(key, value).forEach((k) => {\n        this.cache.add(k, { serialised: null, partial: false, time: this.time() });\n      });\n    }\n    return removed;\n  }\n\n  public get indices(): Indices<T> {\n    return this.baseCollection.indices;\n  }\n\n  private getKeys<K extends string & keyof T>(key: K, value: T[K]): string[] {\n    const sv = serialiseValue(value);\n    if (key === 'id') {\n      return [sv];\n    }\n    const keys = this.customIndexData.get(key)?.get(sv);\n    return keys ? [...keys] : [];\n  }\n\n  private populateIndices({ serialised }: CacheItem<T>): void {\n    if (!serialised) {\n      return;\n    }\n\n    const id = serialised.get('id')!;\n    this.customIndexData.forEach((idx, attr) => {\n      const value = serialised.get(attr);\n      if (!value) {\n        return;\n      }\n      let idxKeys = idx.get(value);\n      if (!idxKeys) {\n        idxKeys = new Set([id]);\n        idx.set(value, idxKeys);\n      } else if (idxKeys.size && this.indices.isUniqueIndex(attr)) {\n        const idxKey = [...idxKeys][0];\n        if (idxKey !== id) {\n          this.cache.remove(idxKey);\n          idx.set(value, new Set([id]));\n        }\n      } else {\n        idxKeys.add(id);\n      }\n    });\n  }\n\n  private removeIndices({ serialised }: CacheItem<T>): void {\n    if (!serialised) {\n      return;\n    }\n\n    const id = serialised.get('id')!;\n    this.customIndexData.forEach((idx, attr) => {\n      const value = serialised.get(attr);\n      if (!value) {\n        return;\n      }\n      const idxKeys = idx.get(value)!;\n      idxKeys.delete(id);\n      if (!idxKeys.size) {\n        idx.delete(value);\n      }\n    });\n  }\n\n  private storeItem(serialised: Serialised<T>, partial: boolean): void {\n    const cacheItem = { serialised, partial, time: this.time() };\n    this.populateIndices(cacheItem);\n    this.cache.add(serialised.get('id')!, cacheItem);\n  }\n\n  private cachedById<F extends readonly (string & keyof T)[]>(\n    id: T['id'],\n    fields?: F,\n  ): Promise<CacheItem<T>> {\n    const key = serialiseValue(id);\n    return this.cache.cachedAsync(key, async () => {\n      const item = await this.baseCollection.get('id', id, fields!);\n      const cacheItem = {\n        serialised: item ? serialiseRecord(item).set('id', key) : null,\n        partial: Boolean(fields),\n        time: this.time(),\n      };\n      this.populateIndices(cacheItem);\n      return cacheItem;\n    }, this.isFresh(fields));\n  }\n\n  private isFresh(fields?: readonly (string & keyof T)[]): (item: CacheItem<T>) => boolean {\n    return ({ serialised, partial, time }: CacheItem<T>): boolean => {\n      if (this.time() > time + this.maxAge) {\n        return false;\n      }\n      if (!serialised || !partial) {\n        return true;\n      }\n      if (!fields) {\n        return false;\n      }\n      return fields.every((field) => serialised.has(field));\n    };\n  }\n}\n\nexport function cache<T extends IDable>(\n  baseCollection: Collection<T>,\n  options: CacheOptions = {},\n): Collection<T> {\n  if (\n    (options.capacity !== undefined && options.capacity <= 0) ||\n    (options.maxAge !== undefined && options.maxAge < 0)\n  ) {\n    return baseCollection;\n  }\n  return new CachedCollection<T>(baseCollection, options);\n}\n","import type { IDable, IDableBy, IDType } from '../interfaces/IDable';\nimport type { Collection } from '../interfaces/Collection';\nimport LruCache from '../helpers/LruCache';\nimport { serialiseValueBin, deserialiseValueBin } from '../helpers/serialiser';\nimport WrappedCollection, { Wrapped } from './WrappedCollection';\nimport type Encryption from './encryption/Encryption';\nimport nodeEncryptionSync from './encryption/nodeEncryptionSync';\nimport { cache, CacheOptions } from './cached';\n\nexport interface KeyRecord<ID extends IDType, KeyT> {\n  id: ID;\n  key: KeyT;\n}\n\nexport type Encrypted<T extends IDable, WF extends keyof T> = Wrapped<T, WF, Buffer>;\n\ntype EncryptableKeys<T> = readonly (keyof Omit<T, 'id'> & string)[];\n\ntype Encrypter<ID extends IDType> = <T extends IDableBy<ID>>(\n) => <F extends EncryptableKeys<T>>(\n  fields: F,\n  baseCollection: Collection<Encrypted<T, F[-1]>>,\n) => Collection<T>;\n\n// makeEncrypter provides optional 2-tier function call due to\n// https://github.com/Microsoft/TypeScript/issues/26242\n\nfunction makeEncrypter<ID extends IDType>(\n  wrapper: <T extends IDableBy<ID>, F extends EncryptableKeys<T>>(\n    fields: F,\n    baseCollection: Collection<Encrypted<T, F[-1]>>,\n  ) => Collection<T>,\n): Encrypter<ID> {\n  return (fields?: any, baseCollection?: Collection<any>): any => {\n    if (fields && baseCollection) {\n      // non-typescript API (remove need for extra ())\n      return wrapper(fields, baseCollection) as any;\n    }\n    return wrapper;\n  };\n}\n\nexport interface EncryptionOptions<KeyT = Buffer, SerialisedKeyT = Buffer> {\n  allowRaw?: boolean;\n  encryption?: Encryption<KeyT, SerialisedKeyT>;\n}\n\nexport interface RecordEncryptionOptions {\n  keyCache?: CacheOptions;\n}\n\ninterface CustomEncryptionOptions<KeyT, SerialisedKeyT>\n  extends EncryptionOptions<KeyT, SerialisedKeyT> {\n  encryption: Encryption<KeyT, SerialisedKeyT>;\n}\n\nfunction encryptByKey(\n  sKey: Buffer,\n  options?: EncryptionOptions,\n): Encrypter<IDType>;\n\nfunction encryptByKey<KeyT, SerialisedKeyT>(\n  sKey: SerialisedKeyT,\n  options: CustomEncryptionOptions<KeyT, SerialisedKeyT>,\n): Encrypter<IDType>;\n\nfunction encryptByKey<KeyT, SerialisedKeyT>(\n  sKey: SerialisedKeyT,\n  {\n    encryption = nodeEncryptionSync as any,\n    allowRaw = false,\n  }: EncryptionOptions<KeyT, SerialisedKeyT> = {},\n): Encrypter<IDType> {\n  const key = encryption.deserialiseKey(sKey);\n\n  return makeEncrypter(<T extends IDable, F extends EncryptableKeys<T>>(\n    fields: F,\n    baseCollection: Collection<Encrypted<T, F[-1]>>,\n  ) => new WrappedCollection<T, F, Buffer, never>(baseCollection, fields, {\n    wrap: (k, v): Promise<Buffer> | Buffer => encryption.encrypt(key, serialiseValueBin(v)),\n    unwrap: async (k, v): Promise<any> => {\n      if (!(v instanceof Buffer)) {\n        if (allowRaw) {\n          return v; // probably an old record before encryption was added\n        }\n        throw new Error('unencrypted data');\n      }\n      return deserialiseValueBin(await encryption.decrypt(key, v));\n    },\n  }));\n}\n\nfunction encryptByRecord<ID extends IDType>(\n  keyCollection: Collection<KeyRecord<ID, Buffer>>,\n  options?: EncryptionOptions & RecordEncryptionOptions,\n): Encrypter<ID>;\n\nfunction encryptByRecord<ID extends IDType, KeyT, SerialisedKeyT>(\n  keyCollection: Collection<KeyRecord<ID, SerialisedKeyT>>,\n  options: CustomEncryptionOptions<KeyT, SerialisedKeyT> & RecordEncryptionOptions,\n): Encrypter<ID>;\n\nfunction encryptByRecord<ID extends IDType, KeyT, SerialisedKeyT>(\n  keyCollection: Collection<KeyRecord<ID, SerialisedKeyT>>,\n  {\n    encryption = nodeEncryptionSync as any,\n    allowRaw = false,\n    keyCache,\n    ...extraOptions\n  }: EncryptionOptions<KeyT, SerialisedKeyT> & RecordEncryptionOptions = {},\n): Encrypter<ID> {\n  if ((extraOptions as any).cacheSize) {\n    throw new Error('{ cacheSize: size } is deprecated; use { keyCache: { capacity: size } } instead');\n  }\n\n  if (keyCache) {\n    /* eslint-disable-next-line no-param-reassign */\n    keyCollection = cache(keyCollection, keyCache);\n  }\n\n  const rawKeyCache = new LruCache<SerialisedKeyT, KeyT>(1024);\n\n  const loadKey = async (\n    generateIfNeeded: boolean,\n    record: { id?: ID },\n  ): Promise<KeyT> => {\n    const { id } = record;\n\n    if (id === undefined) {\n      throw new Error('Must provide ID for encryption');\n    }\n\n    const item = await keyCollection.get('id', id, ['key']);\n    if (item) {\n      return rawKeyCache.cached(item.key, () => encryption.deserialiseKey(item.key));\n    }\n    if (!generateIfNeeded) {\n      throw new Error('No encryption key found for record');\n    }\n    const key = await encryption.generateKey();\n    const serialisedKey = encryption.serialiseKey(key);\n    await keyCollection.add({ id, key: serialisedKey });\n    rawKeyCache.add(serialisedKey, key);\n    return key;\n  };\n\n  const removeKey = async ({ id }: { id: ID }): Promise<void> => {\n    await keyCollection.remove('id', id);\n  };\n\n  // https://github.com/microsoft/TypeScript/issues/39080\n  return makeEncrypter<ID>(<T extends IDableBy<ID>, F extends EncryptableKeys<T>>(\n    fields: F,\n    baseCollection: Collection<Encrypted<T, F[-1]>>,\n  ) => new WrappedCollection<T, F, Buffer, KeyT>(baseCollection, fields, {\n    wrap: (k, v, key): Promise<Buffer> | Buffer => encryption.encrypt(key, serialiseValueBin(v)),\n    unwrap: async (k, v, key): Promise<any> => {\n      if (!(v instanceof Buffer)) {\n        if (allowRaw) {\n          return v; // probably an old record before encryption was added\n        }\n        throw new Error('unencrypted data');\n      }\n      return deserialiseValueBin(await encryption.decrypt(key, v));\n    },\n    preWrap: loadKey.bind(null, true),\n    preUnwrap: loadKey.bind(null, false),\n    preRemove: removeKey,\n  }));\n}\n\nfunction encryptByRecordWithMasterKey<ID extends IDType>(\n  sMasterKey: Buffer,\n  keyCollection: Collection<KeyRecord<ID, Buffer>>,\n  options?: EncryptionOptions & RecordEncryptionOptions,\n): Encrypter<ID>;\n\nfunction encryptByRecordWithMasterKey<ID extends IDType, KeyT, SerialisedKeyT>(\n  sMasterKey: SerialisedKeyT,\n  keyCollection: Collection<KeyRecord<ID, Buffer>>,\n  options: CustomEncryptionOptions<KeyT, SerialisedKeyT> & RecordEncryptionOptions,\n): Encrypter<ID>;\n\nfunction encryptByRecordWithMasterKey<ID extends IDType, KeyT, SerialisedKeyT>(\n  sMasterKey: SerialisedKeyT,\n  keyCollection: Collection<KeyRecord<ID, Buffer>>,\n  options: EncryptionOptions<KeyT, SerialisedKeyT> & RecordEncryptionOptions = {},\n): Encrypter<ID> {\n  const opts = options as CustomEncryptionOptions<KeyT, SerialisedKeyT> & RecordEncryptionOptions;\n  const keyEnc = encryptByKey(sMasterKey, opts);\n  const encKeyCollection = keyEnc<KeyRecord<ID, SerialisedKeyT>>()(\n    ['key'],\n    keyCollection,\n  );\n  return encryptByRecord(encKeyCollection, opts);\n}\n\nexport {\n  encryptByKey,\n  encryptByRecord,\n  encryptByRecordWithMasterKey,\n};\n","import zlib from 'zlib';\nimport { promisify } from 'util';\nimport type { IDable } from '../interfaces/IDable';\nimport type { Collection } from '../interfaces/Collection';\nimport { serialiseValueBin, deserialiseValueBin } from '../helpers/serialiser';\nimport WrappedCollection, { Wrapped } from './WrappedCollection';\n\ntype CompressableKeys<T> = readonly (keyof Omit<T, 'id'> & string)[];\n\nexport type Compressed<T extends IDable, WF extends keyof T> = Wrapped<T, WF, Buffer>;\n\nexport interface CompressOptions {\n  allowRaw?: boolean;\n  allowRawBuffer?: boolean;\n  compressionThresholdBytes?: number;\n}\n\nconst gzipCompress = promisify<Buffer, Buffer>(zlib.gzip);\nconst gzipDecompress = promisify<Buffer, Buffer>(zlib.gunzip);\n\nconst MARK_UNCOMPRESSED = Buffer.of(0);\n\nasync function compressValue(v: unknown, {\n  compressionThresholdBytes = 200,\n}: CompressOptions): Promise<Buffer> {\n  const serialised = serialiseValueBin(v);\n  if (serialised.length >= compressionThresholdBytes) {\n    const gzipped = await gzipCompress(serialised);\n    if (gzipped.length < serialised.length + 1) {\n      return gzipped;\n    }\n  }\n  return Buffer.concat([MARK_UNCOMPRESSED, serialised]);\n}\n\nasync function decompressValue(v: Buffer, {\n  allowRaw = true,\n  allowRawBuffer = false,\n}: CompressOptions): Promise<any> {\n  if (!(v instanceof Buffer)) {\n    if (allowRaw) {\n      return v; // probably an old record before compression was added\n    }\n    throw new Error('unknown compression type');\n  }\n  if (v[0] === 0x1F && v[1] === 0x8B) { // gzip \"magic number\"\n    return deserialiseValueBin(await gzipDecompress(v));\n  }\n  if (v[0] === MARK_UNCOMPRESSED[0]) {\n    return deserialiseValueBin(v.subarray(1));\n  }\n  if (allowRaw && allowRawBuffer) {\n    return v;\n  }\n  throw new Error('unknown compression type');\n}\n\nexport function compress<T extends IDable, F extends CompressableKeys<T>>(\n  fields: F,\n  baseCollection: Collection<Compressed<T, F[-1]>>,\n  options: CompressOptions = {},\n): Collection<T> {\n  return new WrappedCollection<T, F, Buffer, never>(baseCollection, fields, {\n    wrap: (k, v): Promise<Buffer> => compressValue(v, options),\n    unwrap: (k, v): Promise<any> => decompressValue(v, options),\n  });\n}\n","import type { Collection, UpdateOptions, Indices } from '../interfaces/Collection';\nimport type { IDable } from '../interfaces/IDable';\nimport { safeGet } from '../helpers/safeAccess';\n\ntype MigrationFunc = (stored: unknown | undefined, record: Readonly<any>) => any;\n\ntype MigrationFuncs<T, ExtraFetchFields extends readonly (string & keyof T)[]> = {\n  [K in keyof T]?: (\n    stored: T[K] | undefined,\n    record: Readonly<Pick<T, K | ExtraFetchFields[-1]>>,\n  ) => T[K];\n};\n\nclass MigratedCollection<\n  T extends IDable,\n  ExtraFetchFields extends readonly (string & keyof T)[],\n> implements Collection<T> {\n  private readonly migrations: Map<string & keyof T, MigrationFunc>;\n\n  private readonly migratedAttrs: (string & keyof T)[];\n\n  public constructor(\n    private readonly baseCollection: Collection<T>,\n    migrations: MigrationFuncs<T, ExtraFetchFields>,\n    private readonly extraFetchFields?: ExtraFetchFields,\n  ) {\n    this.migrations = new Map(Object.entries(migrations)) as Map<string & keyof T, MigrationFunc>;\n    this.migratedAttrs = [...this.migrations.keys()];\n  }\n\n  public async add(entry: T): Promise<void> {\n    return this.baseCollection.add(entry);\n  }\n\n  public async get<\n    K extends string & keyof T,\n    F extends readonly (string & keyof T)[]\n  >(\n    searchAttribute: K,\n    searchValue: T[K],\n    returnAttributes?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>> | null> {\n    const raw = await this.baseCollection.get(\n      searchAttribute,\n      searchValue,\n      this.extendAttributes(returnAttributes)!,\n    );\n    return raw ? this.applyMigration(raw, returnAttributes) : null;\n  }\n\n  public async getAll<\n    K extends string & keyof T,\n    F extends readonly (string & keyof T)[],\n  >(\n    searchAttribute?: K,\n    searchValue?: T[K],\n    returnAttributes?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>>[]> {\n    const raws = await this.baseCollection.getAll(\n      searchAttribute!,\n      searchValue as any,\n      this.extendAttributes(returnAttributes)!,\n    );\n    return raws.map((raw) => this.applyMigration(raw, returnAttributes));\n  }\n\n  public async update<K extends string & keyof T>(\n    searchAttribute: K,\n    searchValue: T[K],\n    update: Partial<T>,\n    options?: UpdateOptions,\n  ): Promise<void> {\n    return this.baseCollection.update(searchAttribute, searchValue, update, options);\n  }\n\n  public async remove<K extends string & keyof T>(\n    searchAttribute: K,\n    searchValue: T[K],\n  ): Promise<number> {\n    return this.baseCollection.remove(searchAttribute, searchValue);\n  }\n\n  public get indices(): Indices<T> {\n    return this.baseCollection.indices;\n  }\n\n  private extendAttributes<\n    F extends readonly (string & keyof T)[]\n  >(returnAttributes?: F): readonly (string & keyof T)[] | undefined {\n    if (returnAttributes && this.extraFetchFields) {\n      return [...returnAttributes, ...this.extraFetchFields];\n    }\n    return returnAttributes;\n  }\n\n  private applyMigration<F extends readonly (string & keyof T)[]>(\n    raw: Readonly<Pick<T, ExtraFetchFields[-1] | F[-1]>>,\n    returnAttributes?: F,\n  ): Readonly<Pick<T, F[-1]>> {\n    if (returnAttributes && !returnAttributes.some((attr) => this.migrations.has(attr))) {\n      return raw;\n    }\n    const result: Pick<T, F[-1]> = { ...raw };\n    const attrs = returnAttributes || this.migratedAttrs;\n    attrs.forEach((attr) => {\n      const migration = this.migrations.get(attr);\n      if (migration) {\n        result[attr] = migration(safeGet(raw, attr), raw);\n      }\n    });\n    return result;\n  }\n}\n\nfunction migrate<T extends IDable>(\n  migrations: MigrationFuncs<T, []>,\n  baseCollection: Collection<T>,\n): Collection<T>;\n\nfunction migrate<\n  T extends IDable,\n  ExtraFetchFields extends readonly (string & keyof T)[],\n>(\n  extraFetchFields: ExtraFetchFields,\n  migrations: MigrationFuncs<T, ExtraFetchFields>,\n  baseCollection: Collection<T>,\n): Collection<T>;\n\nfunction migrate<\n  T extends IDable,\n  ExtraFetchFields extends readonly (string & keyof T)[],\n>(\n  extraFetchFields: MigrationFuncs<T, []> | ExtraFetchFields,\n  migrations: MigrationFuncs<T, ExtraFetchFields> | Collection<T>,\n  baseCollection?: Collection<T>,\n): Collection<T> {\n  if (baseCollection) {\n    return new MigratedCollection(\n      baseCollection,\n      migrations as MigrationFuncs<T, ExtraFetchFields>,\n      extraFetchFields as ExtraFetchFields,\n    );\n  }\n  return new MigratedCollection(\n    migrations as Collection<T>,\n    extraFetchFields as MigrationFuncs<T, []>,\n  );\n}\n\nexport default migrate;\n","import CollectionStorage from './CollectionStorage';\nimport WrappedCollection, { Wrapped } from './wrappers/WrappedCollection';\nimport type Encryption from './wrappers/encryption/Encryption';\nimport {\n  encryptByKey,\n  encryptByRecord,\n  encryptByRecordWithMasterKey,\n  EncryptionOptions,\n  Encrypted,\n} from './wrappers/encrypted';\nimport { compress, Compressed, CompressOptions } from './wrappers/compressed';\nimport migrate from './wrappers/migrated';\nimport type { DB } from './interfaces/DB';\nimport type { Collection } from './interfaces/Collection';\n\nexport type {\n  DB,\n  Collection,\n  Wrapped,\n  Encryption,\n  Encrypted,\n  EncryptionOptions,\n  Compressed,\n  CompressOptions,\n};\n\nexport { default as MemoryDb } from './memory/MemoryDb';\nexport { default as MongoDb } from './mongo/MongoDb';\nexport { default as RedisDb } from './redis/RedisDb';\nexport { default as LruCache } from './helpers/LruCache';\nexport {\n  WrappedCollection,\n  encryptByKey,\n  encryptByRecord,\n  encryptByRecordWithMasterKey,\n  compress,\n  migrate,\n};\nexport {\n  default as nodeEncryptionSync,\n} from './wrappers/encryption/nodeEncryptionSync';\nexport default CollectionStorage;\n","import MemoryDb from './memory/MemoryDb';\nimport MongoDb from './mongo/MongoDb';\nimport DynamoDb from './dynamodb/DynamoDb';\nimport RedisDb from './redis/RedisDb';\nimport PostgresDb from './postgresql/PostgresDb';\nimport type { DB } from './interfaces/DB';\n\nexport default class CollectionStorage {\n  public static async connect(url: string): Promise<DB> {\n    let dbClass;\n    if (url.startsWith('memory')) {\n      dbClass = MemoryDb;\n    } else if (url.startsWith('mongodb')) {\n      dbClass = MongoDb;\n    } else if (url.startsWith('dynamodb')) {\n      dbClass = DynamoDb;\n    } else if (url.startsWith('redis')) {\n      dbClass = RedisDb;\n    } else if (url.startsWith('postgres')) {\n      dbClass = PostgresDb;\n    } else {\n      throw new Error(`Unsupported database connection string: ${url}`);\n    }\n\n    try {\n      return await dbClass.connect(url);\n    } catch (e) {\n      throw new Error(`Failed to connect to database \"${url}\": ${e.message}`);\n    }\n  }\n}\n"],"sourceRoot":""}