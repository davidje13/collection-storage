{"version":3,"sources":["webpack://collection-storage/webpack/universalModuleDefinition","webpack://collection-storage/webpack/bootstrap","webpack://collection-storage/./src/interfaces/BaseIndices.ts","webpack://collection-storage/./src/interfaces/BaseCollection.ts","webpack://collection-storage/external \"crypto\"","webpack://collection-storage/./src/helpers/retry.ts","webpack://collection-storage/external \"mongodb\"","webpack://collection-storage/external \"zlib\"","webpack://collection-storage/external \"util\"","webpack://collection-storage/external \"url\"","webpack://collection-storage/external \"https\"","webpack://collection-storage/external \"http\"","webpack://collection-storage/./src/mongo/MongoCollection.ts","webpack://collection-storage/external \"ioredis\"","webpack://collection-storage/external \"pg\"","webpack://collection-storage/./src/helpers/serialiser.ts","webpack://collection-storage/./src/memory/MemoryCollection.ts","webpack://collection-storage/./src/interfaces/BaseDB.ts","webpack://collection-storage/./src/memory/MemoryDb.ts","webpack://collection-storage/./src/mongo/MongoDb.ts","webpack://collection-storage/./src/dynamodb/api/Results.ts","webpack://collection-storage/./src/dynamodb/api/AWSError.ts","webpack://collection-storage/./src/dynamodb/api/DDB.ts","webpack://collection-storage/./src/dynamodb/DynamoCollection.ts","webpack://collection-storage/./src/helpers/PromiseTracker.ts","webpack://collection-storage/./src/helpers/LruCache.ts","webpack://collection-storage/./src/dynamodb/api/AWS.ts","webpack://collection-storage/./src/dynamodb/DynamoDb.ts","webpack://collection-storage/./src/redis/helpers.ts","webpack://collection-storage/./src/redis/RedisCollection.ts","webpack://collection-storage/./src/redis/scripts.ts","webpack://collection-storage/./src/redis/RedisConnectionPool.ts","webpack://collection-storage/./src/redis/RedisDb.ts","webpack://collection-storage/./src/postgresql/hstore.ts","webpack://collection-storage/./src/postgresql/sql.ts","webpack://collection-storage/./src/postgresql/PostgresCollection.ts","webpack://collection-storage/./src/postgresql/PostgresDb.ts","webpack://collection-storage/./src/wrappers/WrappedCollection.ts","webpack://collection-storage/./src/wrappers/encryption/nodeEncryptionSync.ts","webpack://collection-storage/./src/wrappers/encrypted.ts","webpack://collection-storage/./src/wrappers/compressed.ts","webpack://collection-storage/./src/wrappers/migrated.ts","webpack://collection-storage/./src/index.ts","webpack://collection-storage/./src/CollectionStorage.ts"],"names":["root","factory","exports","module","define","amd","global","installedModules","__webpack_require__","moduleId","i","l","modules","call","m","c","d","name","getter","o","Object","defineProperty","enumerable","get","r","Symbol","toStringTag","value","t","mode","__esModule","ns","create","key","bind","n","object","property","prototype","hasOwnProperty","p","s","BaseIndices","constructor","keys","getIndices","this","getUniqueIndices","entries","filter","unique","map","getCustomIndices","isIndex","attribute","undefined","isUniqueIndex","Boolean","BaseCollection","innerPreAct","preAct","indices","entry","internalAdd","searchAttribute","searchValue","returnAttributes","Error","internalGet","internalGetAll","update","options","id","upsert","withoutId","internalUpsert","some","k","internalUpdate","internalRemove","wait","pending","addPending","Promise","resolve","reject","push","internalReady","async","e","forEach","f","require","sleep","millis","setTimeout","shouldRetry","timeoutMillis","initialDelayMillis","maxDelayMillis","delayGrowth","jitter","limit","Date","now","currentDelay","attempt","fn","delay","Math","min","random","message","DOT_REG","fieldNameToMongo","encodeURIComponent","replace","MONGO_ERROR_IDX","withUpsertRetry","retry","MongoError","code","exec","getErrorIndex","convertToMongo","converted","v","Buffer","MBinary","_bsontype","convertFromMongo","buffer","decodeURIComponent","makeMongoProjection","names","projection","fieldName","configureCollection","collection","existing","indexes","catch","idxToCreate","idxToDelete","Set","idx","delete","keyName","makeIndex","index","match","find","a","b","aKey","bKey","length","every","indicesMatch","createIndexes","size","all","idxName","dropIndex","MongoCollection","stateRef","closed","super","initAsync","insertOne","updateOne","$set","query","mongoUpdate","updateMany","findOne","cursor","result","raw","deleteMany","deletedCount","MARK_BINARY","charCodeAt","MARK_STRING","MARK_BINARY_BUFF","Uint8Array","of","serialiseValue","toString","JSON","stringify","deserialiseValue","type","data","substr","from","parse","includes","serialiseValueBin","concat","deserialiseValueBin","subarray","serialiseRecord","record","deserialiseRecord","MemoryCollection","simulatedLatency","Map","indexData","serialised","internalCheckDuplicates","set","internalPopulateIndices","has","updates","internalGetSerialisedIds","sId","oldSerialised","oldValue","newValue","newSerialised","internalRemoveIndices","sIds","fields","field","applyFilter","sKey","serialisedValue","checkId","add","BaseDB","makeCollection","getCollection","cached","collectionCache","normKeys","sort","join","cachedNormKeys","cachedCol","created","close","syncClose","toAwait","values","allSettled","then","internalClose","globalDbs","initial","getGlobal","MemoryDb","url","parsedUrl","URL","hostname","params","searchParams","Number","db","MongoDb","client","escapeName","MongoClient","default","connect","useNewUrlParser","useUnifiedTopology","getDb","Paged","aws","pageLimit","POSITIVE_INFINITY","batched","consumer","do","lastKey","page","pageItems","nextKey","items","AWSError","status","isType","endsWith","isTransient","AWS_URL_FORMAT","ifNotEmpty","flatten","escapedExpressions","expressions","attrValues","attrNames","hasExpr","hasAnyValues","attributeExpression","joiner","attributes","parts","hasValues","Array","isArray","rawAttrNames","attr","attrName","attrValue","ExpressionAttributeValues","ExpressionAttributeNames","attrs","retryPolling","retryRemaining","INVALID_NAME_CHARS","hex","padStart","padEnd","createAttributeDefinitions","schemas","attributeName","attributeType","AttributeName","AttributeType","createSecondaryIndex","IndexName","indexName","KeySchema","keySchema","keyType","KeyType","Projection","ProjectionType","projectionType","nonKeyAttributes","NonKeyAttributes","ProvisionedThroughput","throughput","DDB","host","consistentRead","region","getConsumedUnits","totalCapacityUnits","getTableNames","response","ExclusiveStartTableName","lastTableName","TableNames","LastEvaluatedTableName","upsertTable","tableName","pKeySchema","secondaryIndices","waitForReady","TableName","AttributeDefinitions","GlobalSecondaryIndexes","BillingMode","replaceIndices","waitForTable","describeTable","waitForIndices","desc","Table","TableStatus","IndexStatus","item","Item","ConditionExpression","ReturnConsumedCapacity","condition","Key","UpdateExpression","requestedAttrs","ProjectionExpression","ConsistentRead","getItem","keyAttrs","fullAttrs","slice","extracted","tableQuery","callBatched","RequestItems","Keys","batchKeys","Responses","UnprocessedKeys","batchPutItems","batchItems","PutRequest","UnprocessedItems","batchDeleteItems","DeleteRequest","getAllItems","ExclusiveStartKey","Items","LastEvaluatedKey","limitOne","colocatedAttrs","nonColocatedAttrs","KeyConditionExpression","Limit","pkItems","batchGetItems","callDelete","deleteAndReturnItem","returnOld","ReturnValues","Attributes","toCreate","oldIndices","old","toDelete","GlobalSecondaryIndexUpdates","Delete","Create","batchLimit","remaining","queue","splice","retryItems","fnName","body","request","method","service","headers","json","ConsumedCapacity","capacity","reduce","CapacityUnits","wrapError","handleError","ignore","toDynamoValue","B","toDynamoItem","isDynamoBinary","fromDynamoItem","fromDynamoValue","toDynamoKey","INDEX_META_KEY","indexTable","toDDBThroughput","ReadCapacityUnits","max","ceil","read","WriteCapacityUnits","write","getCombinedThroughput","throughputFn","totalThroughput","hasThroughput","cur","configureTable","ddb","nonuniqueKeys","uniqueKeys","indexTableName","deleteTable","info","ix","newKeys","oldKeys","SS","indexItems","putItem","DynamoCollection","itemId","itemNoKey","updateItem","_","getItemsBySecondaryKey","ddbSearchValue","ddbItem","filteredReturn","assign","primaryItem","deleteItem","success","successes","successesOut","failures","runAll","atomicPutUniques","updatedUnique","changedAttrs","PromiseTracker","flightResolve","flight","inflight","finally","current","clear","always","LruCache","flushFn","calc","fresh","storage","remove","peek","next","EMPTY_BUFFER","alloc","ISO_TIME_STRIP","ALGORITHM","withTransientErrorRetry","sha256","hash","createHash","digest","hmac","createHmac","AWS","keyID","secret","baseKey","date","parsedURL","search","binaryBody","canonicalTime","toISOString","canonicalDate","credentialScope","getKey","canonicalPath","encodeURI","decodeURI","pathname","allHeaders","Host","headerNames","header","toLowerCase","canonicalHeaders","signedHeaders","canonicalRequest","signature","Authorization","fetch","protocol","https","http","req","res","on","chunk","text","statusCode","__type","end","keyCache","kRegion","keyCacheRegion","keyCacheDate","DynamoDb","tableNamePrefix","parsed","username","password","process","env","AWS_ACCESS_KEY_ID","AWS_SECRET_ACCESS_KEY","split","parseInt","getDDB","minifyLuaScript","lines","argNames","combined","ln","trim","RegExp","notUndefined","makeIndexKeys","partialSerialisedValue","prefix","parseItem","itemHasContent","unwatchAll","unwatch","mapAwaitSync","RedisCollection","pool","keyPrefix","keyPrefixes","keyInfo","nonUniqueKeys","withConnection","runAdd","patchSerialised","retryWithConnection","patch","getUpdatePatch","runUpdates","insertValue","getAndWatchBySerialisedKey","patches","getByKeysKeepWatches","makeKey","cut","indexedKeys","rawByKeyKeepWatches","pipeline","multi","serialisedId","checkWatch","keyCount","flat","watch","argsList","makeUpdateArgs","results","updateArgs","checkUpdate","chain","updateWithoutCheck","diff","patchUniqueKeys","patchNonUniqueKeys","oldUniqueKeys","oldNonUniqueKeys","serialisedIds","commands","multiExec","exists","hmget","hgetall","keyAddress","smembers","SCRIPT_ADD","FRAG_CHECK_UPDATE","FRAG_UPDATE","SCRIPT_CHECK_UPDATE","SCRIPT_UPDATE_WITHOUT_CHECK","SCRIPT_UPDATE","SCRIPT_REMOVE","withRetry","RedisConnectionPool","RedisStatic","maxConnections","teardown","getConnection","returnConnection","inUse","doClose","closingFn","connections","disconnect","pop","defineCommand","lua","defineAllScripts","q","shift","RedisDb","lazyConnect","getConnectionPool","quoteHValue","DQUOTE_REG","SQUOTE_REG","quoteValue","msg","ID_REG","withIdentifiers","base","identifiers","STATEMENTS","CREATE_TABLE","GET_INDEX_NAMES","CREATE_INDEX","CREATE_UNIQUE_INDEX","DROP_INDEX","INSERT","UPDATE","UPDATE_ID","UPSERT_ID","SELECT_ONE","SELECT_ALL","SELECT_ALL_BY","SELECT_ID","DELETE","DELETE_ID","toHStore","encodeHStore","fromHStore","rawMap","hstore","currentKey","quote","decodeHStore","PostgresCollection","T","rowMode","oldIndexNames","rows","startsWith","keyEntries","I","indicesToDelete","release","rest","runTableQuery","rowCount","queryName","cachedQueries","PostgresDb","Pool","connectionString","hasAnyField","WrappedCollection","baseCollection","wrapper","wrapAll","unwrapAll","getAll","extra","preRemove","processed","preWrap","allFields","wrap","preUnwrap","unwrap","ALG","ALG_BUF","nodeEncryptionSync","encrypt","iv","crypto","randomBytes","cipher","createCipheriv","part","final","decrypt","equals","encrypted","decipher","createDecipheriv","generateKey","createSecretKey","serialiseKey","export","deserialiseKey","makeEncrypter","encryptByKey","encryption","allowRaw","encryptByRecord","keyCollection","cacheSize","cache","loadKey","generateIfNeeded","cachedAsync","removeKey","encryptByRecordWithMasterKey","sMasterKey","opts","keyEnc","gzipCompress","promisify","zlib","gzip","gzipDecompress","gunzip","MARK_UNCOMPRESSED","compress","compressionThresholdBytes","gzipped","compressValue","allowRawBuffer","decompressValue","MigratedCollection","migrations","extraFetchFields","extendAttributes","applyMigration","migration","migrate","CollectionStorage","dbClass"],"mappings":"CAAA,SAA2CA,EAAMC,GAC1B,iBAAZC,SAA0C,iBAAXC,OACxCA,OAAOD,QAAUD,IACQ,mBAAXG,QAAyBA,OAAOC,IAC9CD,OAAO,qBAAsB,GAAIH,GACP,iBAAZC,QACdA,QAAQ,sBAAwBD,IAEhCD,EAAK,sBAAwBC,IAR/B,CASGK,QAAQ,WACX,O,YCTE,IAAIC,EAAmB,GAGvB,SAASC,EAAoBC,GAG5B,GAAGF,EAAiBE,GACnB,OAAOF,EAAiBE,GAAUP,QAGnC,IAAIC,EAASI,EAAiBE,GAAY,CACzCC,EAAGD,EACHE,GAAG,EACHT,QAAS,IAUV,OANAU,EAAQH,GAAUI,KAAKV,EAAOD,QAASC,EAAQA,EAAOD,QAASM,GAG/DL,EAAOQ,GAAI,EAGJR,EAAOD,QA0Df,OArDAM,EAAoBM,EAAIF,EAGxBJ,EAAoBO,EAAIR,EAGxBC,EAAoBQ,EAAI,SAASd,EAASe,EAAMC,GAC3CV,EAAoBW,EAAEjB,EAASe,IAClCG,OAAOC,eAAenB,EAASe,EAAM,CAAEK,YAAY,EAAMC,IAAKL,KAKhEV,EAAoBgB,EAAI,SAAStB,GACX,oBAAXuB,QAA0BA,OAAOC,aAC1CN,OAAOC,eAAenB,EAASuB,OAAOC,YAAa,CAAEC,MAAO,WAE7DP,OAAOC,eAAenB,EAAS,aAAc,CAAEyB,OAAO,KAQvDnB,EAAoBoB,EAAI,SAASD,EAAOE,GAEvC,GADU,EAAPA,IAAUF,EAAQnB,EAAoBmB,IAC/B,EAAPE,EAAU,OAAOF,EACpB,GAAW,EAAPE,GAA8B,iBAAVF,GAAsBA,GAASA,EAAMG,WAAY,OAAOH,EAChF,IAAII,EAAKX,OAAOY,OAAO,MAGvB,GAFAxB,EAAoBgB,EAAEO,GACtBX,OAAOC,eAAeU,EAAI,UAAW,CAAET,YAAY,EAAMK,MAAOA,IACtD,EAAPE,GAA4B,iBAATF,EAAmB,IAAI,IAAIM,KAAON,EAAOnB,EAAoBQ,EAAEe,EAAIE,EAAK,SAASA,GAAO,OAAON,EAAMM,IAAQC,KAAK,KAAMD,IAC9I,OAAOF,GAIRvB,EAAoB2B,EAAI,SAAShC,GAChC,IAAIe,EAASf,GAAUA,EAAO2B,WAC7B,WAAwB,OAAO3B,EAAgB,SAC/C,WAA8B,OAAOA,GAEtC,OADAK,EAAoBQ,EAAEE,EAAQ,IAAKA,GAC5BA,GAIRV,EAAoBW,EAAI,SAASiB,EAAQC,GAAY,OAAOjB,OAAOkB,UAAUC,eAAe1B,KAAKuB,EAAQC,IAGzG7B,EAAoBgC,EAAI,GAIjBhC,EAAoBA,EAAoBiC,EAAI,G,iEC/EtC,MAAMC,EACnBC,YAA6BC,GAAmB,KAAnBA,OAEtBC,aACL,MAAO,CAAC,QAASzB,OAAOwB,KAAKE,KAAKF,OAG7BG,mBACL,MAAO,CAAC,QAAS3B,OAAO4B,QAAQF,KAAKF,MAAMK,OAAO,EAAE,CAAE9B,KAAOA,aAAX,EAAWA,EAAG+B,QAAQC,IAAI,EAAEhB,KAAOA,IAGhFiB,mBACL,OAAOhC,OAAOwB,KAAKE,KAAKF,MAGnBS,QAAQC,GACb,MACgB,OAAdA,QACyBC,IAAzBT,KAAKF,KAAKU,GAIPE,cAAcF,GAA4B,MAC/C,MACgB,OAAdA,GACAG,QAAO,UAACX,KAAKF,KAAKU,UAAX,aAAC,EAAsBJ,S,sVCvBrB,MAAeQ,EAQlBf,YAAYC,GAAiB,qFACrCE,KAAKa,YAAcb,KAAKc,OAAO1B,KAAKY,MACpCA,KAAKe,QAAU,IAAInB,EAAYE,GAGjC,UAAiBkB,GAEf,aADMhB,KAAKa,cACJb,KAAKiB,YAAYD,GAG1B,UAIEE,EACAC,EACAC,GAEA,IAAKpB,KAAKe,QAAQR,QAAQW,GACxB,MAAM,IAAIG,MAAO,gBAAeH,GAGlC,aADMlB,KAAKa,cACJb,KAAKsB,YAAYJ,EAAiBC,EAAaC,GAGxD,aAIEF,EACAC,EACAC,GAEA,GAAIF,IAAoBlB,KAAKe,QAAQR,QAAQW,GAC3C,MAAM,IAAIG,MAAO,gBAAeH,GAGlC,aADMlB,KAAKa,cACJb,KAAKuB,eAAeL,EAAiBC,EAAaC,GAG3D,aACEF,EACAC,EACAK,EACAC,EAAyB,IAEzB,GAAwB,OAApBP,QAA0CT,IAAde,EAAOE,IAAoBF,EAAOE,KAAOP,EACvE,MAAM,IAAIE,MAAM,oBAElB,GAAII,EAAQE,OAAQ,CAClB,GAAwB,OAApBT,EACF,MAAM,IAAIG,MAAO,8BAA6BH,GAEhD,IAAIU,EAAYJ,EAMhB,OALIlD,OAAOkB,UAAUC,eAAe1B,KAAKyD,EAAQ,QAC/CI,E,+VAAY,CAAH,GAAQJ,UACVI,EAAUF,UAEb1B,KAAKa,cACJb,KAAK6B,eAAeV,EAAwBS,EAAWH,GAEhE,IAAKzB,KAAKe,QAAQR,QAAQW,GACxB,MAAM,IAAIG,MAAO,gBAAeH,GAElC,IACGlB,KAAKe,QAAQL,cAAcQ,IAC5B5C,OAAOwB,KAAK0B,GAAQM,KAAMC,GAAM/B,KAAKe,QAAQL,cAAcqB,IAE3D,MAAM,IAAIV,MAAM,aAIlB,aADMrB,KAAKa,cACJb,KAAKgC,eAAed,EAAiBC,EAAaK,EAAQC,GAGnE,aACEP,EACAC,GAEA,IAAKnB,KAAKe,QAAQR,QAAQW,GACxB,MAAM,IAAIG,MAAO,gBAAeH,GAGlC,aADMlB,KAAKa,cACJb,KAAKiC,eAAef,EAAiBC,GAO9C,gBAA0Be,GACxB,MAAMC,EAA8C,GAC9CC,EAAa,IAAqB,IAAIC,QAAQ,CAACC,EAASC,KAC5DJ,EAAQK,KAAK,CAACF,EAASC,MAEzBvC,KAAKyC,cAAgBL,EACrBpC,KAAKa,YAAc6B,gBACXN,IACCpC,KAAKc,UAEd,UACQoB,EACN,MAAOS,GAIP,OAHA3C,KAAKyC,cAAgB,IAAqBJ,QAAQE,OAAOI,GACzD3C,KAAKa,YAAc,KAAc,MAAM8B,QACvCR,EAAQS,QAASC,GAAMA,EAAE,GAAGF,IAG9B3C,KAAKyC,mBAAgBhC,EACrBT,KAAKa,YAAcb,KAAKc,OAAO1B,KAAKY,MACpCmC,EAAQS,QAASC,GAAMA,EAAE,MAIjB/B,UAEV,kBAIEI,EACAC,EACAC,GAC0C,MAE1C,wBADkBpB,KAAKuB,eAAeL,EAAiBC,EAAaC,IACzD,UAAX,QAAiB,KAGTS,eACRH,EACAF,EACAC,GAEA,OAAOzB,KAAKgC,eAAe,KAAMN,EAAIF,EAAQC,M,cClJjDpE,EAAOD,QAAU0F,QAAQ,W,6BCAzB,SAASC,EAAMC,GACb,OAAO,IAAIX,QAASC,GAAiBW,WAAWX,EAASU,IAG5C,KAACE,GACdC,gBAAgB,IAChBC,qBAAqB,GACrBC,iBAAiB,IACjBC,cAAc,EACdC,UAAS,GACP,KAAOb,UACT,MAAMc,EAAQC,KAAKC,MAAQP,EAC3B,IAAIQ,EAAeP,EACnB,IAAK,IAAIQ,EAAU,GAAKA,GAAW,EACjC,IAEE,aAAaC,IACb,MAAOlB,GACP,IAAKO,EAAYP,GACf,MAAMA,EAGR,MAAMmB,EACJC,KAAKC,IAAIL,EAAcN,IACtBE,EAASQ,KAAKE,SAAW,GAI5B,GAFAN,GAAgBL,EAEZG,KAAKC,MAAQI,EAAQN,EAEvB,MADAb,EAAEuB,SAAY,mBAAkBN,cAC1BjB,QAIFI,EAAMe,M,cClClBzG,EAAOD,QAAU0F,QAAQ,Y,cCAzBzF,EAAOD,QAAU0F,QAAQ,S,cCAzBzF,EAAOD,QAAU0F,QAAQ,S,cCAzBzF,EAAOD,QAAU0F,QAAQ,Q,cCAzBzF,EAAOD,QAAU0F,QAAQ,U,cCAzBzF,EAAOD,QAAU0F,QAAQ,S,8DCAzB,wEAaA,MAGMqB,EAAU,MAChB,SAASC,EAAiBjG,GACxB,MAJS,OAILA,EALW,MAQRkG,mBAAmBlG,GAAMmG,QAAQH,EAAS,OAUnD,MAAMI,EAAkB,kCAKxB,MAAMC,EAAkBC,YAAO9B,GAC7BA,aAAa+B,cACF,OAAX/B,EAAEgC,MACmB,SAPvB,SAAuBhC,GAAuB,MAC5C,OAAO,UAAA4B,EAAgBK,KAAKjC,EAAEuB,gBAAvB,eAAkC,KAAM,GAM/CW,CAAclC,IAGhB,SAASmC,EACPjG,GAEA,MAAMkG,EAAqC,GAW3C,OAVAzG,OAAOwB,KAAKjB,GAAO+D,QAASb,IAC1B,IAAIiD,EAAKnG,EAAckD,GACvB,GAAIiD,aAAaC,OACfD,EAAI,IAAIE,SAAQF,QAEX,GAAiB,iBAANA,GAAkBA,EAAEG,UACpC,MAAM,IAAI9D,MAAM,0CAElB0D,EAAUX,EAAiBrC,IAAMiD,IAE5BD,EAGT,SAASK,EACPvG,GAEA,IAAKA,EACH,OAAO,KAET,MAAMkG,EAAe,GASrB,OARAzG,OAAOwB,KAAKjB,GAAO+D,QAASb,IAC1B,IAAIiD,EAAKnG,EAAckD,GA3C3B,IAA4B5D,EA6CP,iBAAN6G,GAAkC,WAAhBA,EAAEG,YAC7BH,EAAIA,EAAEK,QAEPN,GAhDuB5G,EAgDc4D,EA3DzB,QAYX5D,EAXK,KAcFmH,mBAAmBnH,KA4CoB6G,IAEvCD,EAGT,SAASQ,EACPC,GAEA,MAAMC,EAAsC,GAO5C,OANID,IACFC,EAAU,KAAa,EACvBD,EAAM5C,QAAS8C,IACbD,EAAWrB,EAAiBsB,KAAc,KAGvCD,EA+BT/C,eAAeiD,EACbC,EACA9F,EAAoB,IAEpB,MAAM+F,QAA+BD,EAAWE,UAAUC,MAAM,IAAM,IAChEC,EAAoC,GACpCC,EAAc,IAAIC,IAAIL,EAASxF,IAAK8F,GAAQA,EAAIhI,OACtD8H,EAAYG,OAAO,QAEnB9H,OAAOwB,KAAKA,GACTO,IAAKgG,GAhCV,SAAmBA,EAAiB5E,EAAsB,IACxD,MAAMrB,EAASO,QAAQc,EAAQrB,QAE/B,MAAO,CACLjB,IAAK,CAAE,CAFQiF,EAAiBiC,IAEbjG,EAAS,EAAI,UAChCA,UA2BkBkG,CAAUD,EAASvG,EAAKuG,KACzCzD,QAAS2D,IACR,MAAMC,EAAQX,EAASY,KAAMN,GAzBnC,SAAsBO,EAAuBC,GAC3C,GAAIhG,QAAQ+F,EAAEtG,UAAYO,QAAQgG,EAAEvG,QAClC,OAAO,EAET,MAAMwG,EAAOF,EAAEvH,IACT0H,EAAOF,EAAExH,IACTW,EAAOxB,OAAOwB,KAAK8G,GACzB,OAAItI,OAAOwB,KAAK+G,GAAMC,SAAWhH,EAAKgH,QAG/BhH,EAAKiH,MAAOhF,GAAO6E,EAAK7E,KAAO8E,EAAK9E,IAeFiF,CAAab,EAAKI,IACnDC,EACFP,EAAYG,OAAOI,EAAMrI,MAEzB6H,EAAYxD,KAAK+D,KAGnBP,EAAYc,cACRlB,EAAWqB,cAAcjB,GAE7BC,EAAYiB,YACR7E,QAAQ8E,IAAI,IAAIlB,GAAa5F,IAAK+G,GAAYxB,EAAWyB,UAAUD,KAI9D,MAAME,UAA0C1G,IACtDf,YACY+F,EACjB9F,EAAkB,GACDyH,EAAqB,CAAEC,QAAQ,IAEhDC,MAAM3H,GADN,KAHiB8F,aAGjB,KADiB2B,WAGjBvH,KAAK0H,UAAU/B,EAAoBC,EAAY9F,IAGvCgB,SACR,GAAId,KAAKuH,SAASC,OAChB,MAAM,IAAInG,MAAM,qBAIpB,kBAA4BxC,SACpBmB,KAAK4F,WAAW+B,UAAU7C,EAAejG,IAGjD,qBACE6C,EACAF,SAEMgD,EAAgB,IAAMxE,KAAK4F,WAAWgC,UAC1C9C,EAAe,CAAEpD,OACjB,CAAEmG,KAAM/C,EAAetD,IACvB,CAAEG,QAAQ,KAId,qBACET,EACAC,EACAK,GAEA,MAAMsG,EAAQhD,EAAe,CAAE,CAAC5D,GAAkBC,IAC5C4G,EAAc,CAAEF,KAAM/C,EAAetD,IACvCxB,KAAKe,QAAQL,cAAcQ,SACvBlB,KAAK4F,WAAWgC,UAAUE,EAAOC,SAEjC/H,KAAK4F,WAAWoC,WAAWF,EAAOC,GAI5C,kBAIE7G,EACAC,EACAC,GAMA,OAAOgE,QAJWpF,KAAK4F,WAAWqC,QAChCnD,EAAe,CAAE,CAAC5D,GAAkBC,IACpC,CAAEsE,WAAYF,EAAoBnE,MAKtC,qBAIEF,EACAC,EACAC,GAEA,MAAM8G,EAASlI,KAAK4F,WAAWa,KAC7BvF,EAAkB4D,EAAe,CAAE,CAAC5D,GAAkBC,IAAiB,GACvE,CAAEsE,WAAYF,EAAoBnE,KAG9B+G,EAA2B,GAGjC,aAFMD,EAAOtF,QAASwF,GAAQD,EAAO3F,KAAK4C,EAAoBgD,KAEvDD,EAGT,qBACEjH,EACAC,GAKA,aAHqBnB,KAAK4F,WAAWyC,WACnCvD,EAAe,CAAE,CAAC5D,GAAkBC,MAExBmH,cAAgB,K,cCvOlCjL,EAAOD,QAAU0F,QAAQ,Y,cCAzBzF,EAAOD,QAAU0F,QAAQ,O,ijBCQzB,MACMyF,EAAc,IAAIC,WAAW,GAC7BC,EAAc,IAAID,WAAW,GAE7BE,EAAmBC,WAAWC,GAAGL,GAehC,SAASM,EAAehK,GAC7B,OAAIA,aAAiBoG,OACX,IAAGpG,EAAMiK,SAAS,UAEP,iBAAVjK,EACD,IAAGA,EAEQ,kBAAVA,EACFA,EAAQ,IAAM,IAET,OAAVA,EACK,IAED,IAAGkK,KAAKC,UAAUnK,GAGrB,SAASoK,EAAiBpK,GAC/B,MAAMqK,EAAOrK,EAAM,GACbsK,EAAOtK,EAAMuK,OAAO,GAC1B,OAAQF,GACN,IAAK,IAAK,OAAOjE,OAAOoE,KAAKF,EAAM,UACnC,IAAK,IAAK,OAAOA,EACjB,IAAK,IAAK,OAAO,EACjB,IAAK,IAAK,OAAO,EACjB,IAAK,IAAK,OAAO,KACjB,IAAK,IAAK,OAAOJ,KAAKO,MAAMH,GAC5B,QACE,GA9CkB,iBA8CEI,SAASL,GAC3B,OAAOH,KAAKO,MAAMzK,GAEpB,MAAM,IAAIwC,MAAO,qBAAoB6H,IAIpC,SAASM,EAAkB3K,GAChC,OAAIA,aAAiBoG,OACZA,OAAOwE,OAAO,CAACf,EAAkB7J,IAEnCoG,OAAOoE,KAAKR,EAAehK,GAAQ,QAGrC,SAAS6K,EAAoB7K,GAClC,GAAqB,iBAAVA,EACT,OAAOoK,EAAiBpK,GAG1B,MAAMqK,EAAOrK,EAAM,GACnB,OAAIqK,IAASX,EACJ1J,EAAM8K,SAAS,GAEpBT,IAAST,EACJ5J,EAAM8K,SAAS,GAAGb,SAAS,QAE7BG,EAAiBpK,EAAMiK,SAAS,SAGlC,SAASc,EACdC,GAEA,MAAM1B,EAAiC,GAIvC,OAHA7J,OAAOwB,KAAK+J,GAAQjH,QAASb,IAC3BoG,EAAOpG,GAAK8G,EAAgBgB,EAAe9H,MAEtCoG,EAGF,SAAS2B,EACdD,GAEA,MAAM1B,EAA8B,GAOpC,OANA7J,OAAOwB,KAAK+J,GAAQjH,QAASb,IAC3B,MAAMiD,EAAI6E,EAAO9H,GACbiD,IACFmD,EAAOpG,GAAKkH,EAAiBjE,MAG1BmD,E,urBCtEM,MAAM4B,UAA2CnJ,IAKvDf,YACLC,EAAkB,GACDkK,EAAmB,EACnBzC,EAAqB,CAAEC,QAAQ,IAEhDC,MAAM3H,GADN,KAFiBkK,mBAEjB,KADiBzC,WACjB,yCAN+E,IAS/EvH,KAAKmJ,KAAO,IAAIc,IAEhBjK,KAAKe,QAAQT,mBAAmBsC,QAASb,IACvC/B,KAAKkK,UAAUnI,GAAgB,IAAIkI,MAI7BnJ,SACR,GAAId,KAAKuH,SAASC,OAChB,MAAM,IAAInG,MAAM,qBAElB,OA9CJ,SAAe2B,GACb,GAAKA,EAKL,OAAO,IAAIX,QAASC,GAAiBW,WAAWX,EAASU,IAwChDD,CAAM/C,KAAKgK,kBAGpB,kBAA4BnL,GAC1B,MAAMsL,EAAaP,EAAgB/K,GACnCmB,KAAKoK,wBAAwBD,GAAY,GACzCnK,KAAKmJ,KAAKkB,IAAIF,EAAWzI,GAAIyI,GAC7BnK,KAAKsK,wBAAwBH,GAGrBtI,eACRH,EACAF,GAEA,OAAIxB,KAAKmJ,KAAKoB,IAAI1B,EAAenH,IACxB1B,KAAKgC,eAAe,KAAMN,EAAIF,GAEhCxB,KAAKiB,YAAL,GAAmBS,MAAOF,IAGnC,qBACEN,EACAC,EACAK,GAEA,MAEMgJ,EAFOxK,KAAKyK,yBAAyBvJ,EAAiBC,GAEvCd,IAAKqK,IACxB,MAAMC,EAAgB3K,KAAKmJ,KAAK1K,IAAIiM,GAC9BE,EAAWd,EAAkBa,GAC7BE,EAAW,EAAH,KAAQD,GAAapJ,GACnC,GAAIqJ,EAASnJ,KAAOkJ,EAASlJ,GAC3B,MAAM,IAAIL,MAAM,oBAGlB,MAAO,CAAEsJ,gBAAeG,cADFlB,EAAgBiB,MAIxCL,EAAQ5H,QAAQ,EAAG+H,mBAAoB3K,KAAK+K,sBAAsBJ,IAClE,IACEH,EAAQ5H,QAAQ,EAAGkI,mBAAoB9K,KAAKoK,wBAAwBU,GAAe,IACnF,MAAOnI,GAEP,MADA6H,EAAQ5H,QAAQ,EAAG+H,mBAAoB3K,KAAKsK,wBAAwBK,IAC9DhI,EAER6H,EAAQ5H,QAAQ,EAAGkI,oBACjB9K,KAAKmJ,KAAKkB,IAAIS,EAAcpJ,GAAIoJ,GAChC9K,KAAKsK,wBAAwBQ,KAIjC,qBAIE5J,EACAC,EACAC,GAEA,IAAI4J,EAMJ,OAJEA,EADE9J,EACKlB,KAAKyK,yBAAyBvJ,EAAiBC,GAE/C,IAAInB,KAAKmJ,KAAKrJ,QAEhBkL,EAAK3K,IAAKqK,GAtGrB,SACEvB,EACA8B,GAEA,IAAKA,EACH,OAAO9B,EAET,MAAMhB,EAAyB,GAI/B,OAHA8C,EAAOrI,QAASsI,IACd/C,EAAO+C,GAAS/B,EAAK+B,KAEhB/C,EA2FoBgD,CACvBrB,EAAkB9J,KAAKmJ,KAAK1K,IAAIiM,IAChCtJ,IAIJ,qBACEF,EACAC,GAEA,MAAM6J,EAAOhL,KAAKyK,yBAAyBvJ,EAAiBC,GAO5D,OANA6J,EAAKpI,QAAS8H,IACZ,MAAMC,EAAgB3K,KAAKmJ,KAAK1K,IAAIiM,GACpC1K,KAAK+K,sBAAsBJ,GAC3B3K,KAAKmJ,KAAK/C,OAAOsE,KAGZM,EAAKlE,OAGN2D,yBACNvJ,EACAC,GAEA,MAAMiK,EAAOvC,EAAe1H,GAC5B,GAAwB,OAApBD,EACF,OAAOlB,KAAKmJ,KAAKoB,IAAIa,GAAQ,CAACA,GAAQ,GAExC,MAAM7E,EAAQvG,KAAKkK,UAAUhJ,GAC7B,IAAKqF,EACH,MAAM,IAAIlF,MAAO,iBAAgBH,iBAEnC,MAAM8J,EAAOzE,EAAM9H,IAAI2M,GACvB,OAAOJ,EAAO,IAAIA,GAAQ,GAGpBZ,wBACNiB,EACAC,GAEA,GAAIA,GAAWtL,KAAKmJ,KAAKoB,IAAIc,EAAgB3J,IAC3C,MAAM,IAAIL,MAAM,aAElBrB,KAAKe,QAAQT,mBAAmBsC,QAASzD,IACvC,MAAMoH,EAAQvG,KAAKkK,UAAU/K,GAC7B,GAAIa,KAAKe,QAAQL,cAAcvB,IAAQoH,EAAMgE,IAAIc,EAAgBlM,IAC/D,MAAM,IAAIkC,MAAM,eAKdiJ,wBACNe,GAEArL,KAAKe,QAAQT,mBAAmBsC,QAASzD,IACvC,MAAMoH,EAAQvG,KAAKkK,UAAU/K,GACvB6F,EAAIqG,EAAgBlM,GAC1B,IAAId,EAAIkI,EAAM9H,IAAIuG,GACb3G,IACHA,EAAI,IAAI6H,IACRK,EAAM8D,IAAIrF,EAAG3G,IAEfA,EAAEkN,IAAIF,EAAgB3J,MAIlBqJ,sBACNM,GAEArL,KAAKe,QAAQT,mBAAmBsC,QAASzD,IACvC,MAAMoH,EAAQvG,KAAKkK,UAAU/K,GACvB6F,EAAIqG,EAAgBlM,GACpBd,EAAIkI,EAAM9H,IAAIuG,GACpB3G,EAAE+H,OAAOiF,EAAgB3J,IACpBrD,EAAE6I,MACLX,EAAMH,OAAOpB,M,wHCvLN,MAAewG,EAK5B3L,YACmB4L,GAIjB,KAJiBA,iBAIjB,kBATsC,CAAEjE,QAAQ,IAShD,yBAPiC,IAAIyC,KAShCyB,cAAgCvN,EAAc2B,GACnD,MAAM6L,EAAS3L,KAAK4L,gBAAgBnN,IAAIN,GAClC0N,GFboBxN,EEaKyB,GFHzB,IAJQxB,OAAOwB,KAAKzB,GACzByN,OACAzL,IAAK0B,GAAO,GAAEgH,KAAKC,UAAUjH,MAAMgH,KAAKC,UAAU3K,EAAE0D,OACpDgK,KAAK,QAPC,OAFJ,IAAuB1N,EEc1B,GAAIsN,EAAQ,CACV,MAAOK,EAAgBC,GAAaN,EACpC,GAAIE,IAAaG,EACf,MAAM,IAAI3K,MAAO,+BAA8BlD,0BAEjD,OAAO8N,EAET,MAAMC,EAAUlM,KAAKyL,eAAetN,EAAM2B,GAE1C,OADAE,KAAK4L,gBAAgBvB,IAAIlM,EAAM,CAAC0N,EAAUK,IACnCA,EAGTC,QACE,GAAInM,KAAKuH,SAASC,OAChB,OAEFxH,KAAKoM,YACL,MAAMC,EAAU,IAAIrM,KAAK4L,gBAAgBU,UACtCjM,IAAI,EAAE,CAAEpC,MAAJ,0BAAY,EAAAA,GAA8BwE,qBAA1C,aAAW,YAClB,OAAOJ,QAAQkK,WAAWF,GAASG,KAAK,IAAMxM,KAAKyM,iBAG3CL,YACRpM,KAAKuH,SAASC,QAAS,EAIfiF,kBCvCZ,MAAMC,EAVN,SAAsBvO,EAAcwO,GAClC,MAAM9G,EAAYrI,OAAeW,GACjC,OAAI0H,IAIHrI,OAAeW,GAAQwO,EACjBA,GAGSC,CAChB,4BACA,IAAI3C,KAGS,MAAM4C,UAAiBrB,EAC7B3L,aAAY,iBAAEmK,EAAmB,GAAM,IAC5CvC,MAAM,CAACtJ,EAAM2B,IAAS,IAAIiK,EAAiBjK,EAAMkK,EAAkBhK,KAAKuH,WAG1E,eAAsBuF,GACpB,MAAMC,EAAY,IAAIC,MAAIF,GACpB3O,EAAO4O,EAAUE,SACvB,GAAI9O,GAAQuO,EAAUnC,IAAIpM,GACxB,OAAOuO,EAAUjO,IAAIN,GAEvB,MAAM+O,EAASH,EAAUI,aACnBnD,EAAmBoD,OAAOF,EAAOzO,IAAI,qBACrC4O,EAAK,IAAIR,EAAS,CAAE7C,qBAI1B,OAHI7L,GACFuO,EAAUrC,IAAIlM,EAAMkP,GAEfA,EAGF3B,cAAgCvN,EAAc2B,GACnD,OAAO2H,MAAMiE,cAAcvN,EAAM2B,GAG5BqM,QACLnM,KAAKoM,aCpCM,MAAMkB,UAAgB9B,EAC3B3L,YACW0N,EACjBjG,GAEAG,MAAM,CAACtJ,EAAM2B,IAAS,IAAIwH,EACxBtH,KAAKuN,OAAOF,KAAKzH,WAVvB,SAAoBzH,GAClB,OAAOkG,mBAAmBlG,GASMqP,CAAWrP,IACvC2B,EACAE,KAAKuH,WAJP,KAFiBgG,SAUnB,qBAA4BT,GAC1B,MAAM,YAAEW,SAAsB,QAAN,qBAAa,KAEnCC,QAASpG,SACD,QAAN,qBAAwC,KACtCiG,QAAeE,EAAYE,QAAQb,EAAK,CAC5Cc,iBAAiB,EACjBC,oBAAoB,IAEtB,OAAO,IAAIP,EAAQC,EAAQjG,GAGtBoE,cAAgCvN,EAAc2B,GACnD,OAAO2H,MAAMiE,cAAcvN,EAAM2B,GAG5BgO,QACL,OAAO9N,KAAKuN,OAAOF,KAGXZ,gBACR,OAAOzM,KAAKuN,OAAOpB,SCnChB,MAAM4B,EACXlO,YACmBmO,EACAnK,EACAoK,EAAYb,OAAOc,mBACpC,KAHiBF,MAGjB,KAFiBnK,KAEjB,KADiBoK,YAGnBE,QAAQC,GACN,OAAOpO,KAAKgO,IAAIK,GAAG3L,UACjB,IAAI4L,EAEJ,IAAK,IAAIC,EAAO,EAAGA,EAAOvO,KAAKiO,UAAWM,GAAQ,EAAG,CACnD,MAAOC,EAAWC,SAA2BzO,KAAK6D,GAAGyK,GAGrD,SAFMF,EAASI,GACfF,EAAUG,GACLH,EACH,OAIJ,MAAM,IAAIjN,MAAM,oBAIpB,YACE,MAAMqN,EAAa,GAInB,aAHM1O,KAAKmO,QAASvQ,IAClB8Q,EAAMlM,QAAQ5E,KAET8Q,GCnCI,MAAMC,UAAiBtN,MACpCxB,YACmB+O,EACA1F,EACjBhF,GAEAuD,MAAO,aAAYmH,YAAiB1F,eAAkBhF,KADtD,KAHiB0K,SAGjB,KAFiB1F,OAMnB,cAAcvG,EAAYuG,GACxB,OACGvG,aAAagM,GAAYhM,EAAEkM,OAAO3F,IAClCvG,aAAatB,OAASsB,EAAEuB,UAAYgF,EAIzC2F,OAAO3F,GACL,OAAOlJ,KAAKkJ,KAAK4F,SAAU,IAAG5F,IAAWlJ,KAAKkJ,OAASA,EAGzD6F,cACE,OACE/O,KAAK4O,QAAU,KACf5O,KAAKkJ,KAAK4F,SAAS,4BACnB9O,KAAKkJ,KAAK4F,SAAS,4CACnB9O,KAAKkJ,KAAK4F,SAAS,0BACnB9O,KAAKkJ,KAAK4F,SAAS,yB,ksBC6FzB,MAAME,EAAiB,yDAIvB,SAASC,EAAqCpR,GAC5C,OAAOA,EAAEiJ,OAASjJ,OAAI4C,EAGxB,SAASyO,EAAQrQ,EAAgBiB,GAC/B,OAAOA,EAAKO,IAAKlB,GAAQ4J,KAAKC,UAAUnK,EAAMM,KAAO4M,OASvD,SAASoD,EACPC,GAEA,IAAIxR,EAAI,EACR,MAAMyR,EAAsB,GACtBC,EAAoC,GAC1C,IAAIC,GAAU,EACVC,GAAe,EACnB,MAAMrH,EAAkC,GA2BxC,OAzBA7J,OAAOwB,KAAKsP,GAAaxM,QAASzD,IAChC,MAAM,oBAAEsQ,EAAF,OAAuBC,EAAvB,WAA+BC,GAAeP,EAAYjQ,GAE1DyQ,EAAkB,GAClBC,GAAaC,MAAMC,QAAQJ,GAC3BK,EAAeF,MAAMC,QAAQJ,GAAcA,EAAarR,OAAOwB,KAAK6P,GACrEK,EAAalJ,SAIlBkJ,EAAapN,QAASqN,IACpB,MAAMC,EAAY,IAAGtS,EACfuS,EAAa,IAAGvS,EACtBgS,EAAMpN,KAAKiN,EAAoBS,EAAUC,IACzCb,EAAUY,GAAYD,EAClBJ,IACFR,EAAWc,GAAcR,EAAuBM,IAElDrS,GAAK,IAEPuK,EAAOhJ,GAAyB,iBAAXuQ,EAAsBE,EAAM7D,KAAK2D,GAAUA,EAAOE,GACvEJ,EAAeA,GAAgBK,EAC/BN,GAAU,KAGPA,EAIL,OACKpH,GADL,IAEEiI,0BAA2BZ,EAAeH,OAAa5O,EACvD4P,yBAA0Bf,IANnB,GAUX,MAAM7J,EAAc6K,IAAD,CACjBb,oBAAsBQ,GAAiBA,EACvCP,OAAQ,IACRC,WAAYW,GAAS,KAGjBC,EAAe9L,YAClB9B,GAAOgM,EAASE,OAAOlM,EArEQ,8BAqEuC,YAAdA,EAAEuB,QAC3D,CAAEf,cAAe,IAAOE,eAAgB,IAAME,QAAQ,IAElDiN,EAAiB/L,YACpB9B,GAAqB,gCAAdA,EAAEuB,SAGNuM,EAAqB,mBAEpB,SAASjD,EAAWrP,GAIzB,OAAOA,EAAKmG,QAAQmM,EAAqBxS,IACvC,MACMyS,EADOzS,EAAEuK,WAAW,GACTM,SAAS,IAC1B,OAAI4H,EAAI5J,QAAU,EACR,KAAI4J,EAAIC,SAAS,EAAG,KAEtB,KAAID,EAAIC,SAAS,EAAG,OAC3BC,OAAO,EAAG,KAOf,SAASC,EAA2BC,GAClC,MAAMR,EAAQ,IAAIrG,IAQlB,OAPA6G,EAAQlO,QAAS9C,GAASA,EAAK8C,QAAQ,EAAGmO,gBAAeC,oBACvD,GAAKV,EAAM/F,IAAIwG,IAER,GAAIT,EAAM7R,IAAIsS,KAAmBC,EACtC,MAAM,IAAI3P,MAAO,mCAAkC0P,QAFnDT,EAAMjG,IAAI0G,EAAeC,MAKtB,IAAIV,EAAMpQ,WAAWG,IAAI,EAAE0Q,EAAeC,MAAjB,CAC9BC,cAAeF,EACfG,cAAeF,KAInB,SAASG,EAAqBvT,GAC5B,MAAO,CACLwT,UAAWxT,EAAEyT,UACbC,UAAW1T,EAAE2T,UAAUlR,IAAI,EAAG0Q,gBAAeS,cAAlB,CACzBP,cAAeF,EACfU,QAASD,KAEXE,WAAY,CACVC,eAAgB/T,EAAEgU,iBAAmBhU,EAAEiU,iBAAmB,UAAY,aACtEC,iBAAkBlU,EAAEiU,kBAEtBE,sBAAuBnU,EAAEoU,YAI7B,SAAShL,EAAaN,EAAmCC,GACvD,OAAID,EAAE6K,UAAUzK,SAAWH,EAAE2K,UAAUxK,QAGhCJ,EAAE6K,UAAUxK,MAAM,CAAChF,EAAGnE,IAC3BmE,EAAEgP,gBAAkBpK,EAAE2K,UAAU1T,GAAGqT,eACnClP,EAAEyP,UAAY7K,EAAE2K,UAAU1T,GAAG6T,SAI1B,MAAMQ,EAOXpS,YACmBmO,EACAkE,GACjB,eAAEC,GAAiB,GAAsB,IACzC,KAHiBnE,MAGjB,KAFiBkE,OAEjB,oFAN2B,GAO3B,MAAMtC,EAAQZ,EAAepK,KAAKsN,GAC9BtC,GACF,CAAG5P,KAAKoS,QAAUxC,EAElB5P,KAAKoS,OAAS,YAEhBpS,KAAKmS,eAAiBA,EAGxBE,mBACE,OAAOrS,KAAKsS,mBAGdC,gBAEE,OAAO,IAAIxE,EAAM/N,KAAKgO,IAAKtL,UACzB,MAAM8P,QAAwCxS,KAAKjC,KAAK,aAAc,CACpE0U,wBAAyBC,IAE3B,MAAO,CAACF,EAASG,WAAYH,EAASI,yBACrC,IAGLC,YACEC,EACAC,EACAC,EAAqD,GACrDC,EACAjB,GAGA,OAAOhS,KAAKgO,IAAIK,GAAG3L,UACjB,IAAIwJ,GAAU,EACd,UACQlM,KAAKjC,KAAK,cAAe,CAC7BmV,UAAWJ,EACXK,qBAAsBtC,EAA2B,CAC/CkC,KACGC,EAAiB3S,IAAI,EAAGkR,eAAgBA,KAE7CD,UAAWyB,EAAW1S,IAAI,EAAG0Q,gBAAeS,cAAlB,CACxBP,cAAeF,EACfU,QAASD,KAEX4B,uBAAwBnE,EAAW+D,EAAiB3S,IACjDzC,GAAMuT,EAAqBvT,KAE9ByV,YAAarB,EAAa,cAAgB,kBAC1CD,sBAAuBC,IAEzB9F,GAAU,EACV,MAAOvJ,GACP,IAAIgM,EAASE,OAAOlM,EAzMG,0BA4MrB,MAAMA,QAFA3C,KAAKsT,eAAeR,EAAWE,GAUzC,OAJIC,SACIjT,KAAKuT,aAAaT,GAAW,GAG9B5G,IAIXsH,cAAcV,GAEZ,OAAO9S,KAAKjC,KAAK,gBAAiB,CAAEmV,UAAWJ,IAGjDS,aAAaT,EAAmBW,GAC9B,OAAOlD,EAAa7N,UAClB,MAAMgR,QAAa1T,KAAKwT,cAAcV,GACtC,GAA+B,WAA3BY,EAAKC,MAAMC,YACb,MAAM,IAAIvS,MAAM,WAElB,MAAMN,EAAU2S,EAAKC,MAAMP,uBAC3B,GAAIK,GAAkB1S,GAAWA,EAAQe,KAAMlE,GAAyB,WAAlBA,EAAEiW,aACtD,MAAM,IAAIxS,MAAM,aAKtB,kBAAkByR,SAEV9S,KAAKjC,KAAK,cAAe,CAAEmV,UAAWJ,IAG9C,cAAcA,EAAmBgB,EAAe1T,SAExCJ,KAAKjC,KAAK,UAAV,KACJmV,UAAWJ,EACXiB,KAAMD,GACH3E,EAAmB,CACpB6E,oBAAqB,CACnBvE,oBAAsBQ,GAAkB,wBAAuBA,KAC/DP,OAAQ,QACRC,WAAYvP,EAAS,CAACA,GAAU,OAPhC,IAUJ6T,uBAAwB,WAI5B,iBACEnB,EACA3T,EACAqC,EACA0S,SAGMlU,KAAKjC,KAAK,aAAV,KACJmV,UAAWJ,EACXqB,IAAKhV,GACFgQ,EAAmB,CACpBiF,iBAAkB,CAChB3E,oBAAqB,CAACQ,EAAMpR,IAAmB,GAAEoR,KAAQpR,IACzD6Q,OAAS7R,GAAe,OAAMA,EAAEkO,KAAK,KACrC4D,WAAYnO,GAEdwS,oBAAqB,CACnBvE,oBAAqB,CAACQ,EAAMpR,IAAmB,GAAEoR,KAAQpR,IACzD6Q,OAAQ,QACRC,WAAYuE,GAAa,OAZzB,IAeJD,uBAAwB,WAI5B,cACEnB,EACA3T,EACAkV,GAGA,MAAMlL,QAA6BnJ,KAAKjC,KAAK,UAAV,KACjCmV,UAAWJ,EACXqB,IAAKhV,GACFgQ,EAAmB,CAAEmF,qBAAsB7O,EAAW4O,MAHxB,IAIjCE,eAAgBvU,KAAKmS,eACrB8B,uBAAwB,WAI1B,OAAK9K,EAAK4K,MAASzV,OAAOwB,KAAKqJ,EAAK4K,MAAMjN,OAGnCqC,EAAK4K,KAFH,KAKX,oBACEjB,EACAhT,EACAuU,GAGA,IAAKvU,EAAKgH,OACR,MAAO,GAET,GAAoB,IAAhBhH,EAAKgH,OACP,MAAO,OAAO9G,KAAKwU,QAAQ1B,EAAWhT,EAAK,GAAIuU,IAGjD,MAAMI,EAAWnW,OAAOwB,KAAKA,EAAK,IAC5B4U,EAAYL,aAAH,EAAGA,EAAgBM,QAC9BD,GACFD,EAAS7R,QAASb,IACX2S,EAAUnL,SAASxH,IACtB2S,EAAUlS,KAAKT,KAKrB,MAAMhB,EAAU,IAAIkJ,IACpBnK,EAAK8C,QAAQ,CAACzD,EAAKvB,IAAMmD,EAAQsJ,IAAI6E,EAAQ/P,EAAKsV,GAAW7W,IAE7D,MAAMgX,EAAgC9U,EAAKO,IAAI,IAAM,MAC/CwU,EAAa,OACd1F,EAAmB,CAAEmF,qBAAsB7O,EAAWiP,MAD3C,IAEdH,eAAgBvU,KAAKmS,iBAsBvB,aAnBMnS,KAAK8U,YAAYhV,EAAM,IAAK4C,UAAqB,MACrD,MAAMyG,QAAkCnJ,KAAKjC,KAAK,eAAgB,CAChEgX,aAAc,CACZ,CAACjC,GAAD,OACK+B,GADL,IAEEG,KAAMC,KAGVhB,uBAAwB,UAQ1B,OANA9K,EAAK+L,UAAUpC,GAAWlQ,QAASkR,IACjC,MAAMvN,EAAQxF,EAAQtC,IAAIyQ,EAAQ4E,EAAMW,SAC1BhU,IAAV8F,IACFqO,EAAUrO,GAASuN,MAGhB,UAAA3K,EAAKgM,gBAAgBrC,UAArB,eAAiCkC,OAAQ,KAG3CJ,EAGTQ,cAActC,EAAmBpE,GAE/B,OAAO1O,KAAK8U,YAAYpG,EAAO,GAAIhM,iBACS1C,KAAKjC,KAAK,iBAAkB,CACpEgX,aAAc,CACZ,CAACjC,GAAYuC,EAAWhV,IAAKyT,IAAD,CAAawB,WAAY,CAAEvB,KAAMD,OAE/DG,uBAAwB,WAEbsB,iBAAiBzC,IAAc,IAAIzS,IAAKzC,GAAMA,EAAE0X,WAAYvB,OAI7EyB,iBAAiB1C,EAAmBhT,GAElC,OAAOE,KAAK8U,YAAYhV,EAAM,GAAI4C,iBACU1C,KAAKjC,KAAK,iBAAkB,CACpEgX,aAAc,CACZ,CAACjC,GAAYmC,EAAU5U,IAAKlB,IAAD,CAAYsW,cAAe,CAAEtB,IAAKhV,OAE/D8U,uBAAwB,WAEbsB,iBAAiBzC,IAAc,IAAIzS,IAAKzC,GAAMA,EAAE6X,cAAetB,MAIhFuB,YAAY5C,EAAmBuB,GAE7B,MAAMvM,EAAQ,KACZoL,UAAWJ,GACR3D,EAAmB,CAAEmF,qBAAsB7O,EAAW4O,MAFhD,IAGTE,eAAgBvU,KAAKmS,eACrB8B,uBAAwB,UAE1B,OAAO,IAAIlG,EAAM/N,KAAKgO,IAAKtL,UACzB,MAAM8P,QAAkCxS,KAAKjC,KAAK,OAAV,OACnC+J,GADmC,IAEtC6N,kBAAmBrH,KAErB,MAAO,CAACkE,EAASoD,MAAOpD,EAASqD,oBAIrC,6BACE/C,EACAzB,EACAlS,EACAkV,EACAyB,GAGA,MAAMC,EAAiB,CAAC,MAClBC,EAA8B,IACnC3B,GAAkB,IAAIzR,QAASqN,IACjB,OAATA,IACE3R,OAAOmB,eAAe1B,KAAKoB,EAAK8Q,GAClC8F,EAAevT,KAAKyN,GAEpB+F,EAAkBxT,KAAKyN,MAI7B,MAAMnI,EAAQ,KACZoL,UAAWJ,EACX1B,UAAWC,GACRlC,EAAmB,CACpB8G,uBAAwB,CACtBxG,oBAAqB,CAACQ,EAAMpR,IAAmB,GAAEoR,KAAQpR,IACzD6Q,OAAQ,QACRC,WAAYxQ,GAEdmV,qBAAsB7O,EAAWsQ,MAT1B,IAWTxB,gBAAgB,EAChBN,uBAAwB,UAE1B,IAAIvF,EACJ,GAAIoH,EAAU,CAKZpH,SAJwC1O,KAAKjC,KAAK,QAAV,OACnC+J,GADmC,IAEtCoO,MAAO,MAEQN,WAEjBlH,QAAc,IAAIX,EAAM/N,KAAKgO,IAAKtL,UAChC,MAAM8P,QAAkCxS,KAAKjC,KAAK,QAAV,OACnC+J,GADmC,IAEtC6N,kBAAmBrH,KAErB,MAAO,CAACkE,EAASoD,MAAOpD,EAASqD,oBAChC1O,MAGL,IAAKuH,EAAM5H,QAAWuN,IAAmB2B,EAAkBlP,OACzD,OAAO4H,EAGT,MAAMyH,QAAgBnW,KAAKoW,cACzBtD,EACApE,EAAMrO,IAAI,EAAGqB,SAAH,CAAeA,QACzBuN,EAAW+G,IAEb,OAAOtH,EACJrO,IAAI,CAACyT,EAAMlW,IAAOuY,EAAQvY,GAAR,OAAmBkW,GAASqC,EAAQvY,IAAQ,MAC9DuC,OAAQ2T,GAASA,GAGtB,iBAAiBhB,EAAmB3T,SAC5Ba,KAAKqW,WAAWvD,EAAW3T,GAAK,GAGxCmX,oBAAoBxD,EAAmB3T,GACrC,OAAOa,KAAKqW,WAAWvD,EAAW3T,GAAK,GAGzC,iBAAyB2T,EAAmB3T,EAAcoX,GAexD,aAbwCvW,KAAKjC,KAAK,aAAV,KACtCmV,UAAWJ,EACXqB,IAAKhV,GACFgQ,EAAmB,CACpB6E,oBAAqB,CACnBvE,oBAAsBQ,GAAkB,oBAAmBA,KAC3DP,OAAQ,QACRC,WAAY,CAACrR,OAAOwB,KAAKX,GAAK,QAPI,IAUtC8U,uBAAwB,QACxBuC,aAAcD,EAAY,eAAY9V,MAExBgW,WAGlB,qBACE3D,EACAE,EAAqD,IAGrD,MAAMnN,QAAiB7F,KAAKwT,cAAcV,GACpC/R,EAAU,IAAIkJ,IACdyM,EAA6C,GAC7CC,EAAa9Q,EAAS8N,MAAMP,wBAA0B,GAC5D,IAAK,IAAIxV,EAAI,EAAGA,EAAI+Y,EAAW7P,OAAQlJ,GAAK,EAAG,CAC7C,MAAMuI,EAAMwQ,EAAW/Y,GACvBmD,EAAQsJ,IAAIlE,EAAIiL,UAAWjL,GAE7B,IAAK,IAAIvI,EAAI,EAAGA,EAAIoV,EAAiBlM,OAAQlJ,GAAK,EAAG,CACnD,MAAMuI,EAAM6M,EAAiBpV,GACvBgZ,EAAM7V,EAAQtC,IAAI0H,EAAIkL,WAC5B,GAAIuF,EAAK,CACP,IAAK5P,EAAab,EAAKyQ,GACrB,MAAM,IAAIvV,MAAO,2CAA0C8E,EAAIkL,WAEjEtQ,EAAQqF,OAAOD,EAAIkL,gBAEnBqF,EAASlU,KAAK2D,GAGlB,MAAM0Q,EAAW,IAAI9V,EAAQjB,QAE7B,IAAK,IAAIlC,EAAI,EAAGA,EAAIiZ,EAAS/P,OAAQlJ,GAAK,QAClCoC,KAAKjC,KAAK,cAAe,CAC7BmV,UAAWJ,EACXgE,4BAA6B,CAAC,CAC5BC,OAAQ,CAAE3F,UAAWyF,EAASjZ,cAI5BoC,KAAKuT,aAAaT,GAAW,GAErC,IAAK,IAAIlV,EAAI,EAAGA,EAAI8Y,EAAS5P,OAAQlJ,GAAK,QAClCoC,KAAKjC,KAAK,cAAe,CAC7BmV,UAAWJ,EACXK,qBAAsBtC,EAA2B,CAAC6F,EAAS9Y,GAAG2T,YAC9DuF,4BAA6B,CAAC,CAAEE,OAAQ7F,EAAqBuF,EAAS9Y,cAGlEoC,KAAKuT,aAAaT,GAAW,GAK/BgC,YACNpG,EACAuI,EACApT,GAEA,MAAMqT,EAAYxI,EAAMiG,QACxB,OAAO3U,KAAKgO,IAAIK,GAAG,IAAMmC,EAAe9N,UACtC,MAAMyU,EAAQD,EAAUvC,QAExB,IADAuC,EAAUpQ,OAAS,EACZqQ,EAAMrQ,QAAQ,CACnB,MAAMuO,EAAa8B,EAAMC,OAAO,EAAGH,GAG7BI,QAAmBxT,EAAGwR,GAC5B6B,EAAU1U,QAAQ6U,GAEpB,GAAIH,EAAUpQ,OACZ,MAAM,IAAIzF,MAAM,kCAKtB,WACEiW,EACAC,GAEA,MAeMpO,SAfiBnJ,KAAKgO,IAAIwJ,QAAQ,CACtCC,OAAQ,OACR3K,IAAK9M,KAAKkS,KACVE,OAAQpS,KAAKoS,OACbsF,QAAS,WACTC,QAAS,CACP,eAAgB,6BAChB,eAAiB,qBAAoBL,GAEvCC,UAMoBK,KACtB,GAAIzO,EAAK0O,iBAAkB,CACzB,IAAIC,EAEFA,EADEhI,MAAMC,QAAQ5G,EAAK0O,kBACV1O,EAAK0O,iBAAiBE,OAAO,CAACjZ,EAAGb,IAAOa,EAAIsO,OAAOnP,EAAE+Z,eAAiB,GAEtE5K,OAAOjE,EAAK0O,iBAAiBG,eAE1ChY,KAAKsS,oBAAsBwF,EAE7B,OAAO3O,G,2iCCzqBX,SAAS8O,EAAU/O,EAAchF,GAC/B,OAAQvB,IACN,MAAMgM,EAASE,OAAOlM,EAAGuG,GAAQ,IAAI7H,MAAM6C,GAAWvB,GAI1D,SAASuV,EACPhP,EACArF,GAEA,OAAQlB,IACN,GAAIgM,EAASE,OAAOlM,EAAGuG,GACrB,OAAOrF,IAET,MAAMlB,GAIV,MAAMwV,EAAS,OAEf,SAASC,EAAcvZ,GAKrB,MAAO,CAAEwZ,EADG7O,EAAkB3K,GACdiK,SAAS,WAG3B,SAASwP,EAAazZ,GACpB,MAAMsJ,EAAkB,GAIxB,OAHA7J,OAAOwB,KAAKjB,GAAO+D,QAASzD,IAC1BgJ,EAAOhJ,GAAOiZ,EAAcvZ,EAAMM,MAE7BgJ,EAGT,SAASoQ,EAAe1Z,GACtB,OAAOP,OAAOmB,eAAe1B,KAAKc,EAAO,KAiB3C,SAAS2Z,EAA4C3Z,GACnD,IAAKA,EACH,OAAO,KAET,MAAMsJ,EAAkC,GAIxC,OAHA7J,OAAOwB,KAAKjB,GAAO+D,QAASzD,IAC1BgJ,EAAOhJ,GAhBX,SAAyBN,GACvB,GAAI0Z,EAAe1Z,GACjB,OAAO6K,EAAoBzE,OAAOoE,KAAKxK,EAAMwZ,EAAG,WAElD,MAAM,IAAIhX,MAAM,kCAYAoX,CAAgB5Z,EAAMM,MAE/BgJ,EAGT,SAASuQ,EAAYzI,EAAcpR,GACjC,IAAK0Z,EAAe1Z,GAClB,MAAM,IAAIwC,MAAM,kCAElB,MAAO,CACLgX,EAAGpT,OAAOwE,OAAO,CACfxE,OAAOoE,KAAQ4G,EAAF,IAAW,QACxBhL,OAAOoE,KAAKxK,EAAMwZ,EAAG,YACpBvP,SAAS,WAIhB,MAAM6P,GAAiB,CAAEN,EAAGpT,OAAOoE,KAAK,KAAKP,SAAS,WAEhD8P,GAAc9F,GAAiCA,EAAF,IASnD,SAAS+F,GACP7G,GAEA,GAAKA,EAGL,MAAO,CACL8G,kBAAmB/U,KAAKgV,IAAI,EAAGhV,KAAKiV,KAAKhH,EAAWiH,OACpDC,mBAAoBnV,KAAKgV,IAAI,EAAGhV,KAAKiV,KAAKhH,EAAWmH,SAIzD,SAASC,GACPtZ,EACAuZ,GAEA,MAAMC,EAAkB,CAAEL,KAAM,EAAGE,MAAO,GAC1C,IAAII,GAAgB,EASpB,OARAzZ,EAAK8C,QAASqN,IACZ,MAAMuJ,EAAMH,aAAH,EAAGA,EAAepJ,GACvBuJ,IACFD,GAAgB,EAChBD,EAAgBL,MAAQO,EAAIP,KAC5BK,EAAgBH,OAASK,EAAIL,SAG1BI,EAAgBD,EAAkB,KAG3C5W,eAAe+W,GACbC,EACA5G,EACA6G,EACAC,EACAP,GAEA,MAAMQ,EAAiBjB,GAAW9F,IAE3B5G,SAAiB7J,QAAQ8E,IAAsB,CACpDuS,EAAI7G,YACFC,EACA,CAAC,CAAE/B,cAAe,KAAMC,cAAe,IAAKQ,QAAS,SACrDmI,EAActZ,IAAK4P,IAAD,CAChBoB,UAAW7D,EAAWyC,GACtBsB,UAAW,CAAC,CAAER,cAAed,EAAMe,cAAe,IAAKQ,QAAS,SAChEQ,WAAY6G,GAAgBQ,aAAD,EAACA,EAAepJ,QAE7C,EACA4I,GAAgBQ,aAAD,EAACA,EAAe,QAEjCO,EAAW9S,OAAS4S,EAAI7G,YACtBgH,EACA,CAAC,CAAE9I,cAAe,KAAMC,cAAe,IAAKQ,QAAS,SACrD,IACA,EACAqH,GAAgBO,GAAsBQ,EAAYP,KAChDK,EAAII,YAAYD,GAAgB9T,MAAMoS,KAG5C,GAAIjM,IAAY0N,EAAW9S,OACzB,OAIF,MAAMiT,QAAaL,EAAIlF,QAAQqF,EAAgB,CAAEG,GAAIrB,IAAkB,CAAC,WAClEsB,EAAU,IAAI/T,IAAI0T,GAClBM,EAAoB,GAlH5B,IAA2Brb,EAsHzB,GAHIkb,IAnHqBlb,EAmHKkb,EAAK3Z,OAlH5B9B,OAAOmB,eAAe1B,KAAKc,EAAO,QAmHvCqb,EAAQ1X,QAAQuX,EAAK3Z,OAAO+Z,GAAGha,OAAQ2T,IAAUmG,EAAQ7T,OAAO0N,KAE9DmG,EAAQ/S,KAAM,CAEhB,MAAMoJ,EAAQ,IAAI2J,SACZP,EAAIhE,YAAY5C,EAAW,CAAC,QAASxC,IAAQnC,QAAQzL,UACzD,MAAM0X,EAAwB,GAI9B,OAHA1L,EAAM9L,QAASkR,GAASxD,EAAM1N,QAASqN,IACrCmK,EAAW5X,KAAK,CAAEwX,GAAItB,EAAYzI,EAAM6D,EAAK7D,IAAQvO,GAAIoS,EAAKpS,QAEzDgY,EAAItE,cAAcyE,EAAgBO,UAEtC,IAAKF,EAAQpT,OAClB,aAMI4S,EAAIW,QAAQR,EAAgB,CAAEG,GAAIrB,GAAgBvY,OAAQ,CAAE+Z,GAAIP,KAGzD,MAAMU,WAA2C1Z,IAGvDf,YACY6Z,EACA5G,EACjBhT,EAAkB,GAClBuZ,GAEA5R,MAAM3H,GADN,KAJiB4Z,MAIjB,KAHiB5G,YAGjB,oBAPkD,IAUlD,MAAM6G,EAAsC,GAC5Crb,OAAO4B,QAAQJ,GAAM8C,QAAQ,EAAEzD,EAAKsC,OAC9BA,aAAJ,EAAIA,EAASrB,QACXJ,KAAK4Z,WAAWpX,KAAKrD,GAErBwa,EAAcnX,KAAKrD,KAIvBa,KAAK0H,UAAU+R,GACbC,EACA5G,EACA6G,EACA3Z,KAAK4Z,WACLP,IAIJ,wBACE,OAAOrZ,KAAK8S,UAGd,6BACE,OAAO8F,GAAW5Y,KAAK8S,WAGf7R,YAAYpC,GACpB,OAAOmB,KAAKqa,QAAQ/B,EAAazZ,IAGzBgD,eACRH,EACAF,GAEA,MAAMsS,EAAOwE,EAAa,GAAE5W,MAAOF,KAC3BE,GAAI6Y,GAAyBzG,EAAd0G,EAAvB,EAAqC1G,EAArC,QACM3U,EAAM,CAAEuC,GAAI6Y,GAGlB,OAAOva,KAAKya,WAAWtb,EAAKqb,EAAWrb,GAAK4G,MAAMmS,EArPd,kCAyPlC,IAAMlY,KAAKqa,QAAQvG,GAAM/N,MAAMmS,EAC7B,eAIA,IAAMlY,KAAKya,WAAWtb,EAAKqb,EAAWrb,GAAK4G,MAAMkS,EA9PjB,kCAkQ9B,8BAMR,qBACE/W,EACAC,EAFF,GAIiB,IADbO,GAAIgZ,GACS,EADHlZ,EACG,YACf,GAAwB,OAApBN,QACIlB,KAAKya,WACTnC,EAAa,CAAE5W,GAAIP,IACnBmX,EAAa9W,IACbuE,MAAMmS,EAjR0B,kCAiRmBC,QAChD,CACL,MAAMzJ,QAAc1O,KAAKuB,eAAeL,EAAiBC,EAAa,CAAC,aACjEkB,QAAQ8E,IAAIuH,EAAMrO,IAAI,EAAGqB,QAAS1B,KAAKya,WAC3CnC,EAAa,CAAE5W,OACf4W,EAAa9W,GACb8W,EAAa,CAAE,CAACpX,GAAkBC,KAClC4E,MAAMmS,EAxR0B,kCAwRmBC,OAIzD,kBAIEjX,EACAC,EACAC,GAEA,GAAwB,OAApBF,EACF,OAAOsX,QAAqCxY,KAAK0Z,IAAIlF,QACnDxU,KAAK8S,UACLwF,EAAa,CAAE5W,GAAIP,IACnBC,IAIJ,IAAKpB,KAAKe,QAAQL,cAAcQ,GAAkB,CAQhD,OAAOsX,SAPgBxY,KAAK0Z,IAAIiB,uBAC9B3a,KAAK8S,UACLtF,EAAWtM,GACXoX,EAAa,CAAE,CAACpX,GAAkBC,IAClCC,GACA,IAE6C,IAGjD,MAAMwZ,EAAiBxC,EAAcjX,GAC/BhC,QAAYa,KAAK0Z,IAAIlF,QACzBoE,GAAW5Y,KAAK8S,WAChB,CAAEkH,GAAItB,EAAYxX,EAAiB0Z,IACnC,CAAC,OAEH,IAAKzb,EACH,OAAO,KAET,IAAKiC,EACH,OAAOoX,QAAqCxY,KAAK0Z,IAAIlF,QAAQxU,KAAK8S,UAAW3T,IAE/E,MAAM0b,EAAmB,GACnBC,EAAiB,IAAI5U,IAAI9E,GAO/B,GANI0Z,EAAe1U,OAAO,OACxB9H,OAAOyc,OAAOF,EAAS1b,GAErB2b,EAAe1U,OAAOlF,KACxB2Z,EAAQ3Z,GAAmB0Z,GAEzBE,EAAe5T,KAAM,CACvB,MAAM8T,QAAoBhb,KAAK0Z,IAAIlF,QAAQxU,KAAK8S,UAAW3T,EAAK,IAAI2b,IACpE,IAAKE,EAGH,OAAO,KAET1c,OAAOyc,OAAOF,EAASG,GAEzB,OAAOxC,EAA+BqC,GAGxC,qBAIE3Z,EACAC,EACAC,GAEA,IAAKF,EAAiB,CAEpB,aADoBlB,KAAK0Z,IAAIhE,YAAY1V,KAAK8S,UAAW1R,GAAkB+F,OAC9D9G,IAAImY,GAEnB,GAAIxY,KAAKe,QAAQL,cAAcQ,GAAkB,CAC/C,MAAM4S,QAAa9T,KAAKsB,YAAYJ,EAAiBC,EAAcC,GACnE,OAAO0S,EAAO,CAACA,GAAQ,GASzB,aAPoB9T,KAAK0Z,IAAIiB,uBAC3B3a,KAAK8S,UACLtF,EAAWtM,GACXoX,EAAa,CAAE,CAACpX,GAAkBC,IAClCC,GACA,IAEWf,IAAImY,GAGnB,qBACEtX,EACAC,GAEA,GAAwB,OAApBD,EAA0B,CAE5B,aADsBlB,KAAKib,WAAW3C,EAAa,CAAE5W,GAAIP,KACxC,EAAI,EAEvB,MAAMuN,QAAc1O,KAAKuB,eAAeL,EAAiBC,EAAa,CAAC,OAIvE,aAHwBkB,QAAQ8E,IAAIuH,EAAMrO,IAAI,EAAGqB,QAAS1B,KAAKib,WAC7D3C,EAAa,CAAE5W,WAEAvB,OAAQ+a,GAAYA,GAASpU,OAGhD,uBACEpF,EACAoS,EACA8F,EACA/V,GAEA,IAAK+V,EAAW9S,OAEd,kBADMjD,IAIR,MAAMgW,EAAiBjB,GAAW5Y,KAAK8S,WACjCqI,EAAsB,GAC5B,UA3YJzY,eACE4J,EACA8O,EACAvX,GAEA,MAIMwX,SAJgBhZ,QAAQkK,WAAWD,EAAOjM,IAAIqC,gBAC5CmB,EAAGhF,GACTuc,EAAa5Y,KAAK3D,OAEKsB,OAAQR,GAAmB,aAAbA,EAAEiP,QACzC,GAAIyM,EAASvU,OACX,MAAMuU,EAAS,GAiYPC,CAAO1B,EAAYuB,EAAYlL,GAASjQ,KAAK0Z,IAAIW,QACrDR,EACA,CAAEG,GAAItB,EAAYzI,EAAM6D,EAAK7D,IAAQvO,MACrC,MACAqE,MAAMkS,EAlZ0B,kCAkZkB,aAAYhI,WAC1DpM,IACN,MAAOlB,GAKP,YAJM3C,KAAK0Z,IAAIlE,iBACbqE,EACAsB,EAAU9a,IAAK4P,IAAD,CAAa+J,GAAItB,EAAYzI,EAAM6D,EAAK7D,QACtDlK,MAAMoS,GACFxV,GAIV,cAAsBmR,GACpB,OAAO9T,KAAKub,iBACVzH,EAAKpS,GACLoS,EACA9T,KAAK4Z,WACL,IAAM5Z,KAAK0Z,IAAIW,QACbra,KAAK8S,UACLgB,EACA,MACA/N,MAAMkS,EAta0B,kCAsaiB,kBAIvD,iBAAyB9Y,EAAcqC,EAAiB0S,GACtD,MAAMsH,EAAgBxb,KAAK4Z,WAAWzZ,OAAQuG,GAAMpI,OAAOmB,eAAe1B,KAAKyD,EAAQkF,IACvF,IAAK8U,EAAc1U,OAEjB,kBADM9G,KAAK0Z,IAAIe,WAAWza,KAAK8S,UAAW3T,EAAKqC,EAAQ0S,GAGzD,MAAM0C,QAAY5W,KAAK0Z,IAAIlF,QAAQxU,KAAK8S,UAAW3T,EAAKqc,GACxD,IAAK5E,EACH,MAAM,IAAIjI,EAAS,IAlbe,kCAkbuB,iCAE3D,MAAM8M,EAAeD,EAAcrb,OAAQuG,GAAOkQ,EAAIlQ,GAAW2R,IAAO7W,EAAOkF,GAAW2R,SACpFrY,KAAKub,iBACTpc,EAAIuC,GACJF,EACAia,EACA,IAAMzb,KAAK0Z,IAAIe,WAAWza,KAAK8S,UAAW3T,EAAKqC,EAAzC,OAAsDoV,GAAQ1C,WAEhElU,KAAK0Z,IAAIlE,iBACboD,GAAW5Y,KAAK8S,WAChB2I,EAAapb,IAAK4P,IAAD,CAAa+J,GAAItB,EAAYzI,EAAM2G,EAAI3G,QAI5D,iBAAyB9Q,GACvB,IACE,GAAKa,KAAK4Z,WAAW9S,OAEd,CACL,MAAMgN,QAAa9T,KAAK0Z,IAAIpD,oBAAoBtW,KAAK8S,UAAW3T,SAC1Da,KAAK0Z,IAAIlE,iBACboD,GAAW5Y,KAAK8S,WAChB9S,KAAK4Z,WAAWvZ,IAAK4P,IAAD,CAAa+J,GAAItB,EAAYzI,EAAM6D,EAAK7D,mBALxDjQ,KAAK0Z,IAAIuB,WAAWjb,KAAK8S,UAAW3T,GAQ5C,OAAO,EACP,MAAOwD,GACP,GAAIgM,EAASE,OAAOlM,EA9cc,mCA+chC,OAAO,EAET,MAAMA,I,6DC9dG,MAAM+Y,GAAe,c,YAAA,K,EAAA,W,EACN,IAAIxV,I,6FAEhCmI,GAAMxK,GACJ,IAAI8X,EAAgB,OACpB,MAAMC,EAAS,IAAIvZ,QAASC,IAC1BqZ,EAAgBrZ,IACfkK,KAAK,KACNxM,KAAK6b,SAASzV,OAAOwV,KAGvB,OADA5b,KAAK6b,SAAStQ,IAAIqQ,GACX/X,IAAKiY,QAAQH,GAGtB,aACE,MAAMI,EAAU,IAAI/b,KAAK6b,UACzB7b,KAAK6b,SAASG,cACR3Z,QAAQkK,WAAWwP,ICjB7B,MAAME,GAAS,KAAe,EAEf,MAAMC,GAGZrc,YACYiY,EACAqE,G,UACjB,KAFiBrE,WAEjB,KADiBqE,U,EACjB,K,EAAA,U,EALyB,IAAIlS,I,6FAOxB0B,OACLxM,EACAid,EACAC,EAA+BJ,IAE/B,MAAMpd,EAAQmB,KAAKsc,QAAQ7d,IAAIU,GAC/B,GAAIa,KAAKsc,QAAQlW,OAAOjH,GAAM,OAC5B,GAAIkd,EAAMxd,GAER,OADAmB,KAAKsc,QAAQjS,IAAIlL,EAAKN,GACfA,EAET,UAAAmB,KAAKmc,eAAL,cAAAnc,KAAenB,GAEjB,MAAMqN,EAAUkQ,EAAKjd,GAErB,OADAa,KAAKiB,YAAY9B,EAAK+M,GACfA,EAGT,kBACE/M,EACAid,EACAC,EAA+BJ,IAE/B,MAAMpd,EAAQmB,KAAKsc,QAAQ7d,IAAIU,GAC/B,GAAIa,KAAKsc,QAAQlW,OAAOjH,GAAM,OAC5B,GAAIkd,EAAMxd,GAER,OADAmB,KAAKsc,QAAQjS,IAAIlL,EAAKN,GACfA,EAET,UAAAmB,KAAKmc,eAAL,cAAAnc,KAAenB,GAEjB,MAAMqN,QAAgBkQ,EAAKjd,GAE3B,OADAa,KAAKiB,YAAY9B,EAAK+M,GACfA,EAGFX,IAAIpM,EAAQN,GACjBmB,KAAKuc,OAAOpd,GACZa,KAAKiB,YAAY9B,EAAKN,GAGjB2d,KAAKrd,GACV,OAAOa,KAAKsc,QAAQ7d,IAAIU,GAGnBod,OAAOpd,GACZ,GAAIa,KAAKmc,QAAS,CAChB,MAAMtd,EAAQmB,KAAKsc,QAAQ7d,IAAIU,GAC3Ba,KAAKsc,QAAQlW,OAAOjH,IACtBa,KAAKmc,QAAQtd,QAGfmB,KAAKsc,QAAQlW,OAAOjH,GAIjB6c,QACLhc,KAAKsc,QAAQN,QAGP/a,YAAY9B,EAAQN,GAG1B,IAFAmB,KAAKsc,QAAQjS,IAAIlL,EAAKN,GAEfmB,KAAKsc,QAAQpV,KAAOlH,KAAK8X,UAC9B9X,KAAKuc,OAAOvc,KAAKsc,QAAQxc,OAAO2c,OAAO5d,Q,6rBChE7C,MAAM6d,GAAezX,OAAO0X,MAAM,GAC5BC,GAAiB,kBACjBC,GAAY,mBAEZC,GAA0BrY,YAAO9B,KAASA,aAAagM,IAAahM,EAAEoM,eAE5E,SAASgO,GAAO/X,GACd,MAAMgY,EAAOC,sBAAW,UAExB,OADAD,EAAKxb,OAAOwD,GACLgY,EAAKE,OAAO,OAGrB,SAASC,GAAKhe,EAAagK,GACzB,MAAM6T,EAAOI,sBAAW,SAAUje,GAElC,OADA6d,EAAKxb,OAAO2H,EAAM,QACX6T,EAAKE,SAuBC,MAAMG,GAanBxd,YAA6Byd,EAAeC,GAAgB,KAA/BD,QAA+B,iDAV5B,IAAIpB,GAAyB,IAUD,yBAR1B,IAAIA,GAAyB,IAQH,mBANhC,IAAIA,GAAyB,KAMG,mBAJhC,IAAIR,IAI4B,kBAF3C,GAGf1b,KAAKwd,QAAUvY,OAAOoE,KAAM,OAAMkU,EAAU,QAG9ClP,GAAMxK,GACJ,OAAO7D,KAAK6b,SAASxN,GAAGxK,GAG1B2T,SAAQ,OACNC,EADM,IAEN3K,EAFM,OAGNsF,EAHM,QAINsF,EAJM,QAKNC,EAAU,GALJ,KAMNJ,EAAOmF,GAND,KAONe,EAAO,IAAIha,OAIX,MAAMia,EAAa5Q,aAAeE,IAAOF,EAAM,IAAIE,IAAIF,GACvD,GAAI4Q,EAAUC,OACZ,MAAM,IAAItc,MAAM,iDAElB,GAAIrB,KAAKwH,OACP,MAAM,IAAInG,MAAM,qBAGlB,IAAIuc,EAEFA,EADErG,aAAgBtS,OACLsS,EACY,iBAATA,EACHtS,OAAOoE,KAAKkO,EAAM,QAElBtS,OAAOoE,KAAKN,KAAKC,UAAUuO,GAAO,QAGjD,MAAMsG,EAAgBJ,EAAKK,cAAcxZ,QAAQsY,GAAgB,IAC3DmB,EAAgBF,EAAczU,OAAO,EAAG,GACxC4U,EAAmB,GAAED,KAAiB3L,KAAUsF,iBAChDvY,EAAMa,KAAKie,OAAOF,EAAe3L,EAAQsF,GAGzCwG,EAAgBC,UAAUA,UAAUC,UAAUV,EAAUW,aAAe,IAGvEC,EAAqC,SACtC3G,GADmC,IAEtC4G,KAAMb,EAAUxL,KAChB,aAAc2L,IAKVW,EAAclgB,OAAOwB,KAAKwe,GAC7Bje,IAAKoe,GAAWA,EAAOC,eACvB5S,OAEG6S,EAAmBH,EACtBne,IAAKoe,GAAY,GAAEA,KAAUH,EAAWG,QACxC1S,KAAK,IACF6S,EAAgBJ,EAAYzS,KAAK,KAEjC8S,EAAmB,CACvBpH,EACAyG,EArB2B,GAuB3BS,EACAC,EACA7B,GAAOa,IACP7R,KAAK,MASD+S,EAAY3B,GAAKhe,EAPF,CACnB0d,GACAgB,EACAG,EACAjB,GAAO9X,OAAOoE,KAAKwV,EAAkB,UACrC9S,KAAK,OAEmCjD,SAAS,OAUnD,OARAwV,EAAWS,cAAgB,CACxB,GAAElC,iBAAwB7c,KAAKsd,SAASU,IACxC,iBAAgBY,EAChB,aAAYE,GACb/S,KAAK,aAEAuS,EAAWC,KAEXve,KAAKgf,MAAMtB,EAAWE,EAAY,CACvCnG,SACAE,QAAS2G,IAIb,cACMte,KAAKwH,eAGHxH,KAAK6b,SAAS3Z,OACpBlC,KAAKwH,QAAS,GAGRwX,MACNlS,EACAyK,EACA9V,GAEA,GAAIzB,KAAKwH,OACP,MAAM,IAAInG,MAAM,qBAGlB,MAAM4d,EAA6B,UAAjBnS,EAAImS,SAAwBC,KAAQC,KACtD,OAAOnf,KAAK6b,SAASxN,GAAG,IAAMyO,GAAwB,IAAM,IAAIza,QAAQ,CAACC,EAASC,KAChF,MAAM6c,EAAMH,EAASzH,QAAQ1K,EAAKrL,EAAU4d,IAC1C,MAAMzP,EAAkB,GACxByP,EAAIC,GAAG,OAASC,GAAU3P,EAAMpN,KAAK+c,IACrCF,EAAIC,GAAG,MAAO,KACZ,IACE,MAAME,EAAOva,OAAOwE,OAAOmG,GAAO9G,SAAS,QAC3C8G,EAAM9I,OAAS,EACf,MAAM8Q,EAAO7O,KAAKO,MAAMkW,IACnBH,EAAII,YAAcJ,EAAII,YAAc,IAEvCld,EAAO,IAAIoM,EAAS0Q,EAAII,YAAc,EAAG7H,EAAK8H,OAAQ9H,EAAK1T,UAE3D5B,EAAQ,CAAEsM,OAAQyQ,EAAII,WAAY7H,SAEpC,MAAOjV,GACPJ,EAAOI,QAIbyc,EAAIE,GAAG,QAAS/c,GAChB6c,EAAIjG,MAAM5B,GACV6H,EAAIO,UAIA1B,OACNF,EACA3L,EACAsF,GAEA,OAAO1X,KAAK4f,SAASjU,OAAQ,GAAEoS,KAAiB3L,KAAUsF,IAAW,KACnE,MAAMmI,EAAU7f,KAAK8f,eAAenU,OAAQ,GAAEoS,KAAiB3L,IAAU,IAAM+K,GAC7End,KAAK+f,aAAapU,OAAOoS,EAAe,IAAMZ,GAAKnd,KAAKwd,QAASO,IACjE3L,IAEF,OAAO+K,GAAKA,GAAK0C,EAASnI,GAAU,mBCtK3B,MAAMsI,WAAiBxU,EAC5B3L,YACWmO,EACA0L,EACjBuG,EACA5G,GAEA5R,MAAM,CAACtJ,EAAM2B,IAAS,IAAIwa,GACxBta,KAAK0Z,IACLuG,EAAkBzS,EAAWrP,GAC7B2B,EACAuZ,aAJoB,EAIpBA,EAAcja,KAAK,KAAMjB,KAL3B,KAJiB6P,MAIjB,KAHiB0L,MAYnB,eAAsB5M,EAAauM,GACjC,MAAM6G,EAAS,IAAIlT,IAAIF,GACvB,IAAI3N,EACAoe,EAQJ,GAPI2C,EAAOC,UACThhB,EAAM+gB,EAAOC,SACb5C,EAAS2C,EAAOE,WAEhBjhB,EAAMkhB,QAAQC,IAAIC,kBAClBhD,EAAS8C,QAAQC,IAAIE,wBAElBrhB,IAAQoe,EACX,MAAM,IAAIlc,MAAM,iCAElB,MAAM4d,EAA+C,UAAnCiB,EAAO/S,aAAa1O,IAAI,OAAsB,OAAS,QACnE0T,EAAgE,SAA9C+N,EAAO/S,aAAa1O,IAAI,kBAC1CwhB,EAAkBC,EAAO7B,SAASjV,OAAO,GAEzC4E,EAAM,IAAIqP,GAAIle,EAAKoe,GACnB7D,EAAM,IAAIzH,EAAIjE,EAAM,GAAEiR,OAAciB,EAAOhO,OAAQ,CAAEC,mBAC3D,OAAO,IAAI6N,GACThS,EACA0L,EACAuG,EACA5G,IAtEoBnM,EAsEagT,EAAO/S,aAtEQ,CACpD2F,EACAzB,KAEA,IAAIW,EAA4B,KAchC,GAZEA,EADEX,EAEAnE,EAAOzO,IAAK,aAAYqU,WAAmBzB,MAC3CnE,EAAOzO,IAAK,aAAYqU,YACxB5F,EAAOzO,IAAK,aAAYqU,IACxB5F,EAAOzO,IAAI,aAIXyO,EAAOzO,IAAK,aAAYqU,IACxB5F,EAAOzO,IAAI,cAGVuT,GAA6B,MAAfA,EACjB,OAAO,KAET,MAAMpC,EAAQoC,EAAWyO,MAAM,KAC/B,GAAqB,IAAjB7Q,EAAM9I,OACR,MAAM,IAAIzF,MAAO,sCAAqCyR,KAAazB,GAAa,OAAOW,oCAEzF,MAAO,CACLiH,KAAM7L,OAAOsT,SAAS9Q,EAAM,GAAI,IAChCuJ,MAAO/L,OAAOsT,SAAS9Q,EAAM,GAAI,QA3BX1C,MA0EjBxB,cAAgCvN,EAAc2B,GACnD,OAAO2H,MAAMiE,cAAcvN,EAAM2B,GAG5B6gB,SACL,OAAO3gB,KAAK0Z,IAGJjN,gBACR,OAAOzM,KAAKgO,IAAI7B,SChEb,SAASyU,GACdC,KACGC,GAEH,IAAIC,EAAWF,EAAMxgB,IAAK2gB,GAAOA,EAAGC,QAAQlV,KAAK,KAIjD,OAHA+U,EAASle,QAAQ,CAACzE,EAAMP,KACtBmjB,EAAWA,EAASzc,QAAQ,IAAI4c,OAAQ,MAAK/iB,OAAW,KAAO,QAAOP,EAAI,QAErEmjB,E,kjCCfT,MAAMI,GAAmBrN,QAAkCrT,IAATqT,EAElD,SAASsN,GACPthB,EACAuhB,GAEA,OAAOvhB,EACJK,OAAO,EAAGhB,SAAUkiB,EAAuBliB,IAC3CkB,IAAI,EAAGlB,MAAKmiB,YAAc,GAAEA,KAAUD,EAAuBliB,MAGlE,SAASoiB,GACPzN,EACA7I,GAEA,IAAKA,EACH,OAAO6I,EAET,MAAM3L,EAAwC,GAC9C,IAAK,IAAItF,EAAI,EAAGA,EAAIoI,EAAOnE,OAAQjE,GAAK,EACtCsF,EAAO8C,EAAOpI,IAAOiR,EAAajR,GAEpC,OAAOsF,EAGT,SAASqZ,GAAe1N,GACtB,OAAOxV,OAAOgO,OAAOwH,GAAMhS,KAAMkD,GAAa,OAANA,GAG1CtC,eAAe+e,GAAWlU,SAClBA,EAAOmU,UAGfhf,eAAeif,GACbrV,EACAzI,GAEA,MAAMsE,EAAc,GACpB,IAAK,IAAIvK,EAAI,EAAGA,EAAI0O,EAAOxF,OAAQlJ,GAAK,EAEtCuK,EAAO3F,WAAWqB,EAAGyI,EAAO1O,KAE9B,OAAOuK,EAGM,MAAMyZ,WAA0ChhB,IAOtDf,YACYgiB,EACAP,EACjBxhB,EAAkB,IAElB2H,MAAM3H,GADN,KAHiB+hB,OAGjB,KAFiBP,SAEjB,sBAV0D,IAU1D,qBARsC,IAQtC,wBANyC,IASzCthB,KAAKe,QAAQT,mBAAmBsC,QAASb,IACvC,MAAM5C,EAAM4C,EACN+f,EAAa,GAAER,KAAUniB,IAC/Ba,KAAK+hB,YAAY5iB,GAAO2iB,EACxB,MAAME,EAAU,CAAE7iB,MAAKmiB,OAAQQ,GAC3B9hB,KAAKe,QAAQL,cAAcvB,GAC7Ba,KAAK4Z,WAAWpX,KAAKwf,GAErBhiB,KAAKiiB,cAAczf,KAAKwf,KAKpB/gB,YAAYpC,GACpB,MAAMsL,EAAaP,EAAgB/K,GACnC,OAAOmB,KAAK6hB,KAAKK,eAAexf,UAE9B,UADoB1C,KAAKmiB,OAAO5U,EAAQpD,GAAY,GAElD,MAAM,IAAI9I,MAAM,eAKZW,eACRd,EACAC,EACAK,GACA,OAAEG,IAEF,MAAMygB,EAAkBxY,EAAgBpI,GAClC4J,EAAOvC,EAAe1H,GAE5B,MAAwB,OAApBD,EACKlB,KAAK6hB,KAAKQ,oBAAoB3f,UACnC,MAAM4f,QAActiB,KAAKuiB,eAAehV,EAAQnC,EAAMgX,GACtD,GAAIE,QACItiB,KAAKwiB,WAAWjV,EAAQ,CAAC+U,SAC1B,GAAI3gB,EAAQ,CACjB,MAAM8gB,EAAc,SAAKL,GAAR,IAAyB1gB,GAAI0J,IAC9C,UAAWpL,KAAKmiB,OAAO5U,EAAQkV,GAAa,GAC1C,MAAM,IAAIphB,MAAM,eAGnBogB,IAGEzhB,KAAK6hB,KAAKQ,oBAAoB3f,UACnC,MAAMsI,QAAahL,KAAK0iB,2BAA2BnV,EAAQrM,EAAiBkK,GACtEuX,SAAiBhB,GACrB3W,EACCN,GAAQ1K,KAAKuiB,eAAehV,EAAQ7C,EAAK0X,KACzCjiB,OAAOghB,UACJnhB,KAAKwiB,WAAWjV,EAAQoV,IAC7BlB,IAGKngB,YAIRJ,EACAC,EACAC,GAEA,MAAMgK,EAAOvC,EAAe1H,GAC5B,OAAOnB,KAAK6hB,KAAKQ,oBAAoB3f,UAAkB,MACrD,MAAMgI,SAAa1K,KAAK0iB,2BAA2BnV,EAAQrM,EAAiBkK,IAAO,GACnF,QAAY3K,IAARiK,EACF,OAAO,KAGT,wBADsB1K,KAAK4iB,qBAAqBrV,EAAQ,CAAC7C,GAAMtJ,IAChD,UAAf,QAAqB,MACpBqgB,IAGKlgB,eAIRL,EACAC,EACAC,GAEA,OAAOpB,KAAK6hB,KAAKQ,oBAAoB3f,UACnC,IAAIsI,EACJ,GAAI9J,EAAiB,CACnB,MAAMkK,EAAOvC,EAAe1H,GAC5B6J,QAAahL,KAAK0iB,2BAA2BnV,EAAQrM,EAAiBkK,OACjE,CACLJ,QAAauC,EAAOzN,KAAKE,KAAK6iB,QAAQ,MACtC,MAAMC,EAAM9iB,KAAKshB,OAAOxa,OAAS,EACjCkE,EAAOA,EAAK3K,IAAK2E,GAAMA,EAAEoE,OAAO0Z,IAElC,OAAO9iB,KAAK4iB,qBAAqBrV,EAAQvC,EAAM5J,IAC9CqgB,IAGKxf,eACRf,EACAC,GAEA,MAAMiK,EAAOvC,EAAe1H,GACtB4hB,EAAc/iB,KAAKe,QAAQhB,aAEjC,OAAOC,KAAK6hB,KAAKQ,oBAAoB3f,UACnC,MAAMsI,QAAahL,KAAK0iB,2BAA2BnV,EAAQrM,EAAiBkK,GACtEsD,SAAeiT,GACnB3W,EACCN,GAAQ1K,KAAKgjB,oBAAoBzV,EAAQ7C,EAAKqY,KAC9C5iB,OAAOghB,IAEV,GAAqB,IAAjBzS,EAAM5H,OACR,OAAO,EAGT,MAAMmc,EAAW1V,EAAO2V,QAaxB,OAZAxU,EAAM9L,QAASkR,IACb,MAAM8F,EAAawH,GAAcphB,KAAK4Z,WAAY9F,GAC5CmO,EAAgBb,GAAcphB,KAAKiiB,cAAenO,GACxDmP,EAAS1G,OACP,EAAI3C,EAAW9S,OAASmb,EAAcnb,OACtC9G,KAAK6iB,QAAQ/O,EAAKpS,OACfkY,KACAqI,EACHnO,EAAKpS,YAGHuhB,EAASre,OACR8J,EAAM5H,QACZ2a,IAGGoB,QAAQM,GACd,MAAQ,GAAEnjB,KAAKshB,UAAU6B,IAG3B,aACE5V,EADF,EAGE6V,GACkB,IAFlB,GAAE1hB,GAEgB,EAFTyI,EAES,aAClB,MAAMyP,EAAawH,GAAcphB,KAAK4Z,WAAYzP,GAC5C8X,EAAgBb,GAAcphB,KAAKiiB,cAAe9X,GAElDkZ,EAAW,EAAIzJ,EAAW9S,OAASmb,EAAcnb,OACjDoG,EAAS,CACblN,KAAK6iB,QAAQnhB,MACVkY,KACAqI,EACHrI,EAAW9S,OACX,KACApF,KACGpD,OAAO4B,QAAQiK,GAAYmZ,QAGhC,IAAKF,EACH,OAAOziB,cAAc4M,EAAOhC,IAAI8X,KAAanW,IAG/C,MAAM/E,QAAeoF,EAClB2V,QACA3X,IAAI8X,KAAanW,GACjBtI,OACH,IAAKuD,EACH,MAAM,IAAI9G,MAAM,mBAElB,OAAOV,QAAQwH,EAAO,GAAG,IAG3B,qBACEoF,EACA7C,EACA0X,SAEM7U,EAAOgW,MAAMvjB,KAAK6iB,QAAQnY,IAChC,MAAMC,QAAsB3K,KAAKgjB,oBAC/BzV,EACA7C,EACA1K,KAAKe,QAAQT,mBAAmBH,OAAQ4B,GAAMqgB,EAAgBrgB,KAEhE,IAAK4I,EACH,OAEF,MAAMG,EAAgB,MAAKsX,GAO3B,OANA9jB,OAAOwB,KAAKgL,GAAelI,QAASb,IAC9B4I,EAAc5I,KAAO+I,EAAc/I,YAC9B+I,EAAc/I,UACd4I,EAAc5I,MAGlB,CAAE2I,MAAKI,gBAAeH,iBAG/B,iBACE4C,EACAoV,GAEA,MAAMa,EAAWb,EACdtiB,IAAKiiB,GAAUtiB,KAAKyjB,eAAenB,IACnCniB,OAAOghB,IAEV,IAAKqC,EAAS1c,OACZ,OAGF,GAAwB,IAApB0c,EAAS1c,OAAc,CACzB,MAAM4c,QAAgBnW,EAAO2V,QAC1B1hB,OAAOgiB,EAAS,GAAG,GAAIA,EAAS,GAAG,IACnC5e,OAEH,IAAK8e,EACH,MAAM,IAAIriB,MAAM,mBAElB,IAAKqiB,EAAQ,GAAG,GACd,MAAM,IAAIriB,MAAM,aAElB,OAOF,UAJiCsgB,GAC/B6B,EACCG,GAAepW,EAAOqW,YAAYD,EAAW,GAAIA,EAAW,MAExC7hB,KAAMpD,IAAOA,GAClC,MAAM,IAAI2C,MAAM,aAGlB,IAAIwiB,EAAQtW,EAAO2V,QACnBM,EAAS5gB,QAAS+gB,IAChBE,EAAQA,EAAMC,mBAAmBH,EAAW,GAAIA,EAAW,MAI7D,UAFsBE,EAAMjf,OAG1B,MAAM,IAAIvD,MAAM,mBAIZoiB,gBACN,IAAE/Y,EAAF,cAAOC,EAAP,cAAsBG,IAEtB,MAAMiZ,EAAOzlB,OAAO4B,QAAQ4K,GAAewY,OAC3C,IAAKS,EAAKjd,OACR,OAEF,MAAMkd,EAAkB5C,GAAcphB,KAAK4Z,WAAY9O,GACjDmZ,EAAqB7C,GAAcphB,KAAKiiB,cAAenX,GACvDoZ,EAAgB9C,GAAcphB,KAAK4Z,WAAYjP,GAC/CwZ,EAAmB/C,GAAcphB,KAAKiiB,cAAetX,GAC3D,GACEuZ,EAAcpd,SAAWkd,EAAgBld,QACzCqd,EAAiBrd,SAAWmd,EAAmBnd,OAE/C,MAAM,IAAIzF,MAAM,0CAclB,MAAO,CAZU,EAA2D,GAAtD2iB,EAAgBld,OAASmd,EAAmBnd,QACnD,CACb9G,KAAK6iB,QAAQnY,MACVsZ,KACAC,KACAC,KACAC,EACHH,EAAgBld,OAChBkd,EAAgBld,OAASmd,EAAmBnd,OAC5C4D,KACGqZ,IAKP,2BACExW,EACA6W,EACAnZ,GAEA,MAAMyY,QDjVHhhB,eACL6K,EACA8W,GAEA,OAAKA,EAASvd,OAGPyG,EAAO2V,MAAMmB,GAAUzf,OAFrB,GC4Ue0f,CACpB/W,EACA6W,EACG/jB,IAAKqK,GAAQ1K,KAAK6iB,QAAQnY,IAC1BrK,IAAK0B,GAAOkJ,EAAS,CAAC,QAASlJ,KAAMkJ,GAAU,CAAC,UAAWlJ,KAEhE,IAAK2hB,EACH,MAAM,IAAIriB,MAAM,mBAElB,OAAOqiB,EACJrjB,IAAI,EAAE,CAAEyT,KAA0ByN,GAAUzN,EAAM7I,IAClD9K,OAAOqhB,IACPnhB,IAAIyJ,GAGT,0BACEyD,EACA4V,EACAlY,GAEA,MAAM9L,EAAMa,KAAK6iB,QAAQM,GACzB,IAAIrP,EACJ,GAAI7I,EAAQ,CACV,IAAKA,EAAOnE,OAAQ,CAGlB,aADqByG,EAAOgX,OAAOplB,GACnB,QAAKsB,EAEvBqT,QAAavG,EAAOiX,MAAMrlB,KAAQ8L,QAElC6I,QAAavG,EAAOkX,QAAQtlB,GAE9B,MAAM+gB,EAASqB,GAAUzN,EAAM7I,GAC/B,OAAOuW,GAAetB,GAAUA,OAASzf,EAG3C,iCACE8M,EACAlH,EACAgF,GAEA,GAAgB,OAAZhF,EACF,MAAO,CAACgF,GAEV,MAAMyW,EAAY9hB,KAAK+hB,YAAY1b,GACnC,IAAKyb,EACH,MAAM,IAAIzgB,MAAO,iBAAgBgF,iBAEnC,MAAMqe,EAAc,GAAE5C,KAAazW,IAEnC,aADMkC,EAAOgW,MAAMmB,GACZnX,EAAOoX,SAASD,IC1Y3B,MAAME,GAAahE,GAAgB,CACjC,0CACA,aACA,MACA,yCACA,4CACA,eACA,QACA,MACA,6CACA,mBACA,uCACA,MACA,YACC,kBAEGiE,GAAoB,CACxB,yCACA,4CACA,eACA,QACA,OAGIC,GAAc,CAClB,qCACA,6CACA,iBACA,oDACA,OAIIC,GAAsBnE,GAAgB,IACvCiE,GACH,YACC,iBAAkB,gBAAiB,MAGhCG,GAA8BpE,GAAgB,IAC/CkE,IACF,iBAAkB,gBAAiB,MAGhCG,GAAgBrE,GAAgB,IACjCiE,MACAC,GACH,YACC,iBAAkB,gBAAiB,MAGhCI,GAAgBtE,GAAgB,CACpC,4BACA,mBACA,mCACA,OACC,M,yHChEH,MAAMuE,GAAY1gB,YAAO9B,GACV,iBAANA,GACO,oBAAdA,EAAEuB,SAGW,MAAMkhB,GAWZvlB,YACYwlB,EACAvY,EACArL,EACA6jB,GACjB,KAJiBD,cAIjB,KAHiBvY,MAGjB,KAFiBrL,UAEjB,KADiB6jB,iBACjB,sBAfuC,IAevC,gBAbc,GAad,gBAX4C,IAW5C,8CAPe,GASjB,qBACEzhB,EACA0hB,GAEA,MAAMtnB,QAAU+B,KAAKwlB,gBACrB,IACE,aAAa3hB,EAAG5F,GADlB,cAGQsnB,aAAN,EAAMA,EAAWtnB,IACjB+B,KAAKylB,iBAAiBxnB,IAI1B,0BACE4F,EACA0hB,GAEA,OAAOJ,GAAU,IAAMnlB,KAAKkiB,eAAere,EAAI0hB,IAG1CpZ,QACL,OAAInM,KAAKwH,OACAnF,QAAQC,WAGjBtC,KAAKwH,QAAS,EACK,IAAfxH,KAAK0lB,OACP1lB,KAAK2lB,UACEtjB,QAAQC,WAGV,IAAID,QAASC,IAClBtC,KAAK4lB,UAAY,KACf5lB,KAAK2lB,UACLrjB,QAKEqjB,UACN3lB,KAAK6lB,YAAYjjB,QAAS3E,GAAMA,EAAE6nB,cAClC9lB,KAAK6lB,YAAY/e,OAAS,EAG5B,sBACE,GAAI9G,KAAKwH,OACP,MAAM,IAAInG,MAAM,qBAGlB,MAAM3C,EAAIsB,KAAK6lB,YAAYE,MAC3B,GAAIrnB,EAEF,OADAsB,KAAK0lB,OAAS,EACPhnB,EAET,GAAIsB,KAAK0lB,MAAQ1lB,KAAKslB,eAAgB,CACpCtlB,KAAK0lB,OAAS,EACd,MAAMnY,EAAS,IAAIvN,KAAKqlB,YAAYrlB,KAAK8M,IAAK9M,KAAKyB,SAEnD,aADM8L,EAAOI,UDdJ,SAA0BJ,GAOvC,OANAA,EAAOyY,cAAc,MAAO,CAAEC,IAAKrB,KACnCrX,EAAOyY,cAAc,SAAU,CAAEC,IAAKhB,KACtC1X,EAAOyY,cAAc,cAAe,CAAEC,IAAKlB,KAC3CxX,EAAOyY,cAAc,qBAAsB,CAAEC,IAAKjB,KAClDzX,EAAOyY,cAAc,SAAU,CAAEC,IAAKf,KAE/B3X,ECQI2Y,CAAiB3Y,GAE1B,OAAO,IAAIlL,QAASC,IAClBtC,KAAKmX,MAAM3U,KAAKF,KAIZmjB,iBAAiBxnB,GACvB,MAAMkoB,EAAInmB,KAAKmX,MAAMiP,QAMG,MALpBD,EACFA,EAAEloB,IAEF+B,KAAK0lB,OAAS,EACd1lB,KAAK6lB,YAAYrjB,KAAKvE,GACH,IAAf+B,KAAK0lB,QACP,UAAA1lB,KAAK4lB,iBAAL,cAAA5lB,SChGO,MAAMqmB,WAAgB7a,EAC3B3L,YACWgiB,GAEjBpa,MAAM,CAACtJ,EAAM2B,IAAS,IAAI8hB,GAAgB5hB,KAAK6hB,KAAM1jB,EAAM2B,IAD3D,KADiB+hB,OAKnB,qBAA4B/U,GAC1B,MAAQY,QAAS2X,SAAsB,QAAN,qBAAa,KAE9C,OAAO,IAAIgB,GAAQ,IAAIjB,GACrBC,EACAvY,EACA,CAAEwZ,aAAa,GAJU,IAStB5a,cAAgCvN,EAAc2B,GACnD,OAAO2H,MAAMiE,cAAcvN,EAAM2B,GAG5BymB,oBACL,OAAOvmB,KAAK6hB,KAGJpV,gBACR,OAAOzM,KAAK6hB,KAAK1V,SCjCd,SAASqa,GAAYxhB,GAC1B,MAAQ,IAAGA,EAAEV,QAAQ,WAAY,WCDnC,MAAMmiB,GAAa,KAKnB,MAAMC,GAAa,KACZ,SAASC,GAAWC,GAGzB,MAAQ,IAAGA,EAAItiB,QAAQoiB,GAAY,SAGrC,MAAMG,GAAS,WACR,SAASC,GACdC,EACAC,GAEA,OAAOD,EAAKziB,QACVuiB,GACC7hB,GAjBK,IAiBiBgiB,EAAYhiB,EAAEoE,OAAO,IAjB/B9E,QAAQmiB,GAAY,U,qXCOrC,MAAMQ,GAAa,CACjBC,aAAc,CACZ,kCACA,gCACA,uBACA,KACAnb,KAAK,IAEPob,gBAAiB,sFAEjBC,aAAc,8DACdC,oBAAqB,0DACrBC,WAAY,0BAEZC,OAAQ,oDAERC,OAAQ,qEACRC,UAAW,kDAEXC,UAAW,4GAEXC,WAAY,oDACZC,WAAY,0BACZC,cAAe,4CACfC,UAAW,sCAEXC,OAAQ,mCACRC,UAAW,8BAiEb,SAASC,GAASpe,GAChB,OFlGK,SAAsBA,GAC3B,MAAM1B,EAAmB,GAIzB,OAHA7J,OAAOwB,KAAK+J,GAAQjH,QAASb,IAC3BoG,EAAO3F,KAAM,GAAEgkB,GAAYzkB,OAAOykB,GAAY3c,EAAO9H,SAEhDoG,EAAO4D,KAAK,KE6FZmc,CAAate,EAAgBC,IAGtC,SAASse,IACNzmB,EAAIyH,GACL8B,GAEA,MAAMmd,EFjGD,SAAsBC,GAC3B,MAAMlgB,EAAiC,GACvC,IAAI4T,EAAU,GACVuM,EAAa,GACbC,GAAQ,EACZ,IAAK,IAAI7oB,EAAI,EAAGA,EAAI2oB,EAAOvhB,QAAS,CAClC,MAAM7I,EAAIoqB,EAAO3oB,GACjB,OAAQzB,GACN,IAAK,IACL,IAAK,KACL,IAAK,KACL,IAAK,KACCsqB,IACFxM,GAAW9d,GAEb,MACF,IAAK,KACH8d,GAAWsM,EAAO3oB,EAAI,GACtBA,GAAK,EACL,MACF,IAAK,IACH6oB,GAASA,EACT,MACF,IAAK,IACCA,EACFxM,GAAW9d,EACgB,MAAlBoqB,EAAO3oB,EAAI,KACpB4oB,EAAavM,EACbA,EAAU,GACVrc,GAAK,GAEP,MACF,IAAK,IACC6oB,EACFxM,GAAW9d,GAEXkK,EAAOmgB,GAAcvM,EACrBuM,EAAa,GACbvM,EAAU,IAEZ,MACF,QACEA,GAAW9d,EAGfyB,GAAK,EAKP,OAHI4oB,IACFngB,EAAOmgB,GAAcvM,GAEhB5T,EE+CQqgB,CAAarf,GAC5Bif,EAAO1mB,GAAKA,EAEZ,MAAMyG,EAAkC,GAExC,OAAK8C,GAOLA,EAAOrI,QAASC,IACdsF,EAAOtF,GAAKoG,EAAiBmf,EAAOvlB,MAE/BsF,IATL7J,OAAO4B,QAAQkoB,GAAQxlB,QAAQ,EAAEb,EAAGiD,MAClCmD,EAAOpG,GAAKkH,EAAiBjE,KAExBmD,GASI,MAAMsgB,WAA6C7nB,IAGzDf,YACYgiB,EACA/O,EACjBhT,EAAkB,GACDyH,EAAqB,CAAEC,QAAQ,I,UAEhDC,MAAM3H,GADN,KAJiB+hB,OAIjB,KAHiB/O,YAGjB,KADiBvL,W,EANgE,I,EAOjF,mB,EAAA,M,sFAGAvH,KAAK0H,UAnGThF,eACEmf,EACA/O,EACAhT,EAAoB,IAEpB,MAAM7B,QAAU4jB,EAAKlU,UACrB,UAGQ1P,EAAE6J,MAAMgf,GAAgBG,GAAWC,aAAc,CACrDwB,EAAG5V,KAGL,MAAM/R,QAAgB9C,EAAE6J,MAAM,CAC5B6gB,QAAS,QACTnJ,KAAMyH,GAAWE,gBACjB7a,OAAQ,CAACwG,KAEL8V,EAAgB,IAAI1iB,IACxBnF,EAAQ8nB,KACLxoB,IAAK3B,GAAMA,EAAE,IACbyB,OAAQvC,GAAOA,EAAEkrB,WAAchW,EAAF,OAAoBlV,EAAEkrB,WAAchW,EAAF,QAK9DiW,EAAazqB,OAAO4B,QAAQJ,GAClC,IAAK,IAAIlC,EAAI,EAAGA,EAAImrB,EAAWjiB,OAAQlJ,GAAK,EAAG,CAC7C,MAAOmE,EAAGiD,GAAK+jB,EAAWnrB,GAC1B,GAAIoH,GAAKA,EAAE5E,OAAQ,CACjB,MAAMjC,EAAQ,GAAE2U,MAAc/Q,IACzB6mB,EAAcxiB,OAAOjI,UAClBF,EAAE6J,MAAMgf,GAAgBG,GAAWI,oBAAqB,CAC5DqB,EAAG5V,EACHkW,EAAG7qB,IACFmG,QAAQ,OAAQqiB,GAAW5kB,SAE3B,CACL,MAAM5D,EAAQ,GAAE2U,MAAc/Q,IACzB6mB,EAAcxiB,OAAOjI,UAClBF,EAAE6J,MAAMgf,GAAgBG,GAAWG,aAAc,CACrDsB,EAAG5V,EACHkW,EAAG7qB,IACFmG,QAAQ,OAAQqiB,GAAW5kB,MAIpC,MAAMknB,EAAkB,IAAIL,GAC5B,IAAK,IAAIhrB,EAAI,EAAGA,EAAIqrB,EAAgBniB,OAAQlJ,GAAK,EAAG,CAClD,MAAMuI,EAAM8iB,EAAgBrrB,SACtBK,EAAE6J,MAAMgf,GAAgBG,GAAWK,WAAY,CACnDoB,EAAG5V,EACHkW,EAAG7iB,MA9CT,QAoDElI,EAAEirB,WAyCazP,CAAeoI,EAAM/O,EAAWhT,IAGjD,qBAA+D,IAAnC,GAAE4B,GAAiC,EAA1BynB,EAA0B,mBACvDnpB,KAAKopB,cAAc,SAAUvgB,EAAenH,GAAKumB,GAASkB,IAGlE,qBACEznB,EACAF,SAEMxB,KAAKopB,cAAc,YAAavgB,EAAenH,GAAKumB,GAASzmB,IAGrE,qBACEN,EACAC,EAFF,GAIiB,IADf,GAAEO,GACa,EADNynB,EACM,aACf,MAAMze,EAAM7B,EAAe1H,GACrBknB,EAASJ,GAASkB,GAExB,GAAwB,OAApBjoB,QACIlB,KAAKopB,cAAc,YAAaf,EAAQ3d,OACzC,CACL,MAAMhM,QAAUsB,KAAKopB,cAAc,SAAUf,EAAQnnB,EAAiBwJ,GACtE,QAAWjK,IAAPiB,GAAoBhD,EAAE2qB,SAAW,GAAK3qB,EAAEmqB,KAAK,GAAG,KAAOnnB,EACzD,MAAM,IAAIL,MAAM,qBAKtB,kBAIEH,EACAC,EACAC,GAEA,IAAIgH,EAMJ,OAJEA,EADsB,OAApBlH,QACUlB,KAAKopB,cAAc,YAAavgB,EAAe1H,UAE/CnB,KAAKopB,cAAc,aAAcloB,EAAiB2H,EAAe1H,IAE1EiH,EAAIihB,SAGFlB,GAAc/f,EAAIygB,KAAK,GAAIznB,GAFzB,KAKX,qBAIEF,EACAC,EACAC,GAEA,IAAIgH,EAQJ,OAJEA,EAHGlH,EAE0B,OAApBA,QACGlB,KAAKopB,cAAc,YAAavgB,EAAe1H,UAE/CnB,KAAKopB,cAAc,gBAAiBloB,EAAiB2H,EAAe1H,UAJpEnB,KAAKopB,cAAc,cAM1BhhB,EAAIygB,KAAKxoB,IAAK2E,GAAMmjB,GAAcnjB,EAAG5D,IAG9C,qBACEF,EACAC,GAEA,IAAIiH,EAMJ,OAJEA,EADsB,OAApBlH,QACUlB,KAAKopB,cAAc,YAAavgB,EAAe1H,UAE/CnB,KAAKopB,cAAc,SAAUloB,EAAiB2H,EAAe1H,IAEpEiH,EAAIihB,SAGLD,cACNE,KACGhd,GAEH,GAAItM,KAAKuH,SAASC,OAChB,MAAM,IAAInG,MAAM,qBAGlB,IAAIsK,EAAS3L,KAAKupB,cAAcD,GAMhC,OALK3d,IACHA,EAASmb,GAAgBG,GAAWqC,GAAY,CAAEZ,EAAG1oB,KAAK8S,YAC1D9S,KAAKupB,cAAcD,GAAa3d,GAG3B3L,KAAK6hB,KAAK/Z,MAAM,CACrB3J,KAAO,GAAE6B,KAAK8S,aAAawW,IAC3BX,QAAS,QACTnJ,KAAM7T,EACNW,YC1OS,MAAMkd,WAAmBhe,EAC9B3L,YACWgiB,GAEjBpa,MAAM,CAACtJ,EAAM2B,IAAS,IAAI2oB,GAAmB5G,EAAM1jB,EAAM2B,EAAME,KAAKuH,WADpE,KADiBsa,OAKnB,qBAA4B/U,GAC1B,MAAM,KAAE2c,SAAe,QAAN,qBAAa,KACxB5H,EAAO,IAAI4H,EAAK,CAAEC,iBAAkB5c,IAE1C,aADM+U,EAAK/Z,MAAM,yCACV,IAAI0hB,GAAW3H,GAGjBnW,cAAgCvN,EAAc2B,GACnD,OAAO2H,MAAMiE,cAAcvN,EAAM2B,GAG5BymB,oBACL,OAAOvmB,KAAK6hB,KAGJpV,gBACR,OAAOzM,KAAK6hB,KAAKlC,O,6rBCIrB,SAASgK,GACP9qB,EACAoM,GAEA,OAAOA,EACJnJ,KAAMoJ,GAAU5M,OAAOkB,UAAUC,eAAe1B,KAAKc,EAAOqM,IAGlD,MAAM0e,GAOZ/pB,YACYgqB,EACA5e,EACA6e,GACjB,KAHiBD,iBAGjB,KAFiB5e,SAEjB,KADiB6e,UAEjB7e,EAAOrI,QAASsI,IACd,GAAI2e,EAAe9oB,QAAQL,cAAcwK,GACvC,MAAM,IAAI7J,MAAO,4BAA2B6J,KAKlD,UAAiBlK,GACf,OAAOhB,KAAK6pB,eAAete,UAAUvL,KAAK+pB,QAAQ/oB,IAGpD,UAIE7B,EACAN,EACAoM,GAEA,GAAIjL,KAAKiL,OAAO1B,SAASpK,GACvB,MAAM,IAAIkC,MAAM,+BAElB,MAAM+G,QAAYpI,KAAK6pB,eAAeprB,IAAIU,EAAKN,EAAOoM,GACtD,OAAO7C,EAAMpI,KAAKgqB,UAAU5hB,EAAK,CAAE,CAACjJ,GAAMN,IAAW,KAGvD,aAIEM,EACAN,EACAoM,GAEA,QAAYxK,IAARtB,GAAqBa,KAAKiL,OAAO1B,SAASpK,GAC5C,MAAM,IAAIkC,MAAM,+BAElB,MAAM+G,QAAYpI,KAAK6pB,eAAeI,OAAO9qB,EAAMN,EAAQoM,GACrDif,OAAiBzpB,IAARtB,EAAqB,CAAE,CAACA,GAAMN,QAAU4B,EACvD,OAAO4B,QAAQ8E,IAAIiB,EAAI/H,IAAK2E,GAAMhF,KAAKgqB,UAAUhlB,EAAGklB,KAGtD,aACE/qB,EACAN,EACA2C,EACAC,GAEA,GAAIzB,KAAKiL,OAAO1B,SAASpK,GACvB,MAAM,IAAIkC,MAAM,kCAElB,MAAM0D,QAAkB/E,KAAK+pB,QAAQvoB,EAAQ,CAAE,CAACrC,GAAMN,IACtD,OAAOmB,KAAK6pB,eAAeroB,OAAOrC,EAAKN,EAAOkG,EAAWtD,GAG3D,aACEtC,EACAN,GAEA,GAAImB,KAAKiL,OAAO1B,SAASpK,GACvB,MAAM,IAAIkC,MAAM,kCAElB,IAAKrB,KAAK8pB,QAAQK,UAChB,OAAOnqB,KAAK6pB,eAAetN,OAAOpd,EAAKN,GAGzC,MAAM6P,QAAc1O,KAAK6pB,eAAeI,OAAO9qB,EAAKN,EAAO,CAAC,OAK5D,aAJMwD,QAAQ8E,IAAIuH,EAAMrO,IAAIqC,gBACpB1C,KAAK8pB,QAAQK,UAAWrW,SACxB9T,KAAK6pB,eAAetN,OAAO,KAAMzI,EAAKpS,OAEvCgN,EAAM5H,OAGf,cACE,OAAO9G,KAAK6pB,eAAe9oB,QAa7B,cACEiE,EACAklB,GAEA,IAAIE,EACJ,GAAIpqB,KAAK8pB,QAAQO,SAAWV,GAAY3kB,EAAGhF,KAAKiL,QAAS,CACvD,MAAMqf,EAAYJ,EAAQ,SAAKA,GAAUllB,GAAMA,EAC/ColB,QAAkBpqB,KAAK8pB,QAAQO,QAAQC,GAEzC,MAAMvlB,EAAY,MAAKC,GAMvB,aALM3C,QAAQ8E,IAAInH,KAAKiL,OAAO5K,IAAIqC,UAC5BpE,OAAOkB,UAAUC,eAAe1B,KAAKiH,EAAGjD,KAC1CgD,EAAUhD,SAAW/B,KAAK8pB,QAAQS,KAAKxoB,EAAIiD,EAAUjD,GAAIqoB,OAGtDrlB,EAaT,gBACEC,EACAklB,GAEA,IAAIE,EACJ,GAAIpqB,KAAK8pB,QAAQU,WAAab,GAAY3kB,EAAGhF,KAAKiL,QAAS,CACzD,MAAMqf,EAAYJ,EAAQ,SAAKA,GAAUllB,GAAMA,EAC/ColB,QAAkBpqB,KAAK8pB,QAAQU,UAAUF,GAE3C,MAAMvlB,EAAY,MAAKC,GAMvB,aALM3C,QAAQ8E,IAAInH,KAAKiL,OAAO5K,IAAIqC,UAC5BpE,OAAOkB,UAAUC,eAAe1B,KAAKiH,EAAGjD,KAC1CgD,EAAUhD,SAAW/B,KAAK8pB,QAAQW,OAAO1oB,EAAIiD,EAAUjD,GAAIqoB,OAGxDrlB,GCrLX,MAAM2lB,GAAM,cACNC,GAAU1lB,OAAOoE,KAAQqhB,GAAF,IAAU,QAmCxBE,OAhC2C,CACxDC,QAAS,CAAC1rB,EAAgB6F,KACxB,MAAM8lB,EAAKC,KAAOC,YAJP,IAKLC,EAASF,KAAOG,eAAeR,GAAKvrB,EAAK2rB,GACzCK,EAAOF,EAAOzpB,OAAOwD,GACrBomB,EAAQH,EAAOG,QACrB,OAAOnmB,OAAOwE,OAAO,CAACkhB,GAASG,EAAIK,EAAMC,KAG3CC,QAAS,CAAClsB,EAAgB6F,KACxB,IAAKA,EAAE2P,MAAM,EAAGgW,GAAQ7jB,QAAQwkB,OAAOX,IACrC,MAAM,IAAItpB,MAAM,gCAGlB,MAAMypB,EAAK9lB,EAAE2P,MAAMgW,GAAQ7jB,OAAQ6jB,GAAQ7jB,OAhBhC,IAiBLykB,EAAYvmB,EAAE2P,MAAMgW,GAAQ7jB,OAjBvB,IAmBL0kB,EAAWT,KAAOU,iBAAiBf,GAAKvrB,EAAK2rB,GAC7CK,EAAOK,EAAShqB,OAAO+pB,GACvBH,EAAQI,EAASJ,QAEvB,OAAOnmB,OAAOwE,OAAO,CAAC0hB,EAAMC,KAG9BM,YAAa,IAAiBX,KAC3BY,gBAAgBZ,KAAOC,YAAY,KAEtCY,aAAezsB,GAA2BA,EAAI0sB,SAE9CC,eAAiB3iB,GAA4B4hB,KAAOY,gBAAgBxiB,ICVtE,SAAS4iB,GACPjC,GAKA,MAAO,CAAC7e,EAAc4e,IAChB5e,GAAU4e,EAELC,EAAQ7e,EAAQ4e,GAElBC,EA4BX,SAASkC,GACP5gB,GACA,WACE6gB,EAAarB,GADf,SAEEsB,GAAW,GACgC,IAE7C,MAAM/sB,EAAM8sB,EAAWH,eAAe1gB,GAEtC,OAAO2gB,GAAc,CACnB9gB,EACA4e,IACG,IAAID,GAAuCC,EAAgB5e,EAAQ,CACtEsf,KAAM,CAACxoB,EAAGiD,IAAgCinB,EAAWpB,QAAQ1rB,EAAKqK,EAAkBxE,IACpFylB,OAAQ/nB,MAAOX,EAAGiD,KAChB,KAAMA,aAAaC,QAAS,CAC1B,GAAIinB,EACF,OAAOlnB,EAET,MAAM,IAAI3D,MAAM,oBAElB,OAAOqI,QAA0BuiB,EAAWZ,QAAQlsB,EAAK6F,QAe/D,SAASmnB,GACPC,GACA,WACEH,EAAarB,GADf,SAEEsB,GAAW,EAFb,UAGEG,EAAY,GACyD,IAEvE,MAAMC,EAAQ,IAAIpQ,GAAmBmQ,GAE/BE,EAAU7pB,MACd8pB,EACA3iB,KAEA,MAAM,GAAEnI,GAAOmI,EAEf,QAAWpJ,IAAPiB,EACF,MAAM,IAAIL,MAAM,kCAGlB,OAAOirB,EAAMG,YAAY/qB,EAAIgB,UAC3B,MAAMoR,QAAasY,EAAc3tB,IAAI,KAAMiD,EAAI,CAAC,QAChD,GAAIoS,EACF,OAAOmY,EAAWH,eAAehY,EAAK3U,KAExC,IAAKqtB,EACH,MAAM,IAAInrB,MAAM,sCAElB,MAAMlC,QAAY8sB,EAAWP,cAE7B,aADMU,EAAc7gB,IAAI,CAAE7J,KAAIvC,IAAK8sB,EAAWL,aAAazsB,KACpDA,KAILutB,EAAYhqB,OAAShB,eACnB0qB,EAAc7P,OAAO,KAAM7a,GACjC4qB,EAAM/P,OAAO7a,IAIf,OAAOqqB,GAAkB,CACvB9gB,EACA4e,IACG,IAAID,GAAsCC,EAAgB5e,EAAQ,CACrEsf,KAAM,CAACxoB,EAAGiD,EAAG7F,IAAkC8sB,EAAWpB,QAAQ1rB,EAAKqK,EAAkBxE,IACzFylB,OAAQ/nB,MAAOX,EAAGiD,EAAG7F,KACnB,KAAM6F,aAAaC,QAAS,CAC1B,GAAIinB,EACF,OAAOlnB,EAET,MAAM,IAAI3D,MAAM,oBAElB,OAAOqI,QAA0BuiB,EAAWZ,QAAQlsB,EAAK6F,KAE3DqlB,QAASkC,EAAQntB,KAAK,MAAM,GAC5BorB,UAAW+B,EAAQntB,KAAK,MAAM,GAC9B+qB,UAAWuC,KAgBf,SAASC,GACPC,EACAR,EACA3qB,EAA6E,IAE7E,MAAMorB,EAAOprB,EAMb,OAAO0qB,GALQH,GAAaY,EAAYC,EACfC,GACvB,CAAC,OACDV,GAEuCS,G,+BCvK3C,MAAME,GAAeC,qBAA0BC,KAAKC,MAC9CC,GAAiBH,qBAA0BC,KAAKG,QAEhDC,GAAoBpoB,OAAO2D,GAAG,GAqC7B,SAAS0kB,GACdriB,EACA4e,EACApoB,EAA2B,IAE3B,OAAO,IAAImoB,GAAuCC,EAAgB5e,EAAQ,CACxEsf,KAAM,CAACxoB,EAAGiD,IAzCdtC,eAA6BsC,GAAY,0BACvCuoB,EAA4B,MAE5B,MAAMpjB,EAAaX,EAAkBxE,GACrC,GAAImF,EAAWrD,QAAUymB,EAA2B,CAClD,MAAMC,QAAgBT,GAAa5iB,GACnC,GAAIqjB,EAAQ1mB,OAASqD,EAAWrD,OAAS,EACvC,OAAO0mB,EAGX,OAAOvoB,OAAOwE,OAAO,CAAC4jB,GAAmBljB,IA+BNsjB,CAAczoB,EAAGvD,GAClDgpB,OAAQ,CAAC1oB,EAAGiD,IA7BhBtC,eAA+BsC,GAAW,SACxCknB,GAAW,EAD6B,eAExCwB,GAAiB,IAEjB,KAAM1oB,aAAaC,QAAS,CAC1B,GAAIinB,EACF,OAAOlnB,EAET,MAAM,IAAI3D,MAAM,4BAElB,GAAa,KAAT2D,EAAE,IAAwB,MAATA,EAAE,GACrB,OAAO0E,QAA0ByjB,GAAenoB,IAElD,GAAIA,EAAE,KAAOqoB,GAAkB,GAC7B,OAAO3jB,EAAoB1E,EAAE2E,SAAS,IAExC,GAAIuiB,GAAYwB,EACd,OAAO1oB,EAET,MAAM,IAAI3D,MAAM,4BAUkBssB,CAAgB3oB,EAAGvD,K,wVCtDvD,MAAMmsB,GAIG/tB,YACYgqB,EACAgE,EACAC,GACjB,KAHiBjE,iBAGjB,KAFiBgE,aAEjB,KADiBC,mBAGnB,UAAiB9sB,GACf,OAAOhB,KAAK6pB,eAAete,IAAIvK,GAGjC,UAIEE,EACAC,EACAC,GAEA,MAAMgH,QAAYpI,KAAK6pB,eAAeprB,IACpCyC,EACAC,EACAnB,KAAK+tB,iBAAiB3sB,IAExB,OAAOgH,EAAMpI,KAAKguB,eAAe5lB,EAAKhH,GAAoB,KAG5D,aAIEF,EACAC,EACAC,GAOA,aALmBpB,KAAK6pB,eAAeI,OACrC/oB,EACAC,EACAnB,KAAK+tB,iBAAiB3sB,KAEZf,IAAK+H,GAAQpI,KAAKguB,eAAe5lB,EAAKhH,IAGpD,aACEF,EACAC,EACAK,EACAC,GAEA,OAAOzB,KAAK6pB,eAAeroB,OAAON,EAAiBC,EAAaK,EAAQC,GAG1E,aACEP,EACAC,GAEA,OAAOnB,KAAK6pB,eAAetN,OAAOrb,EAAiBC,GAGrD,cACE,OAAOnB,KAAK6pB,eAAe9oB,QAGrBgtB,iBAEN3sB,GACA,OAAIA,GAAoBpB,KAAK8tB,iBACpB,IAAI1sB,KAAqBpB,KAAK8tB,kBAEhC1sB,EAGD4sB,eACN5lB,EACAhH,GAEA,GAAIA,IAAqBA,EAAiBU,KAAMmO,GAASjQ,KAAK6tB,WAAW5d,IACvE,OAAO7H,EAET,MAAMD,E,kWAAyB,IAAKC,GASpC,OARchH,GAAoB9C,OAAOwB,KAAKE,KAAK6tB,aAC7CjrB,QAASzD,IACb,MAAM8Q,EAAO9Q,EACP8uB,EAAYjuB,KAAK6tB,WAAW5d,GAC9Bge,IACF9lB,EAAO8H,GAAQge,EAAU7lB,EAAI6H,GAAO7H,MAGjCD,GAuCI+lB,OArBf,SAIEJ,EACAD,EACAhE,GAEA,OAAIA,EACK,IAAI+D,GACT/D,EACAgE,EACAC,GAGG,IAAIF,GACTC,EACAC,IC/FWK,UClCA,MACb,qBAA4BrhB,GAC1B,IAAIshB,EACJ,GAAIthB,EAAIgc,WAAW,UACjBsF,EAAUvhB,OACL,GAAIC,EAAIgc,WAAW,WACxBsF,EAAU9gB,OACL,GAAIR,EAAIgc,WAAW,YACxBsF,EAAUpO,QACL,GAAIlT,EAAIgc,WAAW,SACxBsF,EAAU/H,OACL,KAAIvZ,EAAIgc,WAAW,YAGxB,MAAM,IAAIznB,MAAO,2CAA0CyL,GAF3DshB,EAAU5E,GAKZ,IACE,aAAa4E,EAAQzgB,QAAQb,GAC7B,MAAOnK,GACP,MAAM,IAAItB,MAAO,kCAAiCyL,OAASnK,EAAEuB","file":"index.js","sourcesContent":["(function webpackUniversalModuleDefinition(root, factory) {\n\tif(typeof exports === 'object' && typeof module === 'object')\n\t\tmodule.exports = factory();\n\telse if(typeof define === 'function' && define.amd)\n\t\tdefine(\"collection-storage\", [], factory);\n\telse if(typeof exports === 'object')\n\t\texports[\"collection-storage\"] = factory();\n\telse\n\t\troot[\"collection-storage\"] = factory();\n})(global, function() {\nreturn "," \t// The module cache\n \tvar installedModules = {};\n\n \t// The require function\n \tfunction __webpack_require__(moduleId) {\n\n \t\t// Check if module is in cache\n \t\tif(installedModules[moduleId]) {\n \t\t\treturn installedModules[moduleId].exports;\n \t\t}\n \t\t// Create a new module (and put it into the cache)\n \t\tvar module = installedModules[moduleId] = {\n \t\t\ti: moduleId,\n \t\t\tl: false,\n \t\t\texports: {}\n \t\t};\n\n \t\t// Execute the module function\n \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n \t\t// Flag the module as loaded\n \t\tmodule.l = true;\n\n \t\t// Return the exports of the module\n \t\treturn module.exports;\n \t}\n\n\n \t// expose the modules object (__webpack_modules__)\n \t__webpack_require__.m = modules;\n\n \t// expose the module cache\n \t__webpack_require__.c = installedModules;\n\n \t// define getter function for harmony exports\n \t__webpack_require__.d = function(exports, name, getter) {\n \t\tif(!__webpack_require__.o(exports, name)) {\n \t\t\tObject.defineProperty(exports, name, { enumerable: true, get: getter });\n \t\t}\n \t};\n\n \t// define __esModule on exports\n \t__webpack_require__.r = function(exports) {\n \t\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n \t\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n \t\t}\n \t\tObject.defineProperty(exports, '__esModule', { value: true });\n \t};\n\n \t// create a fake namespace object\n \t// mode & 1: value is a module id, require it\n \t// mode & 2: merge all properties of value into the ns\n \t// mode & 4: return value when already ns object\n \t// mode & 8|1: behave like require\n \t__webpack_require__.t = function(value, mode) {\n \t\tif(mode & 1) value = __webpack_require__(value);\n \t\tif(mode & 8) return value;\n \t\tif((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;\n \t\tvar ns = Object.create(null);\n \t\t__webpack_require__.r(ns);\n \t\tObject.defineProperty(ns, 'default', { enumerable: true, value: value });\n \t\tif(mode & 2 && typeof value != 'string') for(var key in value) __webpack_require__.d(ns, key, function(key) { return value[key]; }.bind(null, key));\n \t\treturn ns;\n \t};\n\n \t// getDefaultExport function for compatibility with non-harmony modules\n \t__webpack_require__.n = function(module) {\n \t\tvar getter = module && module.__esModule ?\n \t\t\tfunction getDefault() { return module['default']; } :\n \t\t\tfunction getModuleExports() { return module; };\n \t\t__webpack_require__.d(getter, 'a', getter);\n \t\treturn getter;\n \t};\n\n \t// Object.prototype.hasOwnProperty.call\n \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n\n \t// __webpack_public_path__\n \t__webpack_require__.p = \"\";\n\n\n \t// Load entry module and return exports\n \treturn __webpack_require__(__webpack_require__.s = 9);\n","import type { Indices } from './Collection';\nimport type { DBKeys } from './DB';\n\nexport default class BaseIndices implements Indices {\n  constructor(private readonly keys: DBKeys<any>) {}\n\n  public getIndices(): string[] {\n    return ['id', ...Object.keys(this.keys)];\n  }\n\n  public getUniqueIndices(): string[] {\n    return ['id', ...Object.entries(this.keys).filter(([, o]) => o?.unique).map(([n]) => n)];\n  }\n\n  public getCustomIndices(): string[] {\n    return Object.keys(this.keys);\n  }\n\n  public isIndex(attribute: string): boolean {\n    return (\n      attribute === 'id' ||\n      this.keys[attribute] !== undefined\n    );\n  }\n\n  public isUniqueIndex(attribute: string): boolean {\n    return (\n      attribute === 'id' ||\n      Boolean(this.keys[attribute]?.unique)\n    );\n  }\n}\n","import type { Collection, UpdateOptions, Indices } from './Collection';\nimport type { IDable } from './IDable';\nimport type { DBKeys } from './DB';\nimport BaseIndices from './BaseIndices';\n\nexport default abstract class BaseCollection<T extends IDable> implements Collection<T> {\n  public readonly indices: Readonly<Indices>;\n\n  // actually read publicly by BaseDB but we don't want this to be a user-accessible property\n  protected internalReady?: () => Promise<void>;\n\n  private innerPreAct: () => Promise<void> | void;\n\n  protected constructor(keys: DBKeys<T>) {\n    this.innerPreAct = this.preAct.bind(this);\n    this.indices = new BaseIndices(keys);\n  }\n\n  public async add(entry: T): Promise<void> {\n    await this.innerPreAct();\n    return this.internalAdd(entry);\n  }\n\n  public async get<\n    K extends keyof T & string,\n    F extends readonly (keyof T & string)[]\n  >(\n    searchAttribute: K,\n    searchValue: T[K],\n    returnAttributes?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>> | null> {\n    if (!this.indices.isIndex(searchAttribute)) {\n      throw new Error(`No index for ${searchAttribute}`);\n    }\n    await this.innerPreAct();\n    return this.internalGet(searchAttribute, searchValue, returnAttributes);\n  }\n\n  public async getAll<\n    K extends keyof T & string,\n    F extends readonly (keyof T & string)[]\n  >(\n    searchAttribute?: K,\n    searchValue?: T[K],\n    returnAttributes?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>>[]> {\n    if (searchAttribute && !this.indices.isIndex(searchAttribute)) {\n      throw new Error(`No index for ${searchAttribute}`);\n    }\n    await this.innerPreAct();\n    return this.internalGetAll(searchAttribute, searchValue, returnAttributes);\n  }\n\n  public async update<K extends keyof T & string>(\n    searchAttribute: K,\n    searchValue: T[K],\n    update: Partial<T>,\n    options: UpdateOptions = {},\n  ): Promise<void> {\n    if (searchAttribute === 'id' && update.id !== undefined && update.id !== searchValue) {\n      throw new Error('Cannot update ID');\n    }\n    if (options.upsert) {\n      if (searchAttribute !== 'id') {\n        throw new Error(`Can only upsert by ID, not ${searchAttribute}`);\n      }\n      let withoutId = update;\n      if (Object.prototype.hasOwnProperty.call(update, 'id')) {\n        withoutId = { ...update };\n        delete withoutId.id;\n      }\n      await this.innerPreAct();\n      return this.internalUpsert(searchValue as T['id'], withoutId, options);\n    }\n    if (!this.indices.isIndex(searchAttribute)) {\n      throw new Error(`No index for ${searchAttribute}`);\n    }\n    if (\n      !this.indices.isUniqueIndex(searchAttribute) &&\n      Object.keys(update).some((k) => this.indices.isUniqueIndex(k))\n    ) {\n      throw new Error('duplicate');\n    }\n\n    await this.innerPreAct();\n    return this.internalUpdate(searchAttribute, searchValue, update, options);\n  }\n\n  public async remove<K extends keyof T & string>(\n    searchAttribute: K,\n    searchValue: T[K],\n  ): Promise<number> {\n    if (!this.indices.isIndex(searchAttribute)) {\n      throw new Error(`No index for ${searchAttribute}`);\n    }\n    await this.innerPreAct();\n    return this.internalRemove(searchAttribute, searchValue);\n  }\n\n  // Subclass constructors can call this with a promise that will resolve when\n  // they are ready to be used. BaseCollection will automatically ensure that\n  // other interactions are queued until this promise resolves.\n  // (this call will always succeed; you can safely ignore the promise returned)\n  protected async initAsync(wait: Promise<unknown>): Promise<void> {\n    const pending: [() => void, (e: Error) => void][] = [];\n    const addPending = (): Promise<void> => new Promise((resolve, reject) => {\n      pending.push([resolve, reject]);\n    });\n    this.internalReady = addPending;\n    this.innerPreAct = async (): Promise<void> => {\n      await addPending();\n      return this.preAct();\n    };\n    try {\n      await wait;\n    } catch (e) {\n      this.internalReady = (): Promise<void> => Promise.reject(e);\n      this.innerPreAct = (): void => { throw e; };\n      pending.forEach((f) => f[1](e));\n      return;\n    }\n    this.internalReady = undefined;\n    this.innerPreAct = this.preAct.bind(this);\n    pending.forEach((f) => f[0]());\n  }\n\n  // eslint-disable-next-line class-methods-use-this\n  protected preAct(): Promise<void> | void {}\n\n  protected async internalGet<\n    K extends keyof T & string,\n    F extends readonly (keyof T & string)[]\n  >(\n    searchAttribute: K,\n    searchValue: T[K],\n    returnAttributes?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>> | null> {\n    const all = await this.internalGetAll(searchAttribute, searchValue, returnAttributes);\n    return all[0] ?? null;\n  }\n\n  protected internalUpsert(\n    id: T['id'],\n    update: Partial<T>,\n    options: UpdateOptions,\n  ): Promise<void> {\n    return this.internalUpdate('id', id, update, options);\n  }\n\n  protected abstract internalAdd(entry: T): Promise<void>;\n\n  protected abstract internalGetAll<\n    K extends keyof T & string,\n    F extends readonly (keyof T & string)[]\n  >(\n    searchAttribute?: K,\n    searchValue?: T[K],\n    fields?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>>[]>;\n\n  protected abstract internalUpdate<K extends keyof T & string>(\n    searchAttribute: K,\n    searchValue: T[K],\n    update: Partial<T>,\n    options: UpdateOptions,\n  ): Promise<void>;\n\n  protected abstract internalRemove<K extends keyof T & string>(\n    searchAttribute: K,\n    searchValue: T[K],\n  ): Promise<number>;\n}\n","module.exports = require(\"crypto\");","function sleep(millis: number): Promise<void> | null {\n  return new Promise((resolve): any => setTimeout(resolve, millis));\n}\n\nexport default (shouldRetry: (e: any) => boolean, {\n  timeoutMillis = 60000,\n  initialDelayMillis = 20,\n  maxDelayMillis = 5000,\n  delayGrowth = 2,\n  jitter = true,\n} = {}) => async <T>(fn: () => Promise<T> | T): Promise<T> => {\n  const limit = Date.now() + timeoutMillis;\n  let currentDelay = initialDelayMillis;\n  for (let attempt = 1; ; attempt += 1) {\n    try {\n      // eslint-disable-next-line no-await-in-loop\n      return await fn();\n    } catch (e) {\n      if (!shouldRetry(e)) {\n        throw e;\n      }\n\n      const delay = (\n        Math.min(currentDelay, maxDelayMillis) *\n        (jitter ? Math.random() : 1)\n      );\n      currentDelay *= delayGrowth;\n\n      if (Date.now() + delay > limit) {\n        e.message += ` (timeout after ${attempt} attempts)`;\n        throw e;\n      }\n\n      // eslint-disable-next-line no-await-in-loop\n      await sleep(delay);\n    }\n  }\n};\n","module.exports = require(\"mongodb\");","module.exports = require(\"zlib\");","module.exports = require(\"util\");","module.exports = require(\"url\");","module.exports = require(\"https\");","module.exports = require(\"http\");","import {\n  Collection as MCollection,\n  Binary as MBinary,\n  IndexSpecification,\n  MongoError,\n} from 'mongodb';\nimport type { IDable } from '../interfaces/IDable';\nimport BaseCollection from '../interfaces/BaseCollection';\nimport type { KeyOptions } from '../interfaces/Collection';\nimport type { DBKeys } from '../interfaces/DB';\nimport type { StateRef } from '../interfaces/BaseDB';\nimport retry from '../helpers/retry';\n\nconst MONGO_ID = '_id';\nconst ID = 'id';\n\nconst DOT_REG = /\\./g;\nfunction fieldNameToMongo(name: string): string {\n  if (name === ID) {\n    return MONGO_ID;\n  }\n  return encodeURIComponent(name).replace(DOT_REG, '%2E');\n}\n\nfunction fieldNameFromMongo(name: string): string {\n  if (name === MONGO_ID) {\n    return ID;\n  }\n  return decodeURIComponent(name);\n}\n\nconst MONGO_ERROR_IDX = /^.*? index: ([^ ]+) dup key:.*$/;\nfunction getErrorIndex(e: MongoError): string {\n  return MONGO_ERROR_IDX.exec(e.message)?.[1] || '';\n}\n\nconst withUpsertRetry = retry((e) => (\n  e instanceof MongoError &&\n  e.code === 11000 &&\n  getErrorIndex(e) === '_id_'\n));\n\nfunction convertToMongo<T extends Partial<IDable>>(\n  value: T,\n): Record<string, unknown> {\n  const converted: Record<string, unknown> = {};\n  Object.keys(value).forEach((k) => {\n    let v = (value as any)[k];\n    if (v instanceof Buffer) {\n      v = new MBinary(v);\n      // eslint-disable-next-line no-underscore-dangle\n    } else if (typeof v === 'object' && v._bsontype) {\n      throw new Error('Must use Buffer to provide binary data');\n    }\n    converted[fieldNameToMongo(k)] = v;\n  });\n  return converted;\n}\n\nfunction convertFromMongo<T extends Partial<IDable>>(\n  value: Record<string, unknown> | null,\n): T | null {\n  if (!value) {\n    return null;\n  }\n  const converted: T = {} as any;\n  Object.keys(value).forEach((k) => {\n    let v = (value as any)[k];\n    // eslint-disable-next-line no-underscore-dangle\n    if (typeof v === 'object' && v._bsontype === 'Binary') {\n      v = v.buffer;\n    }\n    (converted as any)[fieldNameFromMongo(k)] = v;\n  });\n  return converted;\n}\n\nfunction makeMongoProjection(\n  names?: readonly string[],\n): Record<string, boolean> {\n  const projection: Record<string, boolean> = {};\n  if (names) {\n    projection[MONGO_ID] = false;\n    names.forEach((fieldName) => {\n      projection[fieldNameToMongo(fieldName)] = true;\n    });\n  }\n  return projection;\n}\n\ninterface MongoIndex {\n  name: string;\n  key: Record<string, -1 | 0 | 1 | 'hashed'>;\n  unique?: boolean;\n}\n\nfunction makeIndex(keyName: string, options: KeyOptions = {}): IndexSpecification {\n  const unique = Boolean(options.unique);\n  const mongoKey = fieldNameToMongo(keyName);\n  return {\n    key: { [mongoKey]: unique ? 1 : 'hashed' },\n    unique,\n  };\n}\n\nfunction indicesMatch(a: IndexSpecification, b: IndexSpecification): boolean {\n  if (Boolean(a.unique) !== Boolean(b.unique)) {\n    return false;\n  }\n  const aKey = a.key as Record<string, unknown>;\n  const bKey = b.key as Record<string, unknown>;\n  const keys = Object.keys(aKey);\n  if (Object.keys(bKey).length !== keys.length) {\n    return false;\n  }\n  return keys.every((k) => (aKey[k] === bKey[k]));\n}\n\nasync function configureCollection(\n  collection: MCollection,\n  keys: DBKeys<any> = {},\n): Promise<void> {\n  const existing: MongoIndex[] = await collection.indexes().catch(() => []);\n  const idxToCreate: IndexSpecification[] = [];\n  const idxToDelete = new Set(existing.map((idx) => idx.name));\n  idxToDelete.delete('_id_'); // MongoDB implicit primary key\n\n  Object.keys(keys)\n    .map((keyName) => makeIndex(keyName, keys[keyName]))\n    .forEach((index) => {\n      const match = existing.find((idx) => indicesMatch(idx, index));\n      if (match) {\n        idxToDelete.delete(match.name);\n      } else {\n        idxToCreate.push(index);\n      }\n    });\n  if (idxToCreate.length) {\n    await collection.createIndexes(idxToCreate);\n  }\n  if (idxToDelete.size) {\n    await Promise.all([...idxToDelete].map((idxName) => collection.dropIndex(idxName)));\n  }\n}\n\nexport default class MongoCollection<T extends IDable> extends BaseCollection<T> {\n  public constructor(\n    private readonly collection: MCollection,\n    keys: DBKeys<T> = {},\n    private readonly stateRef: StateRef = { closed: false },\n  ) {\n    super(keys);\n    this.initAsync(configureCollection(collection, keys));\n  }\n\n  protected preAct(): void {\n    if (this.stateRef.closed) {\n      throw new Error('Connection closed');\n    }\n  }\n\n  protected async internalAdd(value: T): Promise<void> {\n    await this.collection.insertOne(convertToMongo(value));\n  }\n\n  protected async internalUpsert(\n    id: T['id'],\n    update: Partial<T>,\n  ): Promise<void> {\n    await withUpsertRetry(() => this.collection.updateOne(\n      convertToMongo({ id }),\n      { $set: convertToMongo(update) },\n      { upsert: true },\n    ));\n  }\n\n  protected async internalUpdate<K extends keyof T & string>(\n    searchAttribute: K,\n    searchValue: T[K],\n    update: Partial<T>,\n  ): Promise<void> {\n    const query = convertToMongo({ [searchAttribute]: searchValue });\n    const mongoUpdate = { $set: convertToMongo(update) };\n    if (this.indices.isUniqueIndex(searchAttribute)) {\n      await this.collection.updateOne(query, mongoUpdate);\n    } else {\n      await this.collection.updateMany(query, mongoUpdate);\n    }\n  }\n\n  protected async internalGet<\n    K extends keyof T & string,\n    F extends readonly (keyof T & string)[]\n  >(\n    searchAttribute: K,\n    searchValue: T[K],\n    returnAttributes?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>> | null> {\n    const raw = await this.collection.findOne(\n      convertToMongo({ [searchAttribute]: searchValue }),\n      { projection: makeMongoProjection(returnAttributes) },\n    );\n    return convertFromMongo<T>(raw);\n  }\n\n  protected async internalGetAll<\n    K extends keyof T & string,\n    F extends readonly (keyof T & string)[]\n  >(\n    searchAttribute?: K,\n    searchValue?: T[K],\n    returnAttributes?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>>[]> {\n    const cursor = this.collection.find(\n      searchAttribute ? convertToMongo({ [searchAttribute]: searchValue }) : {},\n      { projection: makeMongoProjection(returnAttributes) },\n    );\n\n    const result: Pick<T, F[-1]>[] = [];\n    await cursor.forEach((raw) => result.push(convertFromMongo<T>(raw)!));\n\n    return result;\n  }\n\n  protected async internalRemove<K extends keyof T & string>(\n    searchAttribute: K,\n    searchValue: T[K],\n  ): Promise<number> {\n    const result = await this.collection.deleteMany(\n      convertToMongo({ [searchAttribute]: searchValue }),\n    );\n    return result.deletedCount || 0;\n  }\n}\n","module.exports = require(\"ioredis\");","module.exports = require(\"pg\");","// B = base64 binary\n// b = raw binary (*Bin functions only)\n// s = raw utf8 string\n// t = true\n// f = false\n// n = null\n// J = JSON (also accepts any plain JSON value for compatibility)\n\nconst JSON_INIT_CHARS = '{[\"0123456789-'; // t/f/n are dedicated values\nconst MARK_BINARY = 'b'.charCodeAt(0);\nconst MARK_STRING = 's'.charCodeAt(0);\n\nconst MARK_BINARY_BUFF = Uint8Array.of(MARK_BINARY);\n\nexport function canonicalJSON(o: Record<string, unknown> | undefined): string {\n  if (!o) {\n    return 'null';\n  }\n  // string comparison is intended\n  /* eslint-disable-next-line @typescript-eslint/require-array-sort-compare */\n  const content = Object.keys(o)\n    .sort()\n    .map((k) => `${JSON.stringify(k)}:${JSON.stringify(o[k])}`)\n    .join(',');\n  return `{${content}}`;\n}\n\nexport function serialiseValue(value: unknown): string {\n  if (value instanceof Buffer) {\n    return `B${value.toString('base64')}`;\n  }\n  if (typeof value === 'string') {\n    return `s${value}`;\n  }\n  if (typeof value === 'boolean') {\n    return value ? 't' : 'f';\n  }\n  if (value === null) {\n    return 'n';\n  }\n  return `J${JSON.stringify(value)}`;\n}\n\nexport function deserialiseValue(value: string): unknown {\n  const type = value[0];\n  const data = value.substr(1);\n  switch (type) {\n    case 'B': return Buffer.from(data, 'base64');\n    case 's': return data;\n    case 't': return true;\n    case 'f': return false;\n    case 'n': return null;\n    case 'J': return JSON.parse(data);\n    default:\n      if (JSON_INIT_CHARS.includes(type)) {\n        return JSON.parse(value);\n      }\n      throw new Error(`Unknown data type ${type}`);\n  }\n}\n\nexport function serialiseValueBin(value: unknown): Buffer {\n  if (value instanceof Buffer) {\n    return Buffer.concat([MARK_BINARY_BUFF, value]);\n  }\n  return Buffer.from(serialiseValue(value), 'utf8');\n}\n\nexport function deserialiseValueBin(value: Buffer | string): unknown {\n  if (typeof value === 'string') {\n    return deserialiseValue(value);\n  }\n\n  const type = value[0];\n  if (type === MARK_BINARY) {\n    return value.subarray(1);\n  }\n  if (type === MARK_STRING) {\n    return value.subarray(1).toString('utf8');\n  }\n  return deserialiseValue(value.toString('utf8'));\n}\n\nexport function serialiseRecord<T>(\n  record: T,\n): Record<string, string> {\n  const result: Record<string, string> = {};\n  Object.keys(record).forEach((k) => {\n    result[k] = serialiseValue((record as any)[k]);\n  });\n  return result;\n}\n\nexport function deserialiseRecord(\n  record: Record<string, string | null>,\n): Record<string, unknown> {\n  const result: Record<string, any> = {};\n  Object.keys(record).forEach((k) => {\n    const v = record[k];\n    if (v) {\n      result[k] = deserialiseValue(v);\n    }\n  });\n  return result;\n}\n","import type { IDable } from '../interfaces/IDable';\nimport BaseCollection from '../interfaces/BaseCollection';\nimport type { DBKeys } from '../interfaces/DB';\nimport type { StateRef } from '../interfaces/BaseDB';\nimport {\n  serialiseValue,\n  serialiseRecord,\n  deserialiseRecord,\n} from '../helpers/serialiser';\n\nfunction sleep(millis: number): Promise<void> | void {\n  if (!millis) {\n    return undefined;\n  }\n\n  // Simulate data access delays to ensure non-flakey e2e tests, etc.\n  return new Promise((resolve): any => setTimeout(resolve, millis));\n}\n\nfunction applyFilter<T, F extends readonly (keyof T)[]>(\n  data: T,\n  fields?: F,\n): Pick<T, F[-1]> {\n  if (!fields) {\n    return data;\n  }\n  const result: Pick<T, F[-1]> = {} as any;\n  fields.forEach((field) => {\n    result[field] = data[field];\n  });\n  return result;\n}\n\nexport default class MemoryCollection<T extends IDable> extends BaseCollection<T> {\n  private readonly data: Map<string, Record<string, string>>;\n\n  private readonly indexData: Partial<Record<keyof T, Map<string, Set<string>>>> = {};\n\n  public constructor(\n    keys: DBKeys<T> = {},\n    private readonly simulatedLatency = 0,\n    private readonly stateRef: StateRef = { closed: false },\n  ) {\n    super(keys);\n\n    this.data = new Map();\n\n    this.indices.getCustomIndices().forEach((k) => {\n      this.indexData[k as keyof T] = new Map();\n    });\n  }\n\n  protected preAct(): Promise<void> | void {\n    if (this.stateRef.closed) {\n      throw new Error('Connection closed');\n    }\n    return sleep(this.simulatedLatency);\n  }\n\n  protected async internalAdd(value: T): Promise<void> {\n    const serialised = serialiseRecord(value);\n    this.internalCheckDuplicates(serialised, true);\n    this.data.set(serialised.id, serialised);\n    this.internalPopulateIndices(serialised);\n  }\n\n  protected internalUpsert(\n    id: T['id'],\n    update: Partial<T>,\n  ): Promise<void> {\n    if (this.data.has(serialiseValue(id))) {\n      return this.internalUpdate('id', id, update);\n    }\n    return this.internalAdd({ id, ...update } as T);\n  }\n\n  protected async internalUpdate<K extends keyof T & string>(\n    searchAttribute: K,\n    searchValue: T[K],\n    update: Partial<T>,\n  ): Promise<void> {\n    const sIds = this.internalGetSerialisedIds(searchAttribute, searchValue);\n\n    const updates = sIds.map((sId) => {\n      const oldSerialised = this.data.get(sId)!;\n      const oldValue = deserialiseRecord(oldSerialised) as T;\n      const newValue = { ...oldValue, ...update };\n      if (newValue.id !== oldValue.id) {\n        throw new Error('Cannot update ID');\n      }\n      const newSerialised = serialiseRecord(newValue);\n      return { oldSerialised, newSerialised };\n    });\n\n    updates.forEach(({ oldSerialised }) => this.internalRemoveIndices(oldSerialised));\n    try {\n      updates.forEach(({ newSerialised }) => this.internalCheckDuplicates(newSerialised, false));\n    } catch (e) {\n      updates.forEach(({ oldSerialised }) => this.internalPopulateIndices(oldSerialised));\n      throw e;\n    }\n    updates.forEach(({ newSerialised }) => {\n      this.data.set(newSerialised.id, newSerialised);\n      this.internalPopulateIndices(newSerialised);\n    });\n  }\n\n  protected async internalGetAll<\n    K extends keyof T & string,\n    F extends readonly (keyof T & string)[]\n  >(\n    searchAttribute?: K,\n    searchValue?: T[K],\n    returnAttributes?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>>[]> {\n    let sIds: string[];\n    if (searchAttribute) {\n      sIds = this.internalGetSerialisedIds(searchAttribute, searchValue!);\n    } else {\n      sIds = [...this.data.keys()];\n    }\n    return sIds.map((sId) => applyFilter(\n      deserialiseRecord(this.data.get(sId)!) as T,\n      returnAttributes,\n    ));\n  }\n\n  protected async internalRemove<K extends keyof T & string>(\n    searchAttribute: K,\n    searchValue: T[K],\n  ): Promise<number> {\n    const sIds = this.internalGetSerialisedIds(searchAttribute, searchValue);\n    sIds.forEach((sId) => {\n      const oldSerialised = this.data.get(sId)!;\n      this.internalRemoveIndices(oldSerialised);\n      this.data.delete(sId);\n    });\n\n    return sIds.length;\n  }\n\n  private internalGetSerialisedIds<K extends keyof T>(\n    searchAttribute: K,\n    searchValue: T[K],\n  ): string[] {\n    const sKey = serialiseValue(searchValue);\n    if (searchAttribute === 'id') {\n      return this.data.has(sKey) ? [sKey] : [];\n    }\n    const index = this.indexData[searchAttribute];\n    if (!index) {\n      throw new Error(`Requested key ${searchAttribute} not indexed`);\n    }\n    const sIds = index.get(sKey);\n    return sIds ? [...sIds] : []; // convert set to array\n  }\n\n  private internalCheckDuplicates(\n    serialisedValue: Record<string, string>,\n    checkId: boolean,\n  ): void {\n    if (checkId && this.data.has(serialisedValue.id)) {\n      throw new Error('duplicate');\n    }\n    this.indices.getCustomIndices().forEach((key) => {\n      const index = this.indexData[key as keyof T]!;\n      if (this.indices.isUniqueIndex(key) && index.has(serialisedValue[key])) {\n        throw new Error('duplicate');\n      }\n    });\n  }\n\n  private internalPopulateIndices(\n    serialisedValue: Record<string, string>,\n  ): void {\n    this.indices.getCustomIndices().forEach((key) => {\n      const index = this.indexData[key as keyof T]!;\n      const v = serialisedValue[key];\n      let o = index.get(v);\n      if (!o) {\n        o = new Set<string>();\n        index.set(v, o);\n      }\n      o.add(serialisedValue.id);\n    });\n  }\n\n  private internalRemoveIndices(\n    serialisedValue: Record<string, string>,\n  ): void {\n    this.indices.getCustomIndices().forEach((key) => {\n      const index = this.indexData[key as keyof T]!;\n      const v = serialisedValue[key];\n      const o = index.get(v)!;\n      o.delete(serialisedValue.id);\n      if (!o.size) {\n        index.delete(v);\n      }\n    });\n  }\n}\n","import type { Collection } from './Collection';\nimport type { IDable } from './IDable';\nimport type { DB, DBKeys } from './DB';\nimport { canonicalJSON } from '../helpers/serialiser';\n\nexport interface StateRef {\n  closed: boolean;\n}\n\ninterface AsyncCollection<T extends IDable> extends Collection<T> {\n  internalReady?: () => Promise<void>;\n}\n\nexport default abstract class BaseDB implements DB {\n  protected readonly stateRef: StateRef = { closed: false };\n\n  private readonly collectionCache = new Map<string, [string, Collection<any>]>();\n\n  constructor(\n    private readonly makeCollection: <T extends IDable>(\n      name: string,\n      keys?: DBKeys<T>,\n    ) => Collection<T>,\n  ) {}\n\n  public getCollection<T extends IDable>(name: string, keys?: DBKeys<T>): Collection<T> {\n    const cached = this.collectionCache.get(name);\n    const normKeys = canonicalJSON(keys);\n    if (cached) {\n      const [cachedNormKeys, cachedCol] = cached;\n      if (normKeys !== cachedNormKeys) {\n        throw new Error(`Cannot requuest collection '${name}' with different keys`);\n      }\n      return cachedCol;\n    }\n    const created = this.makeCollection(name, keys) as AsyncCollection<T>;\n    this.collectionCache.set(name, [normKeys, created]);\n    return created;\n  }\n\n  close(): Promise<void> | void {\n    if (this.stateRef.closed) {\n      return undefined;\n    }\n    this.syncClose();\n    const toAwait = [...this.collectionCache.values()]\n      .map(([, c]) => (c as AsyncCollection<IDable>).internalReady?.());\n    return Promise.allSettled(toAwait).then(() => this.internalClose());\n  }\n\n  protected syncClose(): void {\n    this.stateRef.closed = true;\n  }\n\n  // eslint-disable-next-line class-methods-use-this\n  protected internalClose(): Promise<void> | void {}\n}\n","import { URL } from 'url';\nimport MemoryCollection from './MemoryCollection';\nimport type { DBKeys } from '../interfaces/DB';\nimport type { IDable } from '../interfaces/IDable';\nimport BaseDB from '../interfaces/BaseDB';\n\nfunction getGlobal<T>(name: string, initial: T): T {\n  const existing = (global as any)[name];\n  if (existing) {\n    return existing;\n  }\n\n  (global as any)[name] = initial;\n  return initial;\n}\n\nconst globalDbs = getGlobal(\n  'collectionStorageInMemory',\n  new Map<string, MemoryDb>(),\n);\n\nexport default class MemoryDb extends BaseDB {\n  public constructor({ simulatedLatency = 0 } = {}) {\n    super((name, keys) => new MemoryCollection(keys, simulatedLatency, this.stateRef));\n  }\n\n  public static connect(url: string): MemoryDb {\n    const parsedUrl = new URL(url);\n    const name = parsedUrl.hostname;\n    if (name && globalDbs.has(name)) {\n      return globalDbs.get(name)!;\n    }\n    const params = parsedUrl.searchParams;\n    const simulatedLatency = Number(params.get('simulatedLatency'));\n    const db = new MemoryDb({ simulatedLatency });\n    if (name) {\n      globalDbs.set(name, db);\n    }\n    return db;\n  }\n\n  public getCollection<T extends IDable>(name: string, keys?: DBKeys<T>): MemoryCollection<T> {\n    return super.getCollection(name, keys) as MemoryCollection<T>;\n  }\n\n  public close(): void {\n    this.syncClose();\n  }\n}\n","import type { Db as MongoDbT, MongoClient as MongoClientT } from 'mongodb';\nimport type { DBKeys } from '../interfaces/DB';\nimport BaseDB from '../interfaces/BaseDB';\nimport type { IDable } from '../interfaces/IDable';\nimport type MongoCollectionT from './MongoCollection';\n\nfunction escapeName(name: string): string {\n  return encodeURIComponent(name);\n}\n\nexport default class MongoDb extends BaseDB {\n  private constructor(\n    private readonly client: MongoClientT,\n    MongoCollection: typeof MongoCollectionT,\n  ) {\n    super((name, keys) => new MongoCollection(\n      this.client.db().collection(escapeName(name)),\n      keys,\n      this.stateRef,\n    ));\n  }\n\n  public static async connect(url: string): Promise<MongoDb> {\n    const { MongoClient } = await import('mongodb');\n    const {\n      default: MongoCollection,\n    } = await import(/* webpackMode: \"eager\" */ './MongoCollection');\n    const client = await MongoClient.connect(url, {\n      useNewUrlParser: true,\n      useUnifiedTopology: true,\n    });\n    return new MongoDb(client, MongoCollection);\n  }\n\n  public getCollection<T extends IDable>(name: string, keys?: DBKeys<T>): MongoCollectionT<T> {\n    return super.getCollection(name, keys) as MongoCollectionT<T>;\n  }\n\n  public getDb(): MongoDbT {\n    return this.client.db();\n  }\n\n  protected internalClose(): Promise<void> {\n    return this.client.close();\n  }\n}\n","import type AWS from './AWS';\n\nexport interface Results<I> {\n  batched(consumer: (items: Readonly<I[]>) => (Promise<void> | void)): Promise<void> | void;\n\n  all(): Promise<Readonly<I[]>> | Readonly<I[]>;\n}\n\nexport class Paged<K, I> implements Results<I> {\n  constructor(\n    private readonly aws: AWS,\n    private readonly fn: (start: K | undefined) => Promise<[I[], K]>,\n    private readonly pageLimit = Number.POSITIVE_INFINITY,\n  ) {}\n\n  batched(consumer: (items: I[]) => (Promise<void> | void)): Promise<void> {\n    return this.aws.do(async () => {\n      let lastKey: K | undefined;\n      /* eslint-disable no-await-in-loop */ // pagination must be serial\n      for (let page = 0; page < this.pageLimit; page += 1) {\n        const [pageItems, nextKey]: [I[], K] = await this.fn(lastKey);\n        await consumer(pageItems);\n        lastKey = nextKey;\n        if (!lastKey) {\n          return;\n        }\n      }\n      /* eslint-enable no-await-in-loop */\n      throw new Error('Too many items');\n    });\n  }\n\n  async all(): Promise<I[]> {\n    const items: I[] = [];\n    await this.batched((i) => {\n      items.push(...i);\n    });\n    return items;\n  }\n}\n","// https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Programming.Errors.html\n\nexport default class AWSError extends Error {\n  constructor(\n    private readonly status: number,\n    private readonly type: string,\n    message: string,\n  ) {\n    super(`AWS error ${status}; type: ${type}; message: ${message}`);\n  }\n\n  static isType(e: unknown, type: string): boolean {\n    return (\n      (e instanceof AWSError && e.isType(type)) ||\n      (e instanceof Error && e.message === type)\n    );\n  }\n\n  isType(type: string): boolean {\n    return this.type.endsWith(`#${type}`) || this.type === type;\n  }\n\n  isTransient(): boolean {\n    return (\n      this.status >= 500 ||\n      this.type.endsWith('#LimitExceededException') ||\n      this.type.endsWith('#ProvisionedThroughputExceededException') ||\n      this.type.endsWith('#RequestLimitExceeded') ||\n      this.type.endsWith('#ThrottlingException')\n    );\n  }\n}\n","import type AWS from './AWS';\nimport { Results, Paged } from './Results';\nimport AWSError from './AWSError';\nimport retry from '../../helpers/retry';\n\n// https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/Welcome.html\n\nexport type DDBValue =\n  { S: string } |\n  { N: string } | // number\n  { B: string } | // binary (base64)\n  { BOOL: boolean } |\n  { NULL: true } |\n  { M: Record<string, DDBValue> } |\n  { L: DDBValue[] } |\n  { SS: string[] } | // stringset\n  { NS: string[] } | // numberset\n  { BS: string[] }; // binaryset (base64)\n\nexport type DDBItem = Record<string, DDBValue>;\n\ntype DDBType = 'S' | 'N' | 'B' | 'BOOL' | 'NULL' | 'M' | 'L' | 'SS' | 'NS' | 'BS';\ntype DDBKeyType = 'HASH' | 'RANGE';\n\ninterface DDBConsumedCapacity {\n  CapacityUnits: number;\n}\n\ninterface DDBResponse {\n  ConsumedCapacity?: DDBConsumedCapacity | DDBConsumedCapacity[];\n}\n\ninterface DDBReturnedItem extends DDBResponse {\n  Attributes: DDBItem;\n}\n\ninterface DDBGetResponse extends DDBResponse {\n  Item: DDBItem;\n}\n\ninterface DDBBatchGetResponse extends DDBResponse {\n  Responses: Record<string, DDBItem[]>;\n  UnprocessedKeys: Record<string, {\n    Keys: DDBItem[];\n  }>;\n}\n\ninterface DDBBatchWriteResponse extends DDBResponse {\n  UnprocessedItems: Record<string, {\n    DeleteRequest?: {\n      Key: DDBItem;\n    };\n    PutRequest?: {\n      Item: DDBItem;\n    };\n  }[]>;\n}\n\ninterface DDBListTablesResponse extends DDBResponse {\n  TableNames: string[];\n  LastEvaluatedTableName?: string;\n}\n\ninterface DDBScanResponse extends DDBResponse {\n  Items: DDBItem[];\n  LastEvaluatedKey?: DDBItem;\n}\n\nexport interface DDBProvisionedThroughput {\n  ReadCapacityUnits: number;\n  WriteCapacityUnits: number;\n}\n\ninterface DDBGlobalSecondaryIndex {\n  Backfilling?: boolean;\n  IndexName: string;\n  IndexStatus?: string;\n  KeySchema: {\n    AttributeName: string;\n    KeyType: DDBKeyType;\n  }[];\n  Projection?: {\n    NonKeyAttributes?: string[];\n    ProjectionType: string;\n  };\n  ProvisionedThroughput?: DDBProvisionedThroughput;\n}\n\ninterface DDBAttributeDefinition {\n  AttributeName: string;\n  AttributeType: string;\n}\n\ninterface DDBDescribeResponse extends DDBResponse {\n  Table: {\n    AttributeDefinitions: DDBAttributeDefinition[];\n    GlobalSecondaryIndexes?: DDBGlobalSecondaryIndex[];\n    ItemCount: number;\n    KeySchema: {\n      AttributeName: string;\n      KeyType: DDBKeyType;\n    }[];\n    TableStatus: string;\n    ProvisionedThroughput: DDBProvisionedThroughput;\n  };\n}\n\ninterface KeyDefinition {\n  attributeName: string;\n  attributeType: DDBType;\n  keyType: DDBKeyType;\n}\n\ninterface GlobalSecondaryIndexDefinition {\n  indexName: string;\n  keySchema: KeyDefinition[];\n  projectionType?: 'KEYS_ONLY' | 'INCLUDE' | 'ALL';\n  nonKeyAttributes?: string[];\n  throughput?: DDBProvisionedThroughput;\n}\n\nconst AWS_URL_FORMAT = /^([^:]*):\\/\\/dynamodb\\.([^.]+)\\.amazonaws\\.com(\\/?.*)$/;\nconst ResourceInUseException = 'ResourceInUseException';\nconst ResourceNotFoundException = 'ResourceNotFoundException';\n\nfunction ifNotEmpty<T extends any[] | string>(l: T): T | undefined {\n  return l.length ? l : undefined;\n}\n\nfunction flatten(value: DDBItem, keys: string[]): string {\n  return keys.map((key) => JSON.stringify(value[key])).join();\n}\n\ninterface ExpressionDefinition {\n  attributeExpression: (attr: string, value: string) => string;\n  joiner: string | ((items: string[]) => string);\n  attributes: Readonly<DDBItem | string[]>;\n}\n\nfunction escapedExpressions(\n  expressions: Record<string, ExpressionDefinition>,\n): Record<string, unknown> {\n  let i = 0;\n  const attrValues: DDBItem = {};\n  const attrNames: Record<string, string> = {};\n  let hasExpr = false;\n  let hasAnyValues = false;\n  const result: Record<string, unknown> = {};\n\n  Object.keys(expressions).forEach((key) => {\n    const { attributeExpression, joiner, attributes } = expressions[key];\n\n    const parts: string[] = [];\n    const hasValues = !Array.isArray(attributes);\n    const rawAttrNames = Array.isArray(attributes) ? attributes : Object.keys(attributes);\n    if (!rawAttrNames.length) {\n      return;\n    }\n\n    rawAttrNames.forEach((attr) => {\n      const attrName = `#${i}`;\n      const attrValue = `:${i}`;\n      parts.push(attributeExpression(attrName, attrValue));\n      attrNames[attrName] = attr;\n      if (hasValues) {\n        attrValues[attrValue] = (attributes as DDBItem)[attr];\n      }\n      i += 1;\n    });\n    result[key] = typeof joiner === 'string' ? parts.join(joiner) : joiner(parts);\n    hasAnyValues = hasAnyValues || hasValues;\n    hasExpr = true;\n  });\n\n  if (!hasExpr) {\n    return {};\n  }\n\n  return {\n    ...result,\n    ExpressionAttributeValues: hasAnyValues ? attrValues : undefined,\n    ExpressionAttributeNames: attrNames,\n  };\n}\n\nconst projection = (attrs: readonly string[] | undefined): ExpressionDefinition => ({\n  attributeExpression: (attr): string => attr,\n  joiner: ',',\n  attributes: attrs || [],\n});\n\nconst retryPolling = retry(\n  (e) => (AWSError.isType(e, ResourceNotFoundException) || e.message === 'pending'),\n  { timeoutMillis: 60000, maxDelayMillis: 1000, jitter: false },\n);\nconst retryRemaining = retry(\n  (e) => (e.message === 'remaining unprocessed items'),\n);\n\nconst INVALID_NAME_CHARS = /[^-a-zA-Z0-9_.]/g;\n\nexport function escapeName(name: string): string {\n  // no standard escape scheme conforms to DDB restrictions, so this is home-grown:\n  // (does not attempt to ensure no collisions; more important to allow valid\n  // names through unchanged)\n  return name.replace(INVALID_NAME_CHARS, (c) => {\n    const code = c.charCodeAt(0);\n    const hex = code.toString(16);\n    if (hex.length <= 2) {\n      return `_u${hex.padStart(2, '0')}`;\n    }\n    return `_U${hex.padStart(4, '0')}`;\n  }).padEnd(3, '_');\n}\n\ninterface DDBOptions {\n  consistentRead?: boolean;\n}\n\nfunction createAttributeDefinitions(schemas: KeyDefinition[][]): DDBAttributeDefinition[] {\n  const attrs = new Map<string, DDBType>();\n  schemas.forEach((keys) => keys.forEach(({ attributeName, attributeType }) => {\n    if (!attrs.has(attributeName)) {\n      attrs.set(attributeName, attributeType);\n    } else if (attrs.get(attributeName) !== attributeType) {\n      throw new Error(`inconsistent attribute type for ${attributeName}`);\n    }\n  }));\n  return [...attrs.entries()].map(([attributeName, attributeType]) => ({\n    AttributeName: attributeName,\n    AttributeType: attributeType,\n  }));\n}\n\nfunction createSecondaryIndex(i: GlobalSecondaryIndexDefinition): DDBGlobalSecondaryIndex {\n  return {\n    IndexName: i.indexName,\n    KeySchema: i.keySchema.map(({ attributeName, keyType }) => ({\n      AttributeName: attributeName,\n      KeyType: keyType,\n    })),\n    Projection: {\n      ProjectionType: i.projectionType || (i.nonKeyAttributes ? 'INCLUDE' : 'KEYS_ONLY'),\n      NonKeyAttributes: i.nonKeyAttributes,\n    },\n    ProvisionedThroughput: i.throughput,\n  };\n}\n\nfunction indicesMatch(a: GlobalSecondaryIndexDefinition, b: DDBGlobalSecondaryIndex): boolean {\n  if (a.keySchema.length !== b.KeySchema.length) {\n    return false;\n  }\n  return a.keySchema.every((k, i) => (\n    k.attributeName === b.KeySchema[i].AttributeName &&\n    k.keyType === b.KeySchema[i].KeyType\n  ));\n}\n\nexport class DDB {\n  private readonly region: string;\n\n  private readonly consistentRead: boolean;\n\n  private totalCapacityUnits = 0;\n\n  constructor(\n    private readonly aws: AWS,\n    private readonly host: string,\n    { consistentRead = false }: DDBOptions = {},\n  ) {\n    const parts = AWS_URL_FORMAT.exec(host);\n    if (parts) {\n      [, this.region] = parts;\n    } else {\n      this.region = 'us-east-1'; // default region for API calls\n    }\n    this.consistentRead = consistentRead;\n  }\n\n  getConsumedUnits(): number {\n    return this.totalCapacityUnits;\n  }\n\n  getTableNames(): Results<string> {\n    // https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_ListTables.html\n    return new Paged(this.aws, async (lastTableName) => {\n      const response: DDBListTablesResponse = await this.call('ListTables', {\n        ExclusiveStartTableName: lastTableName,\n      });\n      return [response.TableNames, response.LastEvaluatedTableName];\n    }, 10);\n  }\n\n  upsertTable(\n    tableName: string,\n    pKeySchema: KeyDefinition[],\n    secondaryIndices: GlobalSecondaryIndexDefinition[] = [],\n    waitForReady: boolean,\n    throughput?: DDBProvisionedThroughput,\n  ): Promise<boolean> {\n    // https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_CreateTable.html\n    return this.aws.do(async () => {\n      let created = false;\n      try {\n        await this.call('CreateTable', {\n          TableName: tableName,\n          AttributeDefinitions: createAttributeDefinitions([\n            pKeySchema,\n            ...secondaryIndices.map(({ keySchema }) => keySchema),\n          ]),\n          KeySchema: pKeySchema.map(({ attributeName, keyType }) => ({\n            AttributeName: attributeName,\n            KeyType: keyType,\n          })),\n          GlobalSecondaryIndexes: ifNotEmpty(secondaryIndices.map(\n            (i) => createSecondaryIndex(i),\n          )),\n          BillingMode: throughput ? 'PROVISIONED' : 'PAY_PER_REQUEST',\n          ProvisionedThroughput: throughput,\n        });\n        created = true;\n      } catch (e) {\n        if (AWSError.isType(e, ResourceInUseException)) {\n          await this.replaceIndices(tableName, secondaryIndices);\n        } else {\n          throw e;\n        }\n      }\n\n      if (waitForReady) {\n        await this.waitForTable(tableName, true);\n      }\n\n      return created;\n    });\n  }\n\n  describeTable(tableName: string): Promise<DDBDescribeResponse> {\n    // https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_DescribeTable.html\n    return this.call('DescribeTable', { TableName: tableName });\n  }\n\n  waitForTable(tableName: string, waitForIndices: boolean): Promise<void> {\n    return retryPolling(async () => {\n      const desc = await this.describeTable(tableName);\n      if (desc.Table.TableStatus !== 'ACTIVE') {\n        throw new Error('pending');\n      }\n      const indices = desc.Table.GlobalSecondaryIndexes;\n      if (waitForIndices && indices && indices.some((i) => (i.IndexStatus !== 'ACTIVE'))) {\n        throw new Error('pending');\n      }\n    });\n  }\n\n  async deleteTable(tableName: string): Promise<void> {\n    // https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_DeleteTable.html\n    await this.call('DeleteTable', { TableName: tableName });\n  }\n\n  async putItem(tableName: string, item: DDBItem, unique?: string): Promise<void> {\n    // https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_PutItem.html\n    await this.call('PutItem', {\n      TableName: tableName,\n      Item: item,\n      ...escapedExpressions({\n        ConditionExpression: {\n          attributeExpression: (attr): string => `attribute_not_exists(${attr})`,\n          joiner: ' and ',\n          attributes: unique ? [unique] : [],\n        },\n      }),\n      ReturnConsumedCapacity: 'TOTAL',\n    });\n  }\n\n  async updateItem(\n    tableName: string,\n    key: DDBItem,\n    update: DDBItem,\n    condition?: DDBItem,\n  ): Promise<void> {\n    // https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_UpdateItem.html\n    await this.call('UpdateItem', {\n      TableName: tableName,\n      Key: key,\n      ...escapedExpressions({\n        UpdateExpression: {\n          attributeExpression: (attr, value): string => `${attr}=${value}`,\n          joiner: (l): string => `SET ${l.join(',')}`,\n          attributes: update,\n        },\n        ConditionExpression: {\n          attributeExpression: (attr, value): string => `${attr}=${value}`,\n          joiner: ' and ',\n          attributes: condition || {},\n        },\n      }),\n      ReturnConsumedCapacity: 'TOTAL',\n    });\n  }\n\n  async getItem(\n    tableName: string,\n    key: DDBItem,\n    requestedAttrs?: readonly string[],\n  ): Promise<DDBItem | null> {\n    // https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_GetItem.html\n    const data: DDBGetResponse = await this.call('GetItem', {\n      TableName: tableName,\n      Key: key,\n      ...escapedExpressions({ ProjectionExpression: projection(requestedAttrs) }),\n      ConsistentRead: this.consistentRead,\n      ReturnConsumedCapacity: 'TOTAL',\n    });\n\n    // DDB is inconsistent in how it returns 'not found' state:\n    if (!data.Item || !Object.keys(data.Item).length) {\n      return null;\n    }\n    return data.Item;\n  }\n\n  async batchGetItems(\n    tableName: string,\n    keys: DDBItem[],\n    requestedAttrs?: readonly string[],\n  ): Promise<(DDBItem | null)[]> {\n    // https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_BatchGetItem.html\n    if (!keys.length) {\n      return [];\n    }\n    if (keys.length === 1) {\n      return [await this.getItem(tableName, keys[0], requestedAttrs)];\n    }\n\n    const keyAttrs = Object.keys(keys[0]);\n    const fullAttrs = requestedAttrs?.slice();\n    if (fullAttrs) {\n      keyAttrs.forEach((k) => {\n        if (!fullAttrs.includes(k)) {\n          fullAttrs.push(k);\n        }\n      });\n    }\n\n    const indices = new Map<string, number>();\n    keys.forEach((key, i) => indices.set(flatten(key, keyAttrs), i));\n\n    const extracted: (DDBItem | null)[] = keys.map(() => null);\n    const tableQuery = {\n      ...escapedExpressions({ ProjectionExpression: projection(fullAttrs) }),\n      ConsistentRead: this.consistentRead,\n    };\n\n    await this.callBatched(keys, 100, async (batchKeys) => {\n      const data: DDBBatchGetResponse = await this.call('BatchGetItem', {\n        RequestItems: {\n          [tableName]: {\n            ...tableQuery,\n            Keys: batchKeys,\n          },\n        },\n        ReturnConsumedCapacity: 'TOTAL',\n      });\n      data.Responses[tableName].forEach((item) => {\n        const index = indices.get(flatten(item, keyAttrs));\n        if (index !== undefined) {\n          extracted[index] = item;\n        }\n      });\n      return data.UnprocessedKeys[tableName]?.Keys || [];\n    });\n\n    return extracted;\n  }\n\n  batchPutItems(tableName: string, items: DDBItem[]): Promise<void> {\n    // https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_BatchWriteItem.html\n    return this.callBatched(items, 25, async (batchItems) => {\n      const data: DDBBatchWriteResponse = await this.call('BatchWriteItem', {\n        RequestItems: {\n          [tableName]: batchItems.map((item) => ({ PutRequest: { Item: item } })),\n        },\n        ReturnConsumedCapacity: 'TOTAL',\n      });\n      return (data.UnprocessedItems[tableName] || []).map((i) => i.PutRequest!.Item);\n    });\n  }\n\n  batchDeleteItems(tableName: string, keys: DDBItem[]): Promise<void> {\n    // https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_BatchWriteItem.html\n    return this.callBatched(keys, 25, async (batchKeys) => {\n      const data: DDBBatchWriteResponse = await this.call('BatchWriteItem', {\n        RequestItems: {\n          [tableName]: batchKeys.map((key) => ({ DeleteRequest: { Key: key } })),\n        },\n        ReturnConsumedCapacity: 'TOTAL',\n      });\n      return (data.UnprocessedItems[tableName] || []).map((i) => i.DeleteRequest!.Key);\n    });\n  }\n\n  getAllItems(tableName: string, requestedAttrs?: readonly string[]): Results<DDBItem> {\n    // https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_Scan.html\n    const query = {\n      TableName: tableName,\n      ...escapedExpressions({ ProjectionExpression: projection(requestedAttrs) }),\n      ConsistentRead: this.consistentRead,\n      ReturnConsumedCapacity: 'TOTAL',\n    };\n    return new Paged(this.aws, async (lastKey) => {\n      const response: DDBScanResponse = await this.call('Scan', {\n        ...query,\n        ExclusiveStartKey: lastKey,\n      });\n      return [response.Items, response.LastEvaluatedKey];\n    });\n  }\n\n  async getItemsBySecondaryKey(\n    tableName: string,\n    indexName: string,\n    key: DDBItem,\n    requestedAttrs: readonly string[] | undefined,\n    limitOne: boolean,\n  ): Promise<DDBItem[]> {\n    // https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_Query.html\n    const colocatedAttrs = ['id'];\n    const nonColocatedAttrs: string[] = [];\n    (requestedAttrs || []).forEach((attr) => {\n      if (attr !== 'id') {\n        if (Object.hasOwnProperty.call(key, attr)) {\n          colocatedAttrs.push(attr);\n        } else {\n          nonColocatedAttrs.push(attr);\n        }\n      }\n    });\n    const query = {\n      TableName: tableName,\n      IndexName: indexName,\n      ...escapedExpressions({\n        KeyConditionExpression: {\n          attributeExpression: (attr, value): string => `${attr}=${value}`,\n          joiner: ' and ',\n          attributes: key,\n        },\n        ProjectionExpression: projection(colocatedAttrs),\n      }),\n      ConsistentRead: false, // cannot be true for Global Secondary Index\n      ReturnConsumedCapacity: 'TOTAL',\n    };\n    let items: DDBItem[];\n    if (limitOne) {\n      const response: DDBScanResponse = await this.call('Query', {\n        ...query,\n        Limit: 1,\n      });\n      items = response.Items;\n    } else {\n      items = await new Paged(this.aws, async (lastKey) => {\n        const response: DDBScanResponse = await this.call('Query', {\n          ...query,\n          ExclusiveStartKey: lastKey,\n        });\n        return [response.Items, response.LastEvaluatedKey];\n      }).all();\n    }\n\n    if (!items.length || (requestedAttrs && !nonColocatedAttrs.length)) {\n      return items;\n    }\n\n    const pkItems = await this.batchGetItems(\n      tableName,\n      items.map(({ id }) => ({ id })),\n      ifNotEmpty(nonColocatedAttrs),\n    );\n    return items\n      .map((item, i) => (pkItems[i] ? ({ ...item, ...pkItems[i] }) : null))\n      .filter((item) => item) as DDBItem[];\n  }\n\n  async deleteItem(tableName: string, key: DDBItem): Promise<void> {\n    await this.callDelete(tableName, key, false);\n  }\n\n  deleteAndReturnItem(tableName: string, key: DDBItem): Promise<DDBItem> {\n    return this.callDelete(tableName, key, true);\n  }\n\n  private async callDelete(tableName: string, key: DDBItem, returnOld: boolean): Promise<DDBItem> {\n    // https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_DeleteItem.html\n    const response: DDBReturnedItem = await this.call('DeleteItem', {\n      TableName: tableName,\n      Key: key,\n      ...escapedExpressions({\n        ConditionExpression: {\n          attributeExpression: (attr): string => `attribute_exists(${attr})`,\n          joiner: ' and ',\n          attributes: [Object.keys(key)[0]],\n        },\n      }),\n      ReturnConsumedCapacity: 'TOTAL',\n      ReturnValues: returnOld ? 'ALL_OLD' : undefined,\n    });\n    return response.Attributes;\n  }\n\n  private async replaceIndices(\n    tableName: string,\n    secondaryIndices: GlobalSecondaryIndexDefinition[] = [],\n  ): Promise<void> {\n    // https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_UpdateTable.html\n    const existing = await this.describeTable(tableName);\n    const indices = new Map<string, DDBGlobalSecondaryIndex>();\n    const toCreate: GlobalSecondaryIndexDefinition[] = [];\n    const oldIndices = existing.Table.GlobalSecondaryIndexes || [];\n    for (let i = 0; i < oldIndices.length; i += 1) {\n      const idx = oldIndices[i];\n      indices.set(idx.IndexName, idx);\n    }\n    for (let i = 0; i < secondaryIndices.length; i += 1) {\n      const idx = secondaryIndices[i];\n      const old = indices.get(idx.indexName);\n      if (old) {\n        if (!indicesMatch(idx, old)) {\n          throw new Error(`Cannot change existing index definition ${idx.indexName}`);\n        }\n        indices.delete(idx.indexName);\n      } else {\n        toCreate.push(idx);\n      }\n    }\n    const toDelete = [...indices.keys()];\n    /* eslint-disable no-await-in-loop */ // index creation and deletion must be serial\n    for (let i = 0; i < toDelete.length; i += 1) {\n      await this.call('UpdateTable', {\n        TableName: tableName,\n        GlobalSecondaryIndexUpdates: [{\n          Delete: { IndexName: toDelete[i] },\n        }],\n      });\n      // must wait for table to be ACTIVE before next update can be applied\n      await this.waitForTable(tableName, false);\n    }\n    for (let i = 0; i < toCreate.length; i += 1) {\n      await this.call('UpdateTable', {\n        TableName: tableName,\n        AttributeDefinitions: createAttributeDefinitions([toCreate[i].keySchema]),\n        GlobalSecondaryIndexUpdates: [{ Create: createSecondaryIndex(toCreate[i]) }],\n      });\n      // must wait for table to be ACTIVE before next update can be applied\n      await this.waitForTable(tableName, false);\n    }\n    /* eslint-enable no-await-in-loop */\n  }\n\n  private callBatched<T>(\n    items: T[],\n    batchLimit: number,\n    fn: (batchItems: T[]) => Promise<T[]>,\n  ): Promise<void> {\n    const remaining = items.slice();\n    return this.aws.do(() => retryRemaining(async () => {\n      const queue = remaining.slice();\n      remaining.length = 0;\n      while (queue.length) {\n        const batchItems = queue.splice(0, batchLimit);\n\n        /* eslint-disable-next-line no-await-in-loop */ // no benefit from parallelism\n        const retryItems = await fn(batchItems);\n        remaining.push(...retryItems);\n      }\n      if (remaining.length) {\n        throw new Error('remaining unprocessed items');\n      }\n    }));\n  }\n\n  private async call<T extends DDBResponse = DDBResponse>(\n    fnName: string,\n    body?: string | Record<string, unknown> | Buffer,\n  ): Promise<T> {\n    const response = await this.aws.request({\n      method: 'POST',\n      url: this.host,\n      region: this.region,\n      service: 'dynamodb',\n      headers: {\n        'Content-Type': 'application/x-amz-json-1.0',\n        'X-Amz-Target': `DynamoDB_20120810.${fnName}`,\n      },\n      body,\n    });\n    // DynamoDB does not include read/write capacity usage for errors, though\n    // they can consume capacity.\n    // https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/WorkingWithItems.html#WorkingWithItems.ConditionalWrites.ReturnConsumedCapacity\n\n    const data = response.json as T;\n    if (data.ConsumedCapacity) {\n      let capacity;\n      if (Array.isArray(data.ConsumedCapacity)) {\n        capacity = data.ConsumedCapacity.reduce((t, c) => (t + Number(c.CapacityUnits)), 0);\n      } else {\n        capacity = Number(data.ConsumedCapacity.CapacityUnits);\n      }\n      this.totalCapacityUnits += capacity;\n    }\n    return data;\n  }\n}\n","import {\n  DDB,\n  DDBItem,\n  DDBValue,\n  escapeName,\n  DDBProvisionedThroughput,\n} from './api/DDB';\nimport AWSError from './api/AWSError';\nimport type { IDable } from '../interfaces/IDable';\nimport BaseCollection from '../interfaces/BaseCollection';\nimport type { DBKeys } from '../interfaces/DB';\nimport { serialiseValueBin, deserialiseValueBin } from '../helpers/serialiser';\n\nconst ConditionalCheckFailedException = 'ConditionalCheckFailedException';\n\nasync function runAll<T>(\n  values: T[],\n  successesOut: T[],\n  fn: (value: T) => Promise<void>,\n): Promise<void> {\n  const results = await Promise.allSettled(values.map(async (value) => {\n    await fn(value);\n    successesOut.push(value);\n  }));\n  const failures = results.filter((s) => s.status === 'rejected') as PromiseRejectedResult[];\n  if (failures.length) {\n    throw failures[0];\n  }\n}\n\nfunction wrapError(type: string, message: string): (e: unknown) => void {\n  return (e): void => {\n    throw AWSError.isType(e, type) ? new Error(message) : e;\n  };\n}\n\nfunction handleError<T>(\n  type: string,\n  fn: () => Promise<T> | T,\n): (e: unknown) => Promise<T> | T {\n  return (e): (Promise<T> | T) => {\n    if (AWSError.isType(e, type)) {\n      return fn();\n    }\n    throw e;\n  };\n}\n\nconst ignore = (): void => {};\n\nfunction toDynamoValue(value: unknown): DDBValue {\n  // all values must be binary, because keys must be defined\n  // in advance before we know what type of data will be stored\n  // and any column could be a key (or become one in the future)\n  const bin = serialiseValueBin(value);\n  return { B: bin.toString('base64') };\n}\n\nfunction toDynamoItem(value: Record<string, unknown>): DDBItem {\n  const result: DDBItem = {};\n  Object.keys(value).forEach((key) => {\n    result[key] = toDynamoValue(value[key]);\n  });\n  return result;\n}\n\nfunction isDynamoBinary(value: DDBValue): value is { B: string } {\n  return Object.hasOwnProperty.call(value, 'B');\n}\n\nfunction isDynamoStringSet(value: DDBValue): value is { SS: string[] } {\n  return Object.hasOwnProperty.call(value, 'SS');\n}\n\nfunction fromDynamoValue(value: DDBValue): unknown {\n  if (isDynamoBinary(value)) {\n    return deserialiseValueBin(Buffer.from(value.B, 'base64'));\n  }\n  throw new Error('unexpected value type from DDB');\n}\n\nfunction fromDynamoItem<T = Record<string, unknown>>(value: DDBItem): T;\nfunction fromDynamoItem<T = Record<string, unknown>>(value: DDBItem | null | undefined): T | null;\n\nfunction fromDynamoItem<T = Record<string, unknown>>(value: DDBItem | null | undefined): T | null {\n  if (!value) {\n    return null;\n  }\n  const result: Record<string, unknown> = {};\n  Object.keys(value).forEach((key) => {\n    result[key] = fromDynamoValue(value[key]);\n  });\n  return result as T;\n}\n\nfunction toDynamoKey(attr: string, value: DDBValue): DDBValue {\n  if (!isDynamoBinary(value)) {\n    throw new Error('unexpected value type from DDB');\n  }\n  return {\n    B: Buffer.concat([\n      Buffer.from(`${attr}:`, 'utf8'),\n      Buffer.from(value.B, 'base64'),\n    ]).toString('base64'),\n  };\n}\n\nconst INDEX_META_KEY = { B: Buffer.from(':').toString('base64') };\n\nconst indexTable = (tableName: string): string => `${tableName}.`;\n\nexport interface Throughput {\n  read: number;\n  write: number;\n}\n\ntype CollectionThroughputFn = (indexName: string | null) => Throughput | null | undefined;\n\nfunction toDDBThroughput(\n  throughput: Throughput | null | undefined,\n): DDBProvisionedThroughput | undefined {\n  if (!throughput) {\n    return undefined;\n  }\n  return {\n    ReadCapacityUnits: Math.max(1, Math.ceil(throughput.read)),\n    WriteCapacityUnits: Math.max(1, Math.ceil(throughput.write)),\n  };\n}\n\nfunction getCombinedThroughput(\n  keys: string[],\n  throughputFn?: CollectionThroughputFn,\n): Throughput | null {\n  const totalThroughput = { read: 0, write: 0 };\n  let hasThroughput = false;\n  keys.forEach((attr) => {\n    const cur = throughputFn?.(attr);\n    if (cur) {\n      hasThroughput = true;\n      totalThroughput.read += cur.read;\n      totalThroughput.write += cur.write;\n    }\n  });\n  return hasThroughput ? totalThroughput : null;\n}\n\nasync function configureTable(\n  ddb: DDB,\n  tableName: string,\n  nonuniqueKeys: string[],\n  uniqueKeys: string[],\n  throughputFn?: CollectionThroughputFn,\n): Promise<void> {\n  const indexTableName = indexTable(tableName);\n\n  const [created] = await Promise.all<boolean, unknown>([\n    ddb.upsertTable(\n      tableName,\n      [{ attributeName: 'id', attributeType: 'B', keyType: 'HASH' }],\n      nonuniqueKeys.map((attr) => ({\n        indexName: escapeName(attr),\n        keySchema: [{ attributeName: attr, attributeType: 'B', keyType: 'HASH' }],\n        throughput: toDDBThroughput(throughputFn?.(attr)),\n      })),\n      true,\n      toDDBThroughput(throughputFn?.(null)),\n    ),\n    uniqueKeys.length ? ddb.upsertTable(\n      indexTableName,\n      [{ attributeName: 'ix', attributeType: 'B', keyType: 'HASH' }],\n      [],\n      true,\n      toDDBThroughput(getCombinedThroughput(uniqueKeys, throughputFn)),\n    ) : ddb.deleteTable(indexTableName).catch(ignore),\n  ]);\n\n  if (created || !uniqueKeys.length) {\n    return;\n  }\n\n  // table already existed; might need to migrate old data for unique indices\n  const info = await ddb.getItem(indexTableName, { ix: INDEX_META_KEY }, ['unique']);\n  const newKeys = new Set(uniqueKeys);\n  const oldKeys: string[] = [];\n  if (info && isDynamoStringSet(info.unique)) {\n    oldKeys.push(...info.unique.SS.filter((item) => !newKeys.delete(item)));\n  }\n  if (newKeys.size) {\n    // we have new keys which must be populated\n    const attrs = [...newKeys];\n    await ddb.getAllItems(tableName, ['id', ...attrs]).batched(async (items) => {\n      const indexItems: DDBItem[] = [];\n      items.forEach((item) => attrs.forEach((attr) => {\n        indexItems.push({ ix: toDynamoKey(attr, item[attr]), id: item.id });\n      }));\n      return ddb.batchPutItems(indexTableName, indexItems);\n    });\n  } else if (!oldKeys.length) {\n    return; // no change\n  }\n  // do not delete old items; storing them is relatively\n  // cheap compared to scanning and deleting them\n\n  // update stored info about indices\n  await ddb.putItem(indexTableName, { ix: INDEX_META_KEY, unique: { SS: uniqueKeys } });\n}\n\nexport default class DynamoCollection<T extends IDable> extends BaseCollection<T> {\n  private readonly uniqueKeys: (keyof T & string)[] = [];\n\n  public constructor(\n    private readonly ddb: DDB,\n    private readonly tableName: string,\n    keys: DBKeys<T> = {},\n    throughputFn?: CollectionThroughputFn,\n  ) {\n    super(keys);\n\n    const nonuniqueKeys: (keyof T & string)[] = [];\n    Object.entries(keys).forEach(([key, options]) => {\n      if (options?.unique) {\n        this.uniqueKeys.push(key as (keyof T & string));\n      } else {\n        nonuniqueKeys.push(key as (keyof T & string));\n      }\n    });\n\n    this.initAsync(configureTable(\n      ddb,\n      tableName,\n      nonuniqueKeys,\n      this.uniqueKeys,\n      throughputFn,\n    ));\n  }\n\n  get internalTableName(): string {\n    return this.tableName;\n  }\n\n  get internalIndexTableName(): string {\n    return indexTable(this.tableName);\n  }\n\n  protected internalAdd(value: T): Promise<void> {\n    return this.putItem(toDynamoItem(value as any));\n  }\n\n  protected internalUpsert(\n    id: T['id'],\n    update: Partial<T>,\n  ): Promise<void> {\n    const item = toDynamoItem({ id, ...update });\n    const { id: itemId, ...itemNoKey } = item;\n    const key = { id: itemId };\n\n    // optimistically try to update\n    return this.updateItem(key, itemNoKey, key).catch(handleError(\n      ConditionalCheckFailedException,\n\n      // if that fails due to the item not existing, try creating it\n      () => this.putItem(item).catch(handleError(\n        'duplicate id',\n\n        // it that fails due to the item existing, the item was probably\n        // created in the gap between calls; update it\n        () => this.updateItem(key, itemNoKey, key).catch(wrapError(\n          ConditionalCheckFailedException,\n\n          // if it fails again, give up\n          'Failed to upsert item',\n        )),\n      )),\n    ));\n  }\n\n  protected async internalUpdate<K extends keyof T & string>(\n    searchAttribute: K,\n    searchValue: T[K],\n    { id: _, ...update }: Partial<T>,\n  ): Promise<void> {\n    if (searchAttribute === 'id') {\n      await this.updateItem(\n        toDynamoItem({ id: searchValue }),\n        toDynamoItem(update),\n      ).catch(handleError(ConditionalCheckFailedException, ignore));\n    } else {\n      const items = await this.internalGetAll(searchAttribute, searchValue, ['id']);\n      await Promise.all(items.map(({ id }) => this.updateItem(\n        toDynamoItem({ id }),\n        toDynamoItem(update),\n        toDynamoItem({ [searchAttribute]: searchValue }),\n      ).catch(handleError(ConditionalCheckFailedException, ignore))));\n    }\n  }\n\n  protected async internalGet<\n    K extends keyof T & string,\n    F extends readonly (keyof T & string)[]\n  >(\n    searchAttribute: K,\n    searchValue: T[K],\n    returnAttributes?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>> | null> {\n    if (searchAttribute === 'id') {\n      return fromDynamoItem<Pick<T, F[-1]>>(await this.ddb.getItem(\n        this.tableName,\n        toDynamoItem({ id: searchValue }),\n        returnAttributes,\n      ));\n    }\n\n    if (!this.indices.isUniqueIndex(searchAttribute)) {\n      const ddbItems = await this.ddb.getItemsBySecondaryKey(\n        this.tableName,\n        escapeName(searchAttribute),\n        toDynamoItem({ [searchAttribute]: searchValue }),\n        returnAttributes,\n        true,\n      );\n      return fromDynamoItem<Pick<T, F[-1]>>(ddbItems[0]);\n    }\n\n    const ddbSearchValue = toDynamoValue(searchValue);\n    const key = await this.ddb.getItem(\n      indexTable(this.tableName),\n      { ix: toDynamoKey(searchAttribute, ddbSearchValue) },\n      ['id'],\n    );\n    if (!key) {\n      return null;\n    }\n    if (!returnAttributes) {\n      return fromDynamoItem<Pick<T, F[-1]>>(await this.ddb.getItem(this.tableName, key));\n    }\n    const ddbItem: DDBItem = {};\n    const filteredReturn = new Set(returnAttributes);\n    if (filteredReturn.delete('id')) {\n      Object.assign(ddbItem, key);\n    }\n    if (filteredReturn.delete(searchAttribute)) {\n      ddbItem[searchAttribute] = ddbSearchValue;\n    }\n    if (filteredReturn.size) {\n      const primaryItem = await this.ddb.getItem(this.tableName, key, [...filteredReturn]);\n      if (!primaryItem) {\n        // index and main table are out of sync;\n        // assume main table is correct and item does not exist\n        return null;\n      }\n      Object.assign(ddbItem, primaryItem);\n    }\n    return fromDynamoItem<Pick<T, F[-1]>>(ddbItem);\n  }\n\n  protected async internalGetAll<\n    K extends keyof T & string,\n    F extends readonly (keyof T & string)[]\n  >(\n    searchAttribute?: K,\n    searchValue?: T[K],\n    returnAttributes?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>>[]> {\n    if (!searchAttribute) {\n      const items = await this.ddb.getAllItems(this.tableName, returnAttributes).all();\n      return items.map(fromDynamoItem) as Pick<T, F[-1]>[];\n    }\n    if (this.indices.isUniqueIndex(searchAttribute)) {\n      const item = await this.internalGet(searchAttribute, searchValue!, returnAttributes);\n      return item ? [item] : [];\n    }\n    const items = await this.ddb.getItemsBySecondaryKey(\n      this.tableName,\n      escapeName(searchAttribute),\n      toDynamoItem({ [searchAttribute]: searchValue }),\n      returnAttributes,\n      false,\n    );\n    return items.map(fromDynamoItem) as Pick<T, F[-1]>[];\n  }\n\n  protected async internalRemove<K extends keyof T & string>(\n    searchAttribute: K,\n    searchValue: T[K],\n  ): Promise<number> {\n    if (searchAttribute === 'id') {\n      const success = await this.deleteItem(toDynamoItem({ id: searchValue }));\n      return success ? 1 : 0;\n    }\n    const items = await this.internalGetAll(searchAttribute, searchValue, ['id']);\n    const successes = await Promise.all(items.map(({ id }) => this.deleteItem(\n      toDynamoItem({ id }),\n    )));\n    return successes.filter((success) => success).length;\n  }\n\n  private async atomicPutUniques(\n    id: DDBValue,\n    item: DDBItem,\n    uniqueKeys: (keyof T & string)[],\n    fn: () => Promise<void>,\n  ): Promise<void> {\n    if (!uniqueKeys.length) {\n      await fn();\n      return;\n    }\n\n    const indexTableName = indexTable(this.tableName);\n    const successes: string[] = [];\n    try {\n      await runAll(uniqueKeys, successes, (attr) => this.ddb.putItem(\n        indexTableName,\n        { ix: toDynamoKey(attr, item[attr]), id },\n        'ix',\n      ).catch(wrapError(ConditionalCheckFailedException, `duplicate ${attr}`)));\n      await fn();\n    } catch (e) {\n      await this.ddb.batchDeleteItems(\n        indexTableName,\n        successes.map((attr) => ({ ix: toDynamoKey(attr, item[attr]) })),\n      ).catch(ignore); // best effort to reset state, but ignore errors here\n      throw e;\n    }\n  }\n\n  private async putItem(item: DDBItem): Promise<void> {\n    return this.atomicPutUniques(\n      item.id,\n      item,\n      this.uniqueKeys,\n      () => this.ddb.putItem(\n        this.tableName,\n        item,\n        'id',\n      ).catch(wrapError(ConditionalCheckFailedException, 'duplicate id')),\n    );\n  }\n\n  private async updateItem(key: DDBItem, update: DDBItem, condition?: DDBItem): Promise<void> {\n    const updatedUnique = this.uniqueKeys.filter((a) => Object.hasOwnProperty.call(update, a));\n    if (!updatedUnique.length) {\n      await this.ddb.updateItem(this.tableName, key, update, condition);\n      return;\n    }\n    const old = await this.ddb.getItem(this.tableName, key, updatedUnique);\n    if (!old) {\n      throw new AWSError(400, ConditionalCheckFailedException, 'could not find item to update');\n    }\n    const changedAttrs = updatedUnique.filter((a) => (old[a] as any).B !== (update[a] as any).B);\n    await this.atomicPutUniques(\n      key.id,\n      update,\n      changedAttrs,\n      () => this.ddb.updateItem(this.tableName, key, update, { ...old, ...condition }),\n    );\n    await this.ddb.batchDeleteItems(\n      indexTable(this.tableName),\n      changedAttrs.map((attr) => ({ ix: toDynamoKey(attr, old[attr]) })),\n    );\n  }\n\n  private async deleteItem(key: DDBItem): Promise<boolean> {\n    try {\n      if (!this.uniqueKeys.length) {\n        await this.ddb.deleteItem(this.tableName, key);\n      } else {\n        const item = await this.ddb.deleteAndReturnItem(this.tableName, key);\n        await this.ddb.batchDeleteItems(\n          indexTable(this.tableName),\n          this.uniqueKeys.map((attr) => ({ ix: toDynamoKey(attr, item[attr]) })),\n        );\n      }\n      return true;\n    } catch (e) {\n      if (AWSError.isType(e, ConditionalCheckFailedException)) {\n        return false;\n      }\n      throw e;\n    }\n  }\n}\n","export default class PromiseTracker {\n  private readonly inflight = new Set<Promise<any>>();\n\n  do<T>(fn: () => Promise<T>): Promise<T> {\n    let flightResolve = (): void => {};\n    const flight = new Promise((resolve) => {\n      flightResolve = resolve;\n    }).then(() => {\n      this.inflight.delete(flight);\n    });\n    this.inflight.add(flight);\n    return fn().finally(flightResolve);\n  }\n\n  async wait(): Promise<void> {\n    const current = [...this.inflight];\n    this.inflight.clear();\n    await Promise.allSettled(current);\n  }\n}\n","const always = (): boolean => true;\n\nexport default class LruCache<K, V> {\n  private readonly storage = new Map<K, V>();\n\n  public constructor(\n    private readonly capacity: number,\n    private readonly flushFn?: (value: V) => void,\n  ) {}\n\n  public cached(\n    key: K,\n    calc: (key: K) => V,\n    fresh: (value: V) => boolean = always,\n  ): V {\n    const value = this.storage.get(key);\n    if (this.storage.delete(key)) {\n      if (fresh(value!)) {\n        this.storage.set(key, value!);\n        return value!;\n      }\n      this.flushFn?.(value!);\n    }\n    const created = calc(key);\n    this.internalAdd(key, created);\n    return created;\n  }\n\n  public async cachedAsync(\n    key: K,\n    calc: (key: K) => Promise<V>,\n    fresh: (value: V) => boolean = always,\n  ): Promise<V> {\n    const value = this.storage.get(key);\n    if (this.storage.delete(key)) {\n      if (fresh(value!)) {\n        this.storage.set(key, value!);\n        return value!;\n      }\n      this.flushFn?.(value!);\n    }\n    const created = await calc(key);\n    this.internalAdd(key, created);\n    return created;\n  }\n\n  public add(key: K, value: V): void {\n    this.remove(key);\n    this.internalAdd(key, value);\n  }\n\n  public peek(key: K): V | undefined {\n    return this.storage.get(key);\n  }\n\n  public remove(key: K): void {\n    if (this.flushFn) {\n      const value = this.storage.get(key);\n      if (this.storage.delete(key)) {\n        this.flushFn(value!);\n      }\n    } else {\n      this.storage.delete(key);\n    }\n  }\n\n  public clear(): void {\n    this.storage.clear();\n  }\n\n  private internalAdd(key: K, value: V): void {\n    this.storage.set(key, value);\n\n    while (this.storage.size > this.capacity) {\n      this.remove(this.storage.keys().next().value);\n    }\n  }\n}\n","import { createHash, createHmac } from 'crypto';\nimport https from 'https';\nimport http from 'http';\nimport AWSError from './AWSError';\nimport PromiseTracker from '../../helpers/PromiseTracker';\nimport LruCache from '../../helpers/LruCache';\nimport retry from '../../helpers/retry';\n\ntype Method = 'OPTIONS' | 'GET' | 'HEAD' | 'POST' | 'PUT' | 'DELETE';\n\nconst EMPTY_BUFFER = Buffer.alloc(0);\nconst ISO_TIME_STRIP = /(-|:|\\.[0-9]*)/g;\nconst ALGORITHM = 'AWS4-HMAC-SHA256';\n\nconst withTransientErrorRetry = retry((e) => (!(e instanceof AWSError) || e.isTransient()));\n\nfunction sha256(v: Buffer): string {\n  const hash = createHash('sha256');\n  hash.update(v);\n  return hash.digest('hex');\n}\n\nfunction hmac(key: Buffer, data: string): Buffer {\n  const hash = createHmac('sha256', key);\n  hash.update(data, 'utf8');\n  return hash.digest();\n}\n\ninterface RequestOptions {\n  method: Method;\n  url: URL | string;\n  region: string;\n  service: string;\n  headers?: Record<string, string>;\n  body?: string | Record<string, unknown> | Buffer;\n  date?: Date;\n}\n\ninterface FetchResponse {\n  status: number;\n  json: unknown;\n}\n\ninterface AWSErrorResponse {\n  __type: string;\n  message: string;\n}\n\nexport default class AWS {\n  private readonly baseKey: Buffer;\n\n  private readonly keyCacheDate = new LruCache<string, Buffer>(1);\n\n  private readonly keyCacheRegion = new LruCache<string, Buffer>(4);\n\n  private readonly keyCache = new LruCache<string, Buffer>(16);\n\n  private readonly inflight = new PromiseTracker();\n\n  private closed = false;\n\n  constructor(private readonly keyID: string, secret: string) {\n    this.baseKey = Buffer.from(`AWS4${secret}`, 'utf8');\n  }\n\n  do<T>(fn: () => Promise<T>): Promise<T> {\n    return this.inflight.do(fn);\n  }\n\n  request({\n    method,\n    url,\n    region,\n    service,\n    headers = {},\n    body = EMPTY_BUFFER,\n    date = new Date(),\n  }: RequestOptions): Promise<FetchResponse> {\n    // https://docs.aws.amazon.com/general/latest/gr/sigv4-create-canonical-request.html\n\n    const parsedURL = (url instanceof URL) ? url : new URL(url);\n    if (parsedURL.search) {\n      throw new Error('AWS urls with query strings are not supported');\n    }\n    if (this.closed) {\n      throw new Error('connection closed');\n    }\n\n    let binaryBody: Buffer;\n    if (body instanceof Buffer) {\n      binaryBody = body;\n    } else if (typeof body === 'string') {\n      binaryBody = Buffer.from(body, 'utf8');\n    } else {\n      binaryBody = Buffer.from(JSON.stringify(body), 'utf8');\n    }\n\n    const canonicalTime = date.toISOString().replace(ISO_TIME_STRIP, ''); // YYYYMMDD'T'HHmmSS'Z'\n    const canonicalDate = canonicalTime.substr(0, 8); // YYYYMMDD\n    const credentialScope = `${canonicalDate}/${region}/${service}/aws4_request`;\n    const key = this.getKey(canonicalDate, region, service);\n\n    // AWS requires double-uri-encoding, and pathname uses non-standard encoding\n    const canonicalPath = encodeURI(encodeURI(decodeURI(parsedURL.pathname))) || '/';\n    const canonicalQueryString = '';\n\n    const allHeaders: Record<string, string> = {\n      ...headers,\n      Host: parsedURL.host,\n      'X-Amz-Date': canonicalTime,\n    };\n\n    // string comparison is intended\n    /* eslint-disable-next-line @typescript-eslint/require-array-sort-compare */\n    const headerNames = Object.keys(allHeaders)\n      .map((header) => header.toLowerCase())\n      .sort();\n\n    const canonicalHeaders = headerNames\n      .map((header) => `${header}:${allHeaders[header]}\\n`)\n      .join('');\n    const signedHeaders = headerNames.join(';');\n\n    const canonicalRequest = [\n      method,\n      canonicalPath,\n      canonicalQueryString,\n      canonicalHeaders,\n      signedHeaders,\n      sha256(binaryBody),\n    ].join('\\n');\n\n    const stringToSign = [\n      ALGORITHM,\n      canonicalTime,\n      credentialScope,\n      sha256(Buffer.from(canonicalRequest, 'utf8')),\n    ].join('\\n');\n\n    const signature = hmac(key, stringToSign).toString('hex');\n\n    allHeaders.Authorization = [\n      `${ALGORITHM} Credential=${this.keyID}/${credentialScope}`,\n      `SignedHeaders=${signedHeaders}`,\n      `Signature=${signature}`,\n    ].join(', ');\n\n    delete allHeaders.Host; // will be auto-added by node\n\n    return this.fetch(parsedURL, binaryBody, {\n      method,\n      headers: allHeaders,\n    });\n  }\n\n  async close(): Promise<void> {\n    if (this.closed) {\n      return;\n    }\n    await this.inflight.wait();\n    this.closed = true;\n  }\n\n  private fetch(\n    url: URL,\n    body: Buffer,\n    options: http.RequestOptions,\n  ): Promise<FetchResponse> {\n    if (this.closed) {\n      throw new Error('connection closed');\n    }\n\n    const protocol = (url.protocol === 'https') ? https : http;\n    return this.inflight.do(() => withTransientErrorRetry(() => new Promise((resolve, reject) => {\n      const req = protocol.request(url, options, (res) => {\n        const parts: Buffer[] = [];\n        res.on('data', (chunk) => parts.push(chunk));\n        res.on('end', () => {\n          try {\n            const text = Buffer.concat(parts).toString('utf8');\n            parts.length = 0;\n            const json = JSON.parse(text) as AWSErrorResponse;\n            if (!res.statusCode || res.statusCode >= 300) {\n              /* eslint-disable-next-line no-underscore-dangle */ // part of API\n              reject(new AWSError(res.statusCode || 0, json.__type, json.message));\n            } else {\n              resolve({ status: res.statusCode, json });\n            }\n          } catch (e) {\n            reject(e);\n          }\n        });\n      });\n      req.on('error', reject);\n      req.write(body);\n      req.end();\n    })));\n  }\n\n  private getKey(\n    canonicalDate: string,\n    region: string,\n    service: string,\n  ): Buffer {\n    return this.keyCache.cached(`${canonicalDate}/${region}/${service}`, () => {\n      const kRegion = this.keyCacheRegion.cached(`${canonicalDate}/${region}`, () => hmac(\n        this.keyCacheDate.cached(canonicalDate, () => hmac(this.baseKey, canonicalDate)),\n        region,\n      ));\n      return hmac(hmac(kRegion, service), 'aws4_request');\n    });\n  }\n}\n","import DynamoCollection, { Throughput } from './DynamoCollection';\nimport AWS from './api/AWS';\nimport { DDB, escapeName } from './api/DDB';\nimport type { DBKeys } from '../interfaces/DB';\nimport BaseDB from '../interfaces/BaseDB';\nimport type { IDable } from '../interfaces/IDable';\n\nexport type DbThroughputFn = (\n  tableName: string,\n  indexName: string | null,\n) => Throughput | null | undefined;\n\nconst makeThroughputFn = (params: URLSearchParams) => (\n  tableName: string,\n  indexName: string | null,\n): Throughput | null => {\n  let throughput: string | null = null;\n  if (indexName) {\n    throughput = (\n      params.get(`provision_${tableName}_index_${indexName}`) ||\n      params.get(`provision_${tableName}_index`) ||\n      params.get(`provision_${tableName}`) ||\n      params.get('provision')\n    );\n  } else {\n    throughput = (\n      params.get(`provision_${tableName}`) ||\n      params.get('provision')\n    );\n  }\n  if (!throughput || throughput === '-') {\n    return null;\n  }\n  const parts = throughput.split('.');\n  if (parts.length !== 2) {\n    throw new Error(`unexpected provisioning format for ${tableName} ${indexName || ''}: ${throughput} (expected 'read.write' or '-')`);\n  }\n  return {\n    read: Number.parseInt(parts[0], 10),\n    write: Number.parseInt(parts[1], 10),\n  };\n};\n\nexport default class DynamoDb extends BaseDB {\n  private constructor(\n    private readonly aws: AWS,\n    private readonly ddb: DDB,\n    tableNamePrefix: string,\n    throughputFn?: DbThroughputFn,\n  ) {\n    super((name, keys) => new DynamoCollection(\n      this.ddb,\n      tableNamePrefix + escapeName(name),\n      keys,\n      throughputFn?.bind(null, name),\n    ));\n  }\n\n  public static connect(url: string, throughputFn?: DbThroughputFn): DynamoDb {\n    const parsed = new URL(url);\n    let key;\n    let secret;\n    if (parsed.username) {\n      key = parsed.username;\n      secret = parsed.password;\n    } else {\n      key = process.env.AWS_ACCESS_KEY_ID;\n      secret = process.env.AWS_SECRET_ACCESS_KEY;\n    }\n    if (!key || !secret) {\n      throw new Error('No AWS key / secret specified');\n    }\n    const protocol = (parsed.searchParams.get('tls') === 'false') ? 'http' : 'https';\n    const consistentRead = (parsed.searchParams.get('consistentRead') === 'true');\n    const tableNamePrefix = parsed.pathname.substr(1);\n\n    const aws = new AWS(key, secret);\n    const ddb = new DDB(aws, `${protocol}://${parsed.host}`, { consistentRead });\n    return new DynamoDb(\n      aws,\n      ddb,\n      tableNamePrefix,\n      throughputFn || makeThroughputFn(parsed.searchParams),\n    );\n  }\n\n  public getCollection<T extends IDable>(name: string, keys?: DBKeys<T>): DynamoCollection<T> {\n    return super.getCollection(name, keys) as DynamoCollection<T>;\n  }\n\n  public getDDB(): DDB {\n    return this.ddb;\n  }\n\n  protected internalClose(): Promise<void> {\n    return this.aws.close();\n  }\n}\n","import type {\n  Redis,\n  Pipeline,\n  MultiOptions,\n  Ok,\n} from 'ioredis';\n\n// Thanks, https://stackoverflow.com/a/50014868/1180785\ntype ArgumentTypes<T> = T extends (...args: infer U) => any ? U : never;\n\ntype PipelineVersions<I> = {\n  [K in keyof I]: (...args: ArgumentTypes<I[K]>) => Pipeline & PipelineVersions<I>;\n};\n\ninterface RedisWithExtendedPipeline<I> extends Redis {\n  multi(commands?: string[][], options?: MultiOptions): Pipeline & PipelineVersions<I>;\n  multi(options: { pipeline: false }): Promise<Ok>;\n}\n\nexport type ExtendedRedis<I> = I & RedisWithExtendedPipeline<I>;\n\nexport async function multiExec(\n  client: Redis,\n  commands: string[][],\n): Promise<[unknown, any][] | null> {\n  if (!commands.length) {\n    return [];\n  }\n  return client.multi(commands).exec();\n}\n\nexport function minifyLuaScript(\n  lines: string[],\n  ...argNames: string[]\n): string {\n  let combined = lines.map((ln) => ln.trim()).join(' ');\n  argNames.forEach((name, i) => {\n    combined = combined.replace(new RegExp(`\\\\$${name}\\\\b`, 'g'), `ARGV[${i + 1}]`);\n  });\n  return combined;\n}\n","import type { IDable } from '../interfaces/IDable';\nimport BaseCollection from '../interfaces/BaseCollection';\nimport type { UpdateOptions } from '../interfaces/Collection';\nimport type { DBKeys } from '../interfaces/DB';\nimport {\n  serialiseValue,\n  serialiseRecord,\n  deserialiseRecord,\n} from '../helpers/serialiser';\nimport type RedisConnectionPool from './RedisConnectionPool';\nimport { multiExec } from './helpers';\nimport type { ERedis } from './scripts';\n\ninterface Key<T> {\n  key: keyof T & string;\n  prefix: string;\n}\n\ninterface InternalPatch {\n  sId: string;\n  oldSerialised: Record<string, string | null>;\n  newSerialised: Record<string, string>;\n}\n\nconst notUndefined = <T>(item?: T): item is T => (item !== undefined);\n\nfunction makeIndexKeys(\n  keys: Key<any>[],\n  partialSerialisedValue: Record<string, string | null>,\n): string[] {\n  return keys\n    .filter(({ key }) => partialSerialisedValue[key])\n    .map(({ key, prefix }) => `${prefix}:${partialSerialisedValue[key]}`);\n}\n\nfunction parseItem(\n  item: (string | null)[] | Record<string, string | null>,\n  fields?: readonly string[],\n): Record<string, string | null> {\n  if (!fields) {\n    return item as any;\n  }\n  const result: Record<string, string | null> = {};\n  for (let f = 0; f < fields.length; f += 1) {\n    result[fields[f]] = (item as any)[f];\n  }\n  return result;\n}\n\nfunction itemHasContent(item: Record<string, string | null>): boolean {\n  return Object.values(item).some((v) => (v !== null));\n}\n\nasync function unwatchAll(client: ERedis): Promise<void> {\n  await client.unwatch();\n}\n\nasync function mapAwaitSync<T, O>(\n  values: T[],\n  fn: (value: T) => Promise<O>,\n): Promise<O[]> {\n  const result: O[] = [];\n  for (let i = 0; i < values.length; i += 1) {\n    // eslint-disable-next-line no-await-in-loop\n    result.push(await fn(values[i]));\n  }\n  return result;\n}\n\nexport default class RedisCollection<T extends IDable> extends BaseCollection<T> {\n  private readonly keyPrefixes: { [K in keyof T]?: string } = {};\n\n  private readonly uniqueKeys: Key<T>[] = [];\n\n  private readonly nonUniqueKeys: Key<T>[] = [];\n\n  public constructor(\n    private readonly pool: RedisConnectionPool,\n    private readonly prefix: string,\n    keys: DBKeys<T> = {},\n  ) {\n    super(keys);\n\n    this.indices.getCustomIndices().forEach((k) => {\n      const key = k as keyof DBKeys<T>;\n      const keyPrefix = `${prefix}-${key}`;\n      this.keyPrefixes[key] = keyPrefix;\n      const keyInfo = { key, prefix: keyPrefix };\n      if (this.indices.isUniqueIndex(key)) {\n        this.uniqueKeys.push(keyInfo);\n      } else {\n        this.nonUniqueKeys.push(keyInfo);\n      }\n    });\n  }\n\n  protected internalAdd(value: T): Promise<void> {\n    const serialised = serialiseRecord(value);\n    return this.pool.withConnection(async (client) => {\n      const added = await this.runAdd(client, serialised, false);\n      if (!added) {\n        throw new Error('duplicate');\n      }\n    });\n  }\n\n  protected internalUpdate<K extends keyof T & string>(\n    searchAttribute: K,\n    searchValue: T[K],\n    update: Partial<T>,\n    { upsert }: UpdateOptions,\n  ): Promise<void> {\n    const patchSerialised = serialiseRecord(update);\n    const sKey = serialiseValue(searchValue);\n\n    if (searchAttribute === 'id') {\n      return this.pool.retryWithConnection(async (client) => {\n        const patch = await this.getUpdatePatch(client, sKey, patchSerialised);\n        if (patch) {\n          await this.runUpdates(client, [patch]);\n        } else if (upsert) {\n          const insertValue = { ...patchSerialised, id: sKey };\n          if (!await this.runAdd(client, insertValue, true)) {\n            throw new Error('duplicate');\n          }\n        }\n      }, unwatchAll);\n    }\n\n    return this.pool.retryWithConnection(async (client) => {\n      const sIds = await this.getAndWatchBySerialisedKey(client, searchAttribute, sKey);\n      const patches = (await mapAwaitSync(\n        sIds,\n        (sId) => this.getUpdatePatch(client, sId, patchSerialised),\n      )).filter(notUndefined);\n      await this.runUpdates(client, patches);\n    }, unwatchAll);\n  }\n\n  protected internalGet<\n    K extends keyof T & string,\n    F extends readonly (keyof T & string)[]\n  >(\n    searchAttribute: K,\n    searchValue: T[K],\n    returnAttributes?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>> | null> {\n    const sKey = serialiseValue(searchValue);\n    return this.pool.retryWithConnection(async (client) => {\n      const sId = (await this.getAndWatchBySerialisedKey(client, searchAttribute, sKey))[0];\n      if (sId === undefined) {\n        return null;\n      }\n      const results = await this.getByKeysKeepWatches(client, [sId], returnAttributes);\n      return results[0] ?? null;\n    }, unwatchAll);\n  }\n\n  protected internalGetAll<\n    K extends keyof T & string,\n    F extends readonly (keyof T & string)[]\n  >(\n    searchAttribute?: K,\n    searchValue?: T[K],\n    returnAttributes?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>>[]> {\n    return this.pool.retryWithConnection(async (client) => {\n      let sIds: string[];\n      if (searchAttribute) {\n        const sKey = serialiseValue(searchValue);\n        sIds = await this.getAndWatchBySerialisedKey(client, searchAttribute, sKey);\n      } else {\n        sIds = await client.keys(this.makeKey('*'));\n        const cut = this.prefix.length + 1;\n        sIds = sIds.map((v) => v.substr(cut));\n      }\n      return this.getByKeysKeepWatches(client, sIds, returnAttributes);\n    }, unwatchAll);\n  }\n\n  protected internalRemove<K extends keyof T & string>(\n    searchAttribute: K,\n    searchValue: T[K],\n  ): Promise<number> {\n    const sKey = serialiseValue(searchValue);\n    const indexedKeys = this.indices.getIndices();\n\n    return this.pool.retryWithConnection(async (client) => {\n      const sIds = await this.getAndWatchBySerialisedKey(client, searchAttribute, sKey);\n      const items = (await mapAwaitSync(\n        sIds,\n        (sId) => this.rawByKeyKeepWatches(client, sId, indexedKeys),\n      )).filter(notUndefined);\n\n      if (items.length === 0) {\n        return 0;\n      }\n\n      const pipeline = client.multi();\n      items.forEach((item) => {\n        const uniqueKeys = makeIndexKeys(this.uniqueKeys, item);\n        const nonUniqueKeys = makeIndexKeys(this.nonUniqueKeys, item);\n        pipeline.remove(\n          1 + uniqueKeys.length + nonUniqueKeys.length,\n          this.makeKey(item.id!),\n          ...uniqueKeys,\n          ...nonUniqueKeys,\n          item.id!,\n        );\n      });\n      await pipeline.exec();\n      return items.length;\n    }, unwatchAll);\n  }\n\n  private makeKey(serialisedId: string): string {\n    return `${this.prefix}:${serialisedId}`;\n  }\n\n  private async runAdd(\n    client: ERedis,\n    { id, ...serialised }: Record<string, string>,\n    checkWatch: boolean,\n  ): Promise<boolean> {\n    const uniqueKeys = makeIndexKeys(this.uniqueKeys, serialised);\n    const nonUniqueKeys = makeIndexKeys(this.nonUniqueKeys, serialised);\n\n    const keyCount = 1 + uniqueKeys.length + nonUniqueKeys.length;\n    const params = [\n      this.makeKey(id),\n      ...uniqueKeys,\n      ...nonUniqueKeys,\n      uniqueKeys.length,\n      'id', // ID is always first in flattened key/value pairs\n      id,\n      ...Object.entries(serialised).flat(),\n    ];\n\n    if (!checkWatch) {\n      return Boolean(await client.add(keyCount, ...params));\n    }\n\n    const result = await client\n      .multi()\n      .add(keyCount, ...params)\n      .exec();\n    if (!result) {\n      throw new Error('transient error');\n    }\n    return Boolean(result[0][1]);\n  }\n\n  private async getUpdatePatch(\n    client: ERedis,\n    sId: string,\n    patchSerialised: Record<string, string>,\n  ): Promise<InternalPatch | undefined> {\n    await client.watch(this.makeKey(sId));\n    const oldSerialised = await this.rawByKeyKeepWatches(\n      client,\n      sId,\n      this.indices.getCustomIndices().filter((k) => patchSerialised[k]),\n    );\n    if (!oldSerialised) {\n      return undefined;\n    }\n    const newSerialised = { ...patchSerialised };\n    Object.keys(newSerialised).forEach((k) => {\n      if (oldSerialised[k] === newSerialised[k]) {\n        delete newSerialised[k];\n        delete oldSerialised[k];\n      }\n    });\n    return { sId, newSerialised, oldSerialised };\n  }\n\n  private async runUpdates(\n    client: ERedis,\n    patches: InternalPatch[],\n  ): Promise<void> {\n    const argsList = patches\n      .map((patch) => this.makeUpdateArgs(patch))\n      .filter(notUndefined);\n\n    if (!argsList.length) {\n      return;\n    }\n\n    if (argsList.length === 1) {\n      const results = await client.multi()\n        .update(argsList[0][0], argsList[0][1])\n        .exec();\n\n      if (!results) {\n        throw new Error('transient error');\n      }\n      if (!results[0][1]) {\n        throw new Error('duplicate');\n      }\n      return;\n    }\n\n    const updateCheckResults = await mapAwaitSync(\n      argsList,\n      (updateArgs) => client.checkUpdate(updateArgs[0], updateArgs[1]),\n    );\n    if (updateCheckResults.some((r) => !r)) {\n      throw new Error('duplicate');\n    }\n\n    let chain = client.multi();\n    argsList.forEach((updateArgs) => {\n      chain = chain.updateWithoutCheck(updateArgs[0], updateArgs[1]);\n    });\n    const results = await chain.exec();\n\n    if (!results) {\n      throw new Error('transient error');\n    }\n  }\n\n  private makeUpdateArgs(\n    { sId, oldSerialised, newSerialised }: InternalPatch,\n  ): [number, any[]] | undefined {\n    const diff = Object.entries(newSerialised).flat();\n    if (!diff.length) {\n      return undefined; // nothing changed\n    }\n    const patchUniqueKeys = makeIndexKeys(this.uniqueKeys, newSerialised);\n    const patchNonUniqueKeys = makeIndexKeys(this.nonUniqueKeys, newSerialised);\n    const oldUniqueKeys = makeIndexKeys(this.uniqueKeys, oldSerialised);\n    const oldNonUniqueKeys = makeIndexKeys(this.nonUniqueKeys, oldSerialised);\n    if (\n      oldUniqueKeys.length !== patchUniqueKeys.length ||\n      oldNonUniqueKeys.length !== patchNonUniqueKeys.length\n    ) {\n      throw new Error('unexpected key mismatch with old value');\n    }\n    const keyCount = 1 + (patchUniqueKeys.length + patchNonUniqueKeys.length) * 2;\n    const params = [\n      this.makeKey(sId),\n      ...patchUniqueKeys,\n      ...patchNonUniqueKeys,\n      ...oldUniqueKeys,\n      ...oldNonUniqueKeys,\n      patchUniqueKeys.length,\n      patchUniqueKeys.length + patchNonUniqueKeys.length,\n      sId,\n      ...diff,\n    ];\n    return [keyCount, params];\n  }\n\n  private async getByKeysKeepWatches<F extends readonly (keyof T & string)[]>(\n    client: ERedis,\n    serialisedIds: string[],\n    fields?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>>[]> {\n    const results = await multiExec(\n      client,\n      serialisedIds\n        .map((sId) => this.makeKey(sId))\n        .map((k) => (fields ? ['hmget', k, ...fields] : ['hgetall', k])),\n    );\n    if (!results) {\n      throw new Error('transient error');\n    }\n    return results\n      .map(([, item]: [unknown, any]) => parseItem(item, fields))\n      .filter(itemHasContent)\n      .map(deserialiseRecord) as T[];\n  }\n\n  private async rawByKeyKeepWatches(\n    client: ERedis,\n    serialisedId: string,\n    fields?: readonly string[],\n  ): Promise<Record<string, string | null> | undefined> {\n    const key = this.makeKey(serialisedId);\n    let item;\n    if (fields) {\n      if (!fields.length) {\n        // just check existence\n        const exists = await client.exists(key);\n        return exists ? {} : undefined;\n      }\n      item = await client.hmget(key, ...fields);\n    } else {\n      item = await client.hgetall(key);\n    }\n    const parsed = parseItem(item, fields);\n    return itemHasContent(parsed) ? parsed : undefined;\n  }\n\n  private async getAndWatchBySerialisedKey(\n    client: ERedis,\n    keyName: keyof T,\n    serialisedValue: string,\n  ): Promise<string[]> {\n    if (keyName === 'id') {\n      return [serialisedValue];\n    }\n    const keyPrefix = this.keyPrefixes[keyName];\n    if (!keyPrefix) {\n      throw new Error(`Requested key ${keyName} not indexed`);\n    }\n    const keyAddress = `${keyPrefix}:${serialisedValue}`;\n    await client.watch(keyAddress);\n    return client.smembers(keyAddress);\n  }\n}\n","import type { Redis as RedisT } from 'ioredis';\nimport { minifyLuaScript, ExtendedRedis } from './helpers';\n\nexport interface ScriptExtensions {\n  add(keyCount: number, ...keysAndArgs: any[]): Promise<number>;\n  update(keyCount: number, ...keysAndArgs: any[]): Promise<number>;\n  checkUpdate(keyCount: number, ...keysAndArgs: any[]): Promise<number>;\n  updateWithoutCheck(keyCount: number, ...keysAndArgs: any[]): Promise<void>;\n  remove(keyCount: number, ...keysAndArgs: any[]): Promise<void>;\n}\n\nexport type ERedis = ExtendedRedis<ScriptExtensions>;\n\n// KEYS = [id, ...uniqueKeys, ...nonUniqueKeys]\nconst SCRIPT_ADD = minifyLuaScript([\n  'if redis.call(\"exists\",KEYS[1])==1 then',\n  '  return 0',\n  'end',\n  'for k=2,1+tonumber($uniqueKeyCount) do',\n  '  if redis.call(\"exists\",KEYS[k])==1 then',\n  '    return 0',\n  '  end',\n  'end',\n  'redis.call(\"hset\",KEYS[1],unpack(ARGV, 2))',\n  'for k=2,#KEYS do',\n  '  redis.call(\"sadd\",KEYS[k],ARGV[3])',\n  'end',\n  'return 1',\n], 'uniqueKeyCount');\n\nconst FRAG_CHECK_UPDATE = [\n  'for k=2,1+tonumber($uniqueKeyCount) do',\n  '  if redis.call(\"exists\",KEYS[k])==1 then',\n  '    return 0',\n  '  end',\n  'end',\n];\n\nconst FRAG_UPDATE = [\n  'local tkc=tonumber($totalKeyCount)',\n  'redis.call(\"hset\",KEYS[1],unpack(ARGV, 4))',\n  'for k=1,tkc do',\n  '  redis.call(\"smove\",KEYS[1+tkc+k],KEYS[1+k],$id)',\n  'end',\n];\n\n// KEYS = [id, ...patchUniqueKeys, ...patchNonUniqueKeys, ...oldUniqueKeys, ...oldNonUniqueKeys]\nconst SCRIPT_CHECK_UPDATE = minifyLuaScript([\n  ...FRAG_CHECK_UPDATE,\n  'return 1',\n], 'uniqueKeyCount', 'totalKeyCount', 'id');\n\n// KEYS = [id, ...patchUniqueKeys, ...patchNonUniqueKeys, ...oldUniqueKeys, ...oldNonUniqueKeys]\nconst SCRIPT_UPDATE_WITHOUT_CHECK = minifyLuaScript([\n  ...FRAG_UPDATE,\n], 'uniqueKeyCount', 'totalKeyCount', 'id');\n\n// KEYS = [id, ...patchUniqueKeys, ...patchNonUniqueKeys, ...oldUniqueKeys, ...oldNonUniqueKeys]\nconst SCRIPT_UPDATE = minifyLuaScript([\n  ...FRAG_CHECK_UPDATE,\n  ...FRAG_UPDATE,\n  'return 1',\n], 'uniqueKeyCount', 'totalKeyCount', 'id');\n\n// KEYS = [id, ...keys]\nconst SCRIPT_REMOVE = minifyLuaScript([\n  'redis.call(\"del\",KEYS[1])',\n  'for k=2,#KEYS do',\n  '  redis.call(\"srem\",KEYS[k],$id)',\n  'end',\n], 'id');\n\nexport default function defineAllScripts(client: RedisT): ERedis {\n  client.defineCommand('add', { lua: SCRIPT_ADD });\n  client.defineCommand('update', { lua: SCRIPT_UPDATE });\n  client.defineCommand('checkUpdate', { lua: SCRIPT_CHECK_UPDATE });\n  client.defineCommand('updateWithoutCheck', { lua: SCRIPT_UPDATE_WITHOUT_CHECK });\n  client.defineCommand('remove', { lua: SCRIPT_REMOVE });\n\n  return client as ERedis;\n}\n","import type { Redis as RedisT, RedisOptions as RedisOptionsT } from 'ioredis';\nimport defineAllScripts, { ERedis } from './scripts';\nimport retry from '../helpers/retry';\n\ntype RS = new(host?: string, options?: RedisOptionsT) => RedisT;\n\nconst withRetry = retry((e) => (\n  typeof e === 'object' &&\n  e.message === 'transient error'\n));\n\nexport default class RedisConnectionPool {\n  private readonly connections: ERedis[] = [];\n\n  private inUse = 0;\n\n  private queue: ((client: ERedis) => void)[] = [];\n\n  private closingFn?: () => void;\n\n  private closed = false;\n\n  public constructor(\n    private readonly RedisStatic: RS,\n    private readonly url: string,\n    private readonly options: RedisOptionsT,\n    private readonly maxConnections: number,\n  ) {}\n\n  public async withConnection<T>(\n    fn: (c: ERedis) => Promise<T> | T,\n    teardown?: (c: ERedis) => Promise<void> | void,\n  ): Promise<T> {\n    const c = await this.getConnection();\n    try {\n      return await fn(c);\n    } finally {\n      await teardown?.(c);\n      this.returnConnection(c);\n    }\n  }\n\n  public async retryWithConnection<T>(\n    fn: (c: ERedis) => Promise<T> | T,\n    teardown?: (c: ERedis) => Promise<void> | void,\n  ): Promise<T> {\n    return withRetry(() => this.withConnection(fn, teardown));\n  }\n\n  public close(): Promise<void> {\n    if (this.closed) {\n      return Promise.resolve();\n    }\n\n    this.closed = true;\n    if (this.inUse === 0) {\n      this.doClose();\n      return Promise.resolve();\n    }\n\n    return new Promise((resolve): void => {\n      this.closingFn = (): void => {\n        this.doClose();\n        resolve();\n      };\n    });\n  }\n\n  private doClose(): void {\n    this.connections.forEach((c) => c.disconnect());\n    this.connections.length = 0;\n  }\n\n  private async getConnection(): Promise<ERedis> {\n    if (this.closed) {\n      throw new Error('Connection closed');\n    }\n\n    const r = this.connections.pop();\n    if (r) {\n      this.inUse += 1;\n      return r;\n    }\n    if (this.inUse < this.maxConnections) {\n      this.inUse += 1;\n      const client = new this.RedisStatic(this.url, this.options);\n      await client.connect();\n      return defineAllScripts(client);\n    }\n    return new Promise((resolve): void => {\n      this.queue.push(resolve);\n    });\n  }\n\n  private returnConnection(c: ERedis): void {\n    const q = this.queue.shift();\n    if (q) {\n      q(c);\n    } else {\n      this.inUse -= 1;\n      this.connections.push(c);\n      if (this.inUse === 0) {\n        this.closingFn?.();\n      }\n    }\n  }\n}\n","import RedisCollection from './RedisCollection';\nimport type { DBKeys } from '../interfaces/DB';\nimport BaseDB from '../interfaces/BaseDB';\nimport type { IDable } from '../interfaces/IDable';\nimport RedisConnectionPool from './RedisConnectionPool';\n\nexport default class RedisDb extends BaseDB {\n  private constructor(\n    private readonly pool: RedisConnectionPool,\n  ) {\n    super((name, keys) => new RedisCollection(this.pool, name, keys));\n  }\n\n  public static async connect(url: string): Promise<RedisDb> {\n    const { default: RedisStatic } = await import('ioredis');\n    const connectionPoolSize = 5;\n    return new RedisDb(new RedisConnectionPool(\n      RedisStatic,\n      url,\n      { lazyConnect: true },\n      connectionPoolSize,\n    ));\n  }\n\n  public getCollection<T extends IDable>(name: string, keys?: DBKeys<T>): RedisCollection<T> {\n    return super.getCollection(name, keys) as RedisCollection<T>;\n  }\n\n  public getConnectionPool(): RedisConnectionPool {\n    return this.pool;\n  }\n\n  protected internalClose(): Promise<void> {\n    return this.pool.close();\n  }\n}\n","export function quoteHValue(v: string): string {\n  return `\"${v.replace(/([\"\\\\])/g, '\\\\$1')}\"`;\n}\n\nexport function encodeHStore(record: Record<string, string>): string {\n  const result: string[] = [];\n  Object.keys(record).forEach((k) => {\n    result.push(`${quoteHValue(k)}=>${quoteHValue(record[k])}`);\n  });\n  return result.join(',');\n}\n\nexport function decodeHStore(hstore: string): Record<string, string> {\n  const result: Record<string, string> = {};\n  let current = '';\n  let currentKey = '';\n  let quote = false;\n  for (let p = 0; p < hstore.length;) {\n    const c = hstore[p];\n    switch (c) {\n      case ' ':\n      case '\\r':\n      case '\\n':\n      case '\\t':\n        if (quote) {\n          current += c;\n        }\n        break;\n      case '\\\\':\n        current += hstore[p + 1];\n        p += 1;\n        break;\n      case '\"':\n        quote = !quote;\n        break;\n      case '=':\n        if (quote) {\n          current += c;\n        } else if (hstore[p + 1] === '>') {\n          currentKey = current;\n          current = '';\n          p += 1;\n        }\n        break;\n      case ',':\n        if (quote) {\n          current += c;\n        } else {\n          result[currentKey] = current;\n          currentKey = '';\n          current = '';\n        }\n        break;\n      default:\n        current += c;\n        break;\n    }\n    p += 1;\n  }\n  if (currentKey) {\n    result[currentKey] = current;\n  }\n  return result;\n}\n","const DQUOTE_REG = /\"/g;\nexport function quoteIdentifier(msg: string): string {\n  return `\"${msg.replace(DQUOTE_REG, '\"\"')}\"`;\n}\n\nconst SQUOTE_REG = /'/g;\nexport function quoteValue(msg: string): string {\n  // only used for creating indices,\n  // because prepared statements do not support CREATE\n  return `'${msg.replace(SQUOTE_REG, '\\'\\'')}'`;\n}\n\nconst ID_REG = /\\$[A-Z]/g;\nexport function withIdentifiers(\n  base: string,\n  identifiers: Record<string, string>,\n): string {\n  return base.replace(\n    ID_REG,\n    (v) => quoteIdentifier(identifiers[v.substr(1)]),\n  );\n}\n","import type { Pool as PgPoolT, QueryArrayResult as PgQueryArrayResultT } from 'pg';\nimport type { IDable } from '../interfaces/IDable';\nimport BaseCollection from '../interfaces/BaseCollection';\nimport type { DBKeys } from '../interfaces/DB';\nimport type { StateRef } from '../interfaces/BaseDB';\nimport { serialiseValue, deserialiseValue, serialiseRecord } from '../helpers/serialiser';\nimport { encodeHStore, decodeHStore } from './hstore';\nimport { withIdentifiers, quoteValue } from './sql';\n\nconst STATEMENTS = {\n  CREATE_TABLE: [\n    'CREATE TABLE IF NOT EXISTS $T (',\n    'id TEXT NOT NULL PRIMARY KEY,',\n    'data HSTORE NOT NULL',\n    ')',\n  ].join(''),\n\n  GET_INDEX_NAMES: 'SELECT indexname FROM pg_indexes WHERE tablename=$1 AND schemaname=current_schema()',\n\n  CREATE_INDEX: 'CREATE INDEX IF NOT EXISTS $I ON $T USING HASH ((data->$1))',\n  CREATE_UNIQUE_INDEX: 'CREATE UNIQUE INDEX IF NOT EXISTS $I ON $T ((data->$1))',\n  DROP_INDEX: 'DROP INDEX IF EXISTS $I',\n\n  INSERT: 'INSERT INTO $T (id, data) VALUES ($1, $2::hstore)',\n\n  UPDATE: 'UPDATE $T SET data=data||$1::hstore WHERE data->$2=$3 RETURNING id',\n  UPDATE_ID: 'UPDATE $T SET data=data||$1::hstore WHERE id=$2',\n\n  UPSERT_ID: 'INSERT INTO $T (id, data) VALUES ($1, $2::hstore) ON CONFLICT (id) DO UPDATE SET data=$T.data||$2::hstore',\n\n  SELECT_ONE: 'SELECT id, data FROM $T WHERE data->$1=$2 LIMIT 1',\n  SELECT_ALL: 'SELECT id, data FROM $T',\n  SELECT_ALL_BY: 'SELECT id, data FROM $T WHERE data->$1=$2',\n  SELECT_ID: 'SELECT id, data FROM $T WHERE id=$1',\n\n  DELETE: 'DELETE FROM $T WHERE data->$1=$2',\n  DELETE_ID: 'DELETE FROM $T WHERE id=$1',\n};\n\nasync function configureTable(\n  pool: PgPoolT,\n  tableName: string,\n  keys: DBKeys<any> = {},\n): Promise<void> {\n  const c = await pool.connect();\n  try {\n    /* eslint-disable no-await-in-loop */ // client cannot multitask\n\n    await c.query(withIdentifiers(STATEMENTS.CREATE_TABLE, {\n      T: tableName,\n    }));\n\n    const indices = await c.query({\n      rowMode: 'array',\n      text: STATEMENTS.GET_INDEX_NAMES,\n      values: [tableName],\n    });\n    const oldIndexNames = new Set(\n      indices.rows\n        .map((r) => r[0])\n        .filter((i) => (i.startsWith(`${tableName}_i`) || i.startsWith(`${tableName}_u`))),\n    );\n\n    // PostgreSQL does not support prepared statements for CREATE statements,\n    // so we must escape the values manually using quoteValue.\n    const keyEntries = Object.entries(keys);\n    for (let i = 0; i < keyEntries.length; i += 1) {\n      const [k, v] = keyEntries[i];\n      if (v && v.unique) {\n        const name = `${tableName}_u${k}`;\n        if (!oldIndexNames.delete(name)) {\n          await c.query(withIdentifiers(STATEMENTS.CREATE_UNIQUE_INDEX, {\n            T: tableName,\n            I: name,\n          }).replace(/\\$1/g, quoteValue(k)));\n        }\n      } else {\n        const name = `${tableName}_i${k}`;\n        if (!oldIndexNames.delete(name)) {\n          await c.query(withIdentifiers(STATEMENTS.CREATE_INDEX, {\n            T: tableName,\n            I: name,\n          }).replace(/\\$1/g, quoteValue(k)));\n        }\n      }\n    }\n    const indicesToDelete = [...oldIndexNames];\n    for (let i = 0; i < indicesToDelete.length; i += 1) {\n      const idx = indicesToDelete[i];\n      await c.query(withIdentifiers(STATEMENTS.DROP_INDEX, {\n        T: tableName,\n        I: idx,\n      }));\n    }\n\n    /* eslint-enable no-await-in-loop */\n  } finally {\n    c.release();\n  }\n}\n\nfunction toHStore(record: Record<string, unknown>): string {\n  return encodeHStore(serialiseRecord(record));\n}\n\nfunction fromHStore<T>(\n  [id, data]: readonly any[],\n  fields?: readonly string[],\n): T {\n  const rawMap = decodeHStore(data);\n  rawMap.id = id;\n\n  const result: Record<string, unknown> = {};\n\n  if (!fields) {\n    Object.entries(rawMap).forEach(([k, v]) => {\n      result[k] = deserialiseValue(v);\n    });\n    return result as T;\n  }\n\n  fields.forEach((f) => {\n    result[f] = deserialiseValue(rawMap[f]);\n  });\n  return result as T;\n}\n\nexport default class PostgresCollection<T extends IDable> extends BaseCollection<T> {\n  private readonly cachedQueries: Partial<Record<keyof typeof STATEMENTS, string>> = {};\n\n  public constructor(\n    private readonly pool: PgPoolT,\n    private readonly tableName: string,\n    keys: DBKeys<T> = {},\n    private readonly stateRef: StateRef = { closed: false },\n  ) {\n    super(keys);\n\n    this.initAsync(configureTable(pool, tableName, keys));\n  }\n\n  protected async internalAdd({ id, ...rest }: T): Promise<void> {\n    await this.runTableQuery('INSERT', serialiseValue(id), toHStore(rest));\n  }\n\n  protected async internalUpsert(\n    id: T['id'],\n    update: Partial<T>,\n  ): Promise<void> {\n    await this.runTableQuery('UPSERT_ID', serialiseValue(id), toHStore(update));\n  }\n\n  protected async internalUpdate<K extends keyof T & string>(\n    searchAttribute: K,\n    searchValue: T[K],\n    { id, ...rest }: Partial<T>,\n  ): Promise<void> {\n    const sId = serialiseValue(searchValue);\n    const hstore = toHStore(rest);\n\n    if (searchAttribute === 'id') {\n      await this.runTableQuery('UPDATE_ID', hstore, sId);\n    } else {\n      const r = await this.runTableQuery('UPDATE', hstore, searchAttribute, sId);\n      if (id !== undefined && r.rowCount > 0 && r.rows[0][0] !== id) {\n        throw new Error('Cannot update ID');\n      }\n    }\n  }\n\n  protected async internalGet<\n    K extends keyof T & string,\n    F extends readonly (keyof T & string)[]\n  >(\n    searchAttribute: K,\n    searchValue: T[K],\n    returnAttributes?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>> | null> {\n    let raw;\n    if (searchAttribute === 'id') {\n      raw = await this.runTableQuery('SELECT_ID', serialiseValue(searchValue));\n    } else {\n      raw = await this.runTableQuery('SELECT_ONE', searchAttribute, serialiseValue(searchValue));\n    }\n    if (!raw.rowCount) {\n      return null;\n    }\n    return fromHStore<T>(raw.rows[0], returnAttributes);\n  }\n\n  protected async internalGetAll<\n    K extends keyof T & string,\n    F extends readonly (keyof T & string)[]\n  >(\n    searchAttribute?: K,\n    searchValue?: T[K],\n    returnAttributes?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>>[]> {\n    let raw;\n    if (!searchAttribute) {\n      raw = await this.runTableQuery('SELECT_ALL');\n    } else if (searchAttribute === 'id') {\n      raw = await this.runTableQuery('SELECT_ID', serialiseValue(searchValue));\n    } else {\n      raw = await this.runTableQuery('SELECT_ALL_BY', searchAttribute, serialiseValue(searchValue));\n    }\n    return raw.rows.map((v) => fromHStore<T>(v, returnAttributes));\n  }\n\n  protected async internalRemove<K extends keyof T & string>(\n    searchAttribute: K,\n    searchValue: T[K],\n  ): Promise<number> {\n    let raw;\n    if (searchAttribute === 'id') {\n      raw = await this.runTableQuery('DELETE_ID', serialiseValue(searchValue));\n    } else {\n      raw = await this.runTableQuery('DELETE', searchAttribute, serialiseValue(searchValue));\n    }\n    return raw.rowCount;\n  }\n\n  private runTableQuery(\n    queryName: keyof typeof STATEMENTS,\n    ...values: any[]\n  ): Promise<PgQueryArrayResultT<any[]>> {\n    if (this.stateRef.closed) {\n      throw new Error('Connection closed');\n    }\n\n    let cached = this.cachedQueries[queryName];\n    if (!cached) {\n      cached = withIdentifiers(STATEMENTS[queryName], { T: this.tableName });\n      this.cachedQueries[queryName] = cached;\n    }\n\n    return this.pool.query({\n      name: `${this.tableName}_${queryName}`,\n      rowMode: 'array',\n      text: cached,\n      values,\n    });\n  }\n}\n","import type { Pool as PgPoolT } from 'pg';\nimport PostgresCollection from './PostgresCollection';\nimport type { DBKeys } from '../interfaces/DB';\nimport BaseDB from '../interfaces/BaseDB';\nimport type { IDable } from '../interfaces/IDable';\n\nexport default class PostgresDb extends BaseDB {\n  private constructor(\n    private readonly pool: PgPoolT,\n  ) {\n    super((name, keys) => new PostgresCollection(pool, name, keys, this.stateRef));\n  }\n\n  public static async connect(url: string): Promise<PostgresDb> {\n    const { Pool } = await import('pg');\n    const pool = new Pool({ connectionString: url });\n    await pool.query('CREATE EXTENSION IF NOT EXISTS hstore');\n    return new PostgresDb(pool);\n  }\n\n  public getCollection<T extends IDable>(name: string, keys?: DBKeys<T>): PostgresCollection<T> {\n    return super.getCollection(name, keys) as PostgresCollection<T>;\n  }\n\n  public getConnectionPool(): PgPoolT {\n    return this.pool;\n  }\n\n  protected internalClose(): Promise<void> {\n    return this.pool.end();\n  }\n}\n","import type { Collection, UpdateOptions, Indices } from '../interfaces/Collection';\nimport type { IDable } from '../interfaces/IDable';\n\nexport type Wrapped<T extends IDable, Fields extends keyof T, FieldStorage> = {\n  [K in keyof T]: K extends 'id' ? T[K] : K extends Fields ? FieldStorage : T[K];\n};\n\nexport interface Wrapper<T extends IDable, K extends keyof T, FieldStorage, CustomData> {\n  wrap: (\n    key: K,\n    value: T[K],\n    processed: CustomData,\n  ) => Promise<FieldStorage> | FieldStorage;\n\n  unwrap: (\n    key: K,\n    value: FieldStorage,\n    processed: CustomData,\n  ) => Promise<T[K]> | T[K];\n\n  preWrap?: (\n    record: Readonly<Partial<T>>,\n  ) => Promise<CustomData> | CustomData;\n\n  preUnwrap?: (\n    record: Readonly<Partial<Wrapped<T, K, FieldStorage>>>,\n  ) => Promise<CustomData> | CustomData;\n\n  preRemove?: (\n    record: Readonly<Pick<Wrapped<T, K, FieldStorage>, 'id'>>,\n  ) => Promise<void> | void;\n}\n\nfunction hasAnyField(\n  value: Record<string, unknown>,\n  fields: readonly string[],\n): boolean {\n  return fields\n    .some((field) => Object.prototype.hasOwnProperty.call(value, field));\n}\n\nexport default class WrappedCollection<\n  T extends IDable,\n  WF extends readonly (keyof Omit<T, 'id'> & string)[],\n  FieldStorage,\n  E,\n  Inner extends Wrapped<T, WF[-1], FieldStorage> = Wrapped<T, WF[-1], FieldStorage>\n> implements Collection<T> {\n  public constructor(\n    private readonly baseCollection: Collection<Inner>,\n    private readonly fields: WF,\n    private readonly wrapper: Wrapper<T, WF[-1], FieldStorage, E>,\n  ) {\n    fields.forEach((field) => {\n      if (baseCollection.indices.isUniqueIndex(field)) {\n        throw new Error(`Cannot wrap unique index ${field}`);\n      }\n    });\n  }\n\n  public async add(entry: T): Promise<void> {\n    return this.baseCollection.add(await this.wrapAll(entry));\n  }\n\n  public async get<\n    K extends keyof T & keyof Inner & string,\n    F extends readonly (keyof T & string)[]\n  >(\n    key: K,\n    value: T[K] & Inner[K],\n    fields?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>> | null> {\n    if (this.fields.includes(key as any)) {\n      throw new Error('Cannot get by wrapped value');\n    }\n    const raw = await this.baseCollection.get(key, value, fields!);\n    return raw ? this.unwrapAll(raw, { [key]: value }) : null;\n  }\n\n  public async getAll<\n    K extends keyof T & keyof Inner & string,\n    F extends readonly (keyof T & string)[]\n  >(\n    key?: K,\n    value?: T[K] & Inner[NonNullable<K>],\n    fields?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>>[]> {\n    if (key !== undefined && this.fields.includes(key as any)) {\n      throw new Error('Cannot get by wrapped value');\n    }\n    const raw = await this.baseCollection.getAll(key!, value!, fields!);\n    const extra = (key !== undefined) ? { [key]: value } : undefined;\n    return Promise.all(raw.map((v) => this.unwrapAll(v, extra)));\n  }\n\n  public async update<K extends keyof T & keyof Inner & string>(\n    key: K,\n    value: T[K] & Inner[K],\n    update: Partial<T>,\n    options?: UpdateOptions,\n  ): Promise<void> {\n    if (this.fields.includes(key as any)) {\n      throw new Error('Cannot update by wrapped value');\n    }\n    const converted = await this.wrapAll(update, { [key]: value });\n    return this.baseCollection.update(key, value, converted, options);\n  }\n\n  public async remove<K extends keyof T & string>(\n    key: K,\n    value: T[K] & Inner[K],\n  ): Promise<number> {\n    if (this.fields.includes(key as any)) {\n      throw new Error('Cannot remove by wrapped value');\n    }\n    if (!this.wrapper.preRemove) {\n      return this.baseCollection.remove(key, value);\n    }\n\n    const items = await this.baseCollection.getAll(key, value, ['id']);\n    await Promise.all(items.map(async (item) => {\n      await this.wrapper.preRemove!(item);\n      await this.baseCollection.remove('id', item.id);\n    }));\n    return items.length;\n  }\n\n  public get indices(): Indices {\n    return this.baseCollection.indices;\n  }\n\n  private async wrapAll(\n    v: Readonly<T>,\n    extra?: Record<string, unknown>,\n  ): Promise<Inner>;\n\n  private async wrapAll(\n    v: Readonly<Partial<T>>,\n    extra?: Record<string, unknown>,\n  ): Promise<Partial<Inner>>;\n\n  private async wrapAll(\n    v: Readonly<Partial<T>>,\n    extra?: Record<string, unknown>,\n  ): Promise<Partial<Inner>> {\n    let processed: E;\n    if (this.wrapper.preWrap && hasAnyField(v, this.fields)) {\n      const allFields = extra ? { ...extra, ...v } : v;\n      processed = await this.wrapper.preWrap(allFields);\n    }\n    const converted = { ...v } as any;\n    await Promise.all(this.fields.map(async (k) => {\n      if (Object.prototype.hasOwnProperty.call(v, k)) {\n        converted[k] = await this.wrapper.wrap(k, (v as any)[k], processed);\n      }\n    }));\n    return converted;\n  }\n\n  private async unwrapAll(\n    v: Readonly<Inner>,\n    extra?: Record<string, unknown>,\n  ): Promise<T>;\n\n  private async unwrapAll<K extends keyof T>(\n    v: Readonly<Pick<Inner, K>>,\n    extra?: Record<string, unknown>,\n  ): Promise<Pick<T, K>>;\n\n  private async unwrapAll<K extends keyof T>(\n    v: Readonly<Pick<Inner, K>>,\n    extra?: Record<string, unknown>,\n  ): Promise<Pick<T, K>> {\n    let processed: E;\n    if (this.wrapper.preUnwrap && hasAnyField(v, this.fields)) {\n      const allFields = extra ? { ...extra, ...v } : v;\n      processed = await this.wrapper.preUnwrap(allFields as any);\n    }\n    const converted = { ...v } as any;\n    await Promise.all(this.fields.map(async (k) => {\n      if (Object.prototype.hasOwnProperty.call(v, k)) {\n        converted[k] = await this.wrapper.unwrap(k, (v as any)[k], processed);\n      }\n    }));\n    return converted;\n  }\n}\n","import crypto, { KeyObject } from 'crypto';\nimport type Encryption from './Encryption';\n\nconst ALG = 'aes-256-cbc';\nconst ALG_BUF = Buffer.from(`${ALG}:`, 'utf8');\nconst IV_LEN = 16;\n\nconst nodeEncryptionSync: Encryption<KeyObject, Buffer> = {\n  encrypt: (key: KeyObject, v: Buffer): Buffer => {\n    const iv = crypto.randomBytes(IV_LEN);\n    const cipher = crypto.createCipheriv(ALG, key, iv);\n    const part = cipher.update(v);\n    const final = cipher.final();\n    return Buffer.concat([ALG_BUF, iv, part, final]);\n  },\n\n  decrypt: (key: KeyObject, v: Buffer): Buffer => {\n    if (!v.slice(0, ALG_BUF.length).equals(ALG_BUF)) {\n      throw new Error('Unknown encryption algorithm');\n    }\n\n    const iv = v.slice(ALG_BUF.length, ALG_BUF.length + IV_LEN);\n    const encrypted = v.slice(ALG_BUF.length + IV_LEN);\n\n    const decipher = crypto.createDecipheriv(ALG, key, iv);\n    const part = decipher.update(encrypted);\n    const final = decipher.final();\n\n    return Buffer.concat([part, final]);\n  },\n\n  generateKey: (): KeyObject => crypto\n    .createSecretKey(crypto.randomBytes(32)),\n\n  serialiseKey: (key: KeyObject): Buffer => key.export(),\n\n  deserialiseKey: (data: Buffer): KeyObject => crypto.createSecretKey(data),\n};\n\nexport default nodeEncryptionSync;\n","import type { IDable, IDableBy, IDType } from '../interfaces/IDable';\nimport type { Collection } from '../interfaces/Collection';\nimport LruCache from '../helpers/LruCache';\nimport { serialiseValueBin, deserialiseValueBin } from '../helpers/serialiser';\nimport WrappedCollection, { Wrapped } from './WrappedCollection';\nimport type Encryption from './encryption/Encryption';\nimport nodeEncryptionSync from './encryption/nodeEncryptionSync';\n\nexport interface KeyRecord<ID extends IDType, KeyT> {\n  id: ID;\n  key: KeyT;\n}\n\nexport type Encrypted<T extends IDable, WF extends keyof T> = Wrapped<T, WF, Buffer>;\n\ntype EncryptableKeys<T> = readonly (keyof Omit<T, 'id'> & string)[];\n\ntype Encrypter<ID extends IDType> = <T extends IDableBy<ID>>(\n) => <F extends EncryptableKeys<T>>(\n  fields: F,\n  baseCollection: Collection<Encrypted<T, F[-1]>>,\n) => Collection<T>;\n\n// makeEncrypter provides optional 2-tier function call due to\n// https://github.com/Microsoft/TypeScript/issues/26242\n\nfunction makeEncrypter<ID extends IDType>(\n  wrapper: <T extends IDableBy<ID>, F extends EncryptableKeys<T>>(\n    fields: F,\n    baseCollection: Collection<Encrypted<T, F[-1]>>,\n  ) => Collection<T>,\n): Encrypter<ID> {\n  return (fields?: any, baseCollection?: Collection<any>): any => {\n    if (fields && baseCollection) {\n      // non-typescript API (remove need for extra ())\n      return wrapper(fields, baseCollection) as any;\n    }\n    return wrapper;\n  };\n}\n\nexport interface EncryptionOptions<KeyT = Buffer, SerialisedKeyT = Buffer> {\n  allowRaw?: boolean;\n  encryption?: Encryption<KeyT, SerialisedKeyT>;\n}\n\nexport interface RecordEncryptionOptions {\n  cacheSize?: number;\n}\n\ninterface CustomEncryptionOptions<KeyT, SerialisedKeyT>\n  extends EncryptionOptions<KeyT, SerialisedKeyT> {\n  encryption: Encryption<KeyT, SerialisedKeyT>;\n}\n\nfunction encryptByKey(\n  sKey: Buffer,\n  options?: EncryptionOptions,\n): Encrypter<IDType>;\n\nfunction encryptByKey<KeyT, SerialisedKeyT>(\n  sKey: SerialisedKeyT,\n  options: CustomEncryptionOptions<KeyT, SerialisedKeyT>,\n): Encrypter<IDType>;\n\nfunction encryptByKey<KeyT, SerialisedKeyT>(\n  sKey: SerialisedKeyT,\n  {\n    encryption = nodeEncryptionSync as any,\n    allowRaw = false,\n  }: EncryptionOptions<KeyT, SerialisedKeyT> = {},\n): Encrypter<IDType> {\n  const key = encryption.deserialiseKey(sKey);\n\n  return makeEncrypter(<T extends IDable, F extends EncryptableKeys<T>>(\n    fields: F,\n    baseCollection: Collection<Encrypted<T, F[-1]>>,\n  ) => new WrappedCollection<T, F, Buffer, never>(baseCollection, fields, {\n    wrap: (k, v): Promise<Buffer> | Buffer => encryption.encrypt(key, serialiseValueBin(v)),\n    unwrap: async (k, v): Promise<any> => {\n      if (!(v instanceof Buffer)) {\n        if (allowRaw) {\n          return v; // probably an old record before encryption was added\n        }\n        throw new Error('unencrypted data');\n      }\n      return deserialiseValueBin(await encryption.decrypt(key, v));\n    },\n  }));\n}\n\nfunction encryptByRecord<ID extends IDType>(\n  keyCollection: Collection<KeyRecord<ID, Buffer>>,\n  options?: EncryptionOptions & RecordEncryptionOptions,\n): Encrypter<ID>;\n\nfunction encryptByRecord<ID extends IDType, KeyT, SerialisedKeyT>(\n  keyCollection: Collection<KeyRecord<ID, SerialisedKeyT>>,\n  options: CustomEncryptionOptions<KeyT, SerialisedKeyT> & RecordEncryptionOptions,\n): Encrypter<ID>;\n\nfunction encryptByRecord<ID extends IDType, KeyT, SerialisedKeyT>(\n  keyCollection: Collection<KeyRecord<ID, SerialisedKeyT>>,\n  {\n    encryption = nodeEncryptionSync as any,\n    allowRaw = false,\n    cacheSize = 0,\n  }: EncryptionOptions<KeyT, SerialisedKeyT> & RecordEncryptionOptions = {},\n): Encrypter<ID> {\n  const cache = new LruCache<ID, KeyT>(cacheSize);\n\n  const loadKey = async (\n    generateIfNeeded: boolean,\n    record: { id?: ID },\n  ): Promise<KeyT> => {\n    const { id } = record;\n\n    if (id === undefined) {\n      throw new Error('Must provide ID for encryption');\n    }\n\n    return cache.cachedAsync(id, async () => {\n      const item = await keyCollection.get('id', id, ['key']);\n      if (item) {\n        return encryption.deserialiseKey(item.key);\n      }\n      if (!generateIfNeeded) {\n        throw new Error('No encryption key found for record');\n      }\n      const key = await encryption.generateKey();\n      await keyCollection.add({ id, key: encryption.serialiseKey(key) });\n      return key;\n    });\n  };\n\n  const removeKey = async ({ id }: { id: ID }): Promise<void> => {\n    await keyCollection.remove('id', id);\n    cache.remove(id);\n  };\n\n  // https://github.com/microsoft/TypeScript/issues/39080\n  return makeEncrypter<ID>(<T extends IDableBy<ID>, F extends EncryptableKeys<T>>(\n    fields: F,\n    baseCollection: Collection<Encrypted<T, F[-1]>>,\n  ) => new WrappedCollection<T, F, Buffer, KeyT>(baseCollection, fields, {\n    wrap: (k, v, key): Promise<Buffer> | Buffer => encryption.encrypt(key, serialiseValueBin(v)),\n    unwrap: async (k, v, key): Promise<any> => {\n      if (!(v instanceof Buffer)) {\n        if (allowRaw) {\n          return v; // probably an old record before encryption was added\n        }\n        throw new Error('unencrypted data');\n      }\n      return deserialiseValueBin(await encryption.decrypt(key, v));\n    },\n    preWrap: loadKey.bind(null, true),\n    preUnwrap: loadKey.bind(null, false),\n    preRemove: removeKey,\n  }));\n}\n\nfunction encryptByRecordWithMasterKey<ID extends IDType>(\n  sMasterKey: Buffer,\n  keyCollection: Collection<KeyRecord<ID, Buffer>>,\n  options?: EncryptionOptions & RecordEncryptionOptions,\n): Encrypter<ID>;\n\nfunction encryptByRecordWithMasterKey<ID extends IDType, KeyT, SerialisedKeyT>(\n  sMasterKey: SerialisedKeyT,\n  keyCollection: Collection<KeyRecord<ID, Buffer>>,\n  options: CustomEncryptionOptions<KeyT, SerialisedKeyT> & RecordEncryptionOptions,\n): Encrypter<ID>;\n\nfunction encryptByRecordWithMasterKey<ID extends IDType, KeyT, SerialisedKeyT>(\n  sMasterKey: SerialisedKeyT,\n  keyCollection: Collection<KeyRecord<ID, Buffer>>,\n  options: EncryptionOptions<KeyT, SerialisedKeyT> & RecordEncryptionOptions = {},\n): Encrypter<ID> {\n  const opts = options as CustomEncryptionOptions<KeyT, SerialisedKeyT> & RecordEncryptionOptions;\n  const keyEnc = encryptByKey(sMasterKey, opts);\n  const encKeyCollection = keyEnc<KeyRecord<ID, SerialisedKeyT>>()(\n    ['key'],\n    keyCollection,\n  );\n  return encryptByRecord(encKeyCollection, opts);\n}\n\nexport {\n  encryptByKey,\n  encryptByRecord,\n  encryptByRecordWithMasterKey,\n};\n","import zlib from 'zlib';\nimport { promisify } from 'util';\nimport type { IDable } from '../interfaces/IDable';\nimport type { Collection } from '../interfaces/Collection';\nimport { serialiseValueBin, deserialiseValueBin } from '../helpers/serialiser';\nimport WrappedCollection, { Wrapped } from './WrappedCollection';\n\ntype CompressableKeys<T> = readonly (keyof Omit<T, 'id'> & string)[];\n\nexport type Compressed<T extends IDable, WF extends keyof T> = Wrapped<T, WF, Buffer>;\n\nexport interface CompressOptions {\n  allowRaw?: boolean;\n  allowRawBuffer?: boolean;\n  compressionThresholdBytes?: number;\n}\n\nconst gzipCompress = promisify<Buffer, Buffer>(zlib.gzip);\nconst gzipDecompress = promisify<Buffer, Buffer>(zlib.gunzip);\n\nconst MARK_UNCOMPRESSED = Buffer.of(0);\n\nasync function compressValue(v: unknown, {\n  compressionThresholdBytes = 200,\n}: CompressOptions): Promise<Buffer> {\n  const serialised = serialiseValueBin(v);\n  if (serialised.length >= compressionThresholdBytes) {\n    const gzipped = await gzipCompress(serialised);\n    if (gzipped.length < serialised.length + 1) {\n      return gzipped;\n    }\n  }\n  return Buffer.concat([MARK_UNCOMPRESSED, serialised]);\n}\n\nasync function decompressValue(v: Buffer, {\n  allowRaw = true,\n  allowRawBuffer = false,\n}: CompressOptions): Promise<any> {\n  if (!(v instanceof Buffer)) {\n    if (allowRaw) {\n      return v; // probably an old record before compression was added\n    }\n    throw new Error('unknown compression type');\n  }\n  if (v[0] === 0x1F && v[1] === 0x8B) { // gzip \"magic number\"\n    return deserialiseValueBin(await gzipDecompress(v));\n  }\n  if (v[0] === MARK_UNCOMPRESSED[0]) {\n    return deserialiseValueBin(v.subarray(1));\n  }\n  if (allowRaw && allowRawBuffer) {\n    return v;\n  }\n  throw new Error('unknown compression type');\n}\n\nexport function compress<T extends IDable, F extends CompressableKeys<T>>(\n  fields: F,\n  baseCollection: Collection<Compressed<T, F[-1]>>,\n  options: CompressOptions = {},\n): Collection<T> {\n  return new WrappedCollection<T, F, Buffer, never>(baseCollection, fields, {\n    wrap: (k, v): Promise<Buffer> => compressValue(v, options),\n    unwrap: (k, v): Promise<any> => decompressValue(v, options),\n  });\n}\n","import type { Collection, UpdateOptions, Indices } from '../interfaces/Collection';\nimport type { IDable } from '../interfaces/IDable';\n\ntype MigrationFuncs<T, ExtraFetchFields extends readonly (keyof T & string)[]> = {\n  [K in keyof T]?: (\n    stored: T[K] | undefined,\n    record: Readonly<Pick<T, K | ExtraFetchFields[-1]>>,\n  ) => T[K];\n};\n\nclass MigratedCollection<\n  T extends IDable,\n  ExtraFetchFields extends readonly (keyof T & string)[],\n> implements Collection<T> {\n  public constructor(\n    private readonly baseCollection: Collection<T>,\n    private readonly migrations: MigrationFuncs<T, ExtraFetchFields>,\n    private readonly extraFetchFields?: ExtraFetchFields,\n  ) {}\n\n  public async add(entry: T): Promise<void> {\n    return this.baseCollection.add(entry);\n  }\n\n  public async get<\n    K extends keyof T & string,\n    F extends readonly (keyof T & string)[]\n  >(\n    searchAttribute: K,\n    searchValue: T[K],\n    returnAttributes?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>> | null> {\n    const raw = await this.baseCollection.get(\n      searchAttribute,\n      searchValue,\n      this.extendAttributes(returnAttributes)!,\n    );\n    return raw ? this.applyMigration(raw, returnAttributes) : null;\n  }\n\n  public async getAll<\n    K extends keyof T & string,\n    F extends readonly (keyof T & string)[],\n  >(\n    searchAttribute?: K,\n    searchValue?: T[K],\n    returnAttributes?: F,\n  ): Promise<Readonly<Pick<T, F[-1]>>[]> {\n    const raws = await this.baseCollection.getAll(\n      searchAttribute!,\n      searchValue as any,\n      this.extendAttributes(returnAttributes)!,\n    );\n    return raws.map((raw) => this.applyMigration(raw, returnAttributes));\n  }\n\n  public async update<K extends keyof T & string>(\n    searchAttribute: K,\n    searchValue: T[K],\n    update: Partial<T>,\n    options?: UpdateOptions,\n  ): Promise<void> {\n    return this.baseCollection.update(searchAttribute, searchValue, update, options);\n  }\n\n  public async remove<K extends keyof T & string>(\n    searchAttribute: K,\n    searchValue: T[K],\n  ): Promise<number> {\n    return this.baseCollection.remove(searchAttribute, searchValue);\n  }\n\n  public get indices(): Indices {\n    return this.baseCollection.indices;\n  }\n\n  private extendAttributes<\n    F extends readonly (keyof T & string)[]\n  >(returnAttributes?: F): readonly (keyof T & string)[] | undefined {\n    if (returnAttributes && this.extraFetchFields) {\n      return [...returnAttributes, ...this.extraFetchFields];\n    }\n    return returnAttributes;\n  }\n\n  private applyMigration<F extends readonly (keyof T & string)[]>(\n    raw: Readonly<Pick<T, ExtraFetchFields[-1] | F[-1]>>,\n    returnAttributes?: F,\n  ): Readonly<Pick<T, F[-1]>> {\n    if (returnAttributes && !returnAttributes.some((attr) => this.migrations[attr])) {\n      return raw;\n    }\n    const result: Pick<T, F[-1]> = { ...raw };\n    const attrs = returnAttributes || Object.keys(this.migrations);\n    attrs.forEach((key: string) => {\n      const attr = key as keyof Pick<T, F[-1]>;\n      const migration = this.migrations[attr];\n      if (migration) {\n        result[attr] = migration(raw[attr], raw);\n      }\n    });\n    return result;\n  }\n}\n\nfunction migrate<T extends IDable>(\n  migrations: MigrationFuncs<T, []>,\n  baseCollection: Collection<T>,\n): Collection<T>;\n\nfunction migrate<\n  T extends IDable,\n  ExtraFetchFields extends readonly (keyof T & string)[],\n>(\n  extraFetchFields: ExtraFetchFields,\n  migrations: MigrationFuncs<T, ExtraFetchFields>,\n  baseCollection: Collection<T>,\n): Collection<T>;\n\nfunction migrate<\n  T extends IDable,\n  ExtraFetchFields extends readonly (keyof T & string)[],\n>(\n  extraFetchFields: MigrationFuncs<T, []> | ExtraFetchFields,\n  migrations: MigrationFuncs<T, ExtraFetchFields> | Collection<T>,\n  baseCollection?: Collection<T>,\n): Collection<T> {\n  if (baseCollection) {\n    return new MigratedCollection(\n      baseCollection,\n      migrations as MigrationFuncs<T, ExtraFetchFields>,\n      extraFetchFields as ExtraFetchFields,\n    );\n  }\n  return new MigratedCollection(\n    migrations as Collection<T>,\n    extraFetchFields as MigrationFuncs<T, []>,\n  );\n}\n\nexport default migrate;\n","import CollectionStorage from './CollectionStorage';\nimport WrappedCollection, { Wrapped } from './wrappers/WrappedCollection';\nimport type Encryption from './wrappers/encryption/Encryption';\nimport {\n  encryptByKey,\n  encryptByRecord,\n  encryptByRecordWithMasterKey,\n  EncryptionOptions,\n  Encrypted,\n} from './wrappers/encrypted';\nimport { compress, Compressed, CompressOptions } from './wrappers/compressed';\nimport migrate from './wrappers/migrated';\nimport type { DB } from './interfaces/DB';\nimport type { Collection } from './interfaces/Collection';\n\nexport type {\n  DB,\n  Collection,\n  Wrapped,\n  Encryption,\n  Encrypted,\n  EncryptionOptions,\n  Compressed,\n  CompressOptions,\n};\n\nexport { default as MemoryDb } from './memory/MemoryDb';\nexport { default as MongoDb } from './mongo/MongoDb';\nexport { default as RedisDb } from './redis/RedisDb';\nexport { default as LruCache } from './helpers/LruCache';\nexport {\n  WrappedCollection,\n  encryptByKey,\n  encryptByRecord,\n  encryptByRecordWithMasterKey,\n  compress,\n  migrate,\n};\nexport {\n  default as nodeEncryptionSync,\n} from './wrappers/encryption/nodeEncryptionSync';\nexport default CollectionStorage;\n","import MemoryDb from './memory/MemoryDb';\nimport MongoDb from './mongo/MongoDb';\nimport DynamoDb from './dynamodb/DynamoDb';\nimport RedisDb from './redis/RedisDb';\nimport PostgresDb from './postgresql/PostgresDb';\nimport type { DB } from './interfaces/DB';\n\nexport default class CollectionStorage {\n  public static async connect(url: string): Promise<DB> {\n    let dbClass;\n    if (url.startsWith('memory')) {\n      dbClass = MemoryDb;\n    } else if (url.startsWith('mongodb')) {\n      dbClass = MongoDb;\n    } else if (url.startsWith('dynamodb')) {\n      dbClass = DynamoDb;\n    } else if (url.startsWith('redis')) {\n      dbClass = RedisDb;\n    } else if (url.startsWith('postgres')) {\n      dbClass = PostgresDb;\n    } else {\n      throw new Error(`Unsupported database connection string: ${url}`);\n    }\n\n    try {\n      return await dbClass.connect(url);\n    } catch (e) {\n      throw new Error(`Failed to connect to database \"${url}\": ${e.message}`);\n    }\n  }\n}\n"],"sourceRoot":""}